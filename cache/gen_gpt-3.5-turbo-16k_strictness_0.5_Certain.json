{
    "Statistical_Learning_and_Inverse_Problems:_A_Stochastic_Gradient_Approach": {
        "link": "https://openreview.net//forum?id=09QFnDWPF8",
        "pub_url": "https://openreview.net/forum?id=09QFnDWPF8",
        "pdf_link": "https://openreview.net//pdf?id=09QFnDWPF8",
        "paper_id": "09QFnDWPF8",
        "title": "Statistical_Learning_and_Inverse_Problems:_A_Stochastic_Gradient_Approach",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nAll reviewers recommend accepting the paper. Congratulations!\nBut in your camera-ready version, please revise the paper to better emphasize the relevance of this line work to a general machine learning audience. For example, during the discussion one reviewer wrote the following:\n\"The authors have not thoroughly convinced me of the relevance to a ML audience, as I will explain. To me, the relevance is very likely, as they apply SGD to a regression problem, and then ML learners on top of that, which is very much in the vein of ML. My confidence is limited, however, since I am not familiar with functional regression.\nThe paper could better appeal to an ML audience by mentioning ML applications of their method (whether it be functional linear regression or otherwise) early in their paper and in an appealing way. Section 5.2 (Real Data Application) does a good job of this, but giving motivating use cases could help pique reader interest/help them understand application earlier.\"\nThe paper will have greater influence if the final version can convince readers of its relevance to ML!",
        "reviews": [
            "Reviewer 1: \nSummary: This paper studies a method of solving functional inverse problems. The problem set-up is (X,Y) are from a particular distribution, with Y = Af + noise, where f is some function defining the relationship between X and Y. The major example is: if X is a function on [0,1], then Y = int_0^1 f(t)X(t)dt + noise. The goal of the general problem is to find f.\nThe paper introduces a means of finding an appropriate f from a class of functions by stochastic gradient descent, emphasizing results for a particular context: functional linear regression. They review previous results and other techniques for solving stochastic inverse problems, define the problem rigorously, and present example problems. They then give the main algorithm, a sort of functional SGD, and identify issues with it due to functional complexity involving the kernel. To address this, they provide another algorithm which uses the iteratively improving f in the SGD algorithm to teach common ML learners, which are used to build f instead of a kernel. They provide probabilistic error bounds and show a probabilistic convergence rate of O(1/ \\sqrt(n)). They then present synthetic and natural experiments, with a comparison to another method.\nStrengths And Weaknesses: Strengths:\n-great organization\n-clear examples\n-good mathematical exposition\n-solid theoretical results\n-clear writing\n-interesting and good experimental results\n-overall interesting problem\nweaknesses:\n\nexperimental results seem inconsistently or incompletely reported.\na few vagaries in mathematics (see questions)\nQuestions: Questions:\n\nOn Theorem 4.5, you claim the result is independent of the dimensionality of the codomain of L_2(X) and L_2(W), the values of n and k in R^d and R^k. Your proof deals with d=1. Are you sure your results are independent of the value of d? If you are sure, perhaps you could include a comment about how all inferences are independent of the values of k and d?\nTable 4 says SGD outperforms FPLR, but figure 3 indicates FPLR outperforms SGD. Is this an error? Furthermore, I find it odd that all FPLR have the same error in table 4. Are they the same function? (Aside: is SGD = SGD-SIP?)  This makes it look like some of your experimental results are incomplete or incorrect. Furthermore, the thoroughness of the deconvolution results are much less thorough than the FLR in the appendix. Please comment.\nThe order of convergence for the algorithm, O(1 / \\sqrt(n)), seems not so great, and the algorithm that has this guarantee looks jagged and compares poorly to the already established method. Can you comment on the order of convergence, and how it compares to other methods?\n\nMinor issues:\n\nCan you provide a table for results of B2?\nIs the equation at the bottom of page 3 a component-wise integral, since X takes values in R^d but f takes values in R? This may trouble readers if not mentioned. If this is true, is it necessary X take values in R^d?\nOn (138). If x is a specific realization of X, then I believe your conditioning is backwards: you want \\phi(x) = E(\\partial*l(Y,Af)| X = x). Or do you write it the way you do because you use eq (1), with Y still a random variable of the noise, although is X specified? If this is the case, are you taking the expectation only over the noise, \\epsilon? On the other hand, if x is set and Y takes one value for a specified x, what distribution is the expectation over?\nDimensionally not accounted for in (117), (141), etc. EG: A(g)[X] in R^d, so (Ag)^2 not defined if d>1). Also, \\partial l(...)*Ag is R^d x R^d, should you should use transpose or standard inner product?\nPosed assuming the 1-d case, dropping the inner-product brackets (144,147,...). Not sure if this is notationally standard.\n(147) A*g is in R^k, but E(\\Phi((X;w)g(X)) is in R^d. Even if d = 1, dimensions do not match. Is \\Phi in normally in R^{k x d}?\n\nTypos/minor issues:\n\nSentence in (64-66) is confusing, hard to understand.\n\"a prespecified basis functions\" (74-75)\n\"to control directly to tackle (3) directly\" (103-104)\n\"Y is giving by\" (bottom of page 3)\n\"also in deconvolutional problems\" (112)\nindeed have a solution (128)\ndoes not dependent (136)\na coarser grid where and each (214-215)\nBroken references in (380)\nFigure 3 says FPCR.\nLimitations: \nThis is my first time being exposed to the topic of the statistical inverse problem, so I am unfamiliar with some of the relevant literature.\nThey apply the method to standard quadratic loss, and only to FLR and deconvolution. I would like to see an exposition, even if brief, supporting the potential breadth of application. Even better, applications to more problems. This may due to my lack of familiarity with the subject.\nHowever, a low rate of convergence for the excess risk, and some choppy graphs for algorithm 1 seem a liability, To be fair, this is made up for with strong and interesting theoretical results that could be built of of, and a strong showing for the ML-assisted algorithm.\nIs it possible the ML-assist may not give much of a boost, or may do harm, if the kernel-sampling in not well suited to the ML-learners?\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 3 good\nRating: 8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: In this paper, the authors propose an SGD approach to solve statistical inverse problems (SIPs). Formally, the problem is to find the parameter f satisfying the relation Y=A[f](X)+\u03b5, where the operator A is known, and Y and X are given observations. This can be achieved by minimizing the quantity RA(f)=E[l(Y,A[f](X))], where l is a loss function. For A linear and bounded, and with additional (milder) assumptions, the authors are able to write the gradient of RA(f) as the average of a function uf, whose expression has to be derived explicitly for the specific SIP considered. With this result at hand, the authors propose two algorithms to solve SIPs in the spirit of SGD, where the average giving the gradient is approximated by one sample at each iteration. Their main result proves a performance guarantee for such algorithms. The authors apply the proposed techniques to functional linear regressions, performing numerical tests both on synthetic and real data, and deconvolution (discussed in the supplementary material).\nStrengths And Weaknesses: The paper proposes an SGD approach to solve SIPs, thus providing, to the best of my knowledge, an original contribution (at least within the probabilistic formulation of inverse problems). The exposition is clear and compact (section 5 could be improved, though), and the related literature is well covered. \nMy main concerns with this work are the following:\n\nGeneral applicability of the proposed method. Even considering the (not so week) Assumption 4.1, the proposed method crucially depends on the possibility of identifying the kernel \u03d5 appearing in Lemma 4.3. The authors do not discuss the limitations associated with identifying \u03d5, and only present applications where this is doable. Moreover, the proposed algorithms are designed (or, at least, presented) following Corollary 4.4, i.e. considering the squared loss function. It is unclear to me if Theorem 4.5 applies only under this corollary. \n\nActual improvements over other methods. The comparisons proposed by the authors seem to suggest that their algorithms are at most as good as the FPLR (see Table 2). I wonder then what are the actual advantages of solving SIPs with the proposed SGD algorithms, particularly considering the previous point.\nQuestions: I have the following questions/comments for the authors:\n\nI would appreciate it if the authors could comment on my concerns in the previous section. I believe that addressing these points in the main text would be beneficial for the paper.\n\nThe presentation of numerical results could be improved. I believe that Figures 1 and 2 in section 5.2 are a little aimless, as they do not really support any claim in the paper (they take up quite some space, though). Moreover, the label font size in Figure 1 is too small and the x-axis has no scale (or ticks). It is unclear what's on the y-axis in Figure 2 (f(s)? If so, we don't know the real f anyway...what is the point?). In any case, I would suggest combining the two figures and using the same format for both. The synthetic data experiments could be useful to test robustness against the signal-to-noise ratio.\n\nThe sentence 'We highlight that those choices of splines and penalty term are widely used in the literature', line 230, might need a reference.\n\nI am not sure I understand what 'with only one observation' means in this sentence: 'The main benefit is that with only one observation we are able to compute an unbiased estimator for the gradient of the risk function under the true distribution', line 158/159. Can you clarify?\n\nI would change the article 'An' in the title with 'A'.\n\nLine 215 'where and each' -> 'where each'?\n\nLine 103/104 'to control directly to tackle (3) directly' -> 'to tackle (3) directly'?\nLimitations: The authors have partially addressed the limitations of their work, though there is space for improvement (see the section Strengths And Weaknesses).\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 2 fair\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper mainly focuses on the formulation of SIP (statistical inverse problem) and the method to solve SIP.\nIn the first part of this paper, the authors formulate SIP utilizing functional analysis. They also give some examples of SIP under this formulation.\nIn the second part, after showing how to calculate the gradient under this setting, they propose two SGD-based algorithm to solve SIP. They give a finite sample bound for the expected excess risk of their algorithms.\nIn the last part, the authors provide numerical results for two applications of the Functional Linear Regression problem.\nStrengths And Weaknesses: Strengths: The authors give a novel numerical method to solve SIP, which shows good originality. They give both theoretical analysis and real data experiments, which shows the good quality of this paper. \nWeakness: It seems that they do not show the intuition and advantage of their new method, which makes this paper somehow unclear. And the proof techniques are just classical convex optimization analysis. Therefore this paper lacks significance to some extent.\nQuestions: 1.In Lemma 4.3, you've mentioned that there exists a kernel \\Phi. Can this kernel be easily found in many SIP problems (other than functional linear regression)?\nLimitations: It might be interesting if the results can be extended to nonlinear SIP (or any other relaxation of Assumption 4.1).\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper studies a method of solving functional inverse problems. The problem set-up is (X,Y) are from a particular distribution, with Y = Af + noise, where f is some function defining the relationship between X and Y. The major example is: if X is a function on [0,1], then Y = int_0^1 f(t)X(t)dt + noise. The goal of the general problem is to find f.\nThe paper introduces a means of finding an appropriate f from a class of functions by stochastic gradient descent, emphasizing results for a particular context: functional linear regression. They review previous results and other techniques for solving stochastic inverse problems, define the problem rigorously, and present example problems. They then give the main algorithm, a sort of functional SGD, and identify issues with it due to functional complexity involving the kernel. To address this, they provide another algorithm which uses the iteratively improving f in the SGD algorithm to teach common ML learners, which are used to build f instead of a kernel. They provide probabilistic error bounds and show a probabilistic convergence rate of O(1/ \\sqrt(n)). They then present synthetic and natural experiments, with a comparison to another method.",
                "Strengths And Weaknesses": "Strengths:\n-great organization\n-clear examples\n-good mathematical exposition\n-solid theoretical results\n-clear writing\n-interesting and good experimental results\n-overall interesting problem\nweaknesses:\n\nexperimental results seem inconsistently or incompletely reported.\na few vagaries in mathematics (see questions)",
                "Questions": "Questions:\n\nOn Theorem 4.5, you claim the result is independent of the dimensionality of the codomain of L_2(X) and L_2(W), the values of n and k in R^d and R^k. Your proof deals with d=1. Are you sure your results are independent of the value of d? If you are sure, perhaps you could include a comment about how all inferences are independent of the values of k and d?\nTable 4 says SGD outperforms FPLR, but figure 3 indicates FPLR outperforms SGD. Is this an error? Furthermore, I find it odd that all FPLR have the same error in table 4. Are they the same function? (Aside: is SGD = SGD-SIP?)  This makes it look like some of your experimental results are incomplete or incorrect. Furthermore, the thoroughness of the deconvolution results are much less thorough than the FLR in the appendix. Please comment.\nThe order of convergence for the algorithm, O(1 / \\sqrt(n)), seems not so great, and the algorithm that has this guarantee looks jagged and compares poorly to the already established method. Can you comment on the order of convergence, and how it compares to other methods?\n\nMinor issues:\n\nCan you provide a table for results of B2?\nIs the equation at the bottom of page 3 a component-wise integral, since X takes values in R^d but f takes values in R? This may trouble readers if not mentioned. If this is true, is it necessary X take values in R^d?\nOn (138). If x is a specific realization of X, then I believe your conditioning is backwards: you want \\phi(x) = E(\\partial*l(Y,Af)| X = x). Or do you write it the way you do because you use eq (1), with Y still a random variable of the noise, although is X specified? If this is the case, are you taking the expectation only over the noise, \\epsilon? On the other hand, if x is set and Y takes one value for a specified x, what distribution is the expectation over?\nDimensionally not accounted for in (117), (141), etc. EG: A(g)[X] in R^d, so (Ag)^2 not defined if d>1). Also, \\partial l(...)*Ag is R^d x R^d, should you should use transpose or standard inner product?\nPosed assuming the 1-d case, dropping the inner-product brackets (144,147,...). Not sure if this is notationally standard.\n(147) A*g is in R^k, but E(\\Phi((X;w)g(X)) is in R^d. Even if d = 1, dimensions do not match. Is \\Phi in normally in R^{k x d}?\n\nTypos/minor issues:\n\nSentence in (64-66) is confusing, hard to understand.\n\"a prespecified basis functions\" (74-75)\n\"to control directly to tackle (3) directly\" (103-104)\n\"Y is giving by\" (bottom of page 3)\n\"also in deconvolutional problems\" (112)\nindeed have a solution (128)\ndoes not dependent (136)\na coarser grid where and each (214-215)\nBroken references in (380)\nFigure 3 says FPCR.",
                "Limitations": "This is my first time being exposed to the topic of the statistical inverse problem, so I am unfamiliar with some of the relevant literature.\nThey apply the method to standard quadratic loss, and only to FLR and deconvolution. I would like to see an exposition, even if brief, supporting the potential breadth of application. Even better, applications to more problems. This may due to my lack of familiarity with the subject.\nHowever, a low rate of convergence for the excess risk, and some choppy graphs for algorithm 1 seem a liability, To be fair, this is made up for with strong and interesting theoretical results that could be built of of, and a strong showing for the ML-assisted algorithm.\nIs it possible the ML-assist may not give much of a boost, or may do harm, if the kernel-sampling in not well suited to the ML-learners?",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "In this paper, the authors propose an SGD approach to solve statistical inverse problems (SIPs). Formally, the problem is to find the parameter f satisfying the relation Y=A[f](X)+\u03b5, where the operator A is known, and Y and X are given observations. This can be achieved by minimizing the quantity RA(f)=E[l(Y,A[f](X))], where l is a loss function. For A linear and bounded, and with additional (milder) assumptions, the authors are able to write the gradient of RA(f) as the average of a function uf, whose expression has to be derived explicitly for the specific SIP considered. With this result at hand, the authors propose two algorithms to solve SIPs in the spirit of SGD, where the average giving the gradient is approximated by one sample at each iteration. Their main result proves a performance guarantee for such algorithms. The authors apply the proposed techniques to functional linear regressions, performing numerical tests both on synthetic and real data, and deconvolution (discussed in the supplementary material).",
                "Strengths And Weaknesses": "The paper proposes an SGD approach to solve SIPs, thus providing, to the best of my knowledge, an original contribution (at least within the probabilistic formulation of inverse problems). The exposition is clear and compact (section 5 could be improved, though), and the related literature is well covered. \nMy main concerns with this work are the following:\n\nGeneral applicability of the proposed method. Even considering the (not so week) Assumption 4.1, the proposed method crucially depends on the possibility of identifying the kernel \u03d5 appearing in Lemma 4.3. The authors do not discuss the limitations associated with identifying \u03d5, and only present applications where this is doable. Moreover, the proposed algorithms are designed (or, at least, presented) following Corollary 4.4, i.e. considering the squared loss function. It is unclear to me if Theorem 4.5 applies only under this corollary. \n\nActual improvements over other methods. The comparisons proposed by the authors seem to suggest that their algorithms are at most as good as the FPLR (see Table 2). I wonder then what are the actual advantages of solving SIPs with the proposed SGD algorithms, particularly considering the previous point.",
                "Questions": "I have the following questions/comments for the authors:\n\nI would appreciate it if the authors could comment on my concerns in the previous section. I believe that addressing these points in the main text would be beneficial for the paper.\n\nThe presentation of numerical results could be improved. I believe that Figures 1 and 2 in section 5.2 are a little aimless, as they do not really support any claim in the paper (they take up quite some space, though). Moreover, the label font size in Figure 1 is too small and the x-axis has no scale (or ticks). It is unclear what's on the y-axis in Figure 2 (f(s)? If so, we don't know the real f anyway...what is the point?). In any case, I would suggest combining the two figures and using the same format for both. The synthetic data experiments could be useful to test robustness against the signal-to-noise ratio.\n\nThe sentence 'We highlight that those choices of splines and penalty term are widely used in the literature', line 230, might need a reference.\n\nI am not sure I understand what 'with only one observation' means in this sentence: 'The main benefit is that with only one observation we are able to compute an unbiased estimator for the gradient of the risk function under the true distribution', line 158/159. Can you clarify?\n\nI would change the article 'An' in the title with 'A'.\n\nLine 215 'where and each' -> 'where each'?\n\nLine 103/104 'to control directly to tackle (3) directly' -> 'to tackle (3) directly'?",
                "Limitations": "The authors have partially addressed the limitations of their work, though there is space for improvement (see the section Strengths And Weaknesses).",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper mainly focuses on the formulation of SIP (statistical inverse problem) and the method to solve SIP.\nIn the first part of this paper, the authors formulate SIP utilizing functional analysis. They also give some examples of SIP under this formulation.\nIn the second part, after showing how to calculate the gradient under this setting, they propose two SGD-based algorithm to solve SIP. They give a finite sample bound for the expected excess risk of their algorithms.\nIn the last part, the authors provide numerical results for two applications of the Functional Linear Regression problem.",
                "Strengths And Weaknesses": "Strengths: The authors give a novel numerical method to solve SIP, which shows good originality. They give both theoretical analysis and real data experiments, which shows the good quality of this paper. \nWeakness: It seems that they do not show the intuition and advantage of their new method, which makes this paper somehow unclear. And the proof techniques are just classical convex optimization analysis. Therefore this paper lacks significance to some extent.",
                "Questions": "1.In Lemma 4.3, you've mentioned that there exists a kernel \\Phi. Can this kernel be easily found in many SIP problems (other than functional linear regression)?",
                "Limitations": "It might be interesting if the results can be extended to nonlinear SIP (or any other relaxation of Assumption 4.1).",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.667,
        "confidence_avg": 3.0,
        "soundness_avg": 3.0,
        "presentation_avg": 3.0,
        "contribution_avg": 2.333,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that this paper makes a significant contribution to the field of statistical inverse problems. The proposed method of solving SIPs using stochastic gradient descent is novel and the theoretical analysis and experimental results provided in the paper support the effectiveness of the approach. \n\nWhile there are some concerns raised by the reviewers regarding the general applicability of the method and the comparison with other methods, these concerns do not outweigh the strengths of the paper. The authors have addressed some of the limitations and have provided explanations for the choices made in the experiments. \n\nOverall, this paper is technically solid, with good originality and impact. The quality of the evaluation, resources, and reproducibility is also commendable. Therefore, I recommend accepting this paper for publication."
    },
    "Efficiency_Ordering_of_Stochastic_Gradient_Descent": {
        "link": "https://openreview.net//forum?id=pnSyqRXx73",
        "pub_url": "https://openreview.net/forum?id=pnSyqRXx73",
        "pdf_link": "https://openreview.net//pdf?id=pnSyqRXx73",
        "paper_id": "pnSyqRXx73",
        "title": "Efficiency_Ordering_of_Stochastic_Gradient_Descent",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nThe paper proposes an asymptotic analysis of SGD when the noise governed by a Markov chain such as a random walk over an arbitrary graph. The paper connects efficiency ordering with an ordering of covariance matrices inherited from the Central Limit Theorems. \nOne of the results of the work is that SGD algorithms can achieve smaller covariance errors by using a more efficient noise sequences from MCMC sampling. The paper considers decentralized optimization over a graph using high-order random walks for SGD and mini-batch gradient descent with shuffling on the other hand, as applications. The reviewers raised questions on experimental results on larger graphs for their applications, and the authors have preformed and committed to including these new experiments. As a result, all the reviewers are in favour of accepting, and are now confident in their scores.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper proposes an asymptotic analysis of SGD when the noise sequence is not necessarily iid but can be a Markov chain such as a random walk over an arbitrary graph. The main contribution of this work is to connect the concept of efficiency ordering (which was previously introduced in the literature to compare Markov chains with the same stationary distribution and hence compare MCMC algorithms) with an ordering of covariance matrices inherited from Central Limit Theorems controlling rescaled SGD iterates driven by Markov chain noise sequences. As a consequence, SGD algorithms can achieve smaller covariance errors when using more efficient noise sequences for MCMC sampling. As applications of this result, the paper considers decentralized optimization over a graph using high-order random walks for SGD on the one hand and (mini-batch) gradient descent with shuffling on the other hand, confirming the superiority of these mechanisms as previously noticed in the literature. The paper also notably shows how some non-Markovian processes (for which non-asymptotic analysis are not available in the literature) can outperform Markovian input sequences for SGD in terms of efficiency ordering. Numerical experiments illustrate the theoretical findings.\nStrengths And Weaknesses: \u2014 STRENGTHS: \n\nThe paper states that the covariance matrices associated to two random walks following an efficiency ordering are Loewner ordered even for non-Markovian stochastic processes. This is an advantage of the asymptotic approach compared to its non-asymptotic counterpart which cannot handle the non-Markovian setting for which the mixing time is irrelevant beyond the Markovian noise setting (see a clarification question regarding this point in the next section below). Moreover, the result implies that better MCMC samplers could be used to enhance SGD thanks to the connection between AV for MCMC and covariance matrices for SGD algorithms from CLT. The paper hence establishes an interesting connection between the MCMC literature and the asymptotic covariance associated to (rescaled) SGD iterates (using the same noise sequence). \n\nThe comparison between shuffling and iid input sequence and the use of shuffling in mini-batch gradient descent are interesting questions even in practice and prior work has observed and established some advantages of these techniques. The present work compares them using an alternative asymptotic point of view compared to the more common non-asymptotic (finite-time bounds) in the literature relying on mixing times.  \n\nThe paper also extends prior art regarding applications. For instance, it shows that a high-order random walk (NBRW) which is non-Markov is more efficient than SRW for SGD on general graphs beyond d-regular graphs for which this was previously established using mixing times. It also confirms some known advantages of shuffling over iid sampling for SGD and addresses a class of functions (verifying (A2)) that is not covered by prior work. \n\nClarity: the paper is well-written and the contributions are clearly stated. The results are sound and the paper is technically solid (I only quickly went through appendices A, C (checked the proof of the main result) and D though).\n\n\n\u2014 WEAKNESSES:\n\nUnlike the asymptotic approach, a non-asymptotic analysis captures the dependence on constants of the problem such as the data and the graph topology in the distributed optimization setting. \n\nAmong other experimental facts, two main elements are presented as motivation to consider asymptotic variance as a tool for the analysis. First, the paper mentions the connexion of AV with the MSE. Nevertheless, this connexion between finite-time MSE and the covariance matrix does not seem to be straightforward beyond the case of quadratic objective functions (or linear stochastic approximation) which is well understood in the literature with existing thorough non-asymptotic analysis (for e.g. [18, 45] as mentioned in the paper). Second, the paper also mentions confidence intervals: although a smaller covariance matrix indeed reduces the confidence interval length, this covariance matrix depends on the Hessian at the minimizer which is unknown. Hence, it is hard to exploit the asymptotic analysis in practice, although this may not be the main purpose of the paper regarding this confidence interval remark. \n\nThe asymptotic analysis seems to provide little additional actionable information compared to the non-asymptotic approach. In l. 112-117, the paper mentions that the asymptotic variance provides more information than non-asymptotic MSE bounds, but is this information usable in practice? Can we leverage this additional information to improve the algorithms easily beyond the case where we already have a more efficient sequence (in the sense of the MC ordering) at hand? Also, for instance, in the paper, if the asymptotic analysis addresses a different class of functions (satisfying (A2)) which does not include PL functions (as previously addressed in the literature), it only confirms previously known facts regarding shuffling for SGD for which more informative finite-time bounds exist as stated by the paper (l. 323). \n\nUsing Theorem 3.6 may not be easy in general, one needs to know an efficiency ordering of two sequences to transfer it to SGD. Is the problem of determining the efficiency ordering between two sequences easier than comparing the covariance matrices inherited from the CLT corresponding to SGD with the two different noise sequences? (see question in the next section)\n\nTechnical significance: The main contribution of the paper as highlighted by the paper is Theorem 3.6. From the technical point of view, this result follows from the definition of the asymptotic variance of the Markov chain in one direction and from the well-known explicit integral form of the covariance matrix together with the stability of the Loewner ordering (Lemma D.2) for the converse (Appendix, p.6). Compared to the proof of this main result, the applications require more technical work. As acknowledged by the authors (especially in the appendix), CLTs are known in the literature, even for general stochastic approximation schemes driven by Markovian noise, of which SGD with Markov noise is a particular case. The paper relies on this prior work for the CLT.\nQuestions: \nRegarding the main contribution (Theorem 3.6), in general, is showing that the AV is small easier than controlling the asymptotic covariance from the CLT? The applications (Props. 4.1 to 4.4) seem to exploit previously known efficiency ordering from the MCMC literature and transfer them to SGD using Theorem 3.6 whereas these last results (from the MCMC literature) may not be easy to establish in general. \n\nThe example of Fig. 1 is interesting and motivates looking at the AV as a metric for ordering instead of SLEM. However, I am wondering if one can also find an example where the converse holds, i.e. where SLEM may be more relevant if this makes sense. I understand that the point in the paper is to motivate looking at AV but commenting on the converse would also be interesting to complete the picture for the reader regarding the comparison between the asymptotic approach and its non-asymptotic counterpart. \n\nIn the contributions, it is stated that the analysis covers non-Markovian stochastic processes beyond Markovian sequences. The example in p. 7 is a second-order Markov chain (which is non-Markov) and it is analyzed via an augmented process which is a Markov chain. Could one also use non-asymptotic analysis based on the mixing time for this same augmented process? This type of approach does not seem to be out of reach for this specific kind of non-Markovian process compared to the asymptotic approach pursued in the paper.\n\n\nTypos: \n\nl. 188: (A2), what is a? It should rather be \\alpha defining the step size in (A1) I guess. \nl. 364-365: what are f and g? Is it \\tilde{f} and \\hat{f} instead?\nLimitations: Limitations are not explicitly discussed by the paper (as acknowledged by the authors in the checklist in Question1. b). Some comments and questions regarding limitations of the work are discussed in the section above.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The authors introduce the notion of efficiency ordering to classify stochastic algorithms.\nThey claim that some non-Markovian dynamics are more efficient that the Markovian ones for SGD.\nStrengths And Weaknesses: The paper is unclear, and the claims seem to overstate the results in general.\nThe figures present data which are far from convincing.\nIn particular, the numerical experiment made on the Dolphins graph of 62 nodes is not meaningful.\nGiven the generality of the statement made by the authors, I would have expected much higher accuracy numerical experiments run on much larger graphs.\nQuestions: The authors should first provide evidence that their proposal is indeed an improvement for stochastic algorithms on very large graphs and non-convex functions to optimize.\nLimitations: Do not apply.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper studies the stochastic gradient descent algorithm as a stochastic sequence generated by a random walk on an arbitrary graph. It explores various Markov Chain Monte Carlo (MCMC) sampling techniques and proposes \"efficiency ordering\" of Markov chains. This is used to demonstrate that more efficient MCMC sampling can also lead to smaller covariances for SGD algorithms in the limit.\nStrengths And Weaknesses: Strengths\n\nPaper is well written and presents both theoretical and empirical studies of the effect of MCMC sampling on SGD algorithms\nIt introduces the novel concept of \"efficiency ordering\" of Markov chains and its. theoretical underpinnings\n-Comparison of non-Markov random walks to their Markovian counterpart.\n\nWeakness\n\nThe main paper lacks sufficient details on the simulation and figures are too small for readability\n-The overall readability of the paper needs to be improved\nQuestions: \nThe discussion on the mini-batch gradient descent can perhaps be relegated to the Appendix which would both free up space for more appropriate and thorough descriptions on empirical analysis of the efficiency ordering and ensure that variants of SGD are handled / discussed more efficiently. For e.g. if one discusses mini-batch gradient descent, why not other variants including momentum acceleration methods and other known techniques?\n\nThe main paper does not discuss the effect of the underlying graph structure (which affects SLEM) and its impact on efficiency ordering of SGD\n\nThe paper does not have a conclusion or future work section. It lacks a discussion on potential drawbacks of the technique.\n\n\nMinor comments\n\n\nAsymptotic covariance matrix - definition of \\hat{mu}_t (g) -> sum_k=1 to t g(X_k) NOT X_t?\nLimitations: Societal impact of the work is not discussed in this paper. Furthermore, limitations of the proposed technique need further thought.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 3 good\nContribution: 4 excellent\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: At each iteration, stochastic gradient descent (SGD) processes data sampled randomly from the training set. Denote this sequence of training data by (Xt)t, which includes the case where Xt are mini-batches. Empirical evidence by the authors suggest that the convergence of SGD is faster when the asymptotic variance (AV) of the chain (Xt)t is smaller, contrary to the commonly held belief that smaller SLEM (second largest eigenvalue modulus) lead to faster convergence of SGD. This motivates the authors to study the AV of data sampling approaches commonly employed in SGD, such as mini-batch shuffling, and define efficiency ordering on chains based on their AV (lower AV implies higher efficiency). They prove rigorously that certain non-Markovian sequences such as shuffling give better efficiency ordering than Markovian i.i.d. input sequences. They then demonstrate experimentally that the former indeed gives rise to faster converging SGD when applied to the CIFAR-10 dataset.\nStrengths And Weaknesses: Strengths:\n\nThe results in the paper give new insights into SGD. In particular, it opens up a direction to look for more efficient SGD algorithms.\nThe techniques involved in the proof are interesting and completely non-trivial. In particular, the idea of lifting non-Markovian sequences to an augmented space to make it Markovian was intriguing. The maths overall seem correct (although I do have some questions below) and fully rigorous.\nThe main body of the paper is well-written and easy to follow.\n\nWeakness:\n\nWhile the main body of the paper is well-written, the appendix, which contains all the proofs, can be improved. I defer some of my issues in the appendix to \"Questions\".\nPlots can be improved by:\nUsing larger label sizes (e.g. labels in Figure 2 are almost impossible to see without zooming in. Also better to increase label sizes in figure 1. Applies also to the figures in the appendix).\nImprove colour-scheme by taking into consideration colorblindness. For instance, avoid red-green-blue combination (see e.g. https://davidmathlogic.com/colorblind/#%23D81B60-%231E88E5-%23FFC107-%23004D40 for more details).\n\n\nThere are a few misprints/suggestions in the text of the main body that I spotted:\nLine 140: M\"\u2208Rn should be M\u2208Rn (note the quotation mark)\nLine 268: \"From the nature of same limiting distributions\" can be phrased better. Maybe along the lines of \"Since the limiting distributions are the same\".\nLine 369: \"we random generate\" should be \"we randomly generate\".\nQuestions: \nWhile the main body of the paper is well-written, the appendix I believe is not at the same quality and can be improved. For instance:\n\nLine 69: \"We can check the solution F~(\u03b8,z)\". What are we checking?\nThe proof of Proposition 4.1 (Appendix F) is confusing. What are the processes X and X\u2032? How are they related to the NBRW and SRW? While I agree with the computations in the proof, I still don't understand how it can be used to conclude that NBRW is more efficient than SRW.\nIn Appendix G, the line \"regroup all the terms in each k-th epoch with length n\" (line 226) is difficult to understand (I do understand now, but it took a while). It may help to supplement with a diagram.\nWhat is \u03c0^ in the proof of Lemma H.1? How is it different from \u03c0?\nI don't understand how the following line is true (Line 291-292):\nWe also note that P(st,st+j)=0 for j\u2260kn and k\u2208N.\n\n Please could you explain more?\nWhat do the embedded plots in figures 5a), 5b), 6a) and 6b) show?\n\n\nThere are several misprints peppered throughout the appendix.\n\nLine 72: I suggest phrasing \"are right and left eigenvector of P\" as \"are the right and left eigenvectors of P respectively\".\nLine 94-95: \"to ensure \u03b8\u2217 being local minimizer\" should be \"to ensure that \u03b8\u2217 is the local minimizer\".\nLine 226: I think \"\u2211i=(k\u22121)nkn\u22121(g(Xi)\u2212E\u03c0(g))\" should read \"\u2211i=(k\u22121)nkn\u22121(g(Xi)\u2212E\u03c0(g))<\u221e\".\nLine 229: \"because of bounded function g\" should be \"because of the boundedness of function g\".\nLine 247: \"Especially, um=\u03c0^\" should be \"In particular, um=\u03c0^\"\ns6 in line 268 should be s8.\naj(t) in line 290 should be Aj(t).\nAppendix G: Lemma 4.2 is mislabelled as Proposition 4.2.\n\n\nWhile the results point to new methods for improving SGD, in practice, how easy is it to compute the asymptotic variance for a given chain? Also, is efficiency ordering still valid for other stochastic optimization methods such as Adam?\nLimitations: The work is mostly theoretical and as far as I can see, has no potential negative societal impact.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper proposes an asymptotic analysis of SGD when the noise sequence is not necessarily iid but can be a Markov chain such as a random walk over an arbitrary graph. The main contribution of this work is to connect the concept of efficiency ordering (which was previously introduced in the literature to compare Markov chains with the same stationary distribution and hence compare MCMC algorithms) with an ordering of covariance matrices inherited from Central Limit Theorems controlling rescaled SGD iterates driven by Markov chain noise sequences. As a consequence, SGD algorithms can achieve smaller covariance errors when using more efficient noise sequences for MCMC sampling. As applications of this result, the paper considers decentralized optimization over a graph using high-order random walks for SGD on the one hand and (mini-batch) gradient descent with shuffling on the other hand, confirming the superiority of these mechanisms as previously noticed in the literature. The paper also notably shows how some non-Markovian processes (for which non-asymptotic analysis are not available in the literature) can outperform Markovian input sequences for SGD in terms of efficiency ordering. Numerical experiments illustrate the theoretical findings.",
                "Strengths And Weaknesses": "\u2014 STRENGTHS: \n\nThe paper states that the covariance matrices associated to two random walks following an efficiency ordering are Loewner ordered even for non-Markovian stochastic processes. This is an advantage of the asymptotic approach compared to its non-asymptotic counterpart which cannot handle the non-Markovian setting for which the mixing time is irrelevant beyond the Markovian noise setting (see a clarification question regarding this point in the next section below). Moreover, the result implies that better MCMC samplers could be used to enhance SGD thanks to the connection between AV for MCMC and covariance matrices for SGD algorithms from CLT. The paper hence establishes an interesting connection between the MCMC literature and the asymptotic covariance associated to (rescaled) SGD iterates (using the same noise sequence). \n\nThe comparison between shuffling and iid input sequence and the use of shuffling in mini-batch gradient descent are interesting questions even in practice and prior work has observed and established some advantages of these techniques. The present work compares them using an alternative asymptotic point of view compared to the more common non-asymptotic (finite-time bounds) in the literature relying on mixing times.  \n\nThe paper also extends prior art regarding applications. For instance, it shows that a high-order random walk (NBRW) which is non-Markov is more efficient than SRW for SGD on general graphs beyond d-regular graphs for which this was previously established using mixing times. It also confirms some known advantages of shuffling over iid sampling for SGD and addresses a class of functions (verifying (A2)) that is not covered by prior work. \n\nClarity: the paper is well-written and the contributions are clearly stated. The results are sound and the paper is technically solid (I only quickly went through appendices A, C (checked the proof of the main result) and D though).\n\n\n\u2014 WEAKNESSES:\n\nUnlike the asymptotic approach, a non-asymptotic analysis captures the dependence on constants of the problem such as the data and the graph topology in the distributed optimization setting. \n\nAmong other experimental facts, two main elements are presented as motivation to consider asymptotic variance as a tool for the analysis. First, the paper mentions the connexion of AV with the MSE. Nevertheless, this connexion between finite-time MSE and the covariance matrix does not seem to be straightforward beyond the case of quadratic objective functions (or linear stochastic approximation) which is well understood in the literature with existing thorough non-asymptotic analysis (for e.g. [18, 45] as mentioned in the paper). Second, the paper also mentions confidence intervals: although a smaller covariance matrix indeed reduces the confidence interval length, this covariance matrix depends on the Hessian at the minimizer which is unknown. Hence, it is hard to exploit the asymptotic analysis in practice, although this may not be the main purpose of the paper regarding this confidence interval remark. \n\nThe asymptotic analysis seems to provide little additional actionable information compared to the non-asymptotic approach. In l. 112-117, the paper mentions that the asymptotic variance provides more information than non-asymptotic MSE bounds, but is this information usable in practice? Can we leverage this additional information to improve the algorithms easily beyond the case where we already have a more efficient sequence (in the sense of the MC ordering) at hand? Also, for instance, in the paper, if the asymptotic analysis addresses a different class of functions (satisfying (A2)) which does not include PL functions (as previously addressed in the literature), it only confirms previously known facts regarding shuffling for SGD for which more informative finite-time bounds exist as stated by the paper (l. 323). \n\nUsing Theorem 3.6 may not be easy in general, one needs to know an efficiency ordering of two sequences to transfer it to SGD. Is the problem of determining the efficiency ordering between two sequences easier than comparing the covariance matrices inherited from the CLT corresponding to SGD with the two different noise sequences? (see question in the next section)\n\nTechnical significance: The main contribution of the paper as highlighted by the paper is Theorem 3.6. From the technical point of view, this result follows from the definition of the asymptotic variance of the Markov chain in one direction and from the well-known explicit integral form of the covariance matrix together with the stability of the Loewner ordering (Lemma D.2) for the converse (Appendix, p.6). Compared to the proof of this main result, the applications require more technical work. As acknowledged by the authors (especially in the appendix), CLTs are known in the literature, even for general stochastic approximation schemes driven by Markovian noise, of which SGD with Markov noise is a particular case. The paper relies on this prior work for the CLT.",
                "Questions": "Regarding the main contribution (Theorem 3.6), in general, is showing that the AV is small easier than controlling the asymptotic covariance from the CLT? The applications (Props. 4.1 to 4.4) seem to exploit previously known efficiency ordering from the MCMC literature and transfer them to SGD using Theorem 3.6 whereas these last results (from the MCMC literature) may not be easy to establish in general. \n\nThe example of Fig. 1 is interesting and motivates looking at the AV as a metric for ordering instead of SLEM. However, I am wondering if one can also find an example where the converse holds, i.e. where SLEM may be more relevant if this makes sense. I understand that the point in the paper is to motivate looking at AV but commenting on the converse would also be interesting to complete the picture for the reader regarding the comparison between the asymptotic approach and its non-asymptotic counterpart. \n\nIn the contributions, it is stated that the analysis covers non-Markovian stochastic processes beyond Markovian sequences. The example in p. 7 is a second-order Markov chain (which is non-Markov) and it is analyzed via an augmented process which is a Markov chain. Could one also use non-asymptotic analysis based on the mixing time for this same augmented process? This type of approach does not seem to be out of reach for this specific kind of non-Markovian process compared to the asymptotic approach pursued in the paper.\n\n\nTypos: \n\nl. 188: (A2), what is a? It should rather be \\alpha defining the step size in (A1) I guess. \nl. 364-365: what are f and g? Is it \\tilde{f} and \\hat{f} instead?",
                "Limitations": "Limitations are not explicitly discussed by the paper (as acknowledged by the authors in the checklist in Question1. b). Some comments and questions regarding limitations of the work are discussed in the section above.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors introduce the notion of efficiency ordering to classify stochastic algorithms.\nThey claim that some non-Markovian dynamics are more efficient that the Markovian ones for SGD.",
                "Strengths And Weaknesses": "The paper is unclear, and the claims seem to overstate the results in general.\nThe figures present data which are far from convincing.\nIn particular, the numerical experiment made on the Dolphins graph of 62 nodes is not meaningful.\nGiven the generality of the statement made by the authors, I would have expected much higher accuracy numerical experiments run on much larger graphs.",
                "Questions": "The authors should first provide evidence that their proposal is indeed an improvement for stochastic algorithms on very large graphs and non-convex functions to optimize.",
                "Limitations": "Do not apply.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper studies the stochastic gradient descent algorithm as a stochastic sequence generated by a random walk on an arbitrary graph. It explores various Markov Chain Monte Carlo (MCMC) sampling techniques and proposes \"efficiency ordering\" of Markov chains. This is used to demonstrate that more efficient MCMC sampling can also lead to smaller covariances for SGD algorithms in the limit.",
                "Strengths And Weaknesses": "Strengths\n\nPaper is well written and presents both theoretical and empirical studies of the effect of MCMC sampling on SGD algorithms\nIt introduces the novel concept of \"efficiency ordering\" of Markov chains and its. theoretical underpinnings\n-Comparison of non-Markov random walks to their Markovian counterpart.\n\nWeakness\n\nThe main paper lacks sufficient details on the simulation and figures are too small for readability\n-The overall readability of the paper needs to be improved",
                "Questions": "The discussion on the mini-batch gradient descent can perhaps be relegated to the Appendix which would both free up space for more appropriate and thorough descriptions on empirical analysis of the efficiency ordering and ensure that variants of SGD are handled / discussed more efficiently. For e.g. if one discusses mini-batch gradient descent, why not other variants including momentum acceleration methods and other known techniques?\n\nThe main paper does not discuss the effect of the underlying graph structure (which affects SLEM) and its impact on efficiency ordering of SGD\n\nThe paper does not have a conclusion or future work section. It lacks a discussion on potential drawbacks of the technique.\n\n\nMinor comments\n\n\nAsymptotic covariance matrix - definition of \\hat{mu}_t (g) -> sum_k=1 to t g(X_k) NOT X_t?",
                "Limitations": "Societal impact of the work is not discussed in this paper. Furthermore, limitations of the proposed technique need further thought.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "3 good",
                "Contribution": "4 excellent",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "At each iteration, stochastic gradient descent (SGD) processes data sampled randomly from the training set. Denote this sequence of training data by (Xt)t, which includes the case where Xt are mini-batches. Empirical evidence by the authors suggest that the convergence of SGD is faster when the asymptotic variance (AV) of the chain (Xt)t is smaller, contrary to the commonly held belief that smaller SLEM (second largest eigenvalue modulus) lead to faster convergence of SGD. This motivates the authors to study the AV of data sampling approaches commonly employed in SGD, such as mini-batch shuffling, and define efficiency ordering on chains based on their AV (lower AV implies higher efficiency). They prove rigorously that certain non-Markovian sequences such as shuffling give better efficiency ordering than Markovian i.i.d. input sequences. They then demonstrate experimentally that the former indeed gives rise to faster converging SGD when applied to the CIFAR-10 dataset.",
                "Strengths And Weaknesses": "Strengths:\n\nThe results in the paper give new insights into SGD. In particular, it opens up a direction to look for more efficient SGD algorithms.\nThe techniques involved in the proof are interesting and completely non-trivial. In particular, the idea of lifting non-Markovian sequences to an augmented space to make it Markovian was intriguing. The maths overall seem correct (although I do have some questions below) and fully rigorous.\nThe main body of the paper is well-written and easy to follow.\n\nWeakness:\n\nWhile the main body of the paper is well-written, the appendix, which contains all the proofs, can be improved. I defer some of my issues in the appendix to \"Questions\".\nPlots can be improved by:\nUsing larger label sizes (e.g. labels in Figure 2 are almost impossible to see without zooming in. Also better to increase label sizes in figure 1. Applies also to the figures in the appendix).\nImprove colour-scheme by taking into consideration colorblindness. For instance, avoid red-green-blue combination (see e.g. https://davidmathlogic.com/colorblind/#%23D81B60-%231E88E5-%23FFC107-%23004D40 for more details).\n\n\nThere are a few misprints/suggestions in the text of the main body that I spotted:\nLine 140: M\"\u2208Rn should be M\u2208Rn (note the quotation mark)\nLine 268: \"From the nature of same limiting distributions\" can be phrased better. Maybe along the lines of \"Since the limiting distributions are the same\".\nLine 369: \"we random generate\" should be \"we randomly generate\".",
                "Questions": "While the main body of the paper is well-written, the appendix I believe is not at the same quality and can be improved. For instance:\n\nLine 69: \"We can check the solution F~(\u03b8,z)\". What are we checking?\nThe proof of Proposition 4.1 (Appendix F) is confusing. What are the processes X and X\u2032? How are they related to the NBRW and SRW? While I agree with the computations in the proof, I still don't understand how it can be used to conclude that NBRW is more efficient than SRW.\nIn Appendix G, the line \"regroup all the terms in each k-th epoch with length n\" (line 226) is difficult to understand (I do understand now, but it took a while). It may help to supplement with a diagram.\nWhat is \u03c0^ in the proof of Lemma H.1? How is it different from \u03c0?\nI don't understand how the following line is true (Line 291-292):\nWe also note that P(st,st+j)=0 for j\u2260kn and k\u2208N.\n\n Please could you explain more?\nWhat do the embedded plots in figures 5a), 5b), 6a) and 6b) show?\n\n\nThere are several misprints peppered throughout the appendix.\n\nLine 72: I suggest phrasing \"are right and left eigenvector of P\" as \"are the right and left eigenvectors of P respectively\".\nLine 94-95: \"to ensure \u03b8\u2217 being local minimizer\" should be \"to ensure that \u03b8\u2217 is the local minimizer\".\nLine 226: I think \"\u2211i=(k\u22121)nkn\u22121(g(Xi)\u2212E\u03c0(g))\" should read \"\u2211i=(k\u22121)nkn\u22121(g(Xi)\u2212E\u03c0(g))<\u221e\".\nLine 229: \"because of bounded function g\" should be \"because of the boundedness of function g\".\nLine 247: \"Especially, um=\u03c0^\" should be \"In particular, um=\u03c0^\"\ns6 in line 268 should be s8.\naj(t) in line 290 should be Aj(t).\nAppendix G: Lemma 4.2 is mislabelled as Proposition 4.2.\n\n\nWhile the results point to new methods for improving SGD, in practice, how easy is it to compute the asymptotic variance for a given chain? Also, is efficiency ordering still valid for other stochastic optimization methods such as Adam?",
                "Limitations": "The work is mostly theoretical and as far as I can see, has no potential negative societal impact.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.25,
        "confidence_avg": 3.5,
        "soundness_avg": 3.5,
        "presentation_avg": 3.0,
        "contribution_avg": 3.0,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is clear that this paper makes significant contributions to the field of stochastic gradient descent (SGD) algorithms. The paper introduces the concept of efficiency ordering of Markov chains and demonstrates how more efficient Markov chain Monte Carlo (MCMC) sampling techniques can lead to smaller covariances for SGD algorithms. The theoretical results are supported by empirical experiments on the CIFAR-10 dataset.\n\nWhile there are some concerns raised by the reviewers, such as the lack of details in the appendix, small and unreadable figures, and the need for larger-scale experiments, these issues do not outweigh the strengths of the paper. The main body of the paper is well-written and the results provide new insights into SGD algorithms.\n\nOverall, the paper is technically solid and has high impact on the field. Therefore, I recommend accepting it for publication."
    },
    "Self-Aware_Personalized_Federated_Learning": {
        "link": "https://openreview.net//forum?id=EqJ5_hZSqgy",
        "pub_url": "https://openreview.net/forum?id=EqJ5_hZSqgy",
        "pdf_link": "https://openreview.net//pdf?id=EqJ5_hZSqgy",
        "paper_id": "EqJ5_hZSqgy",
        "title": "Self-Aware_Personalized_Federated_Learning",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Less certain\nIn this submission, the authors study personalized federated learning and propose a self-aware personalized method to address the balancing challenge from the perspective of uncertainty quantification. This problem is interesting and important (as pointed out by b7BG and rRk4), and the proposed method is derived in a principal way from theory (as pointed out by jvSV) and useful for applications. I recommend accepting this submission.\nThe authors can include some discussion about the communication and computation cost (as suggested by b7BG), and add an ablation study to show the effect of other factors (as suggested by jvSV), to make this submission better.\nHope that the suggestions from all the reviewers and the discussion between reviewers and authors can make this submission a better on.",
        "reviews": [
            "Reviewer 1: \nSummary: In this paper, the authors study an important problem in federated learning, i.e., personalized federated learning, where the goal is to balance the training of the local model of each client and the global model shared by all the clients. In particular, the authors do not follow previous works on model fine-tuning in each local client and size-based weighting in global aggregation, but propose to address the balancing challenge from a statistical uncertainty perspective. Specifically, the authors design a novel solution called Self-FL, which uses uncertainty-driven approaches for the training of the local models and the global model. Empirical results on some well-known datasets show the effectiveness of the proposed Self-FL.\nStrengths And Weaknesses: Strengths:\n1 The authors address an important challenge in personalized federated learning, i.e., balancing of the training of each local model and the global model.\n2 The authors propose a novel perspective for the studied problem and design some novel uncertainty-driven approaches.\nWeakness:\n1 The authors may include more discussions and quantitative analysis about the communication cost.\nQuestions: 1 Can the proposed approach be applied to other tasks, e.g., classification/recognition with some auxiliary data such as knowledge graph, federated recommendation?\nLimitations: The authors do not include sufficient discussions about the communication and computational cost, which are suggested to be included.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper is on personalized federated learning, where the critical challenge is in balance of local and global model tuning. More specially, the goal of global model tuning and local personalized model tuning are not fully aligned.  Toward this problem, the authors develop a self-aware personalized FL method to balance the personal model and global model update based on the inter-client and intra-client uncertainty quantification. The paper recognized and clearly defined critical research questions. To answer the questions, the authors formulate  personalization from a  hierarchical model-based perspective and propose Self-FL, an active personalized FL solution that guides local training and global aggregation via inter- and intra-client uncertainty quantification. The experimental results confirm the effectiveness of the proposed method from task performance and training stableness.\nStrengths And Weaknesses: The authors clearly defined the challenging questions and work on the fundamental research questions. The proposed methods are derived  in a principal way with theory. The performance is promising and experiments are pretty comprehensive. The personalization naturally puts more requirements on evaluation and analysis due to involving performance evaluation across clients. I include my suggestions in the following sections and encourage authors to provide more analysis to uncover personalization challenges in term of data dimension.\nQuestions: One of the challenges in personalization is how to achieve good performance while clients do not have enough data and prevent overfitting.  Could authors provide some intuitions to explain how the model handle the case when the labeled data is limited on some clients?\nLimitations: The authors propose to characterize the performance by weighted accuracy. Even though this is a good way to show the performance, the detailed performance distribution is also suggested. For example, a violin plot could depict the distribution of performance. \nAnother suggestion is to uncover the relationship between performance and other factors including data size and class distribution on client sides.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The authors present a self aware personalized FL system which uses Bayesian hierarchical modeling to balance training of local versus global models. This helps to quantify inter and intra client uncertainty quantification. The authors present both theoretical justification and empirical analysis of the proposed technique - Self-FL.\nStrengths And Weaknesses: Strengths\n\nThe authors identify an important problem -- that of personalizing federated learning problems\nThe paper is well written\nA reasonably well written Related Work and Experimental Studies section\n\nWeakness\n\nThe problem of tuning local versus global models has been studied extensively in literature and therefore the novelty of the proposed approach is questionable.\nQuestions: \nThe motivation for using Bayesian hierarchical modeling for personalization needs to be better explained. \n\nHow exactly is personalization quantified and how is the notion of \"personalization\" different from learning parallel algorithms where local models are updated by information from global models?\n\n\nMinor comments\nSection 2.1. to bake prior knowledge -> to take prior knowledge\nLimitations: \nThe use of local versus global training  is extensively used in literature. It is unclear how this idea is different from the notion of \"personalization\" introduced here. Infact, the basic premise seems to be the construction of a generative model at the client side and update its parameters using a global counterpart (assuming a generative model for global training).\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 2 fair\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "In this paper, the authors study an important problem in federated learning, i.e., personalized federated learning, where the goal is to balance the training of the local model of each client and the global model shared by all the clients. In particular, the authors do not follow previous works on model fine-tuning in each local client and size-based weighting in global aggregation, but propose to address the balancing challenge from a statistical uncertainty perspective. Specifically, the authors design a novel solution called Self-FL, which uses uncertainty-driven approaches for the training of the local models and the global model. Empirical results on some well-known datasets show the effectiveness of the proposed Self-FL.",
                "Strengths And Weaknesses": "Strengths:\n1 The authors address an important challenge in personalized federated learning, i.e., balancing of the training of each local model and the global model.\n2 The authors propose a novel perspective for the studied problem and design some novel uncertainty-driven approaches.\nWeakness:\n1 The authors may include more discussions and quantitative analysis about the communication cost.",
                "Questions": "1 Can the proposed approach be applied to other tasks, e.g., classification/recognition with some auxiliary data such as knowledge graph, federated recommendation?",
                "Limitations": "The authors do not include sufficient discussions about the communication and computational cost, which are suggested to be included.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper is on personalized federated learning, where the critical challenge is in balance of local and global model tuning. More specially, the goal of global model tuning and local personalized model tuning are not fully aligned.  Toward this problem, the authors develop a self-aware personalized FL method to balance the personal model and global model update based on the inter-client and intra-client uncertainty quantification. The paper recognized and clearly defined critical research questions. To answer the questions, the authors formulate  personalization from a  hierarchical model-based perspective and propose Self-FL, an active personalized FL solution that guides local training and global aggregation via inter- and intra-client uncertainty quantification. The experimental results confirm the effectiveness of the proposed method from task performance and training stableness.",
                "Strengths And Weaknesses": "The authors clearly defined the challenging questions and work on the fundamental research questions. The proposed methods are derived  in a principal way with theory. The performance is promising and experiments are pretty comprehensive. The personalization naturally puts more requirements on evaluation and analysis due to involving performance evaluation across clients. I include my suggestions in the following sections and encourage authors to provide more analysis to uncover personalization challenges in term of data dimension.",
                "Questions": "One of the challenges in personalization is how to achieve good performance while clients do not have enough data and prevent overfitting.  Could authors provide some intuitions to explain how the model handle the case when the labeled data is limited on some clients?",
                "Limitations": "The authors propose to characterize the performance by weighted accuracy. Even though this is a good way to show the performance, the detailed performance distribution is also suggested. For example, a violin plot could depict the distribution of performance. \nAnother suggestion is to uncover the relationship between performance and other factors including data size and class distribution on client sides.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors present a self aware personalized FL system which uses Bayesian hierarchical modeling to balance training of local versus global models. This helps to quantify inter and intra client uncertainty quantification. The authors present both theoretical justification and empirical analysis of the proposed technique - Self-FL.",
                "Strengths And Weaknesses": "Strengths\n\nThe authors identify an important problem -- that of personalizing federated learning problems\nThe paper is well written\nA reasonably well written Related Work and Experimental Studies section\n\nWeakness\n\nThe problem of tuning local versus global models has been studied extensively in literature and therefore the novelty of the proposed approach is questionable.",
                "Questions": "The motivation for using Bayesian hierarchical modeling for personalization needs to be better explained. \n\nHow exactly is personalization quantified and how is the notion of \"personalization\" different from learning parallel algorithms where local models are updated by information from global models?\n\n\nMinor comments\nSection 2.1. to bake prior knowledge -> to take prior knowledge",
                "Limitations": "The use of local versus global training  is extensively used in literature. It is unclear how this idea is different from the notion of \"personalization\" introduced here. Infact, the basic premise seems to be the construction of a generative model at the client side and update its parameters using a global counterpart (assuming a generative model for global training).",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.667,
        "confidence_avg": 3.0,
        "soundness_avg": 2.667,
        "presentation_avg": 2.667,
        "contribution_avg": 2.667,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the paper addresses an important challenge in personalized federated learning and proposes a novel perspective and solution. The proposed Self-FL method shows promising results in balancing the training of local and global models. \n\nReviewer 1 highlights the importance of addressing the communication and computational cost, which is a valid concern. However, this limitation does not outweigh the strengths of the paper. \n\nReviewer 2 also acknowledges the importance of the research questions addressed in the paper and suggests providing more analysis on personalization challenges. These suggestions can be considered for future work, but they do not diminish the contribution of the proposed method.\n\nReviewer 3 raises concerns about the novelty of the proposed approach and questions the motivation for using Bayesian hierarchical modeling. While these concerns are valid, the other reviewers have recognized the importance and effectiveness of the proposed method, which outweighs the potential lack of novelty.\n\nOverall, the paper is technically solid, with high impact on the field of personalized federated learning. The evaluation is comprehensive, and there are no unaddressed ethical considerations. Therefore, I recommend accepting the paper."
    },
    "Nonnegative_Tensor_Completion_via_Integer_Optimization": {
        "link": "https://openreview.net//forum?id=xnI37HyfoP",
        "pub_url": "https://openreview.net/forum?id=xnI37HyfoP",
        "pdf_link": "https://openreview.net//pdf?id=xnI37HyfoP",
        "paper_id": "xnI37HyfoP",
        "title": "Nonnegative_Tensor_Completion_via_Integer_Optimization",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nAll reviewers found the paper clearly interesting, and agree that it makes a valuable and novel contribution in the field of tensor learning, and the consensus to accept the paper is thus without ambiguity.\nHowever, all reviewers, who were all from the start fairly positive about the paper, and who made a number of constructive comments and suggestions that could improve the paper, were quite disappointed by the responses of the authors which seem to suggest that the latter were only prepared to make minimal changes to address the concerns of the reviewers. This explains why the ratings of the paper are not higher...\nWe obviously understand that it would not have been possible to address some of the concerns of the reviewers during the rebuttal period, but the authors are now strongly encouraged to take into account the comments of the reviewers when preparing the final version of this manuscript. The authors are in particular encouraged to take into account the questions and comments about related work and to the extend possible to include more detailed discussions of the related work and the connections with this work. Also, they are encouraged to clarify the technical parts of the manuscript about which the reviewers asked clarification questions.",
        "reviews": [
            "Reviewer 1: \nSummary: The authors introduce an algorithm for nonnegative tensor completion. For that, a new tensor norm is defined which is shown to be a convex surrogate of the tensor rank. To define this norm, the authors first show that the convex hull of the ball of the nonnegative rank-1 tensors whose maximum entry is 1 is the same as the convex hull of all the binary rank-1 tensors. Since the latter is a polytope and the binary rank-1 tensors are the vertices of the polytope, linear integer programming techniques can be used to optimize over it. Therefore, the norm of a nonnegative tensor of any rank is defined using such polytopes. The authors further study the norm by proving its NP-hardness and its stochastic complexity, in terms of Rademacher complexity. Finally, it is shown how integer linear programming can be used for efficient computation of the global minima. The numerical results show that the proposed method can achieve better estimation error and is able to complete tensors with fewer samples.\nStrengths And Weaknesses: Strengths: \n\nThe problem of tensor completion is an interesting problem that shows up in different applications from recommender systems to wireless communications. Aside from that, the introduction of a norm that is a convex surrogate of the tensor rank and has nice properties for optimization problems is impactful on its own. \nThe authors study the different aspects of the problem and the proposed norm theoretically, prove the claims, and/or refer the reader to the relevant papers.\nA numerical algorithm is proposed to use the introduced norm for the nonnegative tensor completion problem. Although the proposed norm is NP-hard to calculate to arbitrary accuracy, the proposed algorithm is able to calculate the global minima. This is due to the proposed norm being a 0-1 polytope. \nThe paper is well-structured and the proofs are well-written. The authors discuss the limitations\n\nWeaknesses:\nThere are not many weaknesses. The authors could have moved all or some of the proofs to the appendix. This would have opened some space to provide more intuition to the reader, add some visualizations, explain the algorithm in more detail, and possibly add more experiments. For example, it would have been interesting to evaluate the algorithm for hyperparameters other than the ground truth. This is of great practical importance, as we usually do not have access to the true rank or the true maximum value of the tensor.\nQuestions: It would have been interesting to evaluate the algorithm for hyperparameters other than the ground truth.\nLimitations: There is no dedicated \"limitations\" section. But the authors discuss the limitations, such as the solution being limited to nonnegative tensors, the computational complexity, and the running time.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 3 good\nContribution: 4 excellent\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The authors proposed an approximated algorithm for nonnegative tensor completion that seems to work very efficiently (the claim is in linear time).\nStrengths And Weaknesses: The paper is very well written and the authors present their results in a clear way.\nThe result is definitely original and very important.\nMy only concern is about the authors' claims based on Figures 3 and 4\nThe data for the BCG algorithm in the right panels are far from being linear!\nData in Fig. 3 are very noisy and those in Fig. 4 have a clear upwards curvature, suggesting a more than linear growth for larger n values.\nMoreover, from the numerical experiments is not clear at all whether the algorithm is matching the IT threshold: data supporting this claim are completely missing or should be presented in a more evident way.\nQuestions: In order to become fully convincing, the paper should report much stronger numerical evidence of scalability (i.e. linear behaviour with n) and efficiency (i.e. ability to work close to the IT threshold).\nMoreover, I have to admit to being very surprised that an algorithm that performs a local optimization by flipping single variables one at a time is able to reach the optimal solution in general. The authors should discuss the reasons beyond this unreasonable effectiveness.\nI would like to understand whether the apparent very good performance depends on the tensor low-rank (which is not larger than 10 in all numerical experiments shown by the authors). What happens if the tensor rank is increased? Does the algorithm keep working with the same efficiency and scalability?\nLimitations: The authors do not really discuss the issue.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper studies the tensor completion problem for tensors with non-negative entries. The paper proposes a non-negative analog of the nuclear norm, denoted \u2016\u22c5\u2016+ whose 1-ball is defined to be a convex combination of rank-1 0,1-tensors. The paper proposes to solve the problem, dual to \u2016\u22c5\u2016+-minimization to recover unknown non-negative tensor from a subset of observed entries. This approach is a natural analog of the nuclear norm minimization for general tensors. The paper proves that this approach w.h.p. can recover the unknown tensor from an essentially statistically optimal number of unknown samples. The authors prove that this minimization problem is NP-hard. At the same time, they show that the BCG algorithm can solve the problem with a linear number of calls to a linear separation oracle. Moreover, the paper proposes a heuristic algorithm for the oracle and studies its performance on synthetic data.\nStrengths And Weaknesses: Significance: Tensors with non-negative entries frequently appear in practice, hence improved algorithms for this setup are likely to have further applications. This paper proposes a natural idea for the problem, which does not seem to be explored in the prior work. The experimental results presented by the authors show that their heuristic algorithm has better performance on tensors with low non-negative rank compared to some state-of-the-art approaches.\nClarity: The technical proofs seem to be correct and the paper is reasonably well-written. However, there is a number of vague statements, typos, or claims that are potentially overstated. See questions below. Additionally, it will be very helpful for the reader if details of BCG algorithm are included at least in the appendix.\nFinally, the paper uses notation that is non-standard in the literature, which makes it a bit harder to read. For instance, r is typically reserved for the rank of the tensor, while this paper uses k for the rank and ri for the dimensions of the tensor.\nQuestions: \nCan you please clarify what results in the papers cited on lines 33-34 achieve information-theoretic bounds? Are there specific numbered theorems? As far as I know, for n\u00d7n\u00d7n tensors of rank r, Yuan and Zhang'16 prove recovery from r^{1/2}n^{3/2} samples, which is not the information-theoretic rate (O~(rn)). I was not able to locate the corresponding information-theoretic rate results in the other two cited papers. I would like to kindly suggest to include exact statements of the prior work that achieves information-theoretic bounds in the appendix, as they are quite rare and are directly related to the main contribution of this paper.\n\nCor 4.3 does not seem to achieve the information-theoretic bound unless the rank k=O(1). Do I understand correctly that if e=0, Cor 4.3 proves recovery from essentially k4\u22c5\u03c1 entries (as opposed to k\u22c5\u03c1)? If that's correct, I believe the authors should either explicitly say that k=O(1), or they should be more explicit in the description of their results.\n\nThe abstract and the text of the paper contain the claim: \"We prove that our algorithm converges in a linear (in numerical tolerance) number of oracle steps, while achieving the information-theoretic rate.\" However, the nature of the oracle does not seem to be mentioned until the end of the paper. In particular, it is not mentioned that this oracle solves an NP-hard problem. I believe those are important details, which if mentioned early give a better understanding of the results of the paper.\n\nAre there any additional simple assumptions that guarantee that the oracle can be implemented in polynomial time? This will give specific assumptions under which your algorithm for (8) works in polynomial time. Note that for standard nuclear norm (NN) minimization there are some regimes in which problem can be solved in polynomial time, even though the general problem is NP-hard. For example, using SOS, NN minimization is known for tensors with orthogonal components by Potechin-Steurer'17 and for low-rank tensors with random components by Kivva-Potechin'20.\n\nProp. 3.1 and Cor 3.3 are a bit hard to understand, and I needed to look into the paper of Lecue et al to understand the claim. For example, in Prop 3.1, what is y? This variable seems to have meaning only when comes in pair with x, i.e., in pair x\u27e8i\u27e9,y\u27e8i\u27e9. It will also simplify reading if the definition of E used in L197 is included. I believe it just stands for average over all entries of the tensor, but there are other ways to interpret it. What is the difference between \u03c8 and \u03c8^ in Prop. 4.1 and Cor 4.3?\n\nDid you try to run your algorithm on any real-world dataset? How does it compare to state-of-the-art approaches on such datasets? How does your algorithm compare to Liu-Moitra NeurIPS'20?\n\nIn line 199 it seems that o(\u03c1/n) should be O(\u03c1/n). How can \u03ben be faster than O(\u03c1/n) if this is an information theoretic bound? Can you clarify this claim please? Also, in the context of tensor completion 2\u03c1>\u03c0>n.\n\nWhat do you mean by \"NP-hard to solve to any accuracy\"? These words can correspond to different orders of quantifiers, which would result in different claims.  \n\nL 226 has claim: \"Although it is NP-hard, there is substantial structure that enables efficient numerical computation of global minima of (8).\" Efficient computation typically stands for \"polynomial time\", which suggests that you claim P = NP. Clearly, that's not what you claim. I would kindly suggest to reformulate or clarify this claim. \n\nIn line 249 you claim that your implementation converges to the global optima. However, the experimental results, in the regimes where your theory suggests almost exact recovery (Table 2), have an error in the range 0.01-0.16 (which is much better than other approaches), but is still far from 0. Can you please clarify this? \n\nLine 30 says \"exponentially more samples than the information-theoretic rate\". Can you please clarify what do you mean? Exponential in which variable? The number of samples is always at most linear in the size of the tensor.\nLimitations: The paper proposes an approach that is NP-hard in the worst case and this paper does not seem to prove any runtime guarantees. However, the authors show that the problem can be solved in a linear number of calls to an integer-programming oracle (which is still NP-hard). It will be nice to explore special cases in which a polynomial-time algorithm (say, for oracle)  is available. \nI believe the paper will also significantly benefit from experiments on real-world data.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The authors introduce an algorithm for nonnegative tensor completion. For that, a new tensor norm is defined which is shown to be a convex surrogate of the tensor rank. To define this norm, the authors first show that the convex hull of the ball of the nonnegative rank-1 tensors whose maximum entry is 1 is the same as the convex hull of all the binary rank-1 tensors. Since the latter is a polytope and the binary rank-1 tensors are the vertices of the polytope, linear integer programming techniques can be used to optimize over it. Therefore, the norm of a nonnegative tensor of any rank is defined using such polytopes. The authors further study the norm by proving its NP-hardness and its stochastic complexity, in terms of Rademacher complexity. Finally, it is shown how integer linear programming can be used for efficient computation of the global minima. The numerical results show that the proposed method can achieve better estimation error and is able to complete tensors with fewer samples.",
                "Strengths And Weaknesses": "Strengths: \n\nThe problem of tensor completion is an interesting problem that shows up in different applications from recommender systems to wireless communications. Aside from that, the introduction of a norm that is a convex surrogate of the tensor rank and has nice properties for optimization problems is impactful on its own. \nThe authors study the different aspects of the problem and the proposed norm theoretically, prove the claims, and/or refer the reader to the relevant papers.\nA numerical algorithm is proposed to use the introduced norm for the nonnegative tensor completion problem. Although the proposed norm is NP-hard to calculate to arbitrary accuracy, the proposed algorithm is able to calculate the global minima. This is due to the proposed norm being a 0-1 polytope. \nThe paper is well-structured and the proofs are well-written. The authors discuss the limitations\n\nWeaknesses:\nThere are not many weaknesses. The authors could have moved all or some of the proofs to the appendix. This would have opened some space to provide more intuition to the reader, add some visualizations, explain the algorithm in more detail, and possibly add more experiments. For example, it would have been interesting to evaluate the algorithm for hyperparameters other than the ground truth. This is of great practical importance, as we usually do not have access to the true rank or the true maximum value of the tensor.",
                "Questions": "It would have been interesting to evaluate the algorithm for hyperparameters other than the ground truth.",
                "Limitations": "There is no dedicated \"limitations\" section. But the authors discuss the limitations, such as the solution being limited to nonnegative tensors, the computational complexity, and the running time.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "3 good",
                "Contribution": "4 excellent",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors proposed an approximated algorithm for nonnegative tensor completion that seems to work very efficiently (the claim is in linear time).",
                "Strengths And Weaknesses": "The paper is very well written and the authors present their results in a clear way.\nThe result is definitely original and very important.\nMy only concern is about the authors' claims based on Figures 3 and 4\nThe data for the BCG algorithm in the right panels are far from being linear!\nData in Fig. 3 are very noisy and those in Fig. 4 have a clear upwards curvature, suggesting a more than linear growth for larger n values.\nMoreover, from the numerical experiments is not clear at all whether the algorithm is matching the IT threshold: data supporting this claim are completely missing or should be presented in a more evident way.",
                "Questions": "In order to become fully convincing, the paper should report much stronger numerical evidence of scalability (i.e. linear behaviour with n) and efficiency (i.e. ability to work close to the IT threshold).\nMoreover, I have to admit to being very surprised that an algorithm that performs a local optimization by flipping single variables one at a time is able to reach the optimal solution in general. The authors should discuss the reasons beyond this unreasonable effectiveness.\nI would like to understand whether the apparent very good performance depends on the tensor low-rank (which is not larger than 10 in all numerical experiments shown by the authors). What happens if the tensor rank is increased? Does the algorithm keep working with the same efficiency and scalability?",
                "Limitations": "The authors do not really discuss the issue.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper studies the tensor completion problem for tensors with non-negative entries. The paper proposes a non-negative analog of the nuclear norm, denoted \u2016\u22c5\u2016+ whose 1-ball is defined to be a convex combination of rank-1 0,1-tensors. The paper proposes to solve the problem, dual to \u2016\u22c5\u2016+-minimization to recover unknown non-negative tensor from a subset of observed entries. This approach is a natural analog of the nuclear norm minimization for general tensors. The paper proves that this approach w.h.p. can recover the unknown tensor from an essentially statistically optimal number of unknown samples. The authors prove that this minimization problem is NP-hard. At the same time, they show that the BCG algorithm can solve the problem with a linear number of calls to a linear separation oracle. Moreover, the paper proposes a heuristic algorithm for the oracle and studies its performance on synthetic data.",
                "Strengths And Weaknesses": "Significance: Tensors with non-negative entries frequently appear in practice, hence improved algorithms for this setup are likely to have further applications. This paper proposes a natural idea for the problem, which does not seem to be explored in the prior work. The experimental results presented by the authors show that their heuristic algorithm has better performance on tensors with low non-negative rank compared to some state-of-the-art approaches.\nClarity: The technical proofs seem to be correct and the paper is reasonably well-written. However, there is a number of vague statements, typos, or claims that are potentially overstated. See questions below. Additionally, it will be very helpful for the reader if details of BCG algorithm are included at least in the appendix.\nFinally, the paper uses notation that is non-standard in the literature, which makes it a bit harder to read. For instance, r is typically reserved for the rank of the tensor, while this paper uses k for the rank and ri for the dimensions of the tensor.",
                "Questions": "Can you please clarify what results in the papers cited on lines 33-34 achieve information-theoretic bounds? Are there specific numbered theorems? As far as I know, for n\u00d7n\u00d7n tensors of rank r, Yuan and Zhang'16 prove recovery from r^{1/2}n^{3/2} samples, which is not the information-theoretic rate (O~(rn)). I was not able to locate the corresponding information-theoretic rate results in the other two cited papers. I would like to kindly suggest to include exact statements of the prior work that achieves information-theoretic bounds in the appendix, as they are quite rare and are directly related to the main contribution of this paper.\n\nCor 4.3 does not seem to achieve the information-theoretic bound unless the rank k=O(1). Do I understand correctly that if e=0, Cor 4.3 proves recovery from essentially k4\u22c5\u03c1 entries (as opposed to k\u22c5\u03c1)? If that's correct, I believe the authors should either explicitly say that k=O(1), or they should be more explicit in the description of their results.\n\nThe abstract and the text of the paper contain the claim: \"We prove that our algorithm converges in a linear (in numerical tolerance) number of oracle steps, while achieving the information-theoretic rate.\" However, the nature of the oracle does not seem to be mentioned until the end of the paper. In particular, it is not mentioned that this oracle solves an NP-hard problem. I believe those are important details, which if mentioned early give a better understanding of the results of the paper.\n\nAre there any additional simple assumptions that guarantee that the oracle can be implemented in polynomial time? This will give specific assumptions under which your algorithm for (8) works in polynomial time. Note that for standard nuclear norm (NN) minimization there are some regimes in which problem can be solved in polynomial time, even though the general problem is NP-hard. For example, using SOS, NN minimization is known for tensors with orthogonal components by Potechin-Steurer'17 and for low-rank tensors with random components by Kivva-Potechin'20.\n\nProp. 3.1 and Cor 3.3 are a bit hard to understand, and I needed to look into the paper of Lecue et al to understand the claim. For example, in Prop 3.1, what is y? This variable seems to have meaning only when comes in pair with x, i.e., in pair x\u27e8i\u27e9,y\u27e8i\u27e9. It will also simplify reading if the definition of E used in L197 is included. I believe it just stands for average over all entries of the tensor, but there are other ways to interpret it. What is the difference between \u03c8 and \u03c8^ in Prop. 4.1 and Cor 4.3?\n\nDid you try to run your algorithm on any real-world dataset? How does it compare to state-of-the-art approaches on such datasets? How does your algorithm compare to Liu-Moitra NeurIPS'20?\n\nIn line 199 it seems that o(\u03c1/n) should be O(\u03c1/n). How can \u03ben be faster than O(\u03c1/n) if this is an information theoretic bound? Can you clarify this claim please? Also, in the context of tensor completion 2\u03c1>\u03c0>n.\n\nWhat do you mean by \"NP-hard to solve to any accuracy\"? These words can correspond to different orders of quantifiers, which would result in different claims.  \n\nL 226 has claim: \"Although it is NP-hard, there is substantial structure that enables efficient numerical computation of global minima of (8).\" Efficient computation typically stands for \"polynomial time\", which suggests that you claim P = NP. Clearly, that's not what you claim. I would kindly suggest to reformulate or clarify this claim. \n\nIn line 249 you claim that your implementation converges to the global optima. However, the experimental results, in the regimes where your theory suggests almost exact recovery (Table 2), have an error in the range 0.01-0.16 (which is much better than other approaches), but is still far from 0. Can you please clarify this? \n\nLine 30 says \"exponentially more samples than the information-theoretic rate\". Can you please clarify what do you mean? Exponential in which variable? The number of samples is always at most linear in the size of the tensor.",
                "Limitations": "The paper proposes an approach that is NP-hard in the worst case and this paper does not seem to prove any runtime guarantees. However, the authors show that the problem can be solved in a linear number of calls to an integer-programming oracle (which is still NP-hard). It will be nice to explore special cases in which a polynomial-time algorithm (say, for oracle)  is available. \nI believe the paper will also significantly benefit from experiments on real-world data.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.333,
        "confidence_avg": 3.667,
        "soundness_avg": 3.333,
        "presentation_avg": 3.0,
        "contribution_avg": 3.333,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that this paper makes a significant contribution to the field of nonnegative tensor completion. The proposed algorithm and the introduced norm have been well-studied and theoretically analyzed. The numerical results also demonstrate the effectiveness of the proposed method in terms of estimation error and tensor completion with fewer samples.\n\nReviewer 1 highlights the strengths of the paper, including the impact of the introduced norm, the theoretical analysis, and the well-structured presentation. The reviewer suggests that the authors could have provided more intuition, visualizations, and experiments, but overall, the strengths outweigh the weaknesses.\n\nReviewer 2 acknowledges the efficiency of the proposed algorithm but raises concerns about the claims based on the provided figures. The reviewer suggests that stronger numerical evidence is needed to support the scalability and efficiency claims. Additionally, the reviewer questions the effectiveness of the local optimization approach and suggests further investigation into the algorithm's performance with increased tensor rank.\n\nReviewer 3 recognizes the significance of the proposed approach for tensors with non-negative entries and the experimental results that show improved performance compared to state-of-the-art approaches. However, the reviewer raises several questions and concerns regarding the clarity of certain statements, the information-theoretic bounds, the nature of the oracle, and the runtime guarantees. The reviewer suggests exploring special cases with polynomial-time algorithms and conducting experiments on real-world datasets.\n\nOverall, the reviewers' feedback provides valuable insights into the strengths and weaknesses of the paper. While there are some concerns and areas for improvement, the positive aspects of the paper outweigh the weaknesses. Therefore, I recommend accepting this paper for publication."
    },
    "TPU-KNN:_K_Nearest_Neighbor_Search_at_Peak_FLOP_s": {
        "link": "https://openreview.net//forum?id=OoNmOfYVhEU",
        "pub_url": "https://openreview.net/forum?id=OoNmOfYVhEU",
        "pdf_link": "https://openreview.net//pdf?id=OoNmOfYVhEU",
        "paper_id": "OoNmOfYVhEU",
        "title": "TPU-KNN:_K_Nearest_Neighbor_Search_at_Peak_FLOP_s",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nThe authors design an efficient implementation of nearest neighbor search on a TPU accelerator unit. The implementation is motivated by a refined roofline performance model that takes into account the memory and instruction bottlenecks that are found to be significant and that are not typically optimized for. Empirical results demonstrate that the proposed TPU solver outperforms state-of-the art GPU solvers. The package is available on Tensorflow.\nThe reviewers agree that the paper is well written, well structured and the proposed method can have significant practical impact. \nSome concerns regarding the evaluation came up in the reviews but the additional experiments provided could address most of these concerns. What remains is a question on whether the performance gain over GPU comes from the algorithmic optimization itself or the higher efficiency of the TPU, and whether the algorithmic optimization would be similarly effective on other accelerators. The reviewers agree that performing such an analysis is outside the scope of this work. However, I want to encourage the authors to incorporate additional discussion to help the reader understand what parts of the work are specific to TPUs.\nOverall this paper represents a well executed piece of work at the intersection between algorithm design and systems with an open source package that is available to the community. I recommend acceptance.",
        "reviews": [
            "Reviewer 1: \nSummary: The paper presents a new NN-search algorithm, that reaches the peak performance on TPUs. The paper is based on observations of hardware architectural properties and the so called roofline performance model. The algorithm is implemented for TPUs. The evaluation is done on two TPU versions using two KNN datasets, and compared to several GPU algorithms.\nStrengths And Weaknesses: Strengths\n\nNice connection between theoretical observations and practical results\nGood performance\nCan have significant practical impact\n\nWeaknesses\n\nLimited evaluation, only evaluated on two versions on TPUs, and two datasets\nWould have been interesting to see how general the algorithm is, i.e., would it reach the same performance limits in other hardware platforms also?\nQuestions: \nThe algorithm descriptions (Algorithm 1 and Algorithm 2 (suppl. mtrl)) looks relatively clear and straight-forward to implement on other platforms. Can you elaborate a bit on why it would be such a substantial effort to do?\nLimitations: I think the authors have adequately addressed the limitations of their work.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper presents an ANN algorithm on TPU and analyzes the memory and instruction bandwidth of ANN algorithms.\nStrengths And Weaknesses: Strong Points\n\nThe problem is well-motivated. \nThe related work is comprehensively studied and discussed. And the entire story is easy to follow for readers. \nThe methodology to study the algorithm from the hardware bottlenecks is interesting.\n\nWeak Points\n\nI suggest the authors to include a brief discussion of TPU, e.g., what it can be done and what it can not be done (efficiently).\nThe experimental evaluation is a bit problematic. How about other methods on GPUs/TPUs, e.g., hashing and graph-based methods besides the FAISS baseline?\nIn Figure 3, the highest recall shown for Glove is 0.9. Is there a recall limitation for the proposed algorithm? \nThe technical contribution of the bi-stage partial reduction and scoring is limited.\nQuestions: \nCould we have other methods on GPUs/TPUs, e.g., hashing and graph-based methods besides the FAISS baseline, on more measures, e.g. cosine?\nCould we show that the proposed algorithm can achieve high recalls for most ANN datasets?\nLimitations: I suggest the authors to discuss the limitation of the algorithm, e.g., how to adapt the problem to other common similarity measures.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 4 excellent\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper presents a new algorithm implementation of K nearest neighbor search that is able to increase the arithmetic intensity. The distances between all queries and entries in the database are calculated in L3 BLAS fashion. Then only the top-1 entry is kept in each bin. The bin size can be adjusted based on the requirement of the recall. The roofline analysis shows a better peak throughput while the end-to-end evaluation demonstrates a better throughput-recall trade-off than the previous solutions.\nStrengths And Weaknesses: Strengths\n\nThis paper presents a detailed analytical model of the kernel implementation of the BLAS-based operation. The authors conclude the impact of COPs and introduce the algorithm accordingly.\n\nThe proposed solution is simple yet effective. The adjustment of the bin size provides a simple method to balance recall and throughput.\n\n\nWeaknesses\n\nUnclear hardware motivation. The paper is entitled 'TPU-KNN'. However, throughout this paper, I'm not able to find any information indicating that the proposed algorithm requires any special architectural support from TPU rather than other accelerators. It seems that the same analysis could also apply to GPU or other accelerators. \n\nVague definition of COPs. I cannot understand the usage of the concept of coefficient-wise operations (COPs). In Table 1, comparing with the datasheet of A100/V100, I can understand COPs as a FLOP in the vector cores (or SMs in NV's terminology) while the FLOP means a half-precision FLOP in the tensor core. However, in the later description like Algorithm 1, one COP seems to be a general non-matrix operation without considering the problem size. In this case, one COP, for example, vectorized comparison, could include multiple FLOPs and seems to be unmatched by what is presented in Table 1.\n\nIncomplete Evaluation. Based on what I've mentioned in 1, the evaluation part lacks a fair baseline. I can understand the advantage of recall of the proposed algorithm. However, it is hard to understand whether the performance gain over GPU comes from the algorithm itself or the higher efficiency of TPU. To isolate this factor, the authors should either provide the result of the proposed algorithm implemented on GPUs or the baseline algorithms implemented on TPU.\nQuestions: \nIs the proposed algorithm specialized for TPU? If it is, what special architectural support from TPU does it utilize?\n\nHow do you define ONE COP? For example, are vectorized comparisons between two 256 arrays and the comparison between two 16 arrays each counted as one COP? If not, how should I interpret the data presented in Table 1?\n\nCould you provide a direct comparison of the proposed algorithm on the same hardware platform?\nLimitations: The authors discussed the limitation of the current implementation.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper studies using TPU for approximate nearest neighbor search. With careful analysis, it finds that search performance is bound by memory access and coefficient-wise operation instead of distance computation. Thus, it proposes to conduct partial reduce to reduce memory access such that search can reach peak FLOPs. Experiment results show that the proposed solution outperforms existing ones in both QPS and recall.\nStrengths And Weaknesses: Strength\n\n   The extended roofline analysis is interesting and shows the bottleneck of nearest neighbor search with TPU.\n\n   The proposed partial reduce scheme reduces the amount of memory access and comes with theoretical analysis.\n\n   The experiment results show that the proposed solution has good performance.\n\n\nWeakness\n\n   It would improve the paper if the authors can give a brief introduction about the characteristics of GPU and TPU. Are TPUs widely available as a commodity hardware?\n\n   The proposed solution may also work for GPUs as GPUs are also limited by memory access from Table 1. Moreover, as shown in Figure 2, the proposed solution is still bound by coefficient-wise operations for Euclidean distance search. Any thoughts on reducing the number of coefficient-wise operations?\n\n   The experiment study is far from the NeurIPS standard. Does the method still outperform the partial search methods (e.g., IVF) when the dataset is large (e.g., SIFT10M or 100M)? How does the proposed method perform when changing the window size W?\nQuestions: See weakness.\nLimitations: Yes\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The paper presents a new NN-search algorithm, that reaches the peak performance on TPUs. The paper is based on observations of hardware architectural properties and the so called roofline performance model. The algorithm is implemented for TPUs. The evaluation is done on two TPU versions using two KNN datasets, and compared to several GPU algorithms.",
                "Strengths And Weaknesses": "Strengths\n\nNice connection between theoretical observations and practical results\nGood performance\nCan have significant practical impact\n\nWeaknesses\n\nLimited evaluation, only evaluated on two versions on TPUs, and two datasets\nWould have been interesting to see how general the algorithm is, i.e., would it reach the same performance limits in other hardware platforms also?",
                "Questions": "The algorithm descriptions (Algorithm 1 and Algorithm 2 (suppl. mtrl)) looks relatively clear and straight-forward to implement on other platforms. Can you elaborate a bit on why it would be such a substantial effort to do?",
                "Limitations": "I think the authors have adequately addressed the limitations of their work.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper presents an ANN algorithm on TPU and analyzes the memory and instruction bandwidth of ANN algorithms.",
                "Strengths And Weaknesses": "Strong Points\n\nThe problem is well-motivated. \nThe related work is comprehensively studied and discussed. And the entire story is easy to follow for readers. \nThe methodology to study the algorithm from the hardware bottlenecks is interesting.\n\nWeak Points\n\nI suggest the authors to include a brief discussion of TPU, e.g., what it can be done and what it can not be done (efficiently).\nThe experimental evaluation is a bit problematic. How about other methods on GPUs/TPUs, e.g., hashing and graph-based methods besides the FAISS baseline?\nIn Figure 3, the highest recall shown for Glove is 0.9. Is there a recall limitation for the proposed algorithm? \nThe technical contribution of the bi-stage partial reduction and scoring is limited.",
                "Questions": "Could we have other methods on GPUs/TPUs, e.g., hashing and graph-based methods besides the FAISS baseline, on more measures, e.g. cosine?\nCould we show that the proposed algorithm can achieve high recalls for most ANN datasets?",
                "Limitations": "I suggest the authors to discuss the limitation of the algorithm, e.g., how to adapt the problem to other common similarity measures.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "4 excellent",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper presents a new algorithm implementation of K nearest neighbor search that is able to increase the arithmetic intensity. The distances between all queries and entries in the database are calculated in L3 BLAS fashion. Then only the top-1 entry is kept in each bin. The bin size can be adjusted based on the requirement of the recall. The roofline analysis shows a better peak throughput while the end-to-end evaluation demonstrates a better throughput-recall trade-off than the previous solutions.",
                "Strengths And Weaknesses": "Strengths\n\nThis paper presents a detailed analytical model of the kernel implementation of the BLAS-based operation. The authors conclude the impact of COPs and introduce the algorithm accordingly.\n\nThe proposed solution is simple yet effective. The adjustment of the bin size provides a simple method to balance recall and throughput.\n\n\nWeaknesses\n\nUnclear hardware motivation. The paper is entitled 'TPU-KNN'. However, throughout this paper, I'm not able to find any information indicating that the proposed algorithm requires any special architectural support from TPU rather than other accelerators. It seems that the same analysis could also apply to GPU or other accelerators. \n\nVague definition of COPs. I cannot understand the usage of the concept of coefficient-wise operations (COPs). In Table 1, comparing with the datasheet of A100/V100, I can understand COPs as a FLOP in the vector cores (or SMs in NV's terminology) while the FLOP means a half-precision FLOP in the tensor core. However, in the later description like Algorithm 1, one COP seems to be a general non-matrix operation without considering the problem size. In this case, one COP, for example, vectorized comparison, could include multiple FLOPs and seems to be unmatched by what is presented in Table 1.\n\nIncomplete Evaluation. Based on what I've mentioned in 1, the evaluation part lacks a fair baseline. I can understand the advantage of recall of the proposed algorithm. However, it is hard to understand whether the performance gain over GPU comes from the algorithm itself or the higher efficiency of TPU. To isolate this factor, the authors should either provide the result of the proposed algorithm implemented on GPUs or the baseline algorithms implemented on TPU.",
                "Questions": "Is the proposed algorithm specialized for TPU? If it is, what special architectural support from TPU does it utilize?\n\nHow do you define ONE COP? For example, are vectorized comparisons between two 256 arrays and the comparison between two 16 arrays each counted as one COP? If not, how should I interpret the data presented in Table 1?\n\nCould you provide a direct comparison of the proposed algorithm on the same hardware platform?",
                "Limitations": "The authors discussed the limitation of the current implementation.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper studies using TPU for approximate nearest neighbor search. With careful analysis, it finds that search performance is bound by memory access and coefficient-wise operation instead of distance computation. Thus, it proposes to conduct partial reduce to reduce memory access such that search can reach peak FLOPs. Experiment results show that the proposed solution outperforms existing ones in both QPS and recall.",
                "Strengths And Weaknesses": "Strength\n\n   The extended roofline analysis is interesting and shows the bottleneck of nearest neighbor search with TPU.\n\n   The proposed partial reduce scheme reduces the amount of memory access and comes with theoretical analysis.\n\n   The experiment results show that the proposed solution has good performance.\n\n\nWeakness\n\n   It would improve the paper if the authors can give a brief introduction about the characteristics of GPU and TPU. Are TPUs widely available as a commodity hardware?\n\n   The proposed solution may also work for GPUs as GPUs are also limited by memory access from Table 1. Moreover, as shown in Figure 2, the proposed solution is still bound by coefficient-wise operations for Euclidean distance search. Any thoughts on reducing the number of coefficient-wise operations?\n\n   The experiment study is far from the NeurIPS standard. Does the method still outperform the partial search methods (e.g., IVF) when the dataset is large (e.g., SIFT10M or 100M)? How does the proposed method perform when changing the window size W?",
                "Questions": "See weakness.",
                "Limitations": "Yes",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.75,
        "confidence_avg": 4.25,
        "soundness_avg": 2.75,
        "presentation_avg": 3.25,
        "contribution_avg": 2.25,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the paper presents a technically solid and impactful contribution in the field of approximate nearest neighbor search. The algorithm proposed in the paper shows good performance and has the potential for significant practical impact. The reviewers have highlighted the strengths of the paper, including the clear connection between theoretical observations and practical results, the comprehensive study of related work, and the simple yet effective methodology.\n\nWhile there are some limitations and weaknesses pointed out by the reviewers, such as the limited evaluation on only two versions of TPUs and two datasets, and the lack of a fair baseline comparison, these concerns do not outweigh the positive aspects of the paper. The reviewers have also expressed confidence in their assessments and have not raised any major concerns regarding evaluation, resources, reproducibility, or ethical considerations.\n\nTherefore, based on the reviews and considering the strictness level of 0.5 for this conference, I recommend accepting the paper. The confidence level is certain, as the positive aspects of the paper outweigh the limitations and weaknesses raised by the reviewers."
    },
    "Equivariant_Networks_for_Crystal_Structures": {
        "link": "https://openreview.net//forum?id=0Dh8dz4snu",
        "pub_url": "https://openreview.net/forum?id=0Dh8dz4snu",
        "pdf_link": "https://openreview.net//pdf?id=0Dh8dz4snu",
        "paper_id": "0Dh8dz4snu",
        "title": "Equivariant_Networks_for_Crystal_Structures",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nThis paper proposes an extension of recent work on equivariant graph neural networks to account for equivariance to crystalline symmetries. This work has the potential to be quite impactful since modeling crystalline structures is important and has received little attention compared to the modeling of molecular systems. \nTwo reviewers argued in favor of acceptance, citing the nontrivial nature of the problem and the solution. They also commented on the high quality of the writing. Lastly, the positive reviewers found the results promising after discussion. The negative reviewer focused on missing background material and lack of novelty of the proposed method. I am confident that the authors have / will continue to address the concerns of the negative referee by adding extra background materials and definitions for common terms. I believe that this paper makes enough novel progress on a difficult problem to be worth accepting to NeurIPS despite the fact that it builds on prior work.",
        "reviews": [
            "Reviewer 1: \nSummary: The work introduces a method to design neural networks that are equivariant w.r.t. crystal symmetries, which arise in the description of materials structures. Given the success of symmetry as an inductive bias in molecular and materials science, based so far mostly on the groups SO(3), E(3), and the permutation group, the authors hypothesise that explicitly \"baking in\" equivariance w.r.t. crystal symmetries may provide a useful inductive bias for machine learning on crystals. First an introduction is given to a few basic concepts of solid-state physics such as lattices, point groups, and space groups based on the graphene example. Then the equivariant network architecture is described as a form of equivariant message passing. Equivariance is achieved by defining a weight-tying pattern that respects the symmetry of the crystal structure. Finally, the method is demonstrated on a series of targets available from Materials Project data. The method performs favorably.\nStrengths And Weaknesses: Strengths: The paper provides an elegant solution to a non-trivial problem with potential applications in materials science. The solution to this problem is non-trivial and clean. The presentation of the mathematics as well as the required background in solid-state physics / crystal symmetry is well-developed using the classic graphene text book example and understandable even for an audience without a physics/materials science background. The experiment is being done with great care w.r.t. data set selection. \nWeaknesses: The paper only shows a single, simple experiment reporting average metrics on a common benchmark data set. While it shows marginal improvements over existing methods, the method provides no additional insights into specific materials or an attempt to discover new ones. It is not tested in the wild on a real materials problem. There is also no effect undertaken into understanding why the method works. Design choices are not tested or compared to others. The work would also strongly benefit from analyzing the inference time required on these networks. In particular the choice to construct a 2x2x2 supercell seems like it could rapidly lead to high inference cost. This leaves open many questions about whether such a system has potential for real-world impact. Finally, the presentation of the actual model leaves open many question. It is not immediately apparent how exactly the parameter-sharing MLPs are implemented.\nQuestions: \n\"In this paper, we address the problem of designing equivariant layers for supervised learning on materials.\" - why is this a problem? It is not clear a prior why equivariance (as opposed to invariance) is a desirable property as most target properties are invariant under the prescribed symmetries.\n\nThe introduction could strongly benefit from some description of when crystal symmetries are important. E.g. there are many applications in computational materials science where crystal symmetry is not helpful (e.g. molecular dynamics, relaxations, ... ), but only the symmetries of E(3) as well as the symmetric group are still valid. On the other hand, current methods can only incorporate these and would not properly exploit additional symmetry information as proposed here. This should be laid out more clearly.\n\nTypo: \"tilling the space\" should likely be \"filling the space\"?\n\nI wonder if it might be beneficial to use a Bessel embedding instead of a Gaussian one? A number of works in the ML potential field have adopted this and it's been found to give improved performance, see Klicpera, J., Gro\u00df, J., & G\u00fcnnemann, S. (2020). Directional message passing for molecular graphs. arXiv preprint arXiv:2003.03123. for example. \n\n\"This has the benefit of simplicity while still allowing a complete description of the input structure\" --> it's not clear why a Gaussian encoding vs just the interatomic distance is simpler, this sentence should be clarified. Distance is equally complete + simple, if those were the only 2 criterions (I realize it performs better in practice, but these are not the reasons why).\n\nSection 6.2 would benefit from some more detail. A lot of time is (rightfully) spent on group theory of crystals but then the actual core idea is introduced only briefly. This could be explained in more detail and ideally also giving some theoretical background. In particular, it is not clear how exactly the parameter-sharing is implemented: there is this sentence \"For our model, we choose functions \\phi_e^{\\alpha(i, j)} and \\phi_h^{\\beta(i, j)} to be MLPs with one hidden layer\", but it is not clear whether there is one separate MLP for each possible pair (i, j)? The appendix further confuses this by stating that \"the weights for the hidden layer and output layers are shared across all \\alpha(i, j)\" --> this presentation would strongly benefit from more detail, in particular how the parameter-sharing is implemented.\n\nIn the comparison to other methods on MP: it is great that the authors do a proper filtering of the MP structures, this is solid data cleaning. However, when re-training another group's model there is often a chance that one underreports the performance of that model b/c the authors will have a better understanding of their own model's hyperparameters and a stronger incentive to optimize it. While this is in some sense difficult to avoid it would be great if the authors could at least clarify how the hyperparameters for the competing models were defined and if any hyperparameter optimization was performed and if yes, how that compared to the hyperparameter optimization done for ECN. \n\nThe empirical results show only a small improvement. Given that no estimate of the statistical variance of the MAEs is given, it's difficult to say if these improvements are even statistically significant. If computationally feasible, this would strongly benefit from that. In addition, it would be great if the authors could add a (albeit speculative) sentence on why a model that explicitly accounts for crystal symmetry only marginally outperforms models that don't. \n\nIn the conclusion the authors say \"Such models could be used for other tasks on materials such as dynamics prediction [...]\" --> this is difficult to imagine since any crystal symmetry would immediately be gone under molecular dynamics? Or was something different meant here? If yes, please specify more clearly.\n\nThe authors at some point outline 2 strategies for encoding atoms, one based simply on a one-hot of the atomic number, one based on row+column of the PT and on a binary +U feature -- I could not find these experiments anywhere? Did I miss them?\nLimitations: N/A\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper generalizes the message passing operation which preserve Sn equivariant to more general permutation groups, specifically crystalline symmetry groups, by parameter sharing pattern respecting equivariance condition. Models with the proposed message passing operation achieve comparable results with SOTA on the Materials Project dataset.\nThe idea is to improve the expressivity of GNNs by building an 8-time larger supercell and imposing parameter sharing using space group symmetry operations.\nIt takes me quite long time to review this paper, partly because I have less background of Crystal. I think this manuscript would be suitable for publication on journals like JCTC, rather than a machine learning conference.\nStrengths And Weaknesses: Strength:\n\nThe motivation that full permutation equivariance might be overly restrictive is insightful and interesting.\nThe empirical result is interesting.\n\nWeakness:\n\nThe presentation is unclear. The paper could be more self-contained if \u201cVoronoi face\u201d and \u201cCordero radii\u201d are explained in the main text or appendix. In line 199-209, there should be definition of SN, SP, SN and SP\u00d7N. It seems that SN means permutations within unit cell, SP means permutations across unit cells (in supercell) derived from point group P, and SP\u00d7N means all permutations?\nExperiments are only conducted on one dataset, using different training and test splits and preprocessing scheme from previous works. The improvement is marginal according to line 301-302: \u201cThe SP version offers slightly better performance than the P1\u00af model overall\u201d \u2013 the differences comparing to previous work are similar to the different between two proposed variants in Table 1.\nAs line 302-303 suggest, having more symmetry than necessary might be beneficial. The absence of ECN-\u201cfull permutation equivariance\u201d in experiment drastically weaken the empirical result, i.e. the result cannot support the core proposition of this paper, that generalized permutation equivariance is better than full permutation equivariance (both input supercell) for crystal data.\nNovelty of the proposed method is limited. The proposed method could be viewed as an application of [49] Equivariance Through Parameter-Sharing for crystal symmetry group.\nQuestions: \nI am still a little confused what the authors mean by P1 and Sp symmetry group exactly. This is the symmetry of the P1 group: http://img.chem.ucl.ac.uk/sgp/large/002az1.htm. I don\u2019t know what the authors mean by Sp group, which is not in the space group table. Example 6.1 is for a P2 group, which is different from P1 and Sp group.\n\n\nFor the experiments, the authors created a new dataset with 33971 crystals. They assume two structures are redundant if they have the same space group and chemical composition. This is problematic because different crystal structures can have both the same group and chemical composition.\nFor data preprocessing in Appendix A4, motivation of the last step is not clear. Why do they only include insulators?\nThe improvements with respect to SchNet and CGCNN are relatively small. The author didn\u2019t consider latest methods like ALIGNN. Matbench provides a comparison between different models which could be used as a benchmark dataset (https://matbench.materialsproject.org/)\nLimitations: See above.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper studies bespoke equivariant neural architectures for processing crystal structures. Firstly, it is observed that crystals are discrete structures that exhibit substantially richer symmetries than the permutation group (which would normally used for abstract graph representations), which might allow for relaxed equivariance conditions, and hence, stronger architectures. Additionally, the authors show how to combine symmetry groups coming from various crystal structures within the same dataset, through the use of carefully constructed products of groups. The resulting equivariant architectures show promising results on a standard material science benchmark.\nStrengths And Weaknesses: Originality:\nFrom the methodological point of view, the proposed architectures and theoretical treatment appear like a direct application of the principles of geometric deep learning to the specific case of crystal symmetries. The idea of using the direct product of symmetry group is also in line with the GDL principles; see, for example, \"An equivariant Bayesian convolutional network predicts recombination hotspots and accurately resolves binding motifs\" from Brown & Lunter, which uses similar ideas to construct reverse-complement-symmetric architectures (for the processing of DNA).\nI do not have significant background in material science applications, therefore I cannot say for sure to what extent such ideas have already been explored in the context of crystals. However, the authors' aim to bring such symmetries into the spotlight, especially in light of na\u00efve applications of graph neural networks to such problems, are certainly remarkable and deserve credit in either case.\nQuality:\nI find the proposed model to be solidly theoretically grounded, and the results to be reasonable and showing benefits against relevant GNN baselines. Of course, as before, I may not have sufficient context on what are the most meaningful architectures in this domain to use.\nClarity:\nThis is one of the paper's absolute strongpoints. The use of guided examples (particularly in the case of graphene) are remarkably well-made and illustrate the points the paper makes perfectly. The paper was a delight to read as a result.\nSignificance:\nThe main concern for me in the authors' evaluation is the lack of error bars, which the authors stated they are unable to provide due to computational resources. Would it be possible at least to get 1-2 additional seeds for the authors' proposal, in order to get some sense of the variance of the results? Otherwise, the results appear significant, but only one benchmark dataset is used (albeit, one that seems to be a standard choice for materials science).\nOverall:\nWhen weighing in on the different aspects of this paper's presentation, I tend to be in favour of accepting it. It presents a great application area for geometric deep learning, a principled investigation of how GDL can be applied in this space, and all of this is presented in a way that is very likely to reduce the barrier of entry into the field. I look forward to the release of the dataset and other artefacts.\nQuestions: Q1. Could you comment on whether there exist any other suitable baselines and/or benchmark datasets you could have used, provided you had more computational power at your disposal? \nQ2. Would you give any \"items of future work\" for interested authors who do have access to more computation?\nQ3. Could you provide at least 1-2 additional seeds for some of the models you evaluated, to get a feel for the variance?\nQ4. Does this paper, to the best of your knowledge, present the first rigorous exploration of geometric DL over crystal inputs, or are there any pieces of related work you would highlight? Some related works are already listed in the paper, but it is unclear if any of them are mindful of the symmetry structures you point out.\nLimitations: No concerns.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The work introduces a method to design neural networks that are equivariant w.r.t. crystal symmetries, which arise in the description of materials structures. Given the success of symmetry as an inductive bias in molecular and materials science, based so far mostly on the groups SO(3), E(3), and the permutation group, the authors hypothesise that explicitly \"baking in\" equivariance w.r.t. crystal symmetries may provide a useful inductive bias for machine learning on crystals. First an introduction is given to a few basic concepts of solid-state physics such as lattices, point groups, and space groups based on the graphene example. Then the equivariant network architecture is described as a form of equivariant message passing. Equivariance is achieved by defining a weight-tying pattern that respects the symmetry of the crystal structure. Finally, the method is demonstrated on a series of targets available from Materials Project data. The method performs favorably.",
                "Strengths And Weaknesses": "Strengths: The paper provides an elegant solution to a non-trivial problem with potential applications in materials science. The solution to this problem is non-trivial and clean. The presentation of the mathematics as well as the required background in solid-state physics / crystal symmetry is well-developed using the classic graphene text book example and understandable even for an audience without a physics/materials science background. The experiment is being done with great care w.r.t. data set selection. \nWeaknesses: The paper only shows a single, simple experiment reporting average metrics on a common benchmark data set. While it shows marginal improvements over existing methods, the method provides no additional insights into specific materials or an attempt to discover new ones. It is not tested in the wild on a real materials problem. There is also no effect undertaken into understanding why the method works. Design choices are not tested or compared to others. The work would also strongly benefit from analyzing the inference time required on these networks. In particular the choice to construct a 2x2x2 supercell seems like it could rapidly lead to high inference cost. This leaves open many questions about whether such a system has potential for real-world impact. Finally, the presentation of the actual model leaves open many question. It is not immediately apparent how exactly the parameter-sharing MLPs are implemented.",
                "Questions": "\"In this paper, we address the problem of designing equivariant layers for supervised learning on materials.\" - why is this a problem? It is not clear a prior why equivariance (as opposed to invariance) is a desirable property as most target properties are invariant under the prescribed symmetries.\n\nThe introduction could strongly benefit from some description of when crystal symmetries are important. E.g. there are many applications in computational materials science where crystal symmetry is not helpful (e.g. molecular dynamics, relaxations, ... ), but only the symmetries of E(3) as well as the symmetric group are still valid. On the other hand, current methods can only incorporate these and would not properly exploit additional symmetry information as proposed here. This should be laid out more clearly.\n\nTypo: \"tilling the space\" should likely be \"filling the space\"?\n\nI wonder if it might be beneficial to use a Bessel embedding instead of a Gaussian one? A number of works in the ML potential field have adopted this and it's been found to give improved performance, see Klicpera, J., Gro\u00df, J., & G\u00fcnnemann, S. (2020). Directional message passing for molecular graphs. arXiv preprint arXiv:2003.03123. for example. \n\n\"This has the benefit of simplicity while still allowing a complete description of the input structure\" --> it's not clear why a Gaussian encoding vs just the interatomic distance is simpler, this sentence should be clarified. Distance is equally complete + simple, if those were the only 2 criterions (I realize it performs better in practice, but these are not the reasons why).\n\nSection 6.2 would benefit from some more detail. A lot of time is (rightfully) spent on group theory of crystals but then the actual core idea is introduced only briefly. This could be explained in more detail and ideally also giving some theoretical background. In particular, it is not clear how exactly the parameter-sharing is implemented: there is this sentence \"For our model, we choose functions \\phi_e^{\\alpha(i, j)} and \\phi_h^{\\beta(i, j)} to be MLPs with one hidden layer\", but it is not clear whether there is one separate MLP for each possible pair (i, j)? The appendix further confuses this by stating that \"the weights for the hidden layer and output layers are shared across all \\alpha(i, j)\" --> this presentation would strongly benefit from more detail, in particular how the parameter-sharing is implemented.\n\nIn the comparison to other methods on MP: it is great that the authors do a proper filtering of the MP structures, this is solid data cleaning. However, when re-training another group's model there is often a chance that one underreports the performance of that model b/c the authors will have a better understanding of their own model's hyperparameters and a stronger incentive to optimize it. While this is in some sense difficult to avoid it would be great if the authors could at least clarify how the hyperparameters for the competing models were defined and if any hyperparameter optimization was performed and if yes, how that compared to the hyperparameter optimization done for ECN. \n\nThe empirical results show only a small improvement. Given that no estimate of the statistical variance of the MAEs is given, it's difficult to say if these improvements are even statistically significant. If computationally feasible, this would strongly benefit from that. In addition, it would be great if the authors could add a (albeit speculative) sentence on why a model that explicitly accounts for crystal symmetry only marginally outperforms models that don't. \n\nIn the conclusion the authors say \"Such models could be used for other tasks on materials such as dynamics prediction [...]\" --> this is difficult to imagine since any crystal symmetry would immediately be gone under molecular dynamics? Or was something different meant here? If yes, please specify more clearly.\n\nThe authors at some point outline 2 strategies for encoding atoms, one based simply on a one-hot of the atomic number, one based on row+column of the PT and on a binary +U feature -- I could not find these experiments anywhere? Did I miss them?",
                "Limitations": "N/A",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper generalizes the message passing operation which preserve Sn equivariant to more general permutation groups, specifically crystalline symmetry groups, by parameter sharing pattern respecting equivariance condition. Models with the proposed message passing operation achieve comparable results with SOTA on the Materials Project dataset.\nThe idea is to improve the expressivity of GNNs by building an 8-time larger supercell and imposing parameter sharing using space group symmetry operations.\nIt takes me quite long time to review this paper, partly because I have less background of Crystal. I think this manuscript would be suitable for publication on journals like JCTC, rather than a machine learning conference.",
                "Strengths And Weaknesses": "Strength:\n\nThe motivation that full permutation equivariance might be overly restrictive is insightful and interesting.\nThe empirical result is interesting.\n\nWeakness:\n\nThe presentation is unclear. The paper could be more self-contained if \u201cVoronoi face\u201d and \u201cCordero radii\u201d are explained in the main text or appendix. In line 199-209, there should be definition of SN, SP, SN and SP\u00d7N. It seems that SN means permutations within unit cell, SP means permutations across unit cells (in supercell) derived from point group P, and SP\u00d7N means all permutations?\nExperiments are only conducted on one dataset, using different training and test splits and preprocessing scheme from previous works. The improvement is marginal according to line 301-302: \u201cThe SP version offers slightly better performance than the P1\u00af model overall\u201d \u2013 the differences comparing to previous work are similar to the different between two proposed variants in Table 1.\nAs line 302-303 suggest, having more symmetry than necessary might be beneficial. The absence of ECN-\u201cfull permutation equivariance\u201d in experiment drastically weaken the empirical result, i.e. the result cannot support the core proposition of this paper, that generalized permutation equivariance is better than full permutation equivariance (both input supercell) for crystal data.\nNovelty of the proposed method is limited. The proposed method could be viewed as an application of [49] Equivariance Through Parameter-Sharing for crystal symmetry group.",
                "Questions": "I am still a little confused what the authors mean by P1 and Sp symmetry group exactly. This is the symmetry of the P1 group: http://img.chem.ucl.ac.uk/sgp/large/002az1.htm. I don\u2019t know what the authors mean by Sp group, which is not in the space group table. Example 6.1 is for a P2 group, which is different from P1 and Sp group.\n\n\nFor the experiments, the authors created a new dataset with 33971 crystals. They assume two structures are redundant if they have the same space group and chemical composition. This is problematic because different crystal structures can have both the same group and chemical composition.\nFor data preprocessing in Appendix A4, motivation of the last step is not clear. Why do they only include insulators?\nThe improvements with respect to SchNet and CGCNN are relatively small. The author didn\u2019t consider latest methods like ALIGNN. Matbench provides a comparison between different models which could be used as a benchmark dataset (https://matbench.materialsproject.org/)",
                "Limitations": "See above.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper studies bespoke equivariant neural architectures for processing crystal structures. Firstly, it is observed that crystals are discrete structures that exhibit substantially richer symmetries than the permutation group (which would normally used for abstract graph representations), which might allow for relaxed equivariance conditions, and hence, stronger architectures. Additionally, the authors show how to combine symmetry groups coming from various crystal structures within the same dataset, through the use of carefully constructed products of groups. The resulting equivariant architectures show promising results on a standard material science benchmark.",
                "Strengths And Weaknesses": "Originality:\nFrom the methodological point of view, the proposed architectures and theoretical treatment appear like a direct application of the principles of geometric deep learning to the specific case of crystal symmetries. The idea of using the direct product of symmetry group is also in line with the GDL principles; see, for example, \"An equivariant Bayesian convolutional network predicts recombination hotspots and accurately resolves binding motifs\" from Brown & Lunter, which uses similar ideas to construct reverse-complement-symmetric architectures (for the processing of DNA).\nI do not have significant background in material science applications, therefore I cannot say for sure to what extent such ideas have already been explored in the context of crystals. However, the authors' aim to bring such symmetries into the spotlight, especially in light of na\u00efve applications of graph neural networks to such problems, are certainly remarkable and deserve credit in either case.\nQuality:\nI find the proposed model to be solidly theoretically grounded, and the results to be reasonable and showing benefits against relevant GNN baselines. Of course, as before, I may not have sufficient context on what are the most meaningful architectures in this domain to use.\nClarity:\nThis is one of the paper's absolute strongpoints. The use of guided examples (particularly in the case of graphene) are remarkably well-made and illustrate the points the paper makes perfectly. The paper was a delight to read as a result.\nSignificance:\nThe main concern for me in the authors' evaluation is the lack of error bars, which the authors stated they are unable to provide due to computational resources. Would it be possible at least to get 1-2 additional seeds for the authors' proposal, in order to get some sense of the variance of the results? Otherwise, the results appear significant, but only one benchmark dataset is used (albeit, one that seems to be a standard choice for materials science).\nOverall:\nWhen weighing in on the different aspects of this paper's presentation, I tend to be in favour of accepting it. It presents a great application area for geometric deep learning, a principled investigation of how GDL can be applied in this space, and all of this is presented in a way that is very likely to reduce the barrier of entry into the field. I look forward to the release of the dataset and other artefacts.",
                "Questions": "Q1. Could you comment on whether there exist any other suitable baselines and/or benchmark datasets you could have used, provided you had more computational power at your disposal? \nQ2. Would you give any \"items of future work\" for interested authors who do have access to more computation?\nQ3. Could you provide at least 1-2 additional seeds for some of the models you evaluated, to get a feel for the variance?\nQ4. Does this paper, to the best of your knowledge, present the first rigorous exploration of geometric DL over crystal inputs, or are there any pieces of related work you would highlight? Some related works are already listed in the paper, but it is unclear if any of them are mindful of the symmetry structures you point out.",
                "Limitations": "No concerns.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.667,
        "confidence_avg": 3.0,
        "soundness_avg": 3.0,
        "presentation_avg": 3.0,
        "contribution_avg": 2.667,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that this paper presents a technically solid and well-motivated approach to designing equivariant neural networks for materials science. The paper provides an elegant solution to the problem of incorporating crystal symmetries into machine learning models, and the experimental results show promising performance on a standard benchmark dataset.\n\nWhile there are some minor weaknesses pointed out by the reviewers, such as the lack of additional experiments and the absence of error bars, these do not outweigh the strengths of the paper. The clarity of the presentation and the originality of the proposed method are particularly commendable.\n\nOverall, this paper makes a significant contribution to the field of geometric deep learning applied to crystal structures. Therefore, I recommend accepting it for publication."
    },
    "Gradient_Descent_Is_Optimal_Under_Lower_Restricted_Secant_Inequality_And_Upper_Error_Bound": {
        "link": "https://openreview.net//forum?id=s1yaWFDLxVG",
        "pub_url": "https://openreview.net/forum?id=s1yaWFDLxVG",
        "pdf_link": "https://openreview.net//pdf?id=s1yaWFDLxVG",
        "paper_id": "s1yaWFDLxVG",
        "title": "Gradient_Descent_Is_Optimal_Under_Lower_Restricted_Secant_Inequality_And_Upper_Error_Bound",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nA solid theoretical paper with fine execution that establishes the optimality of the vanilla gradient descent method in a class of functions extending the well-studied class of smooth and strongly convex functions. Please make sure to take into account the insightful feedback given by the reviewers in the revised version.",
        "reviews": [
            "Reviewer 1: \nSummary: Building on a series of work that explored alternative assumptions to smoothness and strong-convexity, that still lead to linear convergence of gradient descent but hold more generally, the submission presents an analysis of first order methods on a pair of such conditions; the restricted secant inequality lower bound and smoothness towards the optimum as the upper error bound. The results show that the worst-case convergence of gradient descent on the class of functions satisfying those assumptions is optimal, by providing a matching lower bound for first-order methods. The construction of the lower-bound deviates from the typical construction of quadratic functions using in smooth, convex optimization and uses that the restrictions imposed by the conditions are weaker than smoothness and strong-convexity to hide local deviations.\nStrengths And Weaknesses: To my knowledge, the results presented are new and the proof technique used to obtain the lower bound is technically interesting. The overall presentation of the technical results are reasonably clear. My main concern is on the clarity of the motivations, which I expand on in the next section. Regarding significance, althought not explicitly connected to this line of research in the submission, the results are interesting for the study of the possibility of acceleration under looser conditions than smooth/strong-convex which have attracted attention for applications in ML and explaining the effectiveness of momentum-based methods. This study shows the limitations of some relaxations of smoothness and strong-convexity, showing that acceleration beyond gradient descent is not provable without additional structure.\nQuestions: The introduction relies heavily on the work of Guille-Escuret et al. ([12] in the manuscript) for the motivation of the investigation of the limits of the conditions studied. Motivations specific to the current submission are somewhat missing, and the conclusions are somewhat at odd with the motivations of Guille-Escuret et al., leaving me with some unaddressed questions. Those are not points against the results of the paper, and I believe it is a matter of editing to make the motivations clearer and can be addressed during a discussion period.\n\nWhy focus on the specific conditions in this paper, among the many possible combinations of conditions, even if restricted only to the ones discussed by Guille-Escuret et al.? Have other stronger (in the sense that they would imply the studied condition, up to a change of constants) conditions already been studied?\nOne of the motivations of Guille-Escuret et al. for the study of those conditions was to address the current limitations of the theory for accelerated methods, as in Polyak's Heavy Ball, where the parameter setting used for quadratics does not extend to smooth, strongly-convex functions. The result that Gradient Descent is optimal for this class of problem would suggest that the class considered is too large to be useful for the design of new methods, or contains pathological functions. For example, the construction given for the interpolation, while interesting, indicates that the function has arbitrary many local deviations that are unrelated to each other, leading to the question of whether this relaxation of smoothness/strong-convexity is a valid model to pursue?\n\nApplicability of the assumptions\nSome of the limitations of the work are in regard with the level of applicability of the results. The submission makes the point multiple time that, although the assumptions considered are implied by standard smoothness and strong-convexity assumptions, they are not strictly weaker as their condition number can improve.\nThus the improvement in the rates might be worth the degradation in the dependence on the new condition number, \"provided we can obtain better constants under these conditions\" (L65). This is reiterated in Remark 2.5. While I am sympathetic to this argument---for example, for least-squares, it is known that the strong-convexity constant can be 0 the Polyak-Lojasiewicz condition is always non-zero---the arguments of the paper would be strengthened by a simple, provable example of the gap between pairs of conditions on a problem of interest. Using the notation of Guille-Escuret et al. ([12]), on what problem do we see a benefit from using (RSI-, EB+) instead of smoothness/strong-convexity, that is not already captured by (PL+, *SC-)?\nI acknowledge that the submission also discuss the applicability of the conditions to fitting neural networks (L80-82). However, I would recommend adding a qualifier after \"an impressive feat given the highly non-convex nature of neural networks loss function\" (L82) to avoid overstating their applicability, similar to the qualifying paragraph found in Appendix A after L420.\nLimitations: No concern beyond the lack of a clear-cut use-case for the applicability of the assumptions used here noted above.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper studied the complexity of gradient descent (GD) in RSI- and EB+ settings, which is more general than the common smooth and strongly convex case. The paper provided linear convergence results of GD in this case, and further derived the interpolation conditions and showed the optimality results of GD under this case based on the PEP framework.\nStrengths And Weaknesses: Strength:\n\nThe conciseness of the results, also the analysis covers both upper and lower bound, which is a complete story.\nThe paper is well organized and easy to read.\nThe independence of the interpolation conditions is interesting.\n\nWeakness:\n\nThe assumptions may be still a little restrictive (to be a little picky)\nQuestions: Basically I only have some minor questions:\n\nYou mentioned the optimal set X\u2217 should be convex, which means that the set X\u2217 is connected, right? I have the question because in Appendix A you tried to empirically shows that NN enjoys RSI- & EB+ style trajectory. But the landscape of NN may be complicated, and possibly attains disjoint (or nonconvex) optimal set. So I am confused on the statement \"and therefore, the convergence guarantees of RSI\u2212 & EB+ naturally apply to the optimization of neural networks in this setting.\"\n\nThe independence of interpolation conditions look interesting. Following A. B. Taylor's thesis [32], it seems that the interpolation conditions for both strongly-convex smooth and nonconvex smooth are not independent (am I correct?). As a (kind of) \"intermediate\" setting, the RSI- & EB+ settings will enjoy the independence, which is a little counterintuitive to me. Is there any possible illustration, e.g., analysis technique? It may be better if authors can provide some discussion on the analysis compared to existing literature.\n\n\nSome minor points:\n\nSec 5.2, I may suggest that authors should present the formal definition of HB algorithm, here the \u03b2 should distinguish with that of f\u03f5,\u03b2\nCorllary 1, change \u2227 to \u2229?\nAppendix A, why do you use \"extrapolate\" here, any difference compared to \"interpolate\"?\nLimitations: Yes\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper is a theoretical paper that studies the performance guarantees for gradient descent where the objective satisfies lower restricted secant inequality (weaker than the strong-convexity condition) and an upper error bound (weaker than the smoothness condition) so that this includes some non-convex objectives. The paper also proves that the gradient descent is optimal on this class of functions among all first-order algorithms.\nStrengths And Weaknesses: The paper is well written and is a solid theoretical paper. It is remarkable that the authors can show rigorously that the gradient descent is optimal on the class of functions that satisfy a lower restricted secant inequality and among an upper error bound all first-order algorithms.\nThe weakness of the paper is that even though the paper has a nice theoretical contribution, its practical importance and relevance is less clear to me. The class of objective functions that the author(s) study includes some non-convex functions, but when you have gradient descent, depending on the initialization, the algorithm can easily get stuck at a bad local minimum. Then the optimality discussed in the paper might be restrictive. Also for example, in practice, how do you measure your \u03bc and L? In addition, the optimal stepsize for this class of objective functions is \u03b1=\u03bc/L2, which is smaller than the standard choice \u03b1=2/(\u03bc+L) for the \u03bc-strongly convex and L-smooth objective. I am wondering what is the intuition behind this because \u03bc-strong convexity and L-smoothness can be viewed as a special case under your assumption. What is the intuition that you need to choose smaller stepsize in your setup?\nQuestions: (1) In addition to the questions I mentioned above, one interesting thing I find is that the author(s) show that the gradient descent is optimal on this class of functions among all first-order algorithms. For \u03bc-strongly convex and L-smooth objectives, it is known that Nesterov's accelerated gradient descent and heavy ball method can accelerate. So for your class of functions, the gradient descent is already optimal? What is the intuition behind this? Since your class of functions also include non-convex functions, does this indicate that when you have non-convex objectives, gradient descent might outperform Nesterov's accelerated gradient descent or other momentum-based methods?\n(2) In equation (9), write ''if'' in the text environment.\n(3) In Corollary 1, in the last line, write ''where'' instead of ''Where'' and add a '','' in the equation before the last sentence. Same can be said about Theorem 1.\n(4) In the first line in Theorem 2, it should be ''Let A be''.\n(5) In the second line in the proof of Theorem 2, write ''be the sequence introduced in Lemma 1''.\n(6) In reference [17], nesterov should be Nesterov and please check the other references as well.\nLimitations: It does not seem to me that the author(s) stated the limitations and potential negative societal impacts of their work.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: In this work, the authors considered applying the gradient descent algorithm to functions in the intersection of RSI- and EB+. The intersection set is a generalization of the set of strongly convex and differentiable functions. A matching lower/upper bounds on the convergence rate is derived.\nStrengths And Weaknesses: In this work, the authors extended the results of classical convex optimization and showed that the gradient descent algorithm is optimal for functions in RSI- and EB+. I think the results are interesting to audiences in optimization and machine learning. Furthermore, the presentation of this paper is clear and easy to follow.\nMy major concern is on the importance of the contribution in this work. As the authors mentioned, there are lots of existing literature studying lower/upper conditions. Many of those conditions can also guarantee the linear convergence of gradient-based algorithms; also see my comments in the \"questions\" section. Hence, I am not sure if the contributions in this work are significant and would suggest the authors provide more discussions on the importance of the results.\nQuestions: Major:\n(1) Line 78: since the stochastic gradient descent (SGD) method is considered for the optimization of neural networks, I wonder if the probability of escaping the attraction basin of local minima is sufficiently small. If the escaping probability is non-neglectable, the linear convergence may fail with certain probability and it is unsuitable to claim that RSI- and EB+ provide a guarantee on the linear convergence of SGD.\n(2) In Thm.1 and Thm.2, the optimality gap is characterized by x_i - x_i^* and x_i - x^*. It would be better if the authors can provide a comparison between these two metrics, which is important to the tightness of lower/upper bounds.\n(3) In the proof of Thm.2, it would be better to explicitly show why {x_i} are different points.\n(3) Maybe I missed something, but I think functions in the intersection of RSI- and EB+ also satisfy the Polyak-\u0141ojasiewicz (PL) condition. Under the PL condition, it is already known that descent algorithms with a (small) constant \"step size\" are optimal and converge linearly. Hence, the advantage of the bounds in this work lie in a matching lower/upper bound without a constant factor of difference, which seems marginal. I would suggest the authors provide a more detailed comparison with existing results on PL functions.\n(4) In this experiments, the authors showed that the gradient descent method is better than the heavy-ball method. I wonder if this phenomenon is also observed on other functions in RSI- and EB+, or only appears on this special example. It would be better if more details of this experiments can be provided (e.g., which objective function is constructed).\nMinor: \n(1) Ln.20: it would be better to mention that alpha is the step size.\n(2) Remark 2.2: I wonder if the authors can provide an example of non-convex functions that satisfy RSI-.\n(3) Remark 2.4: the discussion after the first sentence seems unnecessary to me. When comparing RSI- and EB+ to other conditions, people usually assume that the same parameters (mu and L) are used. But I am okay if the authors want to keep this discussion.\n(4) Ln.86: I think the Kurdyka-\u0141ojasiewicz and the Polyak-\u0141ojasiewicz conditions do not \"take the form of a lower and an upper bound on properties of the objective function\", since the gradient and the optimality gap appear on both sides of the inequality. If I am correct, it would be better to revise the statement on Ln.86.\n(5) Ln.224: should \"learning rates\" be \"convergence rates\"?\nLimitations: See my comments in the \"questions\" section.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "Building on a series of work that explored alternative assumptions to smoothness and strong-convexity, that still lead to linear convergence of gradient descent but hold more generally, the submission presents an analysis of first order methods on a pair of such conditions; the restricted secant inequality lower bound and smoothness towards the optimum as the upper error bound. The results show that the worst-case convergence of gradient descent on the class of functions satisfying those assumptions is optimal, by providing a matching lower bound for first-order methods. The construction of the lower-bound deviates from the typical construction of quadratic functions using in smooth, convex optimization and uses that the restrictions imposed by the conditions are weaker than smoothness and strong-convexity to hide local deviations.",
                "Strengths And Weaknesses": "To my knowledge, the results presented are new and the proof technique used to obtain the lower bound is technically interesting. The overall presentation of the technical results are reasonably clear. My main concern is on the clarity of the motivations, which I expand on in the next section. Regarding significance, althought not explicitly connected to this line of research in the submission, the results are interesting for the study of the possibility of acceleration under looser conditions than smooth/strong-convex which have attracted attention for applications in ML and explaining the effectiveness of momentum-based methods. This study shows the limitations of some relaxations of smoothness and strong-convexity, showing that acceleration beyond gradient descent is not provable without additional structure.",
                "Questions": "The introduction relies heavily on the work of Guille-Escuret et al. ([12] in the manuscript) for the motivation of the investigation of the limits of the conditions studied. Motivations specific to the current submission are somewhat missing, and the conclusions are somewhat at odd with the motivations of Guille-Escuret et al., leaving me with some unaddressed questions. Those are not points against the results of the paper, and I believe it is a matter of editing to make the motivations clearer and can be addressed during a discussion period.\n\nWhy focus on the specific conditions in this paper, among the many possible combinations of conditions, even if restricted only to the ones discussed by Guille-Escuret et al.? Have other stronger (in the sense that they would imply the studied condition, up to a change of constants) conditions already been studied?\nOne of the motivations of Guille-Escuret et al. for the study of those conditions was to address the current limitations of the theory for accelerated methods, as in Polyak's Heavy Ball, where the parameter setting used for quadratics does not extend to smooth, strongly-convex functions. The result that Gradient Descent is optimal for this class of problem would suggest that the class considered is too large to be useful for the design of new methods, or contains pathological functions. For example, the construction given for the interpolation, while interesting, indicates that the function has arbitrary many local deviations that are unrelated to each other, leading to the question of whether this relaxation of smoothness/strong-convexity is a valid model to pursue?\n\nApplicability of the assumptions\nSome of the limitations of the work are in regard with the level of applicability of the results. The submission makes the point multiple time that, although the assumptions considered are implied by standard smoothness and strong-convexity assumptions, they are not strictly weaker as their condition number can improve.\nThus the improvement in the rates might be worth the degradation in the dependence on the new condition number, \"provided we can obtain better constants under these conditions\" (L65). This is reiterated in Remark 2.5. While I am sympathetic to this argument---for example, for least-squares, it is known that the strong-convexity constant can be 0 the Polyak-Lojasiewicz condition is always non-zero---the arguments of the paper would be strengthened by a simple, provable example of the gap between pairs of conditions on a problem of interest. Using the notation of Guille-Escuret et al. ([12]), on what problem do we see a benefit from using (RSI-, EB+) instead of smoothness/strong-convexity, that is not already captured by (PL+, *SC-)?\nI acknowledge that the submission also discuss the applicability of the conditions to fitting neural networks (L80-82). However, I would recommend adding a qualifier after \"an impressive feat given the highly non-convex nature of neural networks loss function\" (L82) to avoid overstating their applicability, similar to the qualifying paragraph found in Appendix A after L420.",
                "Limitations": "No concern beyond the lack of a clear-cut use-case for the applicability of the assumptions used here noted above.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper studied the complexity of gradient descent (GD) in RSI- and EB+ settings, which is more general than the common smooth and strongly convex case. The paper provided linear convergence results of GD in this case, and further derived the interpolation conditions and showed the optimality results of GD under this case based on the PEP framework.",
                "Strengths And Weaknesses": "Strength:\n\nThe conciseness of the results, also the analysis covers both upper and lower bound, which is a complete story.\nThe paper is well organized and easy to read.\nThe independence of the interpolation conditions is interesting.\n\nWeakness:\n\nThe assumptions may be still a little restrictive (to be a little picky)",
                "Questions": "Basically I only have some minor questions:\n\nYou mentioned the optimal set X\u2217 should be convex, which means that the set X\u2217 is connected, right? I have the question because in Appendix A you tried to empirically shows that NN enjoys RSI- & EB+ style trajectory. But the landscape of NN may be complicated, and possibly attains disjoint (or nonconvex) optimal set. So I am confused on the statement \"and therefore, the convergence guarantees of RSI\u2212 & EB+ naturally apply to the optimization of neural networks in this setting.\"\n\nThe independence of interpolation conditions look interesting. Following A. B. Taylor's thesis [32], it seems that the interpolation conditions for both strongly-convex smooth and nonconvex smooth are not independent (am I correct?). As a (kind of) \"intermediate\" setting, the RSI- & EB+ settings will enjoy the independence, which is a little counterintuitive to me. Is there any possible illustration, e.g., analysis technique? It may be better if authors can provide some discussion on the analysis compared to existing literature.\n\n\nSome minor points:\n\nSec 5.2, I may suggest that authors should present the formal definition of HB algorithm, here the \u03b2 should distinguish with that of f\u03f5,\u03b2\nCorllary 1, change \u2227 to \u2229?\nAppendix A, why do you use \"extrapolate\" here, any difference compared to \"interpolate\"?",
                "Limitations": "Yes",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper is a theoretical paper that studies the performance guarantees for gradient descent where the objective satisfies lower restricted secant inequality (weaker than the strong-convexity condition) and an upper error bound (weaker than the smoothness condition) so that this includes some non-convex objectives. The paper also proves that the gradient descent is optimal on this class of functions among all first-order algorithms.",
                "Strengths And Weaknesses": "The paper is well written and is a solid theoretical paper. It is remarkable that the authors can show rigorously that the gradient descent is optimal on the class of functions that satisfy a lower restricted secant inequality and among an upper error bound all first-order algorithms.\nThe weakness of the paper is that even though the paper has a nice theoretical contribution, its practical importance and relevance is less clear to me. The class of objective functions that the author(s) study includes some non-convex functions, but when you have gradient descent, depending on the initialization, the algorithm can easily get stuck at a bad local minimum. Then the optimality discussed in the paper might be restrictive. Also for example, in practice, how do you measure your \u03bc and L? In addition, the optimal stepsize for this class of objective functions is \u03b1=\u03bc/L2, which is smaller than the standard choice \u03b1=2/(\u03bc+L) for the \u03bc-strongly convex and L-smooth objective. I am wondering what is the intuition behind this because \u03bc-strong convexity and L-smoothness can be viewed as a special case under your assumption. What is the intuition that you need to choose smaller stepsize in your setup?",
                "Questions": "(1) In addition to the questions I mentioned above, one interesting thing I find is that the author(s) show that the gradient descent is optimal on this class of functions among all first-order algorithms. For \u03bc-strongly convex and L-smooth objectives, it is known that Nesterov's accelerated gradient descent and heavy ball method can accelerate. So for your class of functions, the gradient descent is already optimal? What is the intuition behind this? Since your class of functions also include non-convex functions, does this indicate that when you have non-convex objectives, gradient descent might outperform Nesterov's accelerated gradient descent or other momentum-based methods?\n(2) In equation (9), write ''if'' in the text environment.\n(3) In Corollary 1, in the last line, write ''where'' instead of ''Where'' and add a '','' in the equation before the last sentence. Same can be said about Theorem 1.\n(4) In the first line in Theorem 2, it should be ''Let A be''.\n(5) In the second line in the proof of Theorem 2, write ''be the sequence introduced in Lemma 1''.\n(6) In reference [17], nesterov should be Nesterov and please check the other references as well.",
                "Limitations": "It does not seem to me that the author(s) stated the limitations and potential negative societal impacts of their work.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "In this work, the authors considered applying the gradient descent algorithm to functions in the intersection of RSI- and EB+. The intersection set is a generalization of the set of strongly convex and differentiable functions. A matching lower/upper bounds on the convergence rate is derived.",
                "Strengths And Weaknesses": "In this work, the authors extended the results of classical convex optimization and showed that the gradient descent algorithm is optimal for functions in RSI- and EB+. I think the results are interesting to audiences in optimization and machine learning. Furthermore, the presentation of this paper is clear and easy to follow.\nMy major concern is on the importance of the contribution in this work. As the authors mentioned, there are lots of existing literature studying lower/upper conditions. Many of those conditions can also guarantee the linear convergence of gradient-based algorithms; also see my comments in the \"questions\" section. Hence, I am not sure if the contributions in this work are significant and would suggest the authors provide more discussions on the importance of the results.",
                "Questions": "Major:\n(1) Line 78: since the stochastic gradient descent (SGD) method is considered for the optimization of neural networks, I wonder if the probability of escaping the attraction basin of local minima is sufficiently small. If the escaping probability is non-neglectable, the linear convergence may fail with certain probability and it is unsuitable to claim that RSI- and EB+ provide a guarantee on the linear convergence of SGD.\n(2) In Thm.1 and Thm.2, the optimality gap is characterized by x_i - x_i^* and x_i - x^*. It would be better if the authors can provide a comparison between these two metrics, which is important to the tightness of lower/upper bounds.\n(3) In the proof of Thm.2, it would be better to explicitly show why {x_i} are different points.\n(3) Maybe I missed something, but I think functions in the intersection of RSI- and EB+ also satisfy the Polyak-\u0141ojasiewicz (PL) condition. Under the PL condition, it is already known that descent algorithms with a (small) constant \"step size\" are optimal and converge linearly. Hence, the advantage of the bounds in this work lie in a matching lower/upper bound without a constant factor of difference, which seems marginal. I would suggest the authors provide a more detailed comparison with existing results on PL functions.\n(4) In this experiments, the authors showed that the gradient descent method is better than the heavy-ball method. I wonder if this phenomenon is also observed on other functions in RSI- and EB+, or only appears on this special example. It would be better if more details of this experiments can be provided (e.g., which objective function is constructed).\nMinor: \n(1) Ln.20: it would be better to mention that alpha is the step size.\n(2) Remark 2.2: I wonder if the authors can provide an example of non-convex functions that satisfy RSI-.\n(3) Remark 2.4: the discussion after the first sentence seems unnecessary to me. When comparing RSI- and EB+ to other conditions, people usually assume that the same parameters (mu and L) are used. But I am okay if the authors want to keep this discussion.\n(4) Ln.86: I think the Kurdyka-\u0141ojasiewicz and the Polyak-\u0141ojasiewicz conditions do not \"take the form of a lower and an upper bound on properties of the objective function\", since the gradient and the optimality gap appear on both sides of the inequality. If I am correct, it would be better to revise the statement on Ln.86.\n(5) Ln.224: should \"learning rates\" be \"convergence rates\"?",
                "Limitations": "See my comments in the \"questions\" section.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "soundness_avg": 3.25,
        "presentation_avg": 3.0,
        "contribution_avg": 2.75,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that the paper presents new and technically interesting results. The analysis is solid and the presentation is clear. While there are some questions and limitations raised by the reviewers, they do not significantly impact the overall contribution of the paper. The results have high impact in the field of optimization and machine learning. Therefore, I recommend accepting the paper."
    },
    "Decoupled_Context_Processing_for_Context_Augmented_Language_Modeling": {
        "link": "https://openreview.net//forum?id=02dbnEbEFn",
        "pub_url": "https://openreview.net/forum?id=02dbnEbEFn",
        "pdf_link": "https://openreview.net//pdf?id=02dbnEbEFn",
        "paper_id": "02dbnEbEFn",
        "title": "Decoupled_Context_Processing_for_Context_Augmented_Language_Modeling",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Less certain\nThe paper contributes a retrieval-augmented LM that offers some nice features compared to earlier work. First, it is based on a seq2seq architecture instead of a custom one (e.g., RETRO), which is a plus as it is simple, well studied, and the overall approach is quite elegant. Second, the model of the paper also offers cheaper inference compared to many prior models, and context encoding in the paper can be precomputed offline. \nWhile the reviewers agreed on these pros, the main concern during the reviewers\u2019 discussion was in relation to the downstream evaluation. The paper presents evaluation on only one downstream task, which is on the Natural Question (NQ) QA task and results are much worse than FiD. However, as pointed out by the authors, the better performance of FiD isn\u2019t so surprising (as the paper\u2019s model encodes contexts independently of the questions, as this is done offline). By contrast, FID comes with much greater computational costs. Ultimately, we agree with the authors\u2019 argument that the most comparable model is RETRO, and the paper does quite well in comparison. It is nice to see the paper\u2019s model outperforming other strong baselines such as REALM, DPR, and RAG. To mitigate concerns about their model\u2019s relative poor performance relative to FiD, the authors might want to bring up computational efficiency (e.g., concrete running time) earlier in the paper.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper explores how to leverage retrieved context for language modeling by decoupled encoder-decoder models, like Retro (Retrieval-Enhanced Transformer). The model mainly includes two components: 1) a retrieval that retrieves the k most relevant texts of input x via vector-based search; then 2) a transformer-based encoder-decoder model is used to predict the target based on both input x and the retrieved context. Compared with Retro, this integration of input and retrieved context is at decoder instead of encoder. The model is evaluated on auto-regressive language modeling on C4 datasets and Natural Question (a question asking task).\nStrengths And Weaknesses: Strengths: \nThe proposed approach is simple, and it seems more parameter efficient than Retro.\nIt provides extensive experiments especially on different scales.\nWeaknesses:\n1)Many experiments results are about bits-per-byte on C4 dev. I\u2019m wondering how this metric correlated to end-task performance. \n2)On the only one real-world application, NQ, the performance is still far behind FiD which is very similar to the proposed approach in terms of model architectures. Nothing that FiD only has 770m parameters\nQuestions: How the bootstrapped retriever training affects the NQ results? Do you have any ablation?\nLimitations: This type of training should help more on knowledge intensive or grounded tasks, and it would be great to see more evaluation on them. \nThe model may work on zero-/few shot transfer settings, and it would be great to have such experiments as well.\nIt is hard to understand the point of Figure 5, and how it is related to main story.\nEthics Flag: No\nEthics Review Area: I don\u2019t know\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper presents a method to augment the context based on retrieved relevant information, and keep the additional context representation separated from the history/prompt in an encoder-decoder setup, and thus decoder can be separately trained, and there\u2019s latency benefit since the context and query don\u2019t need to be re-encoded jointly after context is retrieved in inference time.  Authors evaluated their methods on language modeling and open domain question answering tasks and showed the computational benefit of the proposed method.\nStrengths And Weaknesses: The proposed method is intuitive. I feel people have done such evaluations but couldn't find an exact paper with such results. \nThe paper presents experimental results showing the proposed method has good performance (comparable to other approaches while reducing computational cost). \nAuthors did a good job and provide enough details to show the advantage of their method, mainly in terms of the computational efficiency. \nOne weakness of the paper is the novelty. As mentioned above, the proposed method is straightforward, making people feel this is a standard practice to save computational cost.  On the other hand, I'm not aware of similar results in prior work, so it's good to see such quantitative comparisons.  \nAbout the two sets of experimental results.\nFor the LMs, the authors showed perplexity results, and also the ablation study. The POS based analysis is good, providing some insights about the retrieved context and why it's helping the model performance. \nHowever, for the QA task, the analysis is not strong. The results are overall acceptable. But comparing the proposed method to FID and other similar ones, is the performance difference purely because of the encoding during inference (jointly encode the query and retrieved context)?  such understanding is important and very relevant to the proposed method.\nQuestions: Authors provided enough details about computing, which is great.  \nAdditional suggestions:\nQualitative analysis would also help.\nThe paper doesn\u2019t provide any examples. Showing retrieved context and explaining the relevance of that is useful.\nLimitations: The discussion is mostly focused on the computing aspect, which I think is appropriate given the paper's main focus.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper proposes a retrieval-augmented generator/language model, based on an encoder-decoder LM. \nUnlike other recent papers in the literature, the focus here is on a model that:\n\ndoesn't have a complex, custom architecture (unlike, e.g. RETRO), instead using the well-studied and popular seq2seq encoder-decoder transformer architecture.\nhas cheaper inference because context encoding can be done offline, and cached. \nThe proposed model accomplishes this by sacrificing bidirectionality compared to the quite-closely related FID architecture. \nThe result is a model that will have much cheaper and faster test-time runtimes than models that must process context on-the-fly. \nThe model is trained by using the encoder part of the model for contexts only. The input is prefxed to the output in the decoder. The authors propose an interesting context-retrieval training setup, that I do not recall seeing this precise formulation before.\nThe model also compares favourably to RETRO both in term of language modelling and Open domain QA.\nThe authors go the extra mile by providing a series of interesting and thoughtful analyses.\nStrengths And Weaknesses: Strengths:\nI really like this paper.\n\nthe paper is well-written and easy to follow, with sensible notation and equations where needed.\nIdentifying the cost of computation of retrieved items as an important problem is a good insight, and the proposed solution is elegant.\nthe depth of the analysis is really excellent- I enjoyed reading these sections and learnt a lot. \nthe simplicity and elegance of the architecture, compared to e.g. RETRO is inspiring\nI am intrigued by paragraph 220-227, I find this an interesting and simple fix to get the context conditioning to work.\nImproved downstream results compared to RETRO on a \"practical\" NLP application (NQ),\n\nWeaknesses:\n\nthe figures are quite complicated and bit hard to follow (esp fig 1).\nNot sure I fully buy the argument about the encoder not needing to contribute to the parameter count in - the retriever parameters should also count in my view (by the way)\nAdd the parameter counts of other models to Table 3b - some of these models that perform better are significantly smaller than both RETRO and your model.\nNot a big weakness, but it is a shame the dense retriever isnt better than bm25, I would expect it to be better.\nWhilst the model is comparatively strong on NQ c.f. RETRO, I am still a bit disappointed by this number for a 3B param model \nAlso,  although the context can be decoupled with your architecture, the encoder is fine-tuned, so it needs a full index refresh over the retrieval corpus for the caching argument to work,  which isn't needed for models like FID (in the limit, this is will be more efficient, but we should be careful to be precise).\nMissing/relevant work to compare to, or at least mention in RW: DensPI/DensePhrases (https://arxiv.org/abs/1906.05807,https://arxiv.org/abs/2012.12624), MARGE (https://arxiv.org/abs/2006.15020), Memorizing Transformers (https://openreview.net/forum?id=TrjbxzRcnf-). In particular, I think the DensePhrases work is quite spiritually related.\nQuestions: Why mt5 vs other t5s?\nWhy doesn't initialisation from pretrained models work? - I'd like to see numbers or more detail here.\ntypos:\nL1: context retriever -> a context retriever\nL37: metrics -> metrics\nL118: extra bracket\nLimitations: I think the authors do this well in section 6\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 3 good\nContribution: 3 good\nRating: 8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper explores how to leverage retrieved context for language modeling by decoupled encoder-decoder models, like Retro (Retrieval-Enhanced Transformer). The model mainly includes two components: 1) a retrieval that retrieves the k most relevant texts of input x via vector-based search; then 2) a transformer-based encoder-decoder model is used to predict the target based on both input x and the retrieved context. Compared with Retro, this integration of input and retrieved context is at decoder instead of encoder. The model is evaluated on auto-regressive language modeling on C4 datasets and Natural Question (a question asking task).",
                "Strengths And Weaknesses": "Strengths: \nThe proposed approach is simple, and it seems more parameter efficient than Retro.\nIt provides extensive experiments especially on different scales.\nWeaknesses:\n1)Many experiments results are about bits-per-byte on C4 dev. I\u2019m wondering how this metric correlated to end-task performance. \n2)On the only one real-world application, NQ, the performance is still far behind FiD which is very similar to the proposed approach in terms of model architectures. Nothing that FiD only has 770m parameters",
                "Questions": "How the bootstrapped retriever training affects the NQ results? Do you have any ablation?",
                "Limitations": "This type of training should help more on knowledge intensive or grounded tasks, and it would be great to see more evaluation on them. \nThe model may work on zero-/few shot transfer settings, and it would be great to have such experiments as well.\nIt is hard to understand the point of Figure 5, and how it is related to main story.",
                "Ethics Flag": "No",
                "Ethics Review Area": "I don\u2019t know",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper presents a method to augment the context based on retrieved relevant information, and keep the additional context representation separated from the history/prompt in an encoder-decoder setup, and thus decoder can be separately trained, and there\u2019s latency benefit since the context and query don\u2019t need to be re-encoded jointly after context is retrieved in inference time.  Authors evaluated their methods on language modeling and open domain question answering tasks and showed the computational benefit of the proposed method.",
                "Strengths And Weaknesses": "The proposed method is intuitive. I feel people have done such evaluations but couldn't find an exact paper with such results. \nThe paper presents experimental results showing the proposed method has good performance (comparable to other approaches while reducing computational cost). \nAuthors did a good job and provide enough details to show the advantage of their method, mainly in terms of the computational efficiency. \nOne weakness of the paper is the novelty. As mentioned above, the proposed method is straightforward, making people feel this is a standard practice to save computational cost.  On the other hand, I'm not aware of similar results in prior work, so it's good to see such quantitative comparisons.  \nAbout the two sets of experimental results.\nFor the LMs, the authors showed perplexity results, and also the ablation study. The POS based analysis is good, providing some insights about the retrieved context and why it's helping the model performance. \nHowever, for the QA task, the analysis is not strong. The results are overall acceptable. But comparing the proposed method to FID and other similar ones, is the performance difference purely because of the encoding during inference (jointly encode the query and retrieved context)?  such understanding is important and very relevant to the proposed method.",
                "Questions": "Authors provided enough details about computing, which is great.  \nAdditional suggestions:\nQualitative analysis would also help.\nThe paper doesn\u2019t provide any examples. Showing retrieved context and explaining the relevance of that is useful.",
                "Limitations": "The discussion is mostly focused on the computing aspect, which I think is appropriate given the paper's main focus.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposes a retrieval-augmented generator/language model, based on an encoder-decoder LM. \nUnlike other recent papers in the literature, the focus here is on a model that:\n\ndoesn't have a complex, custom architecture (unlike, e.g. RETRO), instead using the well-studied and popular seq2seq encoder-decoder transformer architecture.\nhas cheaper inference because context encoding can be done offline, and cached. \nThe proposed model accomplishes this by sacrificing bidirectionality compared to the quite-closely related FID architecture. \nThe result is a model that will have much cheaper and faster test-time runtimes than models that must process context on-the-fly. \nThe model is trained by using the encoder part of the model for contexts only. The input is prefxed to the output in the decoder. The authors propose an interesting context-retrieval training setup, that I do not recall seeing this precise formulation before.\nThe model also compares favourably to RETRO both in term of language modelling and Open domain QA.\nThe authors go the extra mile by providing a series of interesting and thoughtful analyses.",
                "Strengths And Weaknesses": "Strengths:\nI really like this paper.\n\nthe paper is well-written and easy to follow, with sensible notation and equations where needed.\nIdentifying the cost of computation of retrieved items as an important problem is a good insight, and the proposed solution is elegant.\nthe depth of the analysis is really excellent- I enjoyed reading these sections and learnt a lot. \nthe simplicity and elegance of the architecture, compared to e.g. RETRO is inspiring\nI am intrigued by paragraph 220-227, I find this an interesting and simple fix to get the context conditioning to work.\nImproved downstream results compared to RETRO on a \"practical\" NLP application (NQ),\n\nWeaknesses:\n\nthe figures are quite complicated and bit hard to follow (esp fig 1).\nNot sure I fully buy the argument about the encoder not needing to contribute to the parameter count in - the retriever parameters should also count in my view (by the way)\nAdd the parameter counts of other models to Table 3b - some of these models that perform better are significantly smaller than both RETRO and your model.\nNot a big weakness, but it is a shame the dense retriever isnt better than bm25, I would expect it to be better.\nWhilst the model is comparatively strong on NQ c.f. RETRO, I am still a bit disappointed by this number for a 3B param model \nAlso,  although the context can be decoupled with your architecture, the encoder is fine-tuned, so it needs a full index refresh over the retrieval corpus for the caching argument to work,  which isn't needed for models like FID (in the limit, this is will be more efficient, but we should be careful to be precise).\nMissing/relevant work to compare to, or at least mention in RW: DensPI/DensePhrases (https://arxiv.org/abs/1906.05807,https://arxiv.org/abs/2012.12624), MARGE (https://arxiv.org/abs/2006.15020), Memorizing Transformers (https://openreview.net/forum?id=TrjbxzRcnf-). In particular, I think the DensePhrases work is quite spiritually related.",
                "Questions": "Why mt5 vs other t5s?\nWhy doesn't initialisation from pretrained models work? - I'd like to see numbers or more detail here.\ntypos:\nL1: context retriever -> a context retriever\nL37: metrics -> metrics\nL118: extra bracket",
                "Limitations": "I think the authors do this well in section 6",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.667,
        "confidence_avg": 4.0,
        "soundness_avg": 3.333,
        "presentation_avg": 3.0,
        "contribution_avg": 2.667,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the proposed approach in this paper is technically solid and has several strengths. Reviewer 1 highlights the simplicity and parameter efficiency of the approach, while Reviewer 2 emphasizes the computational benefits and good performance of the method. Reviewer 3 also praises the well-written paper, the elegant architecture, and the depth of the analysis.\n\nAlthough there are some weaknesses mentioned by the reviewers, such as the complexity of the figures and the disappointment with the performance on the NQ task, the overall consensus is that the paper presents a novel and impactful contribution.\n\nConsidering the strictness of the conference, which is 0.5, it is recommended to accept this paper. The reviewers' positive evaluations and the strong technical aspects of the paper outweigh the limitations and weaknesses mentioned."
    },
    "Planning_to_the_Information_Horizon_of_BAMDPs_via_Epistemic_State_Abstraction": {
        "link": "https://openreview.net//forum?id=7eUOC9fEIRO",
        "pub_url": "https://openreview.net/forum?id=7eUOC9fEIRO",
        "pdf_link": "https://openreview.net//pdf?id=7eUOC9fEIRO",
        "paper_id": "7eUOC9fEIRO",
        "title": "Planning_to_the_Information_Horizon_of_BAMDPs_via_Epistemic_State_Abstraction",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nIn post-rebuttal discussion, reviewers debated the merits of the paper and especially reviewer Gwj8's concerns.  In the end, reviewer Gwj8 agreed with other reviewers that the paper should be accepted, although all reviewers would like to see the final revision reflect the points and concerns raised in the post-rebuttal discussion.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper considers how to tractably plan in BAMDPs, which are the belief-level MDPs induced by introducing uncertainty over the transition dynamics into a traditional finite-horizon MDP. The paper makes two contributions:\n\nThe paper coins a notion of \"information horizon\", which is the first timestep at which the agent is guaranteed to be certain about the environment dynamics under a given policy (the information horizon of a BAMDP itself is the maximum of such horizons over all policies). This horizon makes it possible to decompose the complexity of BAMDP planning into a deterministic planning component after the information horizon, and a (much more expensive) belief-space planning component before the information horizon.\nThe paper also suggests an approximate planning scheme for BAMDPs which projects belief states onto a \u03b4-cover for the space of all beliefs. This cover is constructed to contain all the standard basis vectors of the space of beliefs, which correspond to distributions in which the agent is certain of the dynamics. Consequently, as \u03b4 increases, the agent becomes more likely to project its uncertain beliefs onto a deterministic/certain belief. This decreases the effective information horizon. Theoretical analysis provides bounds for the value of a greedy policy under such an approximate belief for a given \u03b4.\nStrengths And Weaknesses: Strengths:\n\nCrisp exposition throughout. POMDPs and Bayesian RL are not my area, but I felt that the proposed concepts built naturally on top of one another.\nExpansive related work (although given that this is not my area, so I cannot say for sure that it is not overlooking work).\nThe value approximation scheme requires fairly weak assumptions on the structure of the MDP, and its utility (relative to precise VI on the BAMDP) is precisely quantified in Section 5.3.\n\nWeaknesses:\n\nThe definition of the information horizon is quite strict. If there is any path taken by a policy \u03c0 under which the agent might still have uncertainty at a given time step h, then the information horizon  for \u03c0 must be greater than h. This is even worse at the level of the BAMDP, where we take a maximum over all \u03c0, including \u03c0 that do not gather much information because they do not act strategically. Consequently, I'm not sure how many \"real\" BAMDPs are likely to have a small information horizon.\nAlthough Algorithm 2 makes fairly weak assumptions, it still requires computations that are likely very expensive in practice, like computation of I and standard VI repeated over every possible transition function. Both of these are very expensive operations, and I'm not sure how one would easily compute the information horizon or prune the computation of optimal policies with respect to each \u03b8 in order to make the process more tractable.\n\nAdmittedly these weaknesses (\"the assumptions are too strong/don't scale\") are common to many theory-oriented papers. My accept recommendation below is because I feel this paper has adequately demonstrated that the \"information horizon\" (and abstractions that decrease effective information horizon) is an interesting concept worthy of further fleshing out, even if the practical questions (like how to make Algorithm 2 more efficient) are not solved in this paper.\nQuestions: \nDo the authors foresee a particular \"killer app\" for this technique for which the information horizon is both small and easy to compute? I can imagine some artificial problems for which this is true, but I'm wondering whether there's a general class for which it holds.\nHow does the complexity of computing the information horizon compare to the overall complexity of BAMDP planning? Is there any worst-case win obtained by using Algorithm 2 in situations where I is not known a priori?\nLimitations: I felt the paper was clear in its assumptions and results (such as acknowledging that Assumption 2 will not hold in practice). I do not see obvious negative social impacts specific to this work.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 2 fair\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper deals with Bayes-adaptive Markov decision processes. The paper presents a complexity measure that quantifies the worst-case difficulty for solving an BAMDPs. The measure, the information horizon, is the longest horizon required for an agent to completely reduce it is uncertainty about either the dynamics or reward of the underlying MDP. This measure can then be used to perform planning in a BAMDP over a reduced horizon, before switching to planning in a fully-known MDP, thus reducing time complexity. \nDespite the reduction of time complexity by reducing the planning horizon, time complexity of value iteration in BAMDP is still dominated by the size of the state space. The second contribution of the paper revolves around applying principles of state-abstraction on the hyperstate-space of BAMDPs (state X info-state). This leads to a complexity that depends on the state size of the abstract BAMDP.\nStrengths And Weaknesses: The paper is very well-written. Assumptions are clearly stated and background work is discussed in detail. The quality of presentation is excellent. There is a clear thread and argument structure to follow. \nThe contribution is solid. BAMDPs are computationally very expensive and this paper proposes, what appears to me, as well-grounded improvements. The impact might be somewhat limited due to the fact that it considers only discrete state-action spaces, but anything else would explode the scope.\nI am not an expert in the domain of BAMDPs, but the concepts presented in the paper appear novel, despite the fact that they are closely related to a large body of work, that the authors cite.\nQuestions: N.A.\nLimitations: \nThe paper discuss the limitations an addresses them. Nonetheless, I wish the authors would find a way to integrate parts of the discussion that appear in the appendix into the main text.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary:  This paper addresses state abstraction in BAMDPs to find approximately Bayes-optimal solutions at reduced computational expense. The paper first introduces the idea of the information horizon: the number of steps at which the true underlying MDP will be identified for any policy. It suggests a simple algorithm to reduce the complexity of solving the BAMDP if the information horizon is less than the BAMDP horizon. This involves finding the optimal Bayes-adaptive policy up until the information horizon, and then executing the optimal policy in the identified MDP thereafter.\nFor most realistic examples, we cannot expect the ambiguity over the underlying MDP to be completely removed in a small (or indeed, finite) number of steps. Therefore, we can't necessarily expect the information horizon to be less than the BAMDP horizon. To address this, the paper suggests to use state abstraction over the information states. Depending on the coarsity of the abstraction, more of the original information states will be considered to be \"close enough\" to having resolved the ambiguity over the MDP. Therefore, for more coarse abstractions, we can expect the information horizon to be reduced in the abstract BAMDP. The paper analyses the sub-optimality induced by considering the abstract version of the BAMDP.\nStrengths And Weaknesses: The paper is well written and easy to follow. I think this idea of considering an appropriate information horizon is both interesting and can potentially be an impactful idea. I think the analysis of state abstraction in BAMDPs can be useful for informing approximate algorithms.\nThere are several shortcomings that I think the paper could address better:\nWeakness 1. The paper uses value iteration over the entire information state space to analyse the complexity of informed value iteration vs value iteration, and to demonstrate how using the information horizon can reduce the complexity of value iteration. However, most algorithms for BAMDPS do not iterate over the entire state space, but only compute solutions over the reachable information state space. To me, it seems like these existing algorithms already implicitly take advantage of the fact that some problems have a reduced information horizon, by becoming equivalent to solving standard MDPs once the information horizon is reached. I think this reduces the impact of the informed value iteration idea, as it seems that other common algorithms already (implicitly) do something similar, and this performance improvement might only be applicable to na\u00efve value iteration (which wouldn't be used in practice for BAMDPs). I will elaborate on this in the questions section.\nI still think that the paper is good overall since explicitly reasoning about the information horizon allows for providing theoretical bounds. However, it would benefit from discussing this if this is the case.\nWeakness 2. Both the informed VI, and informed abstract VI algorithms require knowing what the information horizon is for the given (abstract) BAMDP. However, it is unclear how the information horizon would be determined for a given problem, even for an abstract BAMDP with a known \\delta used to compute the state abstraction. It is also not clear when we can expect the information horizon to be decreased when using the state abstraction technique. I would appreciate a greater discussion of this in the paper and in rebuttal.\nWeakness 3. Most BAMDP problems (even for finite state and action spaces) assume that the space of possible MDPs is infinite. However, in Assumption 1, this paper assumes that the uncertainty is over a finite set of MDPs. Therefore, to match Assumption 1, additional discretisation may be required over the space of MDPs to make it finite. The paper does not discuss this issue, and would be strengthened if it did also analyse the error introduced by discretising the space of possible MDPs to match Assumption 1. Is it possible to apply the abstraction if the space of possible MDPs is infinite? Please discuss\nMinor comments:\n\nIn the preliminaries, \\pi is initially used to indicate a non-stationary deterministic policy. However, when discussing the existence of an optimal policy, \\pi is then used to refer to a stationary deterministic policy. Please make this clearer.\n\nPresentation of Bellman equations needs further formatting (e.g. they overflow for BAMDPs and the use of commas and full stops looks a bit arbitrary)\n\nWhen discussing the information horizon, authors say I<=H but immediately after discussing the case where I=\\infty. Make it more precise.\nQuestions: The informed value iteration idea means that once the information horizon has been reached, we just solve standard MDPs, and only need to find the Bayes-optimal solution up until the information horizon. It seems to me that existing sample-based algorithms already become equivalent to solving standard MDPs after the information horizon is reached.\nLets consider BAMCP [37], or indeed any algorithm which makes use of root sampling (sampling a candidate MDP from the initial state to simulate each rollout). Let's also imagine that the information horizon is 1 (i.e. the ambiguity over the MDP is resolved after one step). To make the example very simple, let\u2019s assume the ambiguity is resolved as follows: if, after the first step the agent reaches states in set A, then the MDP is known to be MDP_A, and if the agent reaches states in set B, then the MDP is known to be MDP_B.\nThen, all trials that reach set A after the first step are using MDP_A, and all trials that reach set B after the first step are using MDP_B. This means that after the first step, BAMCP reduces to performing standard MCTS in two standard MDPs (i.e. standard MCTS in MDP_A for states in set A and standard MCTS in MDP_B for states in set B).  The point I am trying to make is that if ambiguity over the MDP has been resolved, algorithms which search forward over reachable information states (including RL algorithms) already have the property that they become equivalent to solving individual MDPs after reaching the information horizon.\nIf this is true, this limits the impact of the work as I don't think the insight of informed value iteration vs value iteration will translate into improvements into other algorithms (i.e. knowledge of the information horizon can only improve performance for na\u00efve value iteration over the entire BAMDP, but wouldn't improve BAMCP-like algorithms).\nSummary of questions to the authors:\n\nPlease address weaknesses 1, 2, 3 above\nIs it fair to say that sampled-based algorithms such as BAMCP already implicitly make use of the information horizon as discussed above?\nCan utilising the information horizon more explicitly as proposed in your work make any improvement in the efficiency of existing sample-based (or RL) algorithms, which simulate rollouts in candidate MDPs rather than iterating over the entire belief space?\nLimitations: More discussion of limitations due to finite set of MDPs, and applicability of the idea to improve sampled-based/RL algorithms (rather than only improving the most na\u00efve value iteration approach) would improve the paper.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper introduces a novel concept for analyzing the complexity of Bayes-Adaptive MDPs (BAMDPs), which is called the Information Horizon. The authors argue that BAMDPs with low Information Horizon (relative to the episode horizon) -- that is, those BAMDPs in which an agent can potentially deduce the underlying MDP without uncertainty after relatively few environment steps -- can be solved more efficiently since value iteration in the hyperstate space is carried out over a shorter horizon. The authors then demonstrate how the complexity of (approximately) solving BAMDPs can be further reduced via state abstraction, and error bounds are provided for the value functions learned in such abstract BAMDPs.\nStrengths And Weaknesses: Strengths\nThe goal of this paper -- to identify a class of BAMDPs that can be solved efficiently -- is a very interesting and ambitious one. For the most part, the authors do a good job of clearly stating assumptions and precisely defining the setting that they're working in. The notion of the information horizon is quite novel to the best of my knowledge, and it seems to be a reasonable and important concept. The proofs of theoretical results are clear and appear to be correct.\nWeaknesses\nI'm mainly concerned with some of the assumptions that are made throughout the paper. In particular, the assumption that the agent maintains a belief over a finite, constant number of MDPs seems excessively limiting. It would have at least been interesting to have a discussion about cases where the number of MDPs in the support of the agent's belief could increase with the size of the state space, even if it must remain finite. Consequently, I'm afraid the results in this paper may have limited relevance.\nPost-Rebuttal Update\nThe authors cleared up most of my concerns. I am still skeptical about the relevance of the problem setting, particularly that of a constant-size prior MDP support regardless of the size of the MDP, but I think the information horizon approach is interesting. I have adjusted my score to reflect this.\nQuestions: Questions and Comments\nSection 2.1 -- Definition of the value function: I believe there is\na typo in the state/action indexing in the sum -- it should be\nR(sh\u2032,ah\u2032) rather than R(sh,ah).\nAssumption 1: Is the assumption that the parameter space \u0398 is\nfinite not much more limiting than existing work? In the setting with a\nDirichlet prior that is mentioned, the agent would be modeling a belief\nover uncountably many MDPs. Moreover, on line 71, it says \"we do not\nconcern ourselves with the computation of the posterior\" -- but\ndoesn't this neglect much of the issue of intractability in BAMDPs?\nFinally, how fair is it really to assume a constant-time posterior\nupdate? Even with finitely-many MDPs, I would expect that the number of\nknown MDPs (|\u0398|) must somehow grow with the state/action spaces\nin a reasonable model.\nAssumption 2: I believe this is notationally incorrect. While you\nassume \"an agressively-fine quantization\" of \u0394(\u0398),\n\u0394(\u0398) itself is not finite, so |X|\u226e\u221e.\nThe quantization of \u0394(\u0398) should be made explicit, i.e.,\n\"let \u0394^\u2282\u0394(\u0398) be finite... let\nX=S\u00d7\u0394^\".\nValue iteration in hyperstate space: When discussing the complexity\nof value iteration in hyperstate space, the term |X| appears\nfrequently. To my understanding, this term hides a lot of complexity. In\nparticular, we're assuming an aggressively-fine quantization of\n\u0394(\u0398) as part of the space X, which leads me to\nbelieve that |X|\u2208O(|S|exp\u2061(|\u0398|\u22121)). If\n|\u0398|\u2208\u03c9(log\u2061|S|), then already any algorithm with\ncomplexity linear in |X| is intractable. Conversely, if |\u0398|\u2208O(log\u2061|S|), the algorithm may actually be tractable. Thus, I think the\nscaling of |\u0398| w.r.t. |S| should be discussed. Note\nthat if |\u0398|\u2208O(1), then as\nS\u2191\u221e, one has less and less uncertainty over the\nMDP. While this does appear to be addressed in line 222, it may be\ninteresting to discuss settings where these algorithms are tractable,\nsince already so many \"finiteness\" assumptions have been made.\nProposition 1: Naively, one should expect that\nmaxx\u2208X|Vh\u22c6(x)\u2212V\u03d5,h\u22c6(\u03d5(x))|\u2264H\u2212h+1 since the rewards are bounded\nin [0,1]. For this proposition to be at all interesting, we must have\n\u03b4(H\u2212h)<1/2. Thus, as the horizon increases, the parameter\n\u03b4 must decrease proportionally for this to be a meaningful\nresult.\nProposition 3: Similar to my comment about Proposition 1: for this\nresult to be meaningful, we must have \u03b4<(4(H\u2212h)(H\u2212h+1))\u22121. Altogether, for this propositions to match the naive\nperformance-loss bound, we need \u03b4\u2208O(1/H2). This is addressed\non line 349, but can this be reflected in the complexity bound on line\n312, via the\nN(\u0394(\u0398),\u03b4,|\u22c5|TV) term? I\nsuspect that the size of the cover would be very large in this case,\nwhich would add greater dependence on H to the complexity, which the\ngoal was to avoid.\nMinor issues\n\nIt would be helpful to have hyperlinks. In particular, the long list\nof citations starting on line 21 is very daunting when the only way\nto check the citations is by manually scrolling through the\nreferences section.\nFor the long list of citations starting on line 21, it would also be\nnice if they were listed in numerical order, which make it easier to\nscan the list without navigating back in forth between line 21 and\nthe references section so many times.\nLimitations: As previously mentioned, I believe the theoretical results are quite limited due to the assumptions on the belief space over MDPs. The authors discuss these limitations briefly, although it would have been nice to see more in-depth discussion.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 3 good\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper considers how to tractably plan in BAMDPs, which are the belief-level MDPs induced by introducing uncertainty over the transition dynamics into a traditional finite-horizon MDP. The paper makes two contributions:\n\nThe paper coins a notion of \"information horizon\", which is the first timestep at which the agent is guaranteed to be certain about the environment dynamics under a given policy (the information horizon of a BAMDP itself is the maximum of such horizons over all policies). This horizon makes it possible to decompose the complexity of BAMDP planning into a deterministic planning component after the information horizon, and a (much more expensive) belief-space planning component before the information horizon.\nThe paper also suggests an approximate planning scheme for BAMDPs which projects belief states onto a \u03b4-cover for the space of all beliefs. This cover is constructed to contain all the standard basis vectors of the space of beliefs, which correspond to distributions in which the agent is certain of the dynamics. Consequently, as \u03b4 increases, the agent becomes more likely to project its uncertain beliefs onto a deterministic/certain belief. This decreases the effective information horizon. Theoretical analysis provides bounds for the value of a greedy policy under such an approximate belief for a given \u03b4.",
                "Strengths And Weaknesses": "Strengths:\n\nCrisp exposition throughout. POMDPs and Bayesian RL are not my area, but I felt that the proposed concepts built naturally on top of one another.\nExpansive related work (although given that this is not my area, so I cannot say for sure that it is not overlooking work).\nThe value approximation scheme requires fairly weak assumptions on the structure of the MDP, and its utility (relative to precise VI on the BAMDP) is precisely quantified in Section 5.3.\n\nWeaknesses:\n\nThe definition of the information horizon is quite strict. If there is any path taken by a policy \u03c0 under which the agent might still have uncertainty at a given time step h, then the information horizon  for \u03c0 must be greater than h. This is even worse at the level of the BAMDP, where we take a maximum over all \u03c0, including \u03c0 that do not gather much information because they do not act strategically. Consequently, I'm not sure how many \"real\" BAMDPs are likely to have a small information horizon.\nAlthough Algorithm 2 makes fairly weak assumptions, it still requires computations that are likely very expensive in practice, like computation of I and standard VI repeated over every possible transition function. Both of these are very expensive operations, and I'm not sure how one would easily compute the information horizon or prune the computation of optimal policies with respect to each \u03b8 in order to make the process more tractable.\n\nAdmittedly these weaknesses (\"the assumptions are too strong/don't scale\") are common to many theory-oriented papers. My accept recommendation below is because I feel this paper has adequately demonstrated that the \"information horizon\" (and abstractions that decrease effective information horizon) is an interesting concept worthy of further fleshing out, even if the practical questions (like how to make Algorithm 2 more efficient) are not solved in this paper.",
                "Questions": "Do the authors foresee a particular \"killer app\" for this technique for which the information horizon is both small and easy to compute? I can imagine some artificial problems for which this is true, but I'm wondering whether there's a general class for which it holds.\nHow does the complexity of computing the information horizon compare to the overall complexity of BAMDP planning? Is there any worst-case win obtained by using Algorithm 2 in situations where I is not known a priori?",
                "Limitations": "I felt the paper was clear in its assumptions and results (such as acknowledging that Assumption 2 will not hold in practice). I do not see obvious negative social impacts specific to this work.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "2 fair",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper deals with Bayes-adaptive Markov decision processes. The paper presents a complexity measure that quantifies the worst-case difficulty for solving an BAMDPs. The measure, the information horizon, is the longest horizon required for an agent to completely reduce it is uncertainty about either the dynamics or reward of the underlying MDP. This measure can then be used to perform planning in a BAMDP over a reduced horizon, before switching to planning in a fully-known MDP, thus reducing time complexity. \nDespite the reduction of time complexity by reducing the planning horizon, time complexity of value iteration in BAMDP is still dominated by the size of the state space. The second contribution of the paper revolves around applying principles of state-abstraction on the hyperstate-space of BAMDPs (state X info-state). This leads to a complexity that depends on the state size of the abstract BAMDP.",
                "Strengths And Weaknesses": "The paper is very well-written. Assumptions are clearly stated and background work is discussed in detail. The quality of presentation is excellent. There is a clear thread and argument structure to follow. \nThe contribution is solid. BAMDPs are computationally very expensive and this paper proposes, what appears to me, as well-grounded improvements. The impact might be somewhat limited due to the fact that it considers only discrete state-action spaces, but anything else would explode the scope.\nI am not an expert in the domain of BAMDPs, but the concepts presented in the paper appear novel, despite the fact that they are closely related to a large body of work, that the authors cite.",
                "Questions": "N.A.",
                "Limitations": "The paper discuss the limitations an addresses them. Nonetheless, I wish the authors would find a way to integrate parts of the discussion that appear in the appendix into the main text.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper addresses state abstraction in BAMDPs to find approximately Bayes-optimal solutions at reduced computational expense. The paper first introduces the idea of the information horizon: the number of steps at which the true underlying MDP will be identified for any policy. It suggests a simple algorithm to reduce the complexity of solving the BAMDP if the information horizon is less than the BAMDP horizon. This involves finding the optimal Bayes-adaptive policy up until the information horizon, and then executing the optimal policy in the identified MDP thereafter.\nFor most realistic examples, we cannot expect the ambiguity over the underlying MDP to be completely removed in a small (or indeed, finite) number of steps. Therefore, we can't necessarily expect the information horizon to be less than the BAMDP horizon. To address this, the paper suggests to use state abstraction over the information states. Depending on the coarsity of the abstraction, more of the original information states will be considered to be \"close enough\" to having resolved the ambiguity over the MDP. Therefore, for more coarse abstractions, we can expect the information horizon to be reduced in the abstract BAMDP. The paper analyses the sub-optimality induced by considering the abstract version of the BAMDP.",
                "Strengths And Weaknesses": "The paper is well written and easy to follow. I think this idea of considering an appropriate information horizon is both interesting and can potentially be an impactful idea. I think the analysis of state abstraction in BAMDPs can be useful for informing approximate algorithms.\nThere are several shortcomings that I think the paper could address better:\nWeakness 1. The paper uses value iteration over the entire information state space to analyse the complexity of informed value iteration vs value iteration, and to demonstrate how using the information horizon can reduce the complexity of value iteration. However, most algorithms for BAMDPS do not iterate over the entire state space, but only compute solutions over the reachable information state space. To me, it seems like these existing algorithms already implicitly take advantage of the fact that some problems have a reduced information horizon, by becoming equivalent to solving standard MDPs once the information horizon is reached. I think this reduces the impact of the informed value iteration idea, as it seems that other common algorithms already (implicitly) do something similar, and this performance improvement might only be applicable to na\u00efve value iteration (which wouldn't be used in practice for BAMDPs). I will elaborate on this in the questions section.\nI still think that the paper is good overall since explicitly reasoning about the information horizon allows for providing theoretical bounds. However, it would benefit from discussing this if this is the case.\nWeakness 2. Both the informed VI, and informed abstract VI algorithms require knowing what the information horizon is for the given (abstract) BAMDP. However, it is unclear how the information horizon would be determined for a given problem, even for an abstract BAMDP with a known \\delta used to compute the state abstraction. It is also not clear when we can expect the information horizon to be decreased when using the state abstraction technique. I would appreciate a greater discussion of this in the paper and in rebuttal.\nWeakness 3. Most BAMDP problems (even for finite state and action spaces) assume that the space of possible MDPs is infinite. However, in Assumption 1, this paper assumes that the uncertainty is over a finite set of MDPs. Therefore, to match Assumption 1, additional discretisation may be required over the space of MDPs to make it finite. The paper does not discuss this issue, and would be strengthened if it did also analyse the error introduced by discretising the space of possible MDPs to match Assumption 1. Is it possible to apply the abstraction if the space of possible MDPs is infinite? Please discuss\nMinor comments:\n\nIn the preliminaries, \\pi is initially used to indicate a non-stationary deterministic policy. However, when discussing the existence of an optimal policy, \\pi is then used to refer to a stationary deterministic policy. Please make this clearer.\n\nPresentation of Bellman equations needs further formatting (e.g. they overflow for BAMDPs and the use of commas and full stops looks a bit arbitrary)\n\nWhen discussing the information horizon, authors say I<=H but immediately after discussing the case where I=\\infty. Make it more precise.",
                "Questions": "The informed value iteration idea means that once the information horizon has been reached, we just solve standard MDPs, and only need to find the Bayes-optimal solution up until the information horizon. It seems to me that existing sample-based algorithms already become equivalent to solving standard MDPs after the information horizon is reached.\nLets consider BAMCP [37], or indeed any algorithm which makes use of root sampling (sampling a candidate MDP from the initial state to simulate each rollout). Let's also imagine that the information horizon is 1 (i.e. the ambiguity over the MDP is resolved after one step). To make the example very simple, let\u2019s assume the ambiguity is resolved as follows: if, after the first step the agent reaches states in set A, then the MDP is known to be MDP_A, and if the agent reaches states in set B, then the MDP is known to be MDP_B.\nThen, all trials that reach set A after the first step are using MDP_A, and all trials that reach set B after the first step are using MDP_B. This means that after the first step, BAMCP reduces to performing standard MCTS in two standard MDPs (i.e. standard MCTS in MDP_A for states in set A and standard MCTS in MDP_B for states in set B).  The point I am trying to make is that if ambiguity over the MDP has been resolved, algorithms which search forward over reachable information states (including RL algorithms) already have the property that they become equivalent to solving individual MDPs after reaching the information horizon.\nIf this is true, this limits the impact of the work as I don't think the insight of informed value iteration vs value iteration will translate into improvements into other algorithms (i.e. knowledge of the information horizon can only improve performance for na\u00efve value iteration over the entire BAMDP, but wouldn't improve BAMCP-like algorithms).\nSummary of questions to the authors:\n\nPlease address weaknesses 1, 2, 3 above\nIs it fair to say that sampled-based algorithms such as BAMCP already implicitly make use of the information horizon as discussed above?\nCan utilising the information horizon more explicitly as proposed in your work make any improvement in the efficiency of existing sample-based (or RL) algorithms, which simulate rollouts in candidate MDPs rather than iterating over the entire belief space?",
                "Limitations": "More discussion of limitations due to finite set of MDPs, and applicability of the idea to improve sampled-based/RL algorithms (rather than only improving the most na\u00efve value iteration approach) would improve the paper.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper introduces a novel concept for analyzing the complexity of Bayes-Adaptive MDPs (BAMDPs), which is called the Information Horizon. The authors argue that BAMDPs with low Information Horizon (relative to the episode horizon) -- that is, those BAMDPs in which an agent can potentially deduce the underlying MDP without uncertainty after relatively few environment steps -- can be solved more efficiently since value iteration in the hyperstate space is carried out over a shorter horizon. The authors then demonstrate how the complexity of (approximately) solving BAMDPs can be further reduced via state abstraction, and error bounds are provided for the value functions learned in such abstract BAMDPs.",
                "Strengths And Weaknesses": "Strengths\nThe goal of this paper -- to identify a class of BAMDPs that can be solved efficiently -- is a very interesting and ambitious one. For the most part, the authors do a good job of clearly stating assumptions and precisely defining the setting that they're working in. The notion of the information horizon is quite novel to the best of my knowledge, and it seems to be a reasonable and important concept. The proofs of theoretical results are clear and appear to be correct.\nWeaknesses\nI'm mainly concerned with some of the assumptions that are made throughout the paper. In particular, the assumption that the agent maintains a belief over a finite, constant number of MDPs seems excessively limiting. It would have at least been interesting to have a discussion about cases where the number of MDPs in the support of the agent's belief could increase with the size of the state space, even if it must remain finite. Consequently, I'm afraid the results in this paper may have limited relevance.\nPost-Rebuttal Update\nThe authors cleared up most of my concerns. I am still skeptical about the relevance of the problem setting, particularly that of a constant-size prior MDP support regardless of the size of the MDP, but I think the information horizon approach is interesting. I have adjusted my score to reflect this.",
                "Questions": "Questions and Comments\nSection 2.1 -- Definition of the value function: I believe there is\na typo in the state/action indexing in the sum -- it should be\nR(sh\u2032,ah\u2032) rather than R(sh,ah).\nAssumption 1: Is the assumption that the parameter space \u0398 is\nfinite not much more limiting than existing work? In the setting with a\nDirichlet prior that is mentioned, the agent would be modeling a belief\nover uncountably many MDPs. Moreover, on line 71, it says \"we do not\nconcern ourselves with the computation of the posterior\" -- but\ndoesn't this neglect much of the issue of intractability in BAMDPs?\nFinally, how fair is it really to assume a constant-time posterior\nupdate? Even with finitely-many MDPs, I would expect that the number of\nknown MDPs (|\u0398|) must somehow grow with the state/action spaces\nin a reasonable model.\nAssumption 2: I believe this is notationally incorrect. While you\nassume \"an agressively-fine quantization\" of \u0394(\u0398),\n\u0394(\u0398) itself is not finite, so |X|\u226e\u221e.\nThe quantization of \u0394(\u0398) should be made explicit, i.e.,\n\"let \u0394^\u2282\u0394(\u0398) be finite... let\nX=S\u00d7\u0394^\".\nValue iteration in hyperstate space: When discussing the complexity\nof value iteration in hyperstate space, the term |X| appears\nfrequently. To my understanding, this term hides a lot of complexity. In\nparticular, we're assuming an aggressively-fine quantization of\n\u0394(\u0398) as part of the space X, which leads me to\nbelieve that |X|\u2208O(|S|exp\u2061(|\u0398|\u22121)). If\n|\u0398|\u2208\u03c9(log\u2061|S|), then already any algorithm with\ncomplexity linear in |X| is intractable. Conversely, if |\u0398|\u2208O(log\u2061|S|), the algorithm may actually be tractable. Thus, I think the\nscaling of |\u0398| w.r.t. |S| should be discussed. Note\nthat if |\u0398|\u2208O(1), then as\nS\u2191\u221e, one has less and less uncertainty over the\nMDP. While this does appear to be addressed in line 222, it may be\ninteresting to discuss settings where these algorithms are tractable,\nsince already so many \"finiteness\" assumptions have been made.\nProposition 1: Naively, one should expect that\nmaxx\u2208X|Vh\u22c6(x)\u2212V\u03d5,h\u22c6(\u03d5(x))|\u2264H\u2212h+1 since the rewards are bounded\nin [0,1]. For this proposition to be at all interesting, we must have\n\u03b4(H\u2212h)<1/2. Thus, as the horizon increases, the parameter\n\u03b4 must decrease proportionally for this to be a meaningful\nresult.\nProposition 3: Similar to my comment about Proposition 1: for this\nresult to be meaningful, we must have \u03b4<(4(H\u2212h)(H\u2212h+1))\u22121. Altogether, for this propositions to match the naive\nperformance-loss bound, we need \u03b4\u2208O(1/H2). This is addressed\non line 349, but can this be reflected in the complexity bound on line\n312, via the\nN(\u0394(\u0398),\u03b4,|\u22c5|TV) term? I\nsuspect that the size of the cover would be very large in this case,\nwhich would add greater dependence on H to the complexity, which the\ngoal was to avoid.\nMinor issues\n\nIt would be helpful to have hyperlinks. In particular, the long list\nof citations starting on line 21 is very daunting when the only way\nto check the citations is by manually scrolling through the\nreferences section.\nFor the long list of citations starting on line 21, it would also be\nnice if they were listed in numerical order, which make it easier to\nscan the list without navigating back in forth between line 21 and\nthe references section so many times.",
                "Limitations": "As previously mentioned, I believe the theoretical results are quite limited due to the assumptions on the belief space over MDPs. The authors discuss these limitations briefly, although it would have been nice to see more in-depth discussion.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "soundness_avg": 3.75,
        "presentation_avg": 3.5,
        "contribution_avg": 2.5,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is clear that this paper addresses an interesting and important problem in the field of Bayes-Adaptive Markov Decision Processes (BAMDPs). The concept of the information horizon introduced in this paper is novel and has the potential to significantly reduce the complexity of solving BAMDPs. The authors provide a clear and well-structured presentation of their work, and the theoretical analysis is sound.\n\nWhile there are some concerns raised by the reviewers, such as the strict definition of the information horizon and the assumptions made in the paper, these concerns do not outweigh the strengths of the paper. The weaknesses identified by the reviewers are common to many theory-oriented papers and do not significantly impact the overall contribution of this work.\n\nTherefore, I recommend accepting this paper. The technical soundness, high impact potential, and good evaluation make it a strong contribution to the field."
    },
    "Trust_Region_Policy_Optimization_with_Optimal_Transport_Discrepancies:_Duality_and_Algorithm_for_Continuous_Actions": {
        "link": "https://openreview.net//forum?id=BUMiizPcby6",
        "pub_url": "https://openreview.net/forum?id=BUMiizPcby6",
        "pdf_link": "https://openreview.net//pdf?id=BUMiizPcby6",
        "paper_id": "BUMiizPcby6",
        "title": "Trust_Region_Policy_Optimization_with_Optimal_Transport_Discrepancies:_Duality_and_Algorithm_for_Continuous_Actions",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nThe paper studies trust region optimization but replace the typical KL divergence with optimal transport distance - which is a natural and meaningful generalization. The authors provided a tractable algorithm by using optimization duality, and provide experimental results on control tasks. All reviewers appreciate the main idea is novel and interesting, and further the paper is very written and easy to understand. Some reviewer have questions about the theory and experiments. The authors largely address the reviewers' comments during rebuttal, and all authors are in favor of acceptance.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper studies the trust region policy optimization (TRPO) problem, by replacing the KL divergence policy discrepancy constraint in TRPO with optimal transport discrepancies, such as Wasserstein distance. Considering the optimal transport discrepancy region, a dual form of the constrained problem has been developed, which contains a Lagrange multiplier \\lambda. Find the optimal \\lambda^* at each step only needs to solve a one-dimensional convex optimization problem, which can be solved using off-the-shelf solvers, instead of line-search in TRPO. Then, the optimal \\pi can be computed using \\lambda^* with closed-form solution. Experiments on both discrete and continuous settings are conducted.\nStrengths And Weaknesses: Pros:\nThe paper is clearly written. It proposes a new dual form of trust region PO problem using optimal transport discrepancy, where the solution can be computed efficiently compared to line-search using KL divergence.\nCons:\nThe compared methods have included many closely related works in trust region PO, however, the benchmark environments are somehow limited and insufficient. Since the OT-TRPO is derived for both discrete and continuous actions, to give a thorough support for the effectiveness of OT-TRPO, it is recommended to evaluate on some standard RL benchmarks such as the Atari suite, and Mujoco families. The considered tasks, such as CliffWalking, Taxi, MountainCar, Swimmer, etc., are relatively simple environments, in which the learning steps are relatively small to obtain good performances for general algorithms.\nQuestions: \nAre there any explanations that for many environments, such as Taxi, Hopper, and Swimmer, TRPO learns much fasters at early stages compared to OT-TRPO? Does these environments share some similarity in dealing with the trust regions?\n\nWPO can be extended to deal with continuous actions as studied in the original paper, while it is ignored here. For example, in Hopper, WPO can reach much higher scores if we count for the same amount of learning steps. In Figure 1, it seems TRPO can achieve very competitive performance, while this differs from the results reported in BGPG and WNPG. Would the implementation of TRPO has some particular treatment here? \n\nWould an efficiency comparison with the line-search procedure in TRPO be possible? Since one important benefit using the optimal transport discrepancy is that the optimal policy at each step has a closed-form solution to avoid the computational line-search.\n\nLine 341: \u201cit leads to superior asymptotic performance\u201d. I do not think the sentence is rigorous, since when you refer to asymptotic performance you consider nearly infinite samples while the learning steps in the experiments are of very small scale considering current RL problems.\n\nMinor typos:\nLine 338: \u201cnot do\u201d -> \u201cdo not\u201d\nLimitations: Some experimental results of the compared methods are not clear enough. Benchmark environments should be enriched to thoroughly evaluate the empirical performance of OT-TRPO.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper under review studied the problem of trust region policy optimization(TRPO).\nTRPO aims to optimize the expected return through stable policy update, where the \nstability is control by only allowing update within certain region around the current policy \nin each iteration. Hence one needs to pick a norm to measure distances between policies.\nIn this paper, the authors proposed to use OT distance.\nAllowing the continuous setting for action and state spaces, \nthey derive the dual of the proposed OT-TRPO and proved strong duality,\nbase on which, an update algorithm was proposed.\nMoreover, by establishing eq (11), the authors demonstrated the monotonic improvement of the proposed method.\nIn addition, the authors illustrated the efficiency of OT-TRPO through simulations.\nStrengths And Weaknesses: The paper is well written and easy to follow.\nThe idea of using optimal transport discrepancy is natural and interesting.\nThe proposed update algorithm is nicely stated and and properly motivated.\nThe fact that it bypass the actual computation of the forward OT has many potential applications.\nThe theoretical results are sounds besides some questions listed below.\nQuestions: Q1: In section 4.3, the authors stated that eq(11) shows monotonicity of the update.\nHowever, to guarantee J(\u03c0~\u2217)>J(\u03c0), one needs to show that the sum of the last two terms in eq(11) is positive.\nIt is not clear why the sum is always positive. Would the authors explain a bit further on it?\nQ2: Regarding the experiments: what are the choices of costs and other parameters? Are the results sensitive to these choices?\nWhat is the running time comparing to other methods? In particular, step 4 and step 5 in Algo1.\nQ3: Is it possible to empirically validate that the proposed algorithm actually approximates the solution of problem (P)?\nFor example, check for a small discrete setting where OT solution can be computed?\nQ4: Does duality proved in Thm 1 holds for Sinkhorn divergence (instead of classical OT without the entropy term)?\nLimitations: The authors mentioned the convergence properties of the proposed algorithm is left open.\nI agree with the authors that proving converges and calculation of convergence rate \nis an essential step that is currently missing.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The paper proposes to use optimal transport discrepancies as an alternative to the Kullback-Leibler divergence for Trust Region Policy Optimisation (TRPO). The authors provide the intractable optimisation problem (P), and then propose a dual formulation (D) of the optimal transport problem which is tractable. They base the proposed algorithm upon this dual formulation and perform the analysis of the method.\nStrengths And Weaknesses: Strengths:\n\nThe problem statement is interesting and gives insight into optimal transport formulation of the TRPO. The mathematical implementation is solid, and the idea of dual problem formulation to circumvent the intractability is theoretically well grounded.\nThe work is well placed within the current literature, and the authors contrast it with the existing trust regions and optimal transport-based methods such as Song et al (2022).\n\nWeaknesses:\n\nWhile the paper is sound, in the experimental analysis, it could be good to show the failure modes (see below) (see question 1 for the details below)\nIt would be also good to show the impact of different policy parameterisations as described in Algorithm 1, Step 5, as well as different estimates of the advantage function (Step 5); it is also important to more clearly outline which experiment uses which policy parameterisation and the advantage function (see question 2)\nQuestions: Questions:\nQuestion 1: While the analysis in the paper gives substantial detail on experimental comparison against other methods, as well as on a choice of optimal transport distance, it is still important to give more details on the failure modes. The closest I could get to that were the results from Hopper (Figure 1), where the model performs comparably with standard TRPO. Would be interesting to see if there are any other examples when TRPO works pretty much as well or outperforms the model, and what could be the reason behind it? While seeing that the experimental results show convincing experimental advantage, it looks like covering more limitations could be helpful in understanding the potential downsides of the method.\nQuestion 2:\nIn line 664 onwards, authors write:\n \u201cIn continuous action spaces, we also experimented with training a neural network that approximates \u00a0the advantage function of the current policy using Generalized Advantage Estimators. Our experimental results indicate that policy optimization with such a neural network approximate does not\u00a0perform comparably to the single sample estimation of the objective. In general, we observed that (1) simultaneous training of an advantage network and the OT-TRPO policy update could be unstable, and (2) in the case of convergence, OT-TRPO with neural advantage function approximation converges \u00a0to a suboptimal policy. We hypothesize that the OT-TRPO objective is sensitive to biased value\u00a0estimates due to the infimum over the action space in the neighborhood of the mean of the policy. \u00a0The observation that the optimal GAE hyperparameter in the single-sample advantage estimation \u00a0was very close to 1 (i.e., an unbiased Monte Carlo estimate) in our experiments supports this idea. \u201cWould be really good to explicitly state, for the experiments in the main text and in the appendix, which policy parameterisations and which advantage function estimates correspond to which experiment. To support the claim, is it possible, for example, to plot the comparison graphs for different types of estimates? \n**Question 3: **\nIn section A.5, I haven\u2019t found enough information on the details of implementation of the Monte-Carlo estimate, could the authors clarify on this to ensure reproducibility?\nLimitations: Societal impact limitations: I think the authors sufficiently addressed them, especially given that the problem statement of reinforcement learning in simulated environments, the datasets and similar methods are well-known as detailed in Section 2 of the paper.\nTechnical limitations: as outlined in questions, more experimental evidence on the failure modes could be given (see Question 1 for the details).\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 4 excellent\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper studies the trust region policy optimization (TRPO) problem, by replacing the KL divergence policy discrepancy constraint in TRPO with optimal transport discrepancies, such as Wasserstein distance. Considering the optimal transport discrepancy region, a dual form of the constrained problem has been developed, which contains a Lagrange multiplier \\lambda. Find the optimal \\lambda^* at each step only needs to solve a one-dimensional convex optimization problem, which can be solved using off-the-shelf solvers, instead of line-search in TRPO. Then, the optimal \\pi can be computed using \\lambda^* with closed-form solution. Experiments on both discrete and continuous settings are conducted.",
                "Strengths And Weaknesses": "Pros:\nThe paper is clearly written. It proposes a new dual form of trust region PO problem using optimal transport discrepancy, where the solution can be computed efficiently compared to line-search using KL divergence.\nCons:\nThe compared methods have included many closely related works in trust region PO, however, the benchmark environments are somehow limited and insufficient. Since the OT-TRPO is derived for both discrete and continuous actions, to give a thorough support for the effectiveness of OT-TRPO, it is recommended to evaluate on some standard RL benchmarks such as the Atari suite, and Mujoco families. The considered tasks, such as CliffWalking, Taxi, MountainCar, Swimmer, etc., are relatively simple environments, in which the learning steps are relatively small to obtain good performances for general algorithms.",
                "Questions": "Are there any explanations that for many environments, such as Taxi, Hopper, and Swimmer, TRPO learns much fasters at early stages compared to OT-TRPO? Does these environments share some similarity in dealing with the trust regions?\n\nWPO can be extended to deal with continuous actions as studied in the original paper, while it is ignored here. For example, in Hopper, WPO can reach much higher scores if we count for the same amount of learning steps. In Figure 1, it seems TRPO can achieve very competitive performance, while this differs from the results reported in BGPG and WNPG. Would the implementation of TRPO has some particular treatment here? \n\nWould an efficiency comparison with the line-search procedure in TRPO be possible? Since one important benefit using the optimal transport discrepancy is that the optimal policy at each step has a closed-form solution to avoid the computational line-search.\n\nLine 341: \u201cit leads to superior asymptotic performance\u201d. I do not think the sentence is rigorous, since when you refer to asymptotic performance you consider nearly infinite samples while the learning steps in the experiments are of very small scale considering current RL problems.\n\nMinor typos:\nLine 338: \u201cnot do\u201d -> \u201cdo not\u201d",
                "Limitations": "Some experimental results of the compared methods are not clear enough. Benchmark environments should be enriched to thoroughly evaluate the empirical performance of OT-TRPO.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper under review studied the problem of trust region policy optimization(TRPO).\nTRPO aims to optimize the expected return through stable policy update, where the \nstability is control by only allowing update within certain region around the current policy \nin each iteration. Hence one needs to pick a norm to measure distances between policies.\nIn this paper, the authors proposed to use OT distance.\nAllowing the continuous setting for action and state spaces, \nthey derive the dual of the proposed OT-TRPO and proved strong duality,\nbase on which, an update algorithm was proposed.\nMoreover, by establishing eq (11), the authors demonstrated the monotonic improvement of the proposed method.\nIn addition, the authors illustrated the efficiency of OT-TRPO through simulations.",
                "Strengths And Weaknesses": "The paper is well written and easy to follow.\nThe idea of using optimal transport discrepancy is natural and interesting.\nThe proposed update algorithm is nicely stated and and properly motivated.\nThe fact that it bypass the actual computation of the forward OT has many potential applications.\nThe theoretical results are sounds besides some questions listed below.",
                "Questions": "Q1: In section 4.3, the authors stated that eq(11) shows monotonicity of the update.\nHowever, to guarantee J(\u03c0~\u2217)>J(\u03c0), one needs to show that the sum of the last two terms in eq(11) is positive.\nIt is not clear why the sum is always positive. Would the authors explain a bit further on it?\nQ2: Regarding the experiments: what are the choices of costs and other parameters? Are the results sensitive to these choices?\nWhat is the running time comparing to other methods? In particular, step 4 and step 5 in Algo1.\nQ3: Is it possible to empirically validate that the proposed algorithm actually approximates the solution of problem (P)?\nFor example, check for a small discrete setting where OT solution can be computed?\nQ4: Does duality proved in Thm 1 holds for Sinkhorn divergence (instead of classical OT without the entropy term)?",
                "Limitations": "The authors mentioned the convergence properties of the proposed algorithm is left open.\nI agree with the authors that proving converges and calculation of convergence rate \nis an essential step that is currently missing.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper proposes to use optimal transport discrepancies as an alternative to the Kullback-Leibler divergence for Trust Region Policy Optimisation (TRPO). The authors provide the intractable optimisation problem (P), and then propose a dual formulation (D) of the optimal transport problem which is tractable. They base the proposed algorithm upon this dual formulation and perform the analysis of the method.",
                "Strengths And Weaknesses": "Strengths:\n\nThe problem statement is interesting and gives insight into optimal transport formulation of the TRPO. The mathematical implementation is solid, and the idea of dual problem formulation to circumvent the intractability is theoretically well grounded.\nThe work is well placed within the current literature, and the authors contrast it with the existing trust regions and optimal transport-based methods such as Song et al (2022).\n\nWeaknesses:\n\nWhile the paper is sound, in the experimental analysis, it could be good to show the failure modes (see below) (see question 1 for the details below)\nIt would be also good to show the impact of different policy parameterisations as described in Algorithm 1, Step 5, as well as different estimates of the advantage function (Step 5); it is also important to more clearly outline which experiment uses which policy parameterisation and the advantage function (see question 2)",
                "Questions": "Questions:\nQuestion 1: While the analysis in the paper gives substantial detail on experimental comparison against other methods, as well as on a choice of optimal transport distance, it is still important to give more details on the failure modes. The closest I could get to that were the results from Hopper (Figure 1), where the model performs comparably with standard TRPO. Would be interesting to see if there are any other examples when TRPO works pretty much as well or outperforms the model, and what could be the reason behind it? While seeing that the experimental results show convincing experimental advantage, it looks like covering more limitations could be helpful in understanding the potential downsides of the method.\nQuestion 2:\nIn line 664 onwards, authors write:\n \u201cIn continuous action spaces, we also experimented with training a neural network that approximates \u00a0the advantage function of the current policy using Generalized Advantage Estimators. Our experimental results indicate that policy optimization with such a neural network approximate does not\u00a0perform comparably to the single sample estimation of the objective. In general, we observed that (1) simultaneous training of an advantage network and the OT-TRPO policy update could be unstable, and (2) in the case of convergence, OT-TRPO with neural advantage function approximation converges \u00a0to a suboptimal policy. We hypothesize that the OT-TRPO objective is sensitive to biased value\u00a0estimates due to the infimum over the action space in the neighborhood of the mean of the policy. \u00a0The observation that the optimal GAE hyperparameter in the single-sample advantage estimation \u00a0was very close to 1 (i.e., an unbiased Monte Carlo estimate) in our experiments supports this idea. \u201cWould be really good to explicitly state, for the experiments in the main text and in the appendix, which policy parameterisations and which advantage function estimates correspond to which experiment. To support the claim, is it possible, for example, to plot the comparison graphs for different types of estimates? \n**Question 3: **\nIn section A.5, I haven\u2019t found enough information on the details of implementation of the Monte-Carlo estimate, could the authors clarify on this to ensure reproducibility?",
                "Limitations": "Societal impact limitations: I think the authors sufficiently addressed them, especially given that the problem statement of reinforcement learning in simulated environments, the datasets and similar methods are well-known as detailed in Section 2 of the paper.\nTechnical limitations: as outlined in questions, more experimental evidence on the failure modes could be given (see Question 1 for the details).",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "4 excellent",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.0,
        "confidence_avg": 3.333,
        "soundness_avg": 3.0,
        "presentation_avg": 3.333,
        "contribution_avg": 3.333,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the paper proposes a novel approach to the trust region policy optimization (TRPO) problem by using optimal transport discrepancies. The paper is well-written and the proposed method is theoretically well-grounded. The reviewers have raised some valid concerns and questions regarding the experimental evaluation and the limitations of the proposed method.\n\nReviewer 1 suggests that the benchmark environments used in the experiments are limited and recommends evaluating the method on standard RL benchmarks such as the Atari suite and Mujoco families. They also raise questions about the faster learning of TRPO compared to OT-TRPO in certain environments and the efficiency comparison with the line-search procedure in TRPO.\n\nReviewer 2 acknowledges the natural and interesting idea of using optimal transport discrepancy and praises the well-stated and motivated update algorithm. They raise questions about the monotonicity of the update, the choices of costs and other parameters in the experiments, the empirical validation of the proposed algorithm, and the duality for Sinkhorn divergence.\n\nReviewer 3 highlights the solid mathematical implementation and the theoretical grounding of the proposed method. They suggest providing more details on the failure modes in the experimental analysis and clarifying the policy parameterizations and advantage function estimates used in the experiments. They also request more information on the implementation of the Monte-Carlo estimate for reproducibility.\n\nOverall, the reviewers find the paper technically solid and with good-to-excellent evaluation. They have no major concerns with respect to evaluation, resources, reproducibility, or ethical considerations.\n\nBased on the reviews, I recommend accepting the paper. The proposed method addresses an interesting problem and the theoretical foundation is sound. While there are some limitations and questions raised by the reviewers, they do not outweigh the positive aspects of the paper. I am confident in this assessment and believe that the paper will make a valuable contribution to the field."
    },
    "Modeling_Transitivity_and_Cyclicity_in_Directed_Graphs_via_Binary_Code_Box_Embeddings": {
        "link": "https://openreview.net//forum?id=kpSAfnHSgXR",
        "pub_url": "https://openreview.net/forum?id=kpSAfnHSgXR",
        "pdf_link": "https://openreview.net//pdf?id=kpSAfnHSgXR",
        "paper_id": "kpSAfnHSgXR",
        "title": "Modeling_Transitivity_and_Cyclicity_in_Directed_Graphs_via_Binary_Code_Box_Embeddings",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Less certain\nThis paper extends box embeddings to allow for them to represent directed graphs. In particular, the proposed binary box embeddings can represent cycles in graphs, which was not previously possible. The reviewers appreciated the introduction of binary box embeddings and felt the contribution was novel and elegant. During the discussion, the reviewers felt that the rebuttal generally answered their questions and felt that the contribution would be of interest to the NeurIPS community. \nA number of clarity issues brought up in the initial reviews should be addressed for the final version of the work, for instance, the motivation of the binary code embeddings and the discussions with 3KMQ on transitivity holding. Please revise the paper to address the remaining comments from the reviewers and carefully incorporate the additional results presented during the author response discussion phase.",
        "reviews": [
            "Reviewer 1: \nSummary: Introduces the concept of binary code box embeddings and theoretically shows that the proposed models have the expressive power to model arbitrary directed cyclic graphs. Empirical result suggests that the proposed models perform better on 4 link prediction datasets compared to vector based baselines.\nStrengths And Weaknesses: \nBinary code box embeddings is a novel concept with nice theoretical intuitions. It relieves some of the constraints of box embeddings at the expense of weakening transitivity. \n\nShowed both theoretically and empirically the advantage of the binary code models being able to model directed cyclic graphs. \n\nProvided nice intuition for proposed concepts using interval graphs, including box embeddings can be thought of representing a graph as an intersection over some learned subgraphs. Binary codes can be thought of redefining \u201cintersection\u201d, such that two non-overlapping boxes can be seen as overlapping by selecting which dimensions to ignore using the binary codes.\nQuestions: \nThe paper does a good job analysing the expressive power of the model. However, as the author(s) mention, whether or not the model can be trained via gradient descent is not yet clear. The paper does not currently have details on the optimization challenges/ease of the proposed models vs the other baselines. It is often possible that the expressive power is sufficient, but the optimization difficulty is high.\n\nWhile the intuition of binary code box embedding bases off box embeddings, and has a nice theoretical picture, it is hard to intuitively see how much of the geometry structures are still learned by the models, since binary codes break transitivity. It would be interesting to see a visual comparison of the learned boxes in 2D with and without binary codes.\nLimitations: How are the binary code represented during training/inference? Are they represented as a probability since the model is trained using gradient descent, or are they pushed to 0 and 1s?\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The authors consider the problem of modeling directed graphs for semi-supervised link prediction. They propose a new model based on an extension of box embeddings which enables greater representational capacity, particularly in the presence of cycles. This extension may be viewed as a decomposition of a graph into a finite union of graphs, each of which modeled using (modified) box embeddings. The authors show that, with sufficiently high-dimensional embeddings, this model may represent an arbitrary directed acyclic graph. The authors demonstrate the effectiveness of their model through some experiments on synthetic graph models, and some applications on real data.\nStrengths And Weaknesses: Overall, I found the proposed method interesting and with good empirical performance. The authors propose an elegant solution to address issues with existing geometric embedding models. However, I also found this work to be fairly incremental (especially with respect to [2]), both from a theoretical and an empirical perspective, and had some doubts on the general motivation of the paper. Finally, I have some concerns in the empirical evaluations in the paper as it currently stands (see questions). On the balance, I do not feel that this work is currently a substantial enough contribution to warrant publication, although I am willing to revisit this judgment should my questions be addressed.\nThe modification proposed by the authors is elegant and addresses a potential issue in the representational power of box embeddings for graphs, namely the ability to model directed cycles. However, it is not clear to me how this relates to the claims around transitivity. Indeed, it seems to me that in the setting considered by the authors, transitivity is viewed not as a symbolic requirement, but rather a feature of the data (\u201csoft transitivity\u201d). In that setting, the argument given by the authors on ll. 34-35, that there is no encouragement for transitivity to hold seems suspicious: given that such edges are present in the data, it is unclear why a purely data-based approach is not able to recover them.\nAlthough the proposal of the authors is well-motivated theoretically, I found the empirical results to be unconvincing. Indeed, in table 3, the authors show that the G-box model achieves the same performance for 3 of the 4 benchmarks, and is only slightly behind on the 4th one. In practice, it thus seems that the cycle representation is not an issue, and the model is able to disambiguate cycles based on additional context. Especially given the additional flexibility in the *BC-box models, would the authors be able to provide additional empirical evidence that the difference, when it exists, is due to the inability to model cycles?\nTypos:\nL. 36 ok -> tk\nL. 90 it\u2019s -> its\nQuestions: It is unclear to me how the baseline vector model differs from existing pairwise latent embedding models such as node2vec. Indeed, it seems to me that the edge likelihood is exactly the same in either case (modulo directedness, which can be dealt with in such representations by separating the source and target embedding) - the crucial difference being the way edges are sampled and the effective induced weighting through the sampling procedure. Would the authors be able to describe in more detail what the exact loss for the vector model is?\nIn the paragraph preceding table 3, the authors mention that they evaluate t-Box, but this does not seem to appear in the table. Could the authors share these numbers and add them to the table?\nI was confused by the accounting of the number of parameters in the binarycode models in the provided code in the supplementary. My reading of the current code (model.py:375-378) indicates that the total number of parameters is 3dim. However, in main.py:33 the computation of dim as a function of num_parameters and shared_dim gives, e.g. when shared_dim = num_parameters / 2 that dim = num_parameters / 2, leading to a total of 50% more parameters than claimed. Running the code and inspecting the generated embedding tensors seems to support that claim. Would the authors be able to comment on how the parameters are counted for the binary box models?\nLimitations: I did not find any particular limitation except as described in the weaknesses. I do not believe this work has any particular societal impact.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper proposed an extension of box embedding on dealing with directed graphs with cycles. The idea is called binary code box embedding, which learns to project the box embeddings into a subspace of the box space. The authors prove the theoretical expressivity of the proposed model. Empirical results on two tasks further show that the model provides useful inductive biases for preserving transitivity and cyclicity.\nStrengths And Weaknesses: Pros\n\nAn interesting extension of box embeddings for modeling cyclicity \nStrong empirical results\n\nCons\n\nTheoretical results in Sec 3.1 are taken from [2]. The author should cite it right after the title like \u201cTheorem 1 [2]\u201d to avoid misunderstanding. \nTheoretical results in Sec 3.2 are a bit trivial. It seems very clear that the box embedding cannot model any cycles in any dimension.\nThe motivation for using binary code embedding is not very clear. Could you give an example of how the projection models cycles? For instance, how binary code box embedding can embed a pure cycle with 4 nodes with minimal dimension? that would be a nice picture that gives readers an intuition of the idea.\nQuestions: The author in [1] proved that box embedding has some theoretical limitations on embedding some directed graphs (e.g., a counterexample is given in section 7.3 of [1]). How does the proposed model encode such a counterexample?\n[1] Vilnis, L., 2021. Geometric Representation Learning.\nLimitations: The authors discussed the limitations of the proposed Binary Code Box Embeddings and proposed a regularization term to alleviate but not fully address such problem.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "Introduces the concept of binary code box embeddings and theoretically shows that the proposed models have the expressive power to model arbitrary directed cyclic graphs. Empirical result suggests that the proposed models perform better on 4 link prediction datasets compared to vector based baselines.",
                "Strengths And Weaknesses": "Binary code box embeddings is a novel concept with nice theoretical intuitions. It relieves some of the constraints of box embeddings at the expense of weakening transitivity. \n\nShowed both theoretically and empirically the advantage of the binary code models being able to model directed cyclic graphs. \n\nProvided nice intuition for proposed concepts using interval graphs, including box embeddings can be thought of representing a graph as an intersection over some learned subgraphs. Binary codes can be thought of redefining \u201cintersection\u201d, such that two non-overlapping boxes can be seen as overlapping by selecting which dimensions to ignore using the binary codes.",
                "Questions": "The paper does a good job analysing the expressive power of the model. However, as the author(s) mention, whether or not the model can be trained via gradient descent is not yet clear. The paper does not currently have details on the optimization challenges/ease of the proposed models vs the other baselines. It is often possible that the expressive power is sufficient, but the optimization difficulty is high.\n\nWhile the intuition of binary code box embedding bases off box embeddings, and has a nice theoretical picture, it is hard to intuitively see how much of the geometry structures are still learned by the models, since binary codes break transitivity. It would be interesting to see a visual comparison of the learned boxes in 2D with and without binary codes.",
                "Limitations": "How are the binary code represented during training/inference? Are they represented as a probability since the model is trained using gradient descent, or are they pushed to 0 and 1s?",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors consider the problem of modeling directed graphs for semi-supervised link prediction. They propose a new model based on an extension of box embeddings which enables greater representational capacity, particularly in the presence of cycles. This extension may be viewed as a decomposition of a graph into a finite union of graphs, each of which modeled using (modified) box embeddings. The authors show that, with sufficiently high-dimensional embeddings, this model may represent an arbitrary directed acyclic graph. The authors demonstrate the effectiveness of their model through some experiments on synthetic graph models, and some applications on real data.",
                "Strengths And Weaknesses": "Overall, I found the proposed method interesting and with good empirical performance. The authors propose an elegant solution to address issues with existing geometric embedding models. However, I also found this work to be fairly incremental (especially with respect to [2]), both from a theoretical and an empirical perspective, and had some doubts on the general motivation of the paper. Finally, I have some concerns in the empirical evaluations in the paper as it currently stands (see questions). On the balance, I do not feel that this work is currently a substantial enough contribution to warrant publication, although I am willing to revisit this judgment should my questions be addressed.\nThe modification proposed by the authors is elegant and addresses a potential issue in the representational power of box embeddings for graphs, namely the ability to model directed cycles. However, it is not clear to me how this relates to the claims around transitivity. Indeed, it seems to me that in the setting considered by the authors, transitivity is viewed not as a symbolic requirement, but rather a feature of the data (\u201csoft transitivity\u201d). In that setting, the argument given by the authors on ll. 34-35, that there is no encouragement for transitivity to hold seems suspicious: given that such edges are present in the data, it is unclear why a purely data-based approach is not able to recover them.\nAlthough the proposal of the authors is well-motivated theoretically, I found the empirical results to be unconvincing. Indeed, in table 3, the authors show that the G-box model achieves the same performance for 3 of the 4 benchmarks, and is only slightly behind on the 4th one. In practice, it thus seems that the cycle representation is not an issue, and the model is able to disambiguate cycles based on additional context. Especially given the additional flexibility in the *BC-box models, would the authors be able to provide additional empirical evidence that the difference, when it exists, is due to the inability to model cycles?\nTypos:\nL. 36 ok -> tk\nL. 90 it\u2019s -> its",
                "Questions": "It is unclear to me how the baseline vector model differs from existing pairwise latent embedding models such as node2vec. Indeed, it seems to me that the edge likelihood is exactly the same in either case (modulo directedness, which can be dealt with in such representations by separating the source and target embedding) - the crucial difference being the way edges are sampled and the effective induced weighting through the sampling procedure. Would the authors be able to describe in more detail what the exact loss for the vector model is?\nIn the paragraph preceding table 3, the authors mention that they evaluate t-Box, but this does not seem to appear in the table. Could the authors share these numbers and add them to the table?\nI was confused by the accounting of the number of parameters in the binarycode models in the provided code in the supplementary. My reading of the current code (model.py:375-378) indicates that the total number of parameters is 3dim. However, in main.py:33 the computation of dim as a function of num_parameters and shared_dim gives, e.g. when shared_dim = num_parameters / 2 that dim = num_parameters / 2, leading to a total of 50% more parameters than claimed. Running the code and inspecting the generated embedding tensors seems to support that claim. Would the authors be able to comment on how the parameters are counted for the binary box models?",
                "Limitations": "I did not find any particular limitation except as described in the weaknesses. I do not believe this work has any particular societal impact.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposed an extension of box embedding on dealing with directed graphs with cycles. The idea is called binary code box embedding, which learns to project the box embeddings into a subspace of the box space. The authors prove the theoretical expressivity of the proposed model. Empirical results on two tasks further show that the model provides useful inductive biases for preserving transitivity and cyclicity.",
                "Strengths And Weaknesses": "Pros\n\nAn interesting extension of box embeddings for modeling cyclicity \nStrong empirical results\n\nCons\n\nTheoretical results in Sec 3.1 are taken from [2]. The author should cite it right after the title like \u201cTheorem 1 [2]\u201d to avoid misunderstanding. \nTheoretical results in Sec 3.2 are a bit trivial. It seems very clear that the box embedding cannot model any cycles in any dimension.\nThe motivation for using binary code embedding is not very clear. Could you give an example of how the projection models cycles? For instance, how binary code box embedding can embed a pure cycle with 4 nodes with minimal dimension? that would be a nice picture that gives readers an intuition of the idea.",
                "Questions": "The author in [1] proved that box embedding has some theoretical limitations on embedding some directed graphs (e.g., a counterexample is given in section 7.3 of [1]). How does the proposed model encode such a counterexample?\n[1] Vilnis, L., 2021. Geometric Representation Learning.",
                "Limitations": "The authors discussed the limitations of the proposed Binary Code Box Embeddings and proposed a regularization term to alleviate but not fully address such problem.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.333,
        "confidence_avg": 3.333,
        "soundness_avg": 2.667,
        "presentation_avg": 3.333,
        "contribution_avg": 2.667,
        "ai_sum_meta": "Recommendation: Reject\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that the proposed binary code box embeddings model has some interesting theoretical and empirical aspects. However, there are several concerns raised by the reviewers that need to be addressed. Reviewer 1 points out the lack of details on the optimization challenges and the need for visual comparisons of learned boxes. Reviewer 2 questions the motivation of the paper and finds the empirical results unconvincing. Reviewer 3 highlights the lack of clarity in the motivation for using binary code embeddings and suggests providing an example for better understanding. Considering these concerns, it is recommended to reject the paper."
    },
    "Simple_and_Optimal_Greedy_Online_Contention_Resolution_Schemes": {
        "link": "https://openreview.net//forum?id=qx51yfvLnE",
        "pub_url": "https://openreview.net/forum?id=qx51yfvLnE",
        "pdf_link": "https://openreview.net//pdf?id=qx51yfvLnE",
        "paper_id": "qx51yfvLnE",
        "title": "Simple_and_Optimal_Greedy_Online_Contention_Resolution_Schemes",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nExecutive summary:\nThe paper considers the design of greedy online contention resolution schemes (OCRS) for the single-item setting and certain matroids (partition matroids, transversal matroids). The main result is that there is a 1/e-selectable greedy OCRS (which improves over the best known bound of 1/4 for greedy OCRS), and that this is best possible.\nDiscussion and recommendation:\nThis is a nice little result. Not tremendously difficult, but fundamental. A plus is that the question is resolved tightly. All but one reviewer felt positively about the paper. A major concern raised in the reviews was that it's unclear why we care about greedy OCRS. In the rebuttal, the authors emphasized that greedy OCRS yield guarantees against an almighty adversary and that they recently found application in a delegation variant of the Pandora's Box problem (Bechtel, Dughmi, and Patel [EC'22]).\n(Weak) accept.\n\nAdditional comments:\nI always thought of OCRS as one of the two main techniques that have emerged for proving prophet inequalities and guarantees for posted-price mechanisms; the other being the \"balanced prices\" framework. I would encourage to extend the discussion in the related work accordingly, and cite the most relevant works on the \"balanced prices\" framework. Or, at least, cite the most relevant papers in that direction (see list below).\nCitations to add:\nKleinberg and Weinberg. Matroid Prophet Inequalities. STOC'12.\nFeldman, Gravin, Lucier. Combinatorial Auctions via Posted Prices. SODA'15.\nD\"utting, Feldman, Kesselheim, Lucier. Prophet Inequalities made Easy: Stochastic Optimization by Pricing Non-Stochastic Inputs. FOCS'17.\nD\"utting, Kesselheim, Lucier. An O(log log m) Prophet Inequality for Subadditive Combinatorial Auctions. FOCS'20.",
        "reviews": [
            "Reviewer 1: \nSummary: The paper considers greedy online contention resolution schemes. A contention resolution scheme (CRS) is, roughly, a method to round a fractional solution for a (packing) problem to a random integral one. More precisely, given a vector x\u2208[0,1]n that is feasible for a fractional relaxation of a problem, let y\u22080,1n be an integral vector obtained by selecting each yi to be 1 independently with probability xi. But y may be infeasible for the problem, so now the task of the CRS is to switch some of the yi from 1 to 0 in order to obtain a feasible solution (in other words, the CRS selects an integral z\u2264y that is feasible). A CRS is online (abbrev. OCRS) if the yi are revealed one by one, and the OCRS has to pick zi immediately after yi is revealed. OCRSs have applications to various online problems such as prophet inequalities, stochastic probing etc. An OCRS is said to be c-selectable if, roughly, P(zi=1)\u2265c\u22c5xi for each i (the precise definition given in the paper is somewhat more complicated, which I believe has to do with the type of ``almighty adversary\u2019\u2019 considered, which can choose the order in which the entries of yi are revealed with full knowledge of all random number generators). Intuitively, a c-selectable OCRS corresponds to losing a factor c in the rounding procedure.\nThe paper considers a subtype of OCRSs that are called greedy, which means that it first chooses (randomly) a downwards-closed family of coordinates, corresponding to a subset of feasible solutions, and then greedily tries to set each zi to 1 if possible while maintaining a solution corresponding to this downwards-closed family.\nResults:\n\nThey give a 1/e-selectable greedy OCRS for the single-item setting (i.e, the feasibility constraint is \u2211ixi\u22641). This improves over the previous 1/4-selectable greedy OCRS, but is worse than the known 1/2-selectability achieved by a non-greedy OCRS. It also implies immediately the same result for partition matroids.\nThey show that 1/e is tight for greedy OCRSs for the single-item setting.\nThey extend their result to so-called transversal matroids.\n\nIn an experimental evaluation, their 1/e-selectable greedy OCRS indeed improves upon the previous 1/4-selectable greedy OCRS.\nStrengths And Weaknesses: The main result \u2014 improving from 1/4 to 1/e and showing tightness \u2014 is the final answer for single-item greedy OCRSs. This is a nice and clean result. I\u2019m not entirely sure about the significance though, given that a (better) 1/2-selectable non-greedy OCRS is known. Why would one choose this greedy OCRS when the known non-greedy one performs better? The experimental evaluation only contains comparison with the previous (suboptimal) greedy one, but not with the better non-greedy one.\nThe writing is mostly good, but some things were unclear to me for some time because of insufficient definitions (see below; but I could eventually guess the likely intended meaning).\nQuestions: A discussion about benefits of greedy over non-greedy OCRSs would be useful. Are they significantly simpler? Does the 1/2-selectability of the known non-greedy OCRS also hold against almighty adversaries?\nSpecific (minor) comments:\n\nLine 172: Is PI the same thing that you denoted as P before?\nLine 175: What is R(x)? I later found kind of a definition of R in the introduction, but it would have been good to define it in preliminaries.\nLine 211, 237 and elsewhere: You omit some of the subscripts of F. It would have been good to state explicitly that you may drop them from the notation.\nLine 234: Here you seemingly use R with a different meaning than before.\nLine 246: One of the xi should be xj.\nLine 274: Presumably Rv only contains neighbors of v? Otherwise, how would you conclude that each S\u2208F is covered by a matching?\nLine 302 you say that number of iterations is set to 200,000, but in the caption of Figure 1 it states 10,000 instead of 200,000.\nFigure 2: What is the number on the x-axis? I thought it\u2019s the size of N(u), but it goes up to 4 whereas in the description of the setup you say it goes only up to 3.\nLimitations: This is a theoretical work and negative societal impact is not expected. Limitations are clear from the mathematical formulations.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 3 good\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper presents some results regarding online contention resolution schemes. The main result, to my taste, is the result for selecting a single item. One can rephrase this result as follows. We are given a point x in the simplex (\\sum x_i \\le 1) and then draw a random set of \u201celements\u201d by taking each one with probability x_i independently. The elements will then be presented to us in arbitrary order and we have to select one upon seeing it. The question is: What is the best number c such that the probability of selecting any element is at least cx_i? The paper proves that the best such c is 1/e. Nice! The way to do it is as follows. You draw this random set, then clean it up by dropping each element on it with probability 1-x_i/2, and finally take the first element that was not dropped. This can be implemented as a greedy OCRS and therefore it improves upon the factor 1/4 of FSZ16. Also, it is not too hard to show this is best possible. One should note that this clean-up step is needed as otherwise we may have a \u201clarge\u201d probability element that may come first and then would block the remaining \u201csmall\u201d probability elements from ever appearing. Say x_1=1-eps and x_2=eps, if we do not clean-up we will only get element 2 w.p. eps^2.\nThe paper also extends this idea to some classes of transversal matroids.\nStrengths And Weaknesses: The main result is nice and simple. I appreciate that. The authors also show it can be useful in related more complex settings though that part did not feel like very exciting to me. \nI do not like the write-up very much. It is written for specialists and not for a wide audience. Even the problem definition is not clearly stated and there are missing definitions (e.g. that of R(x)). \nI think the authors should try to rephrase their main result in simple terms (in particular without using the OCRS terminology) in the first few pages of the paper. This is relatively easy. And then, once they really need matroids and more general CRS they can give more notation and technicalities.\nQuestions: No further questions\nLimitations: none\nEthics Flag: No\nEthics Review Area: I don\u2019t know\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: An Online Contention Resolution Scheme (OCRS) is a rounding technique designed for online optimization problems especially in Bayesian optimization (example prophet inequalities). The paper focuses on Greedy online contention resolution schemes and provides an optimal greedy OCRS for the single-item setting as well as for more general constraint sets such as partition matroids and transversal matroids. The paper also demonstrates a matching lower bound.\nStrengths And Weaknesses: The paper provides an elegant greedy OCRS for the single-item setting. The scheme itself is very simple and simply selects in F each element i with probability q_i := 1 - x_i/2. The algorithm then selects the first item (in adversarial order) that is active and selected in F. \nSince the work of Feldman etal (that introduced OCRS) also introduced the notion of greedy OCRSs back in 2015, it is rather satisfying to see such a simple scheme that is provably optimal (among greedy schemes).\nI believe that while interesting, the paper is of limited interest to the Neurips community and would be better suited at a TCS venue.\nQuestions: \nIn Definition 2.1, property 2,  what is R(x)? Did you mean A there?\nIn Definition 2.1, could you clarify the order of quantifiers? Are properties 1 and 2 simultaneously satisfied for all sets A and all points x?\nIn Definition 2.1, property 2, should the RHS be c*x_i?\nIn Definition 2.2, clarify that the random subset R(x) is drawn so that the marginal probability of i \\in R(x) = x_i.\nIn line 246, typo - 1 - x_j(1-x_j / 2)\nIn line 261, \u201cno greedy OCRS cannot\u201d -> \u201cno greedy OCRS can\u201d\nLimitations: None\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 3 good\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: The paper studies the problem of designing greedy online content resolution schemes (OCRSs). The author provide an OCRS that provides a 1e-selectable greedy strategy for single-item settings and partition matroids. Then, they provide a similar result for transversal matroids. In this case, they also provide a better result for specific settings.\nMoreover, they show that these results are tight for greedy OCRC. Finally, they provides a experimental analysis with a comparison with previous works.\nStrengths And Weaknesses: strengths: The paper provides better results than previous work. Moreover, the authors show that this bound is tight. The paper is easy to follow and provides a detailed analysis of previous works.\nWeakness: The derivation of the technical results do not seem too involved.\nQuestions: Why is it an important property for OCRSs being greedy? Is it simply because they work against an almighty adversary?\nLimitations: Yes.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The paper considers greedy online contention resolution schemes. A contention resolution scheme (CRS) is, roughly, a method to round a fractional solution for a (packing) problem to a random integral one. More precisely, given a vector x\u2208[0,1]n that is feasible for a fractional relaxation of a problem, let y\u22080,1n be an integral vector obtained by selecting each yi to be 1 independently with probability xi. But y may be infeasible for the problem, so now the task of the CRS is to switch some of the yi from 1 to 0 in order to obtain a feasible solution (in other words, the CRS selects an integral z\u2264y that is feasible). A CRS is online (abbrev. OCRS) if the yi are revealed one by one, and the OCRS has to pick zi immediately after yi is revealed. OCRSs have applications to various online problems such as prophet inequalities, stochastic probing etc. An OCRS is said to be c-selectable if, roughly, P(zi=1)\u2265c\u22c5xi for each i (the precise definition given in the paper is somewhat more complicated, which I believe has to do with the type of ``almighty adversary\u2019\u2019 considered, which can choose the order in which the entries of yi are revealed with full knowledge of all random number generators). Intuitively, a c-selectable OCRS corresponds to losing a factor c in the rounding procedure.\nThe paper considers a subtype of OCRSs that are called greedy, which means that it first chooses (randomly) a downwards-closed family of coordinates, corresponding to a subset of feasible solutions, and then greedily tries to set each zi to 1 if possible while maintaining a solution corresponding to this downwards-closed family.\nResults:\n\nThey give a 1/e-selectable greedy OCRS for the single-item setting (i.e, the feasibility constraint is \u2211ixi\u22641). This improves over the previous 1/4-selectable greedy OCRS, but is worse than the known 1/2-selectability achieved by a non-greedy OCRS. It also implies immediately the same result for partition matroids.\nThey show that 1/e is tight for greedy OCRSs for the single-item setting.\nThey extend their result to so-called transversal matroids.\n\nIn an experimental evaluation, their 1/e-selectable greedy OCRS indeed improves upon the previous 1/4-selectable greedy OCRS.",
                "Strengths And Weaknesses": "The main result \u2014 improving from 1/4 to 1/e and showing tightness \u2014 is the final answer for single-item greedy OCRSs. This is a nice and clean result. I\u2019m not entirely sure about the significance though, given that a (better) 1/2-selectable non-greedy OCRS is known. Why would one choose this greedy OCRS when the known non-greedy one performs better? The experimental evaluation only contains comparison with the previous (suboptimal) greedy one, but not with the better non-greedy one.\nThe writing is mostly good, but some things were unclear to me for some time because of insufficient definitions (see below; but I could eventually guess the likely intended meaning).",
                "Questions": "A discussion about benefits of greedy over non-greedy OCRSs would be useful. Are they significantly simpler? Does the 1/2-selectability of the known non-greedy OCRS also hold against almighty adversaries?\nSpecific (minor) comments:\n\nLine 172: Is PI the same thing that you denoted as P before?\nLine 175: What is R(x)? I later found kind of a definition of R in the introduction, but it would have been good to define it in preliminaries.\nLine 211, 237 and elsewhere: You omit some of the subscripts of F. It would have been good to state explicitly that you may drop them from the notation.\nLine 234: Here you seemingly use R with a different meaning than before.\nLine 246: One of the xi should be xj.\nLine 274: Presumably Rv only contains neighbors of v? Otherwise, how would you conclude that each S\u2208F is covered by a matching?\nLine 302 you say that number of iterations is set to 200,000, but in the caption of Figure 1 it states 10,000 instead of 200,000.\nFigure 2: What is the number on the x-axis? I thought it\u2019s the size of N(u), but it goes up to 4 whereas in the description of the setup you say it goes only up to 3.",
                "Limitations": "This is a theoretical work and negative societal impact is not expected. Limitations are clear from the mathematical formulations.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper presents some results regarding online contention resolution schemes. The main result, to my taste, is the result for selecting a single item. One can rephrase this result as follows. We are given a point x in the simplex (\\sum x_i \\le 1) and then draw a random set of \u201celements\u201d by taking each one with probability x_i independently. The elements will then be presented to us in arbitrary order and we have to select one upon seeing it. The question is: What is the best number c such that the probability of selecting any element is at least cx_i? The paper proves that the best such c is 1/e. Nice! The way to do it is as follows. You draw this random set, then clean it up by dropping each element on it with probability 1-x_i/2, and finally take the first element that was not dropped. This can be implemented as a greedy OCRS and therefore it improves upon the factor 1/4 of FSZ16. Also, it is not too hard to show this is best possible. One should note that this clean-up step is needed as otherwise we may have a \u201clarge\u201d probability element that may come first and then would block the remaining \u201csmall\u201d probability elements from ever appearing. Say x_1=1-eps and x_2=eps, if we do not clean-up we will only get element 2 w.p. eps^2.\nThe paper also extends this idea to some classes of transversal matroids.",
                "Strengths And Weaknesses": "The main result is nice and simple. I appreciate that. The authors also show it can be useful in related more complex settings though that part did not feel like very exciting to me. \nI do not like the write-up very much. It is written for specialists and not for a wide audience. Even the problem definition is not clearly stated and there are missing definitions (e.g. that of R(x)). \nI think the authors should try to rephrase their main result in simple terms (in particular without using the OCRS terminology) in the first few pages of the paper. This is relatively easy. And then, once they really need matroids and more general CRS they can give more notation and technicalities.",
                "Questions": "No further questions",
                "Limitations": "none",
                "Ethics Flag": "No",
                "Ethics Review Area": "I don\u2019t know",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "An Online Contention Resolution Scheme (OCRS) is a rounding technique designed for online optimization problems especially in Bayesian optimization (example prophet inequalities). The paper focuses on Greedy online contention resolution schemes and provides an optimal greedy OCRS for the single-item setting as well as for more general constraint sets such as partition matroids and transversal matroids. The paper also demonstrates a matching lower bound.",
                "Strengths And Weaknesses": "The paper provides an elegant greedy OCRS for the single-item setting. The scheme itself is very simple and simply selects in F each element i with probability q_i := 1 - x_i/2. The algorithm then selects the first item (in adversarial order) that is active and selected in F. \nSince the work of Feldman etal (that introduced OCRS) also introduced the notion of greedy OCRSs back in 2015, it is rather satisfying to see such a simple scheme that is provably optimal (among greedy schemes).\nI believe that while interesting, the paper is of limited interest to the Neurips community and would be better suited at a TCS venue.",
                "Questions": "In Definition 2.1, property 2,  what is R(x)? Did you mean A there?\nIn Definition 2.1, could you clarify the order of quantifiers? Are properties 1 and 2 simultaneously satisfied for all sets A and all points x?\nIn Definition 2.1, property 2, should the RHS be c*x_i?\nIn Definition 2.2, clarify that the random subset R(x) is drawn so that the marginal probability of i \\in R(x) = x_i.\nIn line 246, typo - 1 - x_j(1-x_j / 2)\nIn line 261, \u201cno greedy OCRS cannot\u201d -> \u201cno greedy OCRS can\u201d",
                "Limitations": "None",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper studies the problem of designing greedy online content resolution schemes (OCRSs). The author provide an OCRS that provides a 1e-selectable greedy strategy for single-item settings and partition matroids. Then, they provide a similar result for transversal matroids. In this case, they also provide a better result for specific settings.\nMoreover, they show that these results are tight for greedy OCRC. Finally, they provides a experimental analysis with a comparison with previous works.",
                "Strengths And Weaknesses": "strengths: The paper provides better results than previous work. Moreover, the authors show that this bound is tight. The paper is easy to follow and provides a detailed analysis of previous works.\nWeakness: The derivation of the technical results do not seem too involved.",
                "Questions": "Why is it an important property for OCRSs being greedy? Is it simply because they work against an almighty adversary?",
                "Limitations": "Yes.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "soundness_avg": 3.75,
        "presentation_avg": 2.75,
        "contribution_avg": 2.5,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is clear that the paper presents a technically solid contribution in the field of online contention resolution schemes (OCRSs). The main result of the paper, which improves the 1/4-selectable greedy OCRS to a 1/e-selectable one for the single-item setting, is considered a nice and clean result. However, there are some concerns raised by the reviewers regarding the significance of this improvement compared to the known 1/2-selectable non-greedy OCRS. The experimental evaluation also lacks a comparison with the better non-greedy OCRS.\n\nOverall, the paper provides a simple and optimal greedy OCRS for the single-item setting, and extends the result to partition matroids and transversal matroids. The results are supported by theoretical analysis and experimental evaluation. While the write-up could be improved to make it more accessible to a wider audience, the technical contributions and impact of the paper are considered moderate-to-high.\n\nTherefore, based on the positive evaluations and the lack of major concerns, I recommend accepting the paper."
    },
    "Evaluating_Latent_Space_Robustness_and_Uncertainty_of_EEG-ML_Models_under_Realistic_Distribution_Shifts": {
        "link": "https://openreview.net//forum?id=KRk0lBRPpOC",
        "pub_url": "https://openreview.net/forum?id=KRk0lBRPpOC",
        "pdf_link": "https://openreview.net//pdf?id=KRk0lBRPpOC",
        "paper_id": "KRk0lBRPpOC",
        "title": "Evaluating_Latent_Space_Robustness_and_Uncertainty_of_EEG-ML_Models_under_Realistic_Distribution_Shifts",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nThe paper introduces model-agnostic ways of quantifying predictive uncertainty and latent space differences in the situation when the distribution of data encountered during deployment differs from what the system was trained on and there is no access to the data itself. The model is evaluated on large scale EEG data.\nThe paper solves an important problem, in particular to the field of healthcare which has previously seen instances of models underperforming significantly at the time of deployment. As mentioned by the reviewers, this direction has not been sufficiently explored, so there is novelty in the problem itself, as well as in the solution. The experiments on EEG data were seen as convincing by the reviewers, though some questions were raised about the scope of the paper.\nOverall, there is considerable merit in the work and recommend acceptance of this paper. In the camera ready, the authors should make sure not to overstate the applicability of their method. While this work could, in theory, be applied (or adapted) to other data, the merits of it outside of models trained on EEG data have not been demonstrated and should therefore not be stated as a given.\nReviewers x119 and PL6S have not engaged in the discussion although the authors responded to the issues they raised, which I kept in mind when issuing my recommendation.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper introduces four EEG signal transformations to model the real-world variability observable during deployment. Then, the paper proposes a multi-pronged approach to evaluate the robustness of healthcare ML models. It is well-organized and easy to follow. The extensive experiments demonstrate the paper's claims.\nStrengths And Weaknesses: \nThis paper introduces four EEG signal transformations to model the real-world variability observable during deployment. \nThe paper proposes a multi-pronged approach to evaluate the robustness of healthcare ML models.\nRealistic data shifts in EEG data are explored in the paper.\nThe extensive experiments are conducted on real-world datasets and demonstrate the paper's claims.\nQuestions: \nthe paper's title is so broad. it should be focused on a EEGs.\nthe paper should list baseline models' performance on the related tasks.\nLimitations: \nthe novelty of the paper is weak, as it is adapted from an existing model and a Monte Carlo dropout-based method.\nThe title is to talk about health data representations, but the abstract and introduction talk about specific data - EEGs.\nThere should be baseline models in the experiments to be compared to demonstrate the proposed model efficiency.\nEthics Flag: No\nEthics Review Area: Privacy and Security (e.g., consent)\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 1 poor\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The authors motivate the need for better evaluation methods for medical deep learning models, especially methods that do a better job of predicting in-the-wild problems of a model. Given the potential side-effects that an erroneous prediction can have in medicine, it is vital that better ways to predict how a model under distribution shifts of various intensities would perform, or at the very least, the cases in which the behaviour of the model would differ from the one in training and development validation/testing. \nThe authors firstly motivate, using domain expertise, four scalp EEG data shifts that would do a good job of capturing some real world variation of such datasets. Then they propose using latent space integrity methods and predictive uncertainty as two ways of evaluating the behaviour of a model under varying types and intensities of the four proposed dataset shifts. \nThe authors then proceed to apply their proposed evaluation measures on a number of large-scale pretrained medical encoders and showcase that their methods have some predictive utility over potential pitfalls of such models.\nStrengths And Weaknesses: Originality:\nThe work proposed in this paper is one of high utility, and depending on ones definition of originality, could be assigned variable levels of originality. Given that this paper addresses medical deep learning, and proposes some very reasonable and relatively useful means of evaluating in-the-wild performance of models, I would consider it as original work, but not extremely so \nI think this work might also enable a string of works targeting this direction which is something the medical deep learning community is definitely in need of. \n(Score: 7/10)\nQuality:\nThe quality of the work is very high, both in terms of execution and presentation. \n(Score: 8/10)\nClarity:\nThe paper is quite clear, but could do with some additional figures showing correlations between in-the-wild performance and the proposed measures for a very direct way of showing to the reader what is going on. \n(Score: 7/10)\nSignificance:\nThe ideas in this paper are of high significance, as they start a research direction towards good heuristics for in-the-wild performance for medical deep learning models. They also provide a set of what are effectively four data augmentation methods particularly suited for scalp EEG data, which could benefit the EEG community in general, and provide inspiration to others. \n(Score: 7/10)\nStrengths: Tackles an important problem with novel solutions and excellent execution with high degree of attention to detail. Provides interesting figures and tables to draw conclusions from.\nWeaknesses: \n\nMore datasets/tasks: It would make the claims made over the usefulness of the performance predictive methods more robust if more datasets/tasks were carried out and evaluated. \nClearer correlation figures: Figures directly showing any meaningful correlations between in-the-wild test performance and the proposed methods attempting to predict issues in such performance. \nClarity of training: Are any of the models trained with the proposed data shifts? What happens when they are? Does it improve performance on any of the heuristics and/or actual in-the-wild performance? I would rephrase the training section to ensure the reader knows what the models are trained on, in terms of data shifts. \nPrediction uncertainty discussion: I think it is important for the authors to talk about what prediction uncertainty could be showing here. Yes, if a model is more confident but performs worse, then that's an issue, but wouldn't a better measure be how the training/validation uncertainty changes? Ideally, to reduce any unpredictable model behaviour one would like the model to behave similarly in both data distributions. Furthermore, while the authors compare test performance across different data shifts, they do not show how the training performance of the model looks like. I believe that the training performance of the model should be compared a lot more with the testing performance, such that whatever heuristics are computed will take into account behaviour shifts from a 'known' to an 'unknown' domain in multiple degrees (i.e. from train to val/test, and from val/test to data shifted val/test and other pertubations).\nQuestions: My questions have already been stated in the previous section, but I will restate here for ease of access:\n\nClearer correlation figures: Figures directly showing any meaningful correlations between in-the-wild test performance and the proposed methods attempting to predict issues in such performance. The authors state that lower is better in prediction uncertainty -- that seems misleading. Could you explain that statement a bit more?\nClarity of training: Are any of the models trained with the proposed data shifts? What happens when they are? Does it improve performance on any of the heuristics and/or actual in-the-wild performance? I would rephrase the training section to ensure the reader knows what the models are trained on, in terms of data shifts. \nPrediction uncertainty discussion: I think it is important for the authors to talk about what prediction uncertainty could be showing here. Yes, if a model is more confident but performs worse, then that's an issue, but wouldn't a better measure be how the training/validation uncertainty changes? Ideally, to reduce any unpredictable model behaviour one would like the model to behave similarly in both data distributions. Furthermore, while the authors compare test performance across different data shifts, they do not show how the training performance of the model looks like. I believe that the training performance of the model should be compared a lot more with the testing performance, such that whatever heuristics are computed will take into account behaviour shifts from a 'known' to an 'unknown' domain in multiple degrees (i.e. from train to val/test, and from val/test to data shifted val/test and other pertubations).\nLimitations: The authors have made a fair effort of addressing the limitations of their work, but I think that some of the conclusions drawn were a bit on the overclaiming end, for example:\n\nwe developed four domain-guided data-shifts for EEG signals that reflect the real-world variability observable during test time\nYes, perhaps it covers some, but not all. That should be made more explicit. \n\nThrough evaluation of multiple EEG feature encoders using large-scale EEG data, we empirically showed that the proposed approach can help in anticipating failure scenarios during deployment\nThis was done on a small set of datasets and tasks and using limited models. This should be integrated in this conclusion such that it does not mislead the reader.\nEthics Flag: No\nEthics Review Area: I don\u2019t know\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This work aims to provide a holistic analysis of the robustness of EEG data representations after domain-guided data shifts. The authors provides two evaluation metrics to probe the robustness of EEG, namely latent space integrity and predictive uncertainty, on representations produced by different encoder methods.\nStrengths And Weaknesses: Strength:\n\nThe overall idea is well-motivated and addresses a unique and important challenge in ML for health.\nThe authors performed very thorough analysis in general, testing various data shift and encoder methods - remarkable effort!\n\nWeakness:\n\nThe problem of evaluating representation/prediction learning accuracy under health data shift is a wide topic, and in many cases it means retaining performance across different sites/demographic groups/out-of-distribution cases. While the authors focus on four EEG device-wise data shift scenarios, the title and the introduction part should be careful not to over-claim the scope of this study.\nThe highlights in Table 2 is misleading - when several numbers are equal, they should all be highlighted instead of just highlighting the numbers favoring an argument. \nThe results are not strong enough for a conclusive analysis or novel insights (numbers reported in Table 2 do not show great difference).\nQuestions: \nI would like some clarifications about Figure 3 under scenario \"no shift\" - according to section 3.3, when all edges are homogeneous (i.e., connecting points belong to the same set), the latent space integrity measure value would be 0, but this is not as suggested in Fig 3.\nLimitations: Yes.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 3 good\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: The paper provides a description how four types of feasible and realistic dataset shifts can be used to estimate their effect on robustness of the classification and regression tasks in EEG analysis. \nThe paper uses a latent space of features extracted from the EEG signals and compares how the latent space data points of the original and the transformed data  create a Delaunay graph. If all edges of the in the Delaunay (i.e nearest neighbors)  in the data set would contain only edges from the original latent space points  to the corresponding transformed  latent space points, one would consider the perturbations to be robust.\nThe distributions of the outputs for the original and the transformed data are created with Monte Carlo dropout using the model trained by the original model. This way the data shift  effect to the output  distributions can be seen and quantified for robustness estimation. Experiments are performed, for example, with different sizes of added noise and it is seen that noisy data will lead to collapse of the regression task.\nThe authors suggest that following the described analysis of the robustness can be used as indication of problems in generalization capability of the model under realistic data shifts in medical domain.\nStrengths And Weaknesses: The paper is well written and understandable. It provides insights on a long standing problem of training systems with data that originate from restricted domains that are then deployed in other domains. Of course, the ideal case would be to alleviate the problem with big enough data sets that would already contain all the domains. However, even this would not solve the problem for data shifts that happen in time. The problem is highly relevant.\nThe paper uses four different realistic transformations, but is not using these to augment the data in the training phase. In many cases augmenting the training data significantly improves the results. Keeping the training data set intact by principle does not bring extra value, because the final verdict really comes from a properly gathered test data that contains the variability of data from different sources and domains. These should cover the data shifts. Using a held out data for testing the generalization is not, in my opinion, a good way to test an AI model in the medical domain.\nAlso, using only four transformations is quite small set of variation to the signal. One could argue that it will not provide a comprehensive set of variations that the system will encounter. Using adversarial robustness in training would automatically find the problematic dimensions and improve robustness for a larger, more comprehensive set of  perturbations.\nNow, the value of the paper now lies in the analysis of what is happening if the realistic transformations would not be known - and indicate the failures in robustness when this would happen. Choosing these to be feasible actually minimizes the problem, as one may expect that these changes would already occur also inside the original training data, for example in variations of the electrode impedance. Hence, these would be covered by the natural variation. I have some suggestion below to increase the impact of the paper by further analysis.\nQuestions: To have a more holistic view of the robustness of the trained solution with the use of a given, extensive, data set, one should also check how adversarial training would improve the generalization under the four feasible transformations. This would check and answer if the expected realistic data shifts would be covered automatically by the adversarial robustness. Now, the trained version used is not the optimal model  to estimate the robustness that is achievable by the available data set.\nAlso, the result estimation of the robustness reached by augmenting the data with the four known transformations should be performed as a comparison, as it is interesting to see to what extent the knowledge of the possible data shifts that is used in the training would alleviate the problem.\nThis paper  a very good and thorough work, but more aspects should be covered. Questions to be answered for better rating:\n\nWhat happens for the generalization capability if adversarially robust training is used?\nWhat happens for the generalization capability if domain knowledge augmentation (with the four types) is used?\n\nI would appreciate a discussion on these points with the related additional testing.\nLimitations: The paper is a excellent step forward to address the data shifts in the medical domain\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper introduces four EEG signal transformations to model the real-world variability observable during deployment. Then, the paper proposes a multi-pronged approach to evaluate the robustness of healthcare ML models. It is well-organized and easy to follow. The extensive experiments demonstrate the paper's claims.",
                "Strengths And Weaknesses": "This paper introduces four EEG signal transformations to model the real-world variability observable during deployment. \nThe paper proposes a multi-pronged approach to evaluate the robustness of healthcare ML models.\nRealistic data shifts in EEG data are explored in the paper.\nThe extensive experiments are conducted on real-world datasets and demonstrate the paper's claims.",
                "Questions": "the paper's title is so broad. it should be focused on a EEGs.\nthe paper should list baseline models' performance on the related tasks.",
                "Limitations": "the novelty of the paper is weak, as it is adapted from an existing model and a Monte Carlo dropout-based method.\nThe title is to talk about health data representations, but the abstract and introduction talk about specific data - EEGs.\nThere should be baseline models in the experiments to be compared to demonstrate the proposed model efficiency.",
                "Ethics Flag": "No",
                "Ethics Review Area": "Privacy and Security (e.g., consent)",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "1 poor",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors motivate the need for better evaluation methods for medical deep learning models, especially methods that do a better job of predicting in-the-wild problems of a model. Given the potential side-effects that an erroneous prediction can have in medicine, it is vital that better ways to predict how a model under distribution shifts of various intensities would perform, or at the very least, the cases in which the behaviour of the model would differ from the one in training and development validation/testing. \nThe authors firstly motivate, using domain expertise, four scalp EEG data shifts that would do a good job of capturing some real world variation of such datasets. Then they propose using latent space integrity methods and predictive uncertainty as two ways of evaluating the behaviour of a model under varying types and intensities of the four proposed dataset shifts. \nThe authors then proceed to apply their proposed evaluation measures on a number of large-scale pretrained medical encoders and showcase that their methods have some predictive utility over potential pitfalls of such models.",
                "Strengths And Weaknesses": "Originality:\nThe work proposed in this paper is one of high utility, and depending on ones definition of originality, could be assigned variable levels of originality. Given that this paper addresses medical deep learning, and proposes some very reasonable and relatively useful means of evaluating in-the-wild performance of models, I would consider it as original work, but not extremely so \nI think this work might also enable a string of works targeting this direction which is something the medical deep learning community is definitely in need of. \n(Score: 7/10)\nQuality:\nThe quality of the work is very high, both in terms of execution and presentation. \n(Score: 8/10)\nClarity:\nThe paper is quite clear, but could do with some additional figures showing correlations between in-the-wild performance and the proposed measures for a very direct way of showing to the reader what is going on. \n(Score: 7/10)\nSignificance:\nThe ideas in this paper are of high significance, as they start a research direction towards good heuristics for in-the-wild performance for medical deep learning models. They also provide a set of what are effectively four data augmentation methods particularly suited for scalp EEG data, which could benefit the EEG community in general, and provide inspiration to others. \n(Score: 7/10)\nStrengths: Tackles an important problem with novel solutions and excellent execution with high degree of attention to detail. Provides interesting figures and tables to draw conclusions from.\nWeaknesses: \n\nMore datasets/tasks: It would make the claims made over the usefulness of the performance predictive methods more robust if more datasets/tasks were carried out and evaluated. \nClearer correlation figures: Figures directly showing any meaningful correlations between in-the-wild test performance and the proposed methods attempting to predict issues in such performance. \nClarity of training: Are any of the models trained with the proposed data shifts? What happens when they are? Does it improve performance on any of the heuristics and/or actual in-the-wild performance? I would rephrase the training section to ensure the reader knows what the models are trained on, in terms of data shifts. \nPrediction uncertainty discussion: I think it is important for the authors to talk about what prediction uncertainty could be showing here. Yes, if a model is more confident but performs worse, then that's an issue, but wouldn't a better measure be how the training/validation uncertainty changes? Ideally, to reduce any unpredictable model behaviour one would like the model to behave similarly in both data distributions. Furthermore, while the authors compare test performance across different data shifts, they do not show how the training performance of the model looks like. I believe that the training performance of the model should be compared a lot more with the testing performance, such that whatever heuristics are computed will take into account behaviour shifts from a 'known' to an 'unknown' domain in multiple degrees (i.e. from train to val/test, and from val/test to data shifted val/test and other pertubations).",
                "Questions": "My questions have already been stated in the previous section, but I will restate here for ease of access:\n\nClearer correlation figures: Figures directly showing any meaningful correlations between in-the-wild test performance and the proposed methods attempting to predict issues in such performance. The authors state that lower is better in prediction uncertainty -- that seems misleading. Could you explain that statement a bit more?\nClarity of training: Are any of the models trained with the proposed data shifts? What happens when they are? Does it improve performance on any of the heuristics and/or actual in-the-wild performance? I would rephrase the training section to ensure the reader knows what the models are trained on, in terms of data shifts. \nPrediction uncertainty discussion: I think it is important for the authors to talk about what prediction uncertainty could be showing here. Yes, if a model is more confident but performs worse, then that's an issue, but wouldn't a better measure be how the training/validation uncertainty changes? Ideally, to reduce any unpredictable model behaviour one would like the model to behave similarly in both data distributions. Furthermore, while the authors compare test performance across different data shifts, they do not show how the training performance of the model looks like. I believe that the training performance of the model should be compared a lot more with the testing performance, such that whatever heuristics are computed will take into account behaviour shifts from a 'known' to an 'unknown' domain in multiple degrees (i.e. from train to val/test, and from val/test to data shifted val/test and other pertubations).",
                "Limitations": "The authors have made a fair effort of addressing the limitations of their work, but I think that some of the conclusions drawn were a bit on the overclaiming end, for example:\n\nwe developed four domain-guided data-shifts for EEG signals that reflect the real-world variability observable during test time\nYes, perhaps it covers some, but not all. That should be made more explicit. \n\nThrough evaluation of multiple EEG feature encoders using large-scale EEG data, we empirically showed that the proposed approach can help in anticipating failure scenarios during deployment\nThis was done on a small set of datasets and tasks and using limited models. This should be integrated in this conclusion such that it does not mislead the reader.",
                "Ethics Flag": "No",
                "Ethics Review Area": "I don\u2019t know",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This work aims to provide a holistic analysis of the robustness of EEG data representations after domain-guided data shifts. The authors provides two evaluation metrics to probe the robustness of EEG, namely latent space integrity and predictive uncertainty, on representations produced by different encoder methods.",
                "Strengths And Weaknesses": "Strength:\n\nThe overall idea is well-motivated and addresses a unique and important challenge in ML for health.\nThe authors performed very thorough analysis in general, testing various data shift and encoder methods - remarkable effort!\n\nWeakness:\n\nThe problem of evaluating representation/prediction learning accuracy under health data shift is a wide topic, and in many cases it means retaining performance across different sites/demographic groups/out-of-distribution cases. While the authors focus on four EEG device-wise data shift scenarios, the title and the introduction part should be careful not to over-claim the scope of this study.\nThe highlights in Table 2 is misleading - when several numbers are equal, they should all be highlighted instead of just highlighting the numbers favoring an argument. \nThe results are not strong enough for a conclusive analysis or novel insights (numbers reported in Table 2 do not show great difference).",
                "Questions": "I would like some clarifications about Figure 3 under scenario \"no shift\" - according to section 3.3, when all edges are homogeneous (i.e., connecting points belong to the same set), the latent space integrity measure value would be 0, but this is not as suggested in Fig 3.",
                "Limitations": "Yes.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper provides a description how four types of feasible and realistic dataset shifts can be used to estimate their effect on robustness of the classification and regression tasks in EEG analysis. \nThe paper uses a latent space of features extracted from the EEG signals and compares how the latent space data points of the original and the transformed data  create a Delaunay graph. If all edges of the in the Delaunay (i.e nearest neighbors)  in the data set would contain only edges from the original latent space points  to the corresponding transformed  latent space points, one would consider the perturbations to be robust.\nThe distributions of the outputs for the original and the transformed data are created with Monte Carlo dropout using the model trained by the original model. This way the data shift  effect to the output  distributions can be seen and quantified for robustness estimation. Experiments are performed, for example, with different sizes of added noise and it is seen that noisy data will lead to collapse of the regression task.\nThe authors suggest that following the described analysis of the robustness can be used as indication of problems in generalization capability of the model under realistic data shifts in medical domain.",
                "Strengths And Weaknesses": "The paper is well written and understandable. It provides insights on a long standing problem of training systems with data that originate from restricted domains that are then deployed in other domains. Of course, the ideal case would be to alleviate the problem with big enough data sets that would already contain all the domains. However, even this would not solve the problem for data shifts that happen in time. The problem is highly relevant.\nThe paper uses four different realistic transformations, but is not using these to augment the data in the training phase. In many cases augmenting the training data significantly improves the results. Keeping the training data set intact by principle does not bring extra value, because the final verdict really comes from a properly gathered test data that contains the variability of data from different sources and domains. These should cover the data shifts. Using a held out data for testing the generalization is not, in my opinion, a good way to test an AI model in the medical domain.\nAlso, using only four transformations is quite small set of variation to the signal. One could argue that it will not provide a comprehensive set of variations that the system will encounter. Using adversarial robustness in training would automatically find the problematic dimensions and improve robustness for a larger, more comprehensive set of  perturbations.\nNow, the value of the paper now lies in the analysis of what is happening if the realistic transformations would not be known - and indicate the failures in robustness when this would happen. Choosing these to be feasible actually minimizes the problem, as one may expect that these changes would already occur also inside the original training data, for example in variations of the electrode impedance. Hence, these would be covered by the natural variation. I have some suggestion below to increase the impact of the paper by further analysis.",
                "Questions": "To have a more holistic view of the robustness of the trained solution with the use of a given, extensive, data set, one should also check how adversarial training would improve the generalization under the four feasible transformations. This would check and answer if the expected realistic data shifts would be covered automatically by the adversarial robustness. Now, the trained version used is not the optimal model  to estimate the robustness that is achievable by the available data set.\nAlso, the result estimation of the robustness reached by augmenting the data with the four known transformations should be performed as a comparison, as it is interesting to see to what extent the knowledge of the possible data shifts that is used in the training would alleviate the problem.\nThis paper  a very good and thorough work, but more aspects should be covered. Questions to be answered for better rating:\n\nWhat happens for the generalization capability if adversarially robust training is used?\nWhat happens for the generalization capability if domain knowledge augmentation (with the four types) is used?\n\nI would appreciate a discussion on these points with the related additional testing.",
                "Limitations": "The paper is a excellent step forward to address the data shifts in the medical domain",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "soundness_avg": 2.75,
        "presentation_avg": 3.25,
        "contribution_avg": 2.5,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that this paper addresses an important problem in the field of medical deep learning and provides novel solutions for evaluating the robustness of healthcare ML models. The paper introduces four EEG signal transformations to model real-world variability and proposes a multi-pronged approach to evaluate the robustness of ML models. The extensive experiments conducted on real-world datasets demonstrate the paper's claims.\n\nWhile there are some limitations and areas for improvement mentioned by the reviewers, such as the need for clearer correlation figures and additional datasets/tasks for evaluation, overall the paper is technically solid and has a high impact on the field. The reviewers also acknowledge the high quality and thoroughness of the work.\n\nConsidering the strictness of the conference, which is set at 0.5, it is recommended to accept this paper. The confidence level is certain, as the reviewers have provided positive feedback and there are no unaddressed ethical considerations."
    },
    "COLD_Decoding:_Energy-based_Constrained_Text_Generation_with_Langevin_Dynamics": {
        "link": "https://openreview.net//forum?id=TiZYrQ-mPup",
        "pub_url": "https://openreview.net/forum?id=TiZYrQ-mPup",
        "pdf_link": "https://openreview.net//pdf?id=TiZYrQ-mPup",
        "paper_id": "TiZYrQ-mPup",
        "title": "COLD_Decoding:_Energy-based_Constrained_Text_Generation_with_Langevin_Dynamics",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nThis paper proposes a framework for controlled or constrained text generation where the constraints are encoded with energy-based models (EBMs). Generation proceeds in two steps: first, the discrete words are relaxed into continuous vectors of logits (scores), which enables the use of gradient methods and Langevin dynamics to obtain a sample. Then, to obtain actual words (a discrete output) a LM is used for top-k filtering and the word with the largest score is chosen. The paper demonstrates the applicability of the proposed framework in three different generation tasks, controlled generation, abductive, and counterfactual generation. \nAll reviewers agree (and I agree with them) that this is a solid paper which brings Langevin dynamics (a well-known technique mainly used with continuous outputs, e.g. in vision tasks) to text generation. Although the use of this technique with EBMs is certainly not novel, making it work for text is non-trivial. The reviewers suggest several improvements: reporting the runtimes (the proposed method requires many gradient iterations which brings a considerable slow down), comparing against more baselines more explicit, and adding references and discussion related for recent work such as FUDGE and mix-and-match. The author response was satisfactory and promised to add these details to the final version. \nI strongly encourage the authors to incorporate the reviewer's suggestions in their final version.",
        "reviews": [
            "Reviewer 1: \nSummary: The paper proposes a new framework for energy-based constrained text generation. The proposed method implements text generation as gradient based sampling from an energy-based distribution, derived as a linear composition of the distribution defining each constraint. The method description is clear. Paper is well-written and usually easy to follow, although please see comments for suggested revisions. \nMethod is evaluated in three different tasks requiring constrained generation and obtains promising results in comparison to previous approaches. Comparison to related work could be more extensive and through. Overall, an interesting idea that should inspire other research directions in the related field.\nStrengths And Weaknesses: Comments:\n\nline 17-24: discussion and overview of the problem is introduced too generally, and the examples do not directly connect to the figure. A revision can make more clear how the method is directly applicable to each task. \n\nline 25- 27: the discussion on supervised learning is too generic. The proposed method does not necessarily solve the annotation scarcity. There also many applications where it is feasible to adapt / finetune models with domain specific annotations\n\nline 100: token \"next\" used unnecessary and confusing.\nQuestions: Q1. Evaluation of results and comparison to baselines is a bit superficial. Did the authors do any analysis to see the differences in characteristics of the outputs generated by different models?\nQ2. Table 2: why are the BLEU results so low?\nLimitations: adequate\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This work proposes a constrained generation decoding plug-in framework that does not require additional fine-tuning and can be applied to any left-to-right LM. The authors used sampling from the EBM model to incorporate constraints, and an energy function is specified by defining relevant constraint functions. One of the main novelties of the paper is that it suggests Langevin dynamics for gradient-based efficient sampling. That allows applying the framework to various constrained tasks. Experiments on three different tasks show that the proposed method outperforms previous works on constrained generation.\nStrengths And Weaknesses: Strengths:\n\nUnified decoding framework for constrained generation\nThe method is well-motivated and described carefully\nShows solid improvements upon over methods\n\nWeaknesses:\n\nThe analysis of the results lacks some interesting aspects (see questions)\nQuestions: Q1: Did I correctly understand that the constraint function must be handcrafted, and it has a significant impact on the performance? Do you have any suggestions on how to propose a new constrain function?\nQ2:  Efficiency of the sampling is claimed in the paper. However, there are no insights on the decoding speed/latency and comparison with other methods, if possible\nQ3: Is it possible to incorporate several constraints?\nLimitations:\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 3 good\nContribution: 4 excellent\nRating: 8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: Many applications of text generation require incorporating different constraints (hard or soft constraints) to control the semantics or style of generated text. The authors propose a decoding framework named Energy-based Constrained Decoding with Langevin Dynamics, which can achieve hard and soft constraints in a unified framework and does not need any task-specific fine-tuning. Experimental results on three tasks of constrained text generation show the effectiveness of proposed framework.\nStrengths And Weaknesses: Strengths\n\nThe authors propose a decoding framework to unify hard and soft constrained generation. The framework treats constrained generation as an energy function and is flexible to add any constraints through arbitrary constraint functions.\nThe authors propose a new sampling method to achieve efficient search for a single optimal solution.\nExperiments on three constrained generation tasks show that the proposed framework achieves strong performance on both automatic and human evaluation.\n\nWeaknesses\n\nConsider that 2,000 iterations are required, the author should give the time consumed by the method to generate the text.\nConsidering that GPT2 itself may generate many candidates through top-k sampling, the authors should add a baseline, in which sample-and-select is performed on generated text of GPT2 by top-k sampling.\nQuestions: What is the detail of obtaining a right-to-left LM?\nLimitations: N/A\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper proposes a generative model for constrained text generation. It incorporates hard and soft constraints in text generation and experiments on three tasks, lexically constrained generation, abducting reasoning, and counterfactual reasoning. The approach formulates generation as sampling from an energy-based model. Those constraints are applied as the weighted components for the score function. They introduced Langevin dynamics for efficient gradient-based sampling.\nStrengths And Weaknesses: Strength\nThe paper presents a novel approach to conditional/constrained text generation. Langevin dynamics has been explored in machine learning and computer vision but it\u2019s novel to NLP and text generation. The approach can model different kind of constraints, hard or soft, in a unified approach. It is grounded with solid foundation and potential use cases. \nThe paper is well written and presented. It\u2019s a fairly complicated topic, but examples and figures made the paper easier to follow. \nThe approach is validated on three NLG tasks, and the approach beats prior work like DELOREAN. Weakness \nAlthough the experiments cover three tasks, the scope of comparison is limited. It mostly compares with one baseline, Left-Only, and one model DeLorean. The author of this paper, DeLorean and NeuroLogic are essentially from the same research group, so I am slightly concerned about the credibility of the experimental results. It\u2019s totally possible to compare with prior work using these 3 datasets. The authors can also find some other tasks like sentiment transfer or attribute grounded generation. The FUDGE paper and the Mix and Match paper are good references to look at.\nSome missing reference \nThe mix and match paper is directly relevant; the FUDGE paper (and many other discriminator based constrained NLG papers) are also worth mentioning and comparing with. \nFUDGE: Controlled Text Generation With Future Discriminators\nhttps://aclanthology.org/2021.naacl-main.276.pdf\nMix and Match: Learning-free Controllable Text Generation using Energy Language Models\nhttps://aclanthology.org/2022.acl-long.31.pdf\nQuestions: I wonder how fast is the proposed algorithm? \nI am not 100% sure about the \"sample-and-select\". How many samples do you draw for one example? Any more detail about this sampling procedure?\nLimitations: I am mostly worried about the limited scope of comparison.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 4 excellent\nRating: 8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The paper proposes a new framework for energy-based constrained text generation. The proposed method implements text generation as gradient based sampling from an energy-based distribution, derived as a linear composition of the distribution defining each constraint. The method description is clear. Paper is well-written and usually easy to follow, although please see comments for suggested revisions. \nMethod is evaluated in three different tasks requiring constrained generation and obtains promising results in comparison to previous approaches. Comparison to related work could be more extensive and through. Overall, an interesting idea that should inspire other research directions in the related field.",
                "Strengths And Weaknesses": "Comments:\n\nline 17-24: discussion and overview of the problem is introduced too generally, and the examples do not directly connect to the figure. A revision can make more clear how the method is directly applicable to each task. \n\nline 25- 27: the discussion on supervised learning is too generic. The proposed method does not necessarily solve the annotation scarcity. There also many applications where it is feasible to adapt / finetune models with domain specific annotations\n\nline 100: token \"next\" used unnecessary and confusing.",
                "Questions": "Q1. Evaluation of results and comparison to baselines is a bit superficial. Did the authors do any analysis to see the differences in characteristics of the outputs generated by different models?\nQ2. Table 2: why are the BLEU results so low?",
                "Limitations": "adequate",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This work proposes a constrained generation decoding plug-in framework that does not require additional fine-tuning and can be applied to any left-to-right LM. The authors used sampling from the EBM model to incorporate constraints, and an energy function is specified by defining relevant constraint functions. One of the main novelties of the paper is that it suggests Langevin dynamics for gradient-based efficient sampling. That allows applying the framework to various constrained tasks. Experiments on three different tasks show that the proposed method outperforms previous works on constrained generation.",
                "Strengths And Weaknesses": "Strengths:\n\nUnified decoding framework for constrained generation\nThe method is well-motivated and described carefully\nShows solid improvements upon over methods\n\nWeaknesses:\n\nThe analysis of the results lacks some interesting aspects (see questions)",
                "Questions": "Q1: Did I correctly understand that the constraint function must be handcrafted, and it has a significant impact on the performance? Do you have any suggestions on how to propose a new constrain function?\nQ2:  Efficiency of the sampling is claimed in the paper. However, there are no insights on the decoding speed/latency and comparison with other methods, if possible\nQ3: Is it possible to incorporate several constraints?",
                "Limitations": "",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "3 good",
                "Contribution": "4 excellent",
                "Rating": "8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "Many applications of text generation require incorporating different constraints (hard or soft constraints) to control the semantics or style of generated text. The authors propose a decoding framework named Energy-based Constrained Decoding with Langevin Dynamics, which can achieve hard and soft constraints in a unified framework and does not need any task-specific fine-tuning. Experimental results on three tasks of constrained text generation show the effectiveness of proposed framework.",
                "Strengths And Weaknesses": "Strengths\n\nThe authors propose a decoding framework to unify hard and soft constrained generation. The framework treats constrained generation as an energy function and is flexible to add any constraints through arbitrary constraint functions.\nThe authors propose a new sampling method to achieve efficient search for a single optimal solution.\nExperiments on three constrained generation tasks show that the proposed framework achieves strong performance on both automatic and human evaluation.\n\nWeaknesses\n\nConsider that 2,000 iterations are required, the author should give the time consumed by the method to generate the text.\nConsidering that GPT2 itself may generate many candidates through top-k sampling, the authors should add a baseline, in which sample-and-select is performed on generated text of GPT2 by top-k sampling.",
                "Questions": "What is the detail of obtaining a right-to-left LM?",
                "Limitations": "N/A",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposes a generative model for constrained text generation. It incorporates hard and soft constraints in text generation and experiments on three tasks, lexically constrained generation, abducting reasoning, and counterfactual reasoning. The approach formulates generation as sampling from an energy-based model. Those constraints are applied as the weighted components for the score function. They introduced Langevin dynamics for efficient gradient-based sampling.",
                "Strengths And Weaknesses": "Strength\nThe paper presents a novel approach to conditional/constrained text generation. Langevin dynamics has been explored in machine learning and computer vision but it\u2019s novel to NLP and text generation. The approach can model different kind of constraints, hard or soft, in a unified approach. It is grounded with solid foundation and potential use cases. \nThe paper is well written and presented. It\u2019s a fairly complicated topic, but examples and figures made the paper easier to follow. \nThe approach is validated on three NLG tasks, and the approach beats prior work like DELOREAN. Weakness \nAlthough the experiments cover three tasks, the scope of comparison is limited. It mostly compares with one baseline, Left-Only, and one model DeLorean. The author of this paper, DeLorean and NeuroLogic are essentially from the same research group, so I am slightly concerned about the credibility of the experimental results. It\u2019s totally possible to compare with prior work using these 3 datasets. The authors can also find some other tasks like sentiment transfer or attribute grounded generation. The FUDGE paper and the Mix and Match paper are good references to look at.\nSome missing reference \nThe mix and match paper is directly relevant; the FUDGE paper (and many other discriminator based constrained NLG papers) are also worth mentioning and comparing with. \nFUDGE: Controlled Text Generation With Future Discriminators\nhttps://aclanthology.org/2021.naacl-main.276.pdf\nMix and Match: Learning-free Controllable Text Generation using Energy Language Models\nhttps://aclanthology.org/2022.acl-long.31.pdf",
                "Questions": "I wonder how fast is the proposed algorithm? \nI am not 100% sure about the \"sample-and-select\". How many samples do you draw for one example? Any more detail about this sampling procedure?",
                "Limitations": "I am mostly worried about the limited scope of comparison.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "4 excellent",
                "Rating": "8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 7.25,
        "confidence_avg": 3.25,
        "soundness_avg": 3.5,
        "presentation_avg": 3.0,
        "contribution_avg": 3.5,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is evident that the proposed framework for energy-based constrained text generation is technically solid and has the potential for high impact in the field. The paper presents a clear and well-motivated method that incorporates both hard and soft constraints in text generation. The use of Langevin dynamics for gradient-based sampling is a novel contribution to the field of NLP and text generation.\n\nThe experiments conducted on three different tasks demonstrate the effectiveness of the proposed framework, with the approach outperforming previous works on constrained generation. While there are some suggestions for improvement, such as providing more extensive comparisons to related work and analyzing the characteristics of the generated outputs, these do not raise major concerns.\n\nOverall, the paper presents a technically strong contribution with novel ideas and excellent impact. The evaluation, resources, and reproducibility are well-addressed, and there are no unaddressed ethical considerations. Therefore, I recommend accepting this paper with a high level of confidence."
    },
    "From_Gradient_Flow_on_Population_Loss_to_Learning_with_Stochastic_Gradient_Descent": {
        "link": "https://openreview.net//forum?id=xuw7R0hP7G",
        "pub_url": "https://openreview.net/forum?id=xuw7R0hP7G",
        "pdf_link": "https://openreview.net//pdf?id=xuw7R0hP7G",
        "paper_id": "xuw7R0hP7G",
        "title": "From_Gradient_Flow_on_Population_Loss_to_Learning_with_Stochastic_Gradient_Descent",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nThis paper provides a new way of developing the convergence analysis of gradient descent (GD) and stochastic gradient descent (SGD) by leveraging the convergence of the gradient flow (GF). This framework is very general and provides new insight that future research on SGD will benefit from. All reviewer have positive feedback and I would like to recommend acceptance.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper provides a new way of developing the convergence analysis of gradient descent (GD) and stochastic gradient descent (SGD) by leveraging the convergence of the gradient flow (GF). The main tool of the paper is to construct a Lyapunov potential which implies a convergence rate of the GF, formalized as a general converse Lyapunov like theorem. With additional self-bounding regularity conditions, the convergence of GF is sufficient to imply the convergence of GD and SGD. This framework is so general that it provides a unified analysis of GD and SGD that match the best convergence rate of convex functions or PL/KL functions, but also for phase retrieval and matrix square root problems.\nStrengths And Weaknesses: The paper is well-written, highlights their contribution clearly, provides lots of interpretations and simple examples of their general framework. The framework and the way to show convergence of GD and SGD are creative. There is a lot of conceptual value to the community that allows to develop new convergence analysis of GD and SGD in more complex models (e.g. neural networks). I am not familiar with the optimization theories of GF. The mathematical derivation of convergence seems solid.\nMy evaluation for the work is mostly positive. It may be better for the authors to write a paragraph how this work can be applied in the future. For instance, how SGD convergence analysis for the neural networks can be established under this framework ? More generally, can this framework be extended to other optimization methods, such as second-order methods and other variants of SGD (e.g. Adam, stochastic variance reduced gradient) ?\nQuestions: Typos:\nDuplicate references: [21] & [22]; [41] & [42]\nLimitations: The authors have adequately addressed the limitations of their work.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This work presents a novel framework for analyzing SGD via Lyapunov analyses of continuous-time gradient flow. The authors first establish that, loosely speaking, a Lyapunov function must exist if gradient flow converges. Then the authors show convergence of SGD using the same Lyapunov function. Some interesting and illustrative examples are provided, but there are no experimental results, which makes this a theory paper.\nStrengths And Weaknesses: The level of abstraction regarding Lyapunov functions is not something I have seen in the optimization and SGD literature, and the first result establishing the necessity and sufficiency of Lyapunov functions is interesting, at least to me. However, it is unclear to me what benefit this abstraction brings. The rates established for SGD are not better than any of the prior rates, and, in fact, many of the state-of-the-art rates are established not with the plain SGD but with some minor variation, such as certain varying stepsizes, appropriate batch sizes, or some non-uniform averaging schemes. Such variations probably can be considered under this framework, but this has not been done in this paper yet.\nThe control-theoretic framework feels like an interesting framework to me, but there's no key result that validates the strength of this viewpoint. The insistence on considering Lyapunov functions of gradient flow may be a key insight that future research on SGD will benefit from, but I don't think this work has sufficiently demonstrated the usefulness of this framework beyond its novelty.\nQuestions: What is the key main result that demonstrates the effectiveness of this Lyapunov analysis framework?\nLimitations: The justification of the usefulness of the Lyapunov analysis framework is not sufficiently convincing, since many researchers in the field are already aware that many (if not all) discrete analyses have nice continuous-time counterparts with gradient flow or SDEs.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 2 fair\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The authors of the present paper show the following contributions:\n\nThey provide an equivalence between satisfying certain convergence rates and geometric conditions\nThey apply their framework to gradient descent and stochastic gradient descent, requiring  more assumptions on the function to be optimised to derive convergence rates.\nThey apply their overall framework to matrix square root and phase retrieval where rates of convergence for the gradient flow have been shown in the literature.\nStrengths And Weaknesses: Strengths\n\nThe paper appears to be original, introduce a very nice idea from the ODE's literature with converse Lyapunov theorems (ref 25). The link with gradient descent and stochastic gradient descent is nicely introduced and seems to enable direct analysis from rates of convergence for discrete analysis.\nThe papers show a large diversity of results, which is rare in nowadays paper in conference. \nThe authors really try to apply their machinery to concrete and hard problems in the last section.\nThe hypothesis on the stochastic gradient descent (Assumption 3) is a nice and covers a lot of cases.\n\nWeaknesses\n\nThe paper is overall hard to follow: the progression is okay and technical contributions are understandable but it is hard to understand where the authors want to bring us. As an example of this, I think that the paper lacks some comments in the fifth section where they apply their method: there is absolutely no discussion on knowing whether the rates are tight, whether they are new (for gradient and stochastic gradient descent). Another striking example is the subsection 5.3 where Lemma 4 seems to nicely improve on recent Chatterjee condition without application or explication on this result (even the authors write: \"With a wider choice of g and r we can extend these to more general models (eg. neural networks with milder assumptions on the activation function)\". \nAdding to the previous comment, there is no conclusion, and many times, the paper seems to have been written in a hurry, see some minor flaws below.\nFor the result to hold, there is a need to know in advance rates of convergence, which limit the applicability of the results.\n\nMinor flaws\n\nWhy talking of implicit regularisation in the introduction (ligns after 24) ?\nIn lign 38, the cited papers do not provide convergence analysis and only focus on implicit regularisation\nlign 87, it is not standard that the estimator is not the final iterate, precise that this is your way to see gradient descent. Same lign 96.\nlign 97, (w) is a weird notation for a process. Prefer w or (wt)t\u2a7e0 \nlign 108 ,what is the p-th derivative ? Isn't it simply the gradient ?\nFor all theorem, comment the fact that Admissible rate functions could not exist\nIt would be nice to have a commentary on what is g in Corollary 1\nQuestions: \nTheorem 4 shows 1/T or 1/\\sqrt{T} rates of convergence for the gradient descent whereas Theorem 6 and 7 show exponential rates if the gradient descent case. I understand some PL inequality seems to be hidden here, but this needs to be precised as these theorems are not an application of the Theorem of the previous section.\nThe SGD noise scales like the function value for the phase retrieval example, hence I would expect an exponential rate of convergence for SGD also (Theorem 6). Can the authors comment on this ?\nIn terms of the two applications, it would be nice to refer to known rates of convergence for GD and a comparison with what you obtain with your technique.\nLimitations: I use this paragraph to conclude as I already discussed the limitations on the two previous boxes. My opinion is that it could be a super nice paper: I like the overall idea to go from gradient flow with rates to geometrical implications on the lost and then to (stochastic) gradient descent rates. However, the implication of such results on concrete examples could be more referenced and the writing improved.\nFor now, I give a borderline accept but I will gladly improve my score if the authors give me some evidence that they can improve the paper in such a short notice.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper aims at providing conditions for the convergence of GD/SGD schemes when there is a rate of convergence for Gradient Flow on population loss, and this is done by deriving a potential function and checking the geometric property. Also this potential should satisfy certain properties, called self-bounding regularity conditions, in order to give us the desired convergence for GD/SGD methods. Authors verify that this is indeed applicable not only to convex and PL functions, but also to non-convex problems.\nStrengths And Weaknesses: As authors mention, using admissible potential functions for getting a convergence rate for GF is studied before. Identifying the one-to-one correspondence between admissible rate and potential functions that satisfy the geometric property in (4) seems interesting. Propositions 1 and 2 also provide simple examples on how admissible rates and potentials exist in easy-to-prove scenarios.\nAs I read all of the proofs, there are lots of typos and some derivations, which I will mention in below, are not carried out correctly, and I hope after revision they will not be problematic for the main claims to hold. However, overall the main results are clear and easy to read and providing examples like propositions 1,2 and touching on Phase retrieval and matrix square root problems makes this converse Lyapunov strategy interesting for analysis of GD/SGD using the GF convergence rate. I think this paper aims at connecting GF and GD analysis which is currently a hot research topic in optimization.\nQuestions: grammatical and mathematical typos:\nline 108 derivative. line 112 extra \"in\". line 121 shown. line 144 such that. line 215, F(w(t))\u2264\u2016w0\u201622t. line 226, satisfied. lines 587, 592, it should be \u03a6(w0). line 611, the negative signs in lines 3-4-5 should be removed, as |r\u2032(z)|=\u2212r\u2032(z). line 625, extra \"from\", also R(w,t)=F(w)e\u2212\u03bbt. line 630, \u2016\u2207F(w)\u20162\u03bb. line 634, 3rd line, missing \"=\". line 643, it should be \u2016u\u20163/2. line 651, F(w(T))\u2212F\u2217\u2264\u03a6(w0)T\u2264\u2016w0\u201622T. line 657, \"many ensure\". line 662, proof. line 700, extra \"defined\". line 705, \u03b8\u2033(z)=\u2212\u03c1\u2032(z)\u03c1(z)2. line 712, u=\u2212\u2207\u03a6(w)\u03c1(\u03a6(w)). line 732, since \"\u03b8\" is \"monotonic\", this implies that \"\u03a6(wt+1)\u2264\u03a6(wt)\". \nin line 752 equation (33), 2nd line is wrong. we don't know if F(wt)\u2264F(w0). Instead you should use F(wt)\u2264\u03b6(\u03a6(wt))\u2264\u03b6(\u03a6(w0)). However final conclusion of equation (34) is correct.\nline 772, \u03c8(F(w)) instead of \u2016\u2207F(w)\u20162. line 783, \u03ba>1. line 792, 3rd line is duplicate. line 796 and afterward, you should replace \u03a6(w0) with \u03b8(\u03a6(w0)). line 809 \"M=\". line 810, log2 seems to be log3. line 819, \"note that\" and \"when\".  line 826, \"g\" is missing. \nIn line 947, I couldn't derive second inequality. maybe there should be a larger coefficient.\nlines 1018 and 1025, \u2016M\u2016 instead of M.\nQuestions:\nregarding line 207-8, can you provide such examples, or mention some papers? \nIn line 614, lim\u00a0\u03f5\u21920\u03f5\u22121\u03f5 seems to be infinity, but for your result to hold it should be zero. This also happens in other places like line 181. Please explain. \nMy most important question is regarding the exponential rate of GD in theorems 6 and 7. In the proofs you say combining Lemma 1 with Theorem 4 will give the result. However Theorem 4 has a 1/T rate and g(z)=z. Please carefully explain it and also update the paper to contain more details of this proof.\nIn line 722, please explain (if needed by writing equation) that why 27 is valid if 26 is violated. I think there must be some \"g\" and \"\u03c8\" missing in (27), by looking at line 741.\nIn Theorem (4) you mention O(1T) rate of convergence, but in line 741, I can see 1/T as well as a constant term. Please explain. it seems that line 741 and 761 only differ by a constant and both of them are O(1/T) except that 741 is suboptimal assuming g is zero at optimum. \nIn line 798, I couldn't use Markov to get (39). I'd like to see one line of proof.\nline 804, where do you set \u03ba in the paper?\nLine 853 there is a serious issue with derivation of line 5, because we don't know \u03b8(\u03a6(wt+1))\u2212\u03b8(\u03a6(wt))\u22650, hence equation (50) may not be true. Please revise/explain the proof.\nIn proof of Lemma 11 needs serious revision. The derivation in lines 890 is incorrect and you should write R\u2212(w(s),t)=R(w(s),\u03c3(h(w(s)))t)\u2264R(w,\u03c3(h(w(s)))t+s)\u2264R(w,\u03c3(h(w(s)))t+\u03c3(h(w(s)))s)\u2264=R(w,\u03c3(h(w(s)))(t+s))\u2264R(w,h(w(s))(t+s))=R\u2212(w,s+t).\nMore importantly, I see an inconsistency in using \u03c3(h(w)) and h(w). For example you define R\u2212(w,t)=R(w,\u03c3(h(w))t), but after line 892 suddenly there is no sign of \u03c3 in derivations of \u2207\u03a6g(w) and \u22072\u03a6g(w). As you use \u03c3 in lines 306 and 336, I think \u03c3 is kinda absored in h but I can't wrap my head around this issue. in line 895 equation (51) \u03a6g(w) uses h(w) instead of \u03c3(h(w)). Also in line 911 the second term is used incorrectly and should be modified.\nIn line 1028, how do you calculate the bound on hessian? I assume hessian would be complicated.\nin line 1048 line 3, do you assume min\u00a0F=0?\nSuggestion:\nI urge you to state the result of Chatterjee more rigorously in the Appendix, and explain (mathematically in appendix) how in the lines 374-378 you can recover his result. I also expected a conclusion part at the end of the paper, but I assume you couldn't fit it.\nLimitations: As this is a completely theoretic paper, I cannot think of anything related to social impact.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper provides a new way of developing the convergence analysis of gradient descent (GD) and stochastic gradient descent (SGD) by leveraging the convergence of the gradient flow (GF). The main tool of the paper is to construct a Lyapunov potential which implies a convergence rate of the GF, formalized as a general converse Lyapunov like theorem. With additional self-bounding regularity conditions, the convergence of GF is sufficient to imply the convergence of GD and SGD. This framework is so general that it provides a unified analysis of GD and SGD that match the best convergence rate of convex functions or PL/KL functions, but also for phase retrieval and matrix square root problems.",
                "Strengths And Weaknesses": "The paper is well-written, highlights their contribution clearly, provides lots of interpretations and simple examples of their general framework. The framework and the way to show convergence of GD and SGD are creative. There is a lot of conceptual value to the community that allows to develop new convergence analysis of GD and SGD in more complex models (e.g. neural networks). I am not familiar with the optimization theories of GF. The mathematical derivation of convergence seems solid.\nMy evaluation for the work is mostly positive. It may be better for the authors to write a paragraph how this work can be applied in the future. For instance, how SGD convergence analysis for the neural networks can be established under this framework ? More generally, can this framework be extended to other optimization methods, such as second-order methods and other variants of SGD (e.g. Adam, stochastic variance reduced gradient) ?",
                "Questions": "Typos:\nDuplicate references: [21] & [22]; [41] & [42]",
                "Limitations": "The authors have adequately addressed the limitations of their work.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This work presents a novel framework for analyzing SGD via Lyapunov analyses of continuous-time gradient flow. The authors first establish that, loosely speaking, a Lyapunov function must exist if gradient flow converges. Then the authors show convergence of SGD using the same Lyapunov function. Some interesting and illustrative examples are provided, but there are no experimental results, which makes this a theory paper.",
                "Strengths And Weaknesses": "The level of abstraction regarding Lyapunov functions is not something I have seen in the optimization and SGD literature, and the first result establishing the necessity and sufficiency of Lyapunov functions is interesting, at least to me. However, it is unclear to me what benefit this abstraction brings. The rates established for SGD are not better than any of the prior rates, and, in fact, many of the state-of-the-art rates are established not with the plain SGD but with some minor variation, such as certain varying stepsizes, appropriate batch sizes, or some non-uniform averaging schemes. Such variations probably can be considered under this framework, but this has not been done in this paper yet.\nThe control-theoretic framework feels like an interesting framework to me, but there's no key result that validates the strength of this viewpoint. The insistence on considering Lyapunov functions of gradient flow may be a key insight that future research on SGD will benefit from, but I don't think this work has sufficiently demonstrated the usefulness of this framework beyond its novelty.",
                "Questions": "What is the key main result that demonstrates the effectiveness of this Lyapunov analysis framework?",
                "Limitations": "The justification of the usefulness of the Lyapunov analysis framework is not sufficiently convincing, since many researchers in the field are already aware that many (if not all) discrete analyses have nice continuous-time counterparts with gradient flow or SDEs.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "2 fair",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors of the present paper show the following contributions:\n\nThey provide an equivalence between satisfying certain convergence rates and geometric conditions\nThey apply their framework to gradient descent and stochastic gradient descent, requiring  more assumptions on the function to be optimised to derive convergence rates.\nThey apply their overall framework to matrix square root and phase retrieval where rates of convergence for the gradient flow have been shown in the literature.",
                "Strengths And Weaknesses": "Strengths\n\nThe paper appears to be original, introduce a very nice idea from the ODE's literature with converse Lyapunov theorems (ref 25). The link with gradient descent and stochastic gradient descent is nicely introduced and seems to enable direct analysis from rates of convergence for discrete analysis.\nThe papers show a large diversity of results, which is rare in nowadays paper in conference. \nThe authors really try to apply their machinery to concrete and hard problems in the last section.\nThe hypothesis on the stochastic gradient descent (Assumption 3) is a nice and covers a lot of cases.\n\nWeaknesses\n\nThe paper is overall hard to follow: the progression is okay and technical contributions are understandable but it is hard to understand where the authors want to bring us. As an example of this, I think that the paper lacks some comments in the fifth section where they apply their method: there is absolutely no discussion on knowing whether the rates are tight, whether they are new (for gradient and stochastic gradient descent). Another striking example is the subsection 5.3 where Lemma 4 seems to nicely improve on recent Chatterjee condition without application or explication on this result (even the authors write: \"With a wider choice of g and r we can extend these to more general models (eg. neural networks with milder assumptions on the activation function)\". \nAdding to the previous comment, there is no conclusion, and many times, the paper seems to have been written in a hurry, see some minor flaws below.\nFor the result to hold, there is a need to know in advance rates of convergence, which limit the applicability of the results.\n\nMinor flaws\n\nWhy talking of implicit regularisation in the introduction (ligns after 24) ?\nIn lign 38, the cited papers do not provide convergence analysis and only focus on implicit regularisation\nlign 87, it is not standard that the estimator is not the final iterate, precise that this is your way to see gradient descent. Same lign 96.\nlign 97, (w) is a weird notation for a process. Prefer w or (wt)t\u2a7e0 \nlign 108 ,what is the p-th derivative ? Isn't it simply the gradient ?\nFor all theorem, comment the fact that Admissible rate functions could not exist\nIt would be nice to have a commentary on what is g in Corollary 1",
                "Questions": "Theorem 4 shows 1/T or 1/\\sqrt{T} rates of convergence for the gradient descent whereas Theorem 6 and 7 show exponential rates if the gradient descent case. I understand some PL inequality seems to be hidden here, but this needs to be precised as these theorems are not an application of the Theorem of the previous section.\nThe SGD noise scales like the function value for the phase retrieval example, hence I would expect an exponential rate of convergence for SGD also (Theorem 6). Can the authors comment on this ?\nIn terms of the two applications, it would be nice to refer to known rates of convergence for GD and a comparison with what you obtain with your technique.",
                "Limitations": "I use this paragraph to conclude as I already discussed the limitations on the two previous boxes. My opinion is that it could be a super nice paper: I like the overall idea to go from gradient flow with rates to geometrical implications on the lost and then to (stochastic) gradient descent rates. However, the implication of such results on concrete examples could be more referenced and the writing improved.\nFor now, I give a borderline accept but I will gladly improve my score if the authors give me some evidence that they can improve the paper in such a short notice.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper aims at providing conditions for the convergence of GD/SGD schemes when there is a rate of convergence for Gradient Flow on population loss, and this is done by deriving a potential function and checking the geometric property. Also this potential should satisfy certain properties, called self-bounding regularity conditions, in order to give us the desired convergence for GD/SGD methods. Authors verify that this is indeed applicable not only to convex and PL functions, but also to non-convex problems.",
                "Strengths And Weaknesses": "As authors mention, using admissible potential functions for getting a convergence rate for GF is studied before. Identifying the one-to-one correspondence between admissible rate and potential functions that satisfy the geometric property in (4) seems interesting. Propositions 1 and 2 also provide simple examples on how admissible rates and potentials exist in easy-to-prove scenarios.\nAs I read all of the proofs, there are lots of typos and some derivations, which I will mention in below, are not carried out correctly, and I hope after revision they will not be problematic for the main claims to hold. However, overall the main results are clear and easy to read and providing examples like propositions 1,2 and touching on Phase retrieval and matrix square root problems makes this converse Lyapunov strategy interesting for analysis of GD/SGD using the GF convergence rate. I think this paper aims at connecting GF and GD analysis which is currently a hot research topic in optimization.",
                "Questions": "grammatical and mathematical typos:\nline 108 derivative. line 112 extra \"in\". line 121 shown. line 144 such that. line 215, F(w(t))\u2264\u2016w0\u201622t. line 226, satisfied. lines 587, 592, it should be \u03a6(w0). line 611, the negative signs in lines 3-4-5 should be removed, as |r\u2032(z)|=\u2212r\u2032(z). line 625, extra \"from\", also R(w,t)=F(w)e\u2212\u03bbt. line 630, \u2016\u2207F(w)\u20162\u03bb. line 634, 3rd line, missing \"=\". line 643, it should be \u2016u\u20163/2. line 651, F(w(T))\u2212F\u2217\u2264\u03a6(w0)T\u2264\u2016w0\u201622T. line 657, \"many ensure\". line 662, proof. line 700, extra \"defined\". line 705, \u03b8\u2033(z)=\u2212\u03c1\u2032(z)\u03c1(z)2. line 712, u=\u2212\u2207\u03a6(w)\u03c1(\u03a6(w)). line 732, since \"\u03b8\" is \"monotonic\", this implies that \"\u03a6(wt+1)\u2264\u03a6(wt)\". \nin line 752 equation (33), 2nd line is wrong. we don't know if F(wt)\u2264F(w0). Instead you should use F(wt)\u2264\u03b6(\u03a6(wt))\u2264\u03b6(\u03a6(w0)). However final conclusion of equation (34) is correct.\nline 772, \u03c8(F(w)) instead of \u2016\u2207F(w)\u20162. line 783, \u03ba>1. line 792, 3rd line is duplicate. line 796 and afterward, you should replace \u03a6(w0) with \u03b8(\u03a6(w0)). line 809 \"M=\". line 810, log2 seems to be log3. line 819, \"note that\" and \"when\".  line 826, \"g\" is missing. \nIn line 947, I couldn't derive second inequality. maybe there should be a larger coefficient.\nlines 1018 and 1025, \u2016M\u2016 instead of M.\nQuestions:\nregarding line 207-8, can you provide such examples, or mention some papers? \nIn line 614, lim\u00a0\u03f5\u21920\u03f5\u22121\u03f5 seems to be infinity, but for your result to hold it should be zero. This also happens in other places like line 181. Please explain. \nMy most important question is regarding the exponential rate of GD in theorems 6 and 7. In the proofs you say combining Lemma 1 with Theorem 4 will give the result. However Theorem 4 has a 1/T rate and g(z)=z. Please carefully explain it and also update the paper to contain more details of this proof.\nIn line 722, please explain (if needed by writing equation) that why 27 is valid if 26 is violated. I think there must be some \"g\" and \"\u03c8\" missing in (27), by looking at line 741.\nIn Theorem (4) you mention O(1T) rate of convergence, but in line 741, I can see 1/T as well as a constant term. Please explain. it seems that line 741 and 761 only differ by a constant and both of them are O(1/T) except that 741 is suboptimal assuming g is zero at optimum. \nIn line 798, I couldn't use Markov to get (39). I'd like to see one line of proof.\nline 804, where do you set \u03ba in the paper?\nLine 853 there is a serious issue with derivation of line 5, because we don't know \u03b8(\u03a6(wt+1))\u2212\u03b8(\u03a6(wt))\u22650, hence equation (50) may not be true. Please revise/explain the proof.\nIn proof of Lemma 11 needs serious revision. The derivation in lines 890 is incorrect and you should write R\u2212(w(s),t)=R(w(s),\u03c3(h(w(s)))t)\u2264R(w,\u03c3(h(w(s)))t+s)\u2264R(w,\u03c3(h(w(s)))t+\u03c3(h(w(s)))s)\u2264=R(w,\u03c3(h(w(s)))(t+s))\u2264R(w,h(w(s))(t+s))=R\u2212(w,s+t).\nMore importantly, I see an inconsistency in using \u03c3(h(w)) and h(w). For example you define R\u2212(w,t)=R(w,\u03c3(h(w))t), but after line 892 suddenly there is no sign of \u03c3 in derivations of \u2207\u03a6g(w) and \u22072\u03a6g(w). As you use \u03c3 in lines 306 and 336, I think \u03c3 is kinda absored in h but I can't wrap my head around this issue. in line 895 equation (51) \u03a6g(w) uses h(w) instead of \u03c3(h(w)). Also in line 911 the second term is used incorrectly and should be modified.\nIn line 1028, how do you calculate the bound on hessian? I assume hessian would be complicated.\nin line 1048 line 3, do you assume min\u00a0F=0?\nSuggestion:\nI urge you to state the result of Chatterjee more rigorously in the Appendix, and explain (mathematically in appendix) how in the lines 374-378 you can recover his result. I also expected a conclusion part at the end of the paper, but I assume you couldn't fit it.",
                "Limitations": "As this is a completely theoretic paper, I cannot think of anything related to social impact.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "soundness_avg": 3.25,
        "presentation_avg": 3.0,
        "contribution_avg": 2.75,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that this paper provides a novel framework for analyzing the convergence of gradient descent (GD) and stochastic gradient descent (SGD) by leveraging the convergence of the gradient flow (GF). The paper is well-written and the mathematical derivations seem solid. The reviewers have pointed out some minor flaws and typos, but these can be easily addressed in the revision. The main strength of this paper lies in its creative framework and its potential to provide a unified analysis of GD and SGD in more complex models, such as neural networks. While some reviewers have raised concerns about the usefulness and novelty of the framework, it is clear that this paper makes a significant contribution to the field of optimization and has the potential for high impact. Therefore, I recommend accepting this paper."
    },
    "Fast_Neural_Kernel_Embeddings_for_General_Activations": {
        "link": "https://openreview.net//forum?id=yLilJ1vZgMe",
        "pub_url": "https://openreview.net/forum?id=yLilJ1vZgMe",
        "pdf_link": "https://openreview.net//pdf?id=yLilJ1vZgMe",
        "paper_id": "yLilJ1vZgMe",
        "title": "Fast_Neural_Kernel_Embeddings_for_General_Activations",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nMost prior works on neural kernels have focused on using the ReLU activation. In this work, the authors provide new methods that can approximate multi-layered Neural Network Gaussian Process (NNGP) kernels and Neural Tangent Kernel (NTK) matrices for a wide range of activation functions. All the four reviewers recommended acceptance of the paper.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper builds and extends the theory of infinite-width neural kernel computations. Compared with prior works, we can summarize its contribution as follows:\n(1) It explicitly computes the NNGP and NTK kernels for a wider range of activation functions as shown in table 1.\n(2) It derives an explicit expression of the dual kernel for polynomial activation, which also expends the assumption x,y\u2208Sd\u22121 to a more general one x,y\u2208Rd, and suggests using truncated Hermite expansion to approximate the dual kernel for non-polynomial activations.\n(3) Given the situation that sometimes we are only given the dual kernel but not the corresponding activation or derivative of the activation functions, this paper propose to compute the dual kernel of the derivative without knowing the activation as shown in theorem 3. \n(4) It uses random sketching techniques to accelerate NTK approximation, which is an extention to previous work which was only applicable for ReLU activation.\nStrengths And Weaknesses: Strength:\n\nThis theoretical work extends the previous studies of dual kernels (NTK and NNGP), which is of high quality and might be useful as a good reference for future research in this area.\n\nMost theorems proved in this paper are incremental, but still preserves enough significance.\nQuestions: I'm not familar with neural kernels before, so it's hard for me to provide some useful suggestions for this paper.\nLimitations: The limitations and potential negative social impact are not described since this is a theoretical work.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 1: Your assessment is an educated guess. The submission is not in your area or the submission was difficult to understand. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The Neural Tangent Kenrel offers a compelling framework to (partially) understand some theoretical aspects of neural networks, especially near initialization. In the infinite-width regime, It has been known that NTK with ReLU activation has a closed-form analytic formula which enables exact computation of the NTK in this limit. However, the exact kernel computation for general activations is intractable. This paper proposes an approximate kernel computation method that leverages some tools from functional analysis (Hermite decomposition).\nStrengths And Weaknesses: Strengths:\n\nThe paper is very well written and flows nicely. The problem is well introduced and the results are stated in a logical sequence which serves well the purpose of the paper.\nThe theoretical results are sound and \nThe proposed methods are theoretically supported and the numerical results show some superiority compared to traditional methods used for NTK computation.\nThe proofs are well structured and easy to follow. I have one question about the proof of Thm3, see Questions section.\n\nWeaknesses:\n\nI believe that it would benefit the paper if approximation rates are provided for general depth L networks instead of just depth 1 networks. The dependency on L would capture the growth of the approximation error as depth increases and maybe suggest when to use (or not use) one method or another. Besides, existing work such as [2] show that NTK tends to deteriorate with depth, I am keen to see what happens to the approximate NTK in this case.\nThe paper lacks a more comprehensive literature review. I believe a more in depth discussion of existing results would immensely benefit the paper. See questions section.\nNumerical results are only reported for CIFAR10 (a part the synthetic dataset). It would be better if other (small, not necessarily ImageNet) datasets are included, this would help conclude wether activations such as the exponential or ABRelu is consistently better than ReLU. Also, results for varying depth would add value to the experiments section and make more complete.\nQuestions: \nThere is a similar NTK decomposition in the \u201cSpherical Harmonics\u201c basis that appeared in [1] and [3]. Moreover, authors of [2] show a similar extension of the decomposition on S^d to the whole of R^d (Theorem 5 in [2]). Knowing that Spherical harmonics are linked to Legendre polynomials, it would be great if the authors could discuss similarities and differences with Hermite decomposition.\nA recent work ([4]) has showed that NTK computation (in finite-width setting) can be considerably accelerated with some computational tricks. Can the authors comment on the differences (a part from the finite versus infinite width settings of course). For instance, what is the difference between a kernel computed with [4] for width 100 and an equivalent NTK computed with the methods specified in this paper? What can you say about training/inference time?\nIn the proof of Thm3, the condition on the second derivative can be further weakened to something like |\u03c3\u2033(t)|\u2264C1exp\u2061(C2t2h(t)) where limt\u21920h(t)=0 and h satisfies some mild conditions.\n\n[1] Geifman et al (2020) \u201cOn the Similarity between the Laplace and Neural Tangent Kernels\u201d\n[2] Hayou et al. (2021) \u201cMean-field Behaviour of Neural Tangent Kernel for Deep Neural Networks\u201d\n[3] Hayou et al. (2021) \u201cStable ResNet\u201d\n[4] Novak et al. (2021) \u201cFast Finite Width Neural Tangent Kernel\u201d\n[5] Bietti 2021 \u201cAPPROXIMATION AND LEARNING WITH DEEP CONVOLUTIONAL MODELS: A KERNEL PERSPECTIVE\u201d\nLimitations: Yes.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: In this paper, the authors try to accelerate the computation of NTK with general activation functions. For the q-homogeneous dual kernel,  the authors extend the finite Hermite polynomials approximation technique (Daniely et al. 2016)  and provide approximation bounds. A sketching method is further proposed for the approximation of NTK.   The proposed sketching technique extends the technique (Zandieh et al.  2021) to homogeneous kernels (w.r.t more general activations) with rapidly convergent Taylor expansion.\nStrengths And Weaknesses: Pros.\n\nThis paper focuses on NTK with general activation functions, which is an important direction for understanding deep neural networks with general activation functions. \nA method (Theorem 3) is proposed to compute the dual kernel of the derivative of activations without knowing the activations. \nThe authors provide approximation bound of finite Hermite polynomials approximation to the q-homogeneous dual kernel. \nThe sketching approximation of NTK extends (Zandieh et al.  2021) to more general homogeneous kernels. \nThe paper is well organized and well written.\n\nCons. \n\nAn important property of NTK and other prior work with ReLU is the global convergence of training. This relies on the strictly positive definite property in NTK (with ReLU) or positive-definite of the Gram matrix. This may be part of the reason why ReLU is widely used in the assumption of prior work.   This paper focuses on the approximation of NTK with general activation functions; however, it may lose the global convergence property.\nIt seems that the fast sketching approximation technique (Sec.4) can only apply to K\u03c3 homogeneous dual kernel. The approximation in Eq.(15) is a straightfowrad Gauss-Hermite quadrature for each entry of the kernel K, which is brute-force and still with high complexity. There are still some steps needed before claiming to fill the gap for general activations.\nIn Figure 1,  how to compute the time? Is the sketching approximation technique more efficient than orthogonal random features or other fast kernel approximation techniques?\nIt is better to state more clearly the key technique challenging/improvement compared with (Zandieh et al. 2021).\nQuestions: \nDoes the approximation of NTK with general activation guarantee the global convergence property?\n\nHow to compute L-depth NTK recursively using Eq.(5) ? It is not clearly described in the context.\n\nIn the experiments,  what is the concrete procedure to compute the time in Figure 1?  It is better to compare with orthogonal random features (Yu et al. 2016) or other fast kernel approximation techniques and present the error vs. number of features besides the error vs. time.\n\n\nYu et al. Orthogonal Random Features. NeurIPS  2016. \nZandieh et al. Scaling Neural Tangent Kernels via Sketching and Random Features. NeurIPS 2021.\nDaniely et al. Toward deeper understanding of neural networks: The power of initialization and a dual view on expressivity. NeurIPS 2016.\nLimitations: NA\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: The NTK and NNGP are powerful models for understanding and emulating the performance of neural networks in certain conditions. They are also worthy predictors in their own right, and allow one to easily predict with principled uncertainty. These models require computations involving a kernel or covariance function, which is a certain Gaussian integral representing the covariances between activations for two different inputs. Closed form expressions for kernels are known for many activations, each one having been derived by hand in previous works (see table 1). \nThe authors introduce a method for approximating NNGP kernels via a polynomial series (Theorem 1, 2). Furthermore, a certain expression in the NTK can be related to the NNGP via a derivative (Theorem 3), so the results readily extend to the NNTK. A random sketching method is also provided to approximate large kernel matrices of deep networks. \nThe paper is concluded with some experiments that show that the methods quickly (in terms of both wall-clock and number of series terms) and accurately approximate known NNGPs/NTKs. The authors also observe a 106 x speedup on a toy task compared with the exact kernel evaluation, and show reasonable performance.\nStrengths And Weaknesses: Strengths:\n\nThe method is generally applicable, i.e. the conditions in Theorems 1 and 2 are sufficiently mild a wide range of activations of interest. However, I am confused about the condition in Theorem 2 (see question below).\nThe authors cite a good amount of relevant literature, which is nice to see. The authors might also be interested in \"Stationary Activations for Uncertainty Calibration in Deep Learning\", which places the Matern kernel in the context of NNGP kernels.\n\nWeaknesses:\n\nI did some random sampling of the proofs in the appendix. It is quite possible that I missed some errors. I have some concerns. See \"Questions\" box.\nI found moving from Definition 1 to equation (5) a bit unnatural. In fact, the original motivation for the NNGP is as either (a) an inner product in an infinitely wide hidden layer with iid zero mean Gaussian weights or (b) the covariance of the output of a network. This is equation (5). Now (5) only depends on a bivariate gaussian (u,v)=(w.x, w.y), hence implying definition 1. Going in this direction is more natural IMO. In contrast, currently the authors go in the other direction and state \" By generalizing this observation to vectors in R^d\", without any apparent motivation for the generalisation. Note also that it is not actually a generalisation but an iff. A random vector is Gaussian iff all linear combinations are Gaussian. So while it is in principle possible to go from definition 1 to (5) without \"generalizing this observation to vectors in R^d\", it is not really required to be this abstract. I suggest the authors start with (5) and move to definition 1. That being said, there is nothing technically wrong with the current presentation apart from the word \"generalizing\".\n\nTypos:\n\n\"NTK can be exactly computed using recursively\" removing \"using\".\nChange \"We believe such acceleration thru our methods would open the door to using neural kernels in a wide range of research domains.\" to \"We believe such acceleration through our methods open the door to using neural kernels in a wide range of research domains.\"\nQuestions: \nIn Theorem 2, the derivatives need to be absolutely continuous. However, the first derivative of the ReLU is not absolutely continuous (it is not even defined in a classical sense at the origin). So presumably the first half of Theorem 1 does not apply to the ReLU. How then does (12) hold?\nWhat is the condition required to swap the order of the derivative and the expectation in line 672? Differentiating under the integral is valid when...? The second derivative of the ELU is unbounded, and also does not satisfy your weaker condition (44). Therefore Theorem 3 cannot be applied to the ELU. I don't think this condition is actually required. Differentiation under the integral holds in the sense of generalised functions/distributions/Schwartz functions, as long as the resulting integral is finite. This means that the derivatives will involve Heaviside, Dirac, derivative of Dirac etc.\nLooking at this again, your Theorem 3 is actually almost identical to part of Theorem 6 of reference [44] that you cite. Their expression for \\lambda_3 is your expression for (14), up to a normalisation. Their proof is very similar to yours, but more appropriately uses a Stein's lemma for tempered distributions i.e. Schwartz functions to differentiate under the expectation. I think it is fine to keep your Theorem 3 as is, but acknowledge that this was independently studied in [44] with a much milder condition using Schwartz functions, albeit for a different purpose. Alternatively, cite or reproduce this more general theorem.\nLimitations: I do not envisage any direct societal complications from this work. I hope it is not a cop-out to say that evaluation of societal impact is not necessary for this work, because the contributions are completely task, problem, data and even to some degree model agnostic. Downstream works that use the techniques introduced here should consider these impacts.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper builds and extends the theory of infinite-width neural kernel computations. Compared with prior works, we can summarize its contribution as follows:\n(1) It explicitly computes the NNGP and NTK kernels for a wider range of activation functions as shown in table 1.\n(2) It derives an explicit expression of the dual kernel for polynomial activation, which also expends the assumption x,y\u2208Sd\u22121 to a more general one x,y\u2208Rd, and suggests using truncated Hermite expansion to approximate the dual kernel for non-polynomial activations.\n(3) Given the situation that sometimes we are only given the dual kernel but not the corresponding activation or derivative of the activation functions, this paper propose to compute the dual kernel of the derivative without knowing the activation as shown in theorem 3. \n(4) It uses random sketching techniques to accelerate NTK approximation, which is an extention to previous work which was only applicable for ReLU activation.",
                "Strengths And Weaknesses": "Strength:\n\nThis theoretical work extends the previous studies of dual kernels (NTK and NNGP), which is of high quality and might be useful as a good reference for future research in this area.\n\nMost theorems proved in this paper are incremental, but still preserves enough significance.",
                "Questions": "I'm not familar with neural kernels before, so it's hard for me to provide some useful suggestions for this paper.",
                "Limitations": "The limitations and potential negative social impact are not described since this is a theoretical work.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "1: Your assessment is an educated guess. The submission is not in your area or the submission was difficult to understand. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The Neural Tangent Kenrel offers a compelling framework to (partially) understand some theoretical aspects of neural networks, especially near initialization. In the infinite-width regime, It has been known that NTK with ReLU activation has a closed-form analytic formula which enables exact computation of the NTK in this limit. However, the exact kernel computation for general activations is intractable. This paper proposes an approximate kernel computation method that leverages some tools from functional analysis (Hermite decomposition).",
                "Strengths And Weaknesses": "Strengths:\n\nThe paper is very well written and flows nicely. The problem is well introduced and the results are stated in a logical sequence which serves well the purpose of the paper.\nThe theoretical results are sound and \nThe proposed methods are theoretically supported and the numerical results show some superiority compared to traditional methods used for NTK computation.\nThe proofs are well structured and easy to follow. I have one question about the proof of Thm3, see Questions section.\n\nWeaknesses:\n\nI believe that it would benefit the paper if approximation rates are provided for general depth L networks instead of just depth 1 networks. The dependency on L would capture the growth of the approximation error as depth increases and maybe suggest when to use (or not use) one method or another. Besides, existing work such as [2] show that NTK tends to deteriorate with depth, I am keen to see what happens to the approximate NTK in this case.\nThe paper lacks a more comprehensive literature review. I believe a more in depth discussion of existing results would immensely benefit the paper. See questions section.\nNumerical results are only reported for CIFAR10 (a part the synthetic dataset). It would be better if other (small, not necessarily ImageNet) datasets are included, this would help conclude wether activations such as the exponential or ABRelu is consistently better than ReLU. Also, results for varying depth would add value to the experiments section and make more complete.",
                "Questions": "There is a similar NTK decomposition in the \u201cSpherical Harmonics\u201c basis that appeared in [1] and [3]. Moreover, authors of [2] show a similar extension of the decomposition on S^d to the whole of R^d (Theorem 5 in [2]). Knowing that Spherical harmonics are linked to Legendre polynomials, it would be great if the authors could discuss similarities and differences with Hermite decomposition.\nA recent work ([4]) has showed that NTK computation (in finite-width setting) can be considerably accelerated with some computational tricks. Can the authors comment on the differences (a part from the finite versus infinite width settings of course). For instance, what is the difference between a kernel computed with [4] for width 100 and an equivalent NTK computed with the methods specified in this paper? What can you say about training/inference time?\nIn the proof of Thm3, the condition on the second derivative can be further weakened to something like |\u03c3\u2033(t)|\u2264C1exp\u2061(C2t2h(t)) where limt\u21920h(t)=0 and h satisfies some mild conditions.\n\n[1] Geifman et al (2020) \u201cOn the Similarity between the Laplace and Neural Tangent Kernels\u201d\n[2] Hayou et al. (2021) \u201cMean-field Behaviour of Neural Tangent Kernel for Deep Neural Networks\u201d\n[3] Hayou et al. (2021) \u201cStable ResNet\u201d\n[4] Novak et al. (2021) \u201cFast Finite Width Neural Tangent Kernel\u201d\n[5] Bietti 2021 \u201cAPPROXIMATION AND LEARNING WITH DEEP CONVOLUTIONAL MODELS: A KERNEL PERSPECTIVE\u201d",
                "Limitations": "Yes.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "In this paper, the authors try to accelerate the computation of NTK with general activation functions. For the q-homogeneous dual kernel,  the authors extend the finite Hermite polynomials approximation technique (Daniely et al. 2016)  and provide approximation bounds. A sketching method is further proposed for the approximation of NTK.   The proposed sketching technique extends the technique (Zandieh et al.  2021) to homogeneous kernels (w.r.t more general activations) with rapidly convergent Taylor expansion.",
                "Strengths And Weaknesses": "Pros.\n\nThis paper focuses on NTK with general activation functions, which is an important direction for understanding deep neural networks with general activation functions. \nA method (Theorem 3) is proposed to compute the dual kernel of the derivative of activations without knowing the activations. \nThe authors provide approximation bound of finite Hermite polynomials approximation to the q-homogeneous dual kernel. \nThe sketching approximation of NTK extends (Zandieh et al.  2021) to more general homogeneous kernels. \nThe paper is well organized and well written.\n\nCons. \n\nAn important property of NTK and other prior work with ReLU is the global convergence of training. This relies on the strictly positive definite property in NTK (with ReLU) or positive-definite of the Gram matrix. This may be part of the reason why ReLU is widely used in the assumption of prior work.   This paper focuses on the approximation of NTK with general activation functions; however, it may lose the global convergence property.\nIt seems that the fast sketching approximation technique (Sec.4) can only apply to K\u03c3 homogeneous dual kernel. The approximation in Eq.(15) is a straightfowrad Gauss-Hermite quadrature for each entry of the kernel K, which is brute-force and still with high complexity. There are still some steps needed before claiming to fill the gap for general activations.\nIn Figure 1,  how to compute the time? Is the sketching approximation technique more efficient than orthogonal random features or other fast kernel approximation techniques?\nIt is better to state more clearly the key technique challenging/improvement compared with (Zandieh et al. 2021).",
                "Questions": "Does the approximation of NTK with general activation guarantee the global convergence property?\n\nHow to compute L-depth NTK recursively using Eq.(5) ? It is not clearly described in the context.\n\nIn the experiments,  what is the concrete procedure to compute the time in Figure 1?  It is better to compare with orthogonal random features (Yu et al. 2016) or other fast kernel approximation techniques and present the error vs. number of features besides the error vs. time.\n\n\nYu et al. Orthogonal Random Features. NeurIPS  2016. \nZandieh et al. Scaling Neural Tangent Kernels via Sketching and Random Features. NeurIPS 2021.\nDaniely et al. Toward deeper understanding of neural networks: The power of initialization and a dual view on expressivity. NeurIPS 2016.",
                "Limitations": "NA",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The NTK and NNGP are powerful models for understanding and emulating the performance of neural networks in certain conditions. They are also worthy predictors in their own right, and allow one to easily predict with principled uncertainty. These models require computations involving a kernel or covariance function, which is a certain Gaussian integral representing the covariances between activations for two different inputs. Closed form expressions for kernels are known for many activations, each one having been derived by hand in previous works (see table 1). \nThe authors introduce a method for approximating NNGP kernels via a polynomial series (Theorem 1, 2). Furthermore, a certain expression in the NTK can be related to the NNGP via a derivative (Theorem 3), so the results readily extend to the NNTK. A random sketching method is also provided to approximate large kernel matrices of deep networks. \nThe paper is concluded with some experiments that show that the methods quickly (in terms of both wall-clock and number of series terms) and accurately approximate known NNGPs/NTKs. The authors also observe a 106 x speedup on a toy task compared with the exact kernel evaluation, and show reasonable performance.",
                "Strengths And Weaknesses": "Strengths:\n\nThe method is generally applicable, i.e. the conditions in Theorems 1 and 2 are sufficiently mild a wide range of activations of interest. However, I am confused about the condition in Theorem 2 (see question below).\nThe authors cite a good amount of relevant literature, which is nice to see. The authors might also be interested in \"Stationary Activations for Uncertainty Calibration in Deep Learning\", which places the Matern kernel in the context of NNGP kernels.\n\nWeaknesses:\n\nI did some random sampling of the proofs in the appendix. It is quite possible that I missed some errors. I have some concerns. See \"Questions\" box.\nI found moving from Definition 1 to equation (5) a bit unnatural. In fact, the original motivation for the NNGP is as either (a) an inner product in an infinitely wide hidden layer with iid zero mean Gaussian weights or (b) the covariance of the output of a network. This is equation (5). Now (5) only depends on a bivariate gaussian (u,v)=(w.x, w.y), hence implying definition 1. Going in this direction is more natural IMO. In contrast, currently the authors go in the other direction and state \" By generalizing this observation to vectors in R^d\", without any apparent motivation for the generalisation. Note also that it is not actually a generalisation but an iff. A random vector is Gaussian iff all linear combinations are Gaussian. So while it is in principle possible to go from definition 1 to (5) without \"generalizing this observation to vectors in R^d\", it is not really required to be this abstract. I suggest the authors start with (5) and move to definition 1. That being said, there is nothing technically wrong with the current presentation apart from the word \"generalizing\".\n\nTypos:\n\n\"NTK can be exactly computed using recursively\" removing \"using\".\nChange \"We believe such acceleration thru our methods would open the door to using neural kernels in a wide range of research domains.\" to \"We believe such acceleration through our methods open the door to using neural kernels in a wide range of research domains.\"",
                "Questions": "In Theorem 2, the derivatives need to be absolutely continuous. However, the first derivative of the ReLU is not absolutely continuous (it is not even defined in a classical sense at the origin). So presumably the first half of Theorem 1 does not apply to the ReLU. How then does (12) hold?\nWhat is the condition required to swap the order of the derivative and the expectation in line 672? Differentiating under the integral is valid when...? The second derivative of the ELU is unbounded, and also does not satisfy your weaker condition (44). Therefore Theorem 3 cannot be applied to the ELU. I don't think this condition is actually required. Differentiation under the integral holds in the sense of generalised functions/distributions/Schwartz functions, as long as the resulting integral is finite. This means that the derivatives will involve Heaviside, Dirac, derivative of Dirac etc.\nLooking at this again, your Theorem 3 is actually almost identical to part of Theorem 6 of reference [44] that you cite. Their expression for \\lambda_3 is your expression for (14), up to a normalisation. Their proof is very similar to yours, but more appropriately uses a Stein's lemma for tempered distributions i.e. Schwartz functions to differentiate under the expectation. I think it is fine to keep your Theorem 3 as is, but acknowledge that this was independently studied in [44] with a much milder condition using Schwartz functions, albeit for a different purpose. Alternatively, cite or reproduce this more general theorem.",
                "Limitations": "I do not envisage any direct societal complications from this work. I hope it is not a cop-out to say that evaluation of societal impact is not necessary for this work, because the contributions are completely task, problem, data and even to some degree model agnostic. Downstream works that use the techniques introduced here should consider these impacts.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.5,
        "confidence_avg": 3.0,
        "soundness_avg": 3.0,
        "presentation_avg": 3.25,
        "contribution_avg": 3.0,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is clear that this paper makes significant contributions to the theory of infinite-width neural kernel computations. The reviewers have highlighted the strengths of the paper, including its theoretical soundness, well-written presentation, and the usefulness of the proposed methods. The paper extends previous studies on dual kernels and provides approximation techniques for NTK with general activation functions. The numerical results also demonstrate the effectiveness of the proposed methods.\n\nWhile there are some minor weaknesses and questions raised by the reviewers, they do not significantly impact the overall quality and impact of the paper. The limitations and potential negative social impact are not explicitly discussed, but given the theoretical nature of the work, it is unlikely to have direct societal complications.\n\nTherefore, based on the positive feedback from the reviewers and the high quality of the paper, I recommend accepting it for publication."
    },
    "On_Reinforcement_Learning_and_Distribution_Matching_for_Fine-Tuning_Language_Models_with_no_Catastrophic_Forgetting": {
        "link": "https://openreview.net//forum?id=XvI6h-s4un",
        "pub_url": "https://openreview.net/forum?id=XvI6h-s4un",
        "pdf_link": "https://openreview.net//pdf?id=XvI6h-s4un",
        "paper_id": "XvI6h-s4un",
        "title": "On_Reinforcement_Learning_and_Distribution_Matching_for_Fine-Tuning_Language_Models_with_no_Catastrophic_Forgetting",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nAll reviewers consistently agree that this paper provides valuable contribution in identifying the connection between different RL training paradigms for language models with clear derivations. In addition, it also develops an improved method by incorporating a baseline into DPG.",
        "reviews": [
            "Reviewer 1: \nSummary: The paper elaborates on the idea of the DPG (Parshakova et al., 2019b) and GDC (Khalifa et al., 2021) paper, explicitly states that \"KL-control\", a specific reward maximization method, is also a distribution matching method with energy-based models. The paper also clearly explains the similarity and difference between distributional gradient descent and standard gradient descent. An advantage-based GDC algorithm is introduced in the paper as a standard technique in RL to reduce the variance of gradient estimates. Numerical experiments show the effectiveness of the proposed method.\nStrengths And Weaknesses: DPG framework could be a powerful tool for fine-tuning LMs to maximize some non-differentiable objectives using RL/EBM, but also prevent the catastrophic forgetting problem. The idea is neat with mostly straightforward derivation. The paper clarifies the key concepts and connections to existing training paradigms. Readers that are perplexed about fine-tuning LMs with reinforcement learning would greatly benefit from this paper.\nQuestions: I don't have any critical questions or confusions about the paper.\nLimitations: Limitations and future directions are well discussed at the end of the paper.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper focuses on fine-tuning language models for controllable language generation tasks ( constraining topic, sentiment, gender distributions, etc). The authors derive the connection between distribution matching approaches and approaches that use KL-divergence penalty to prevent distribution shifts. By deriving a parametric reward baseline for Distributional Policy Gradients (DPG) and use it to extend the work by Khalifa et al., a distribution matching approach for nudging autoregressive generation distributions, this work achieves variance reduction and superior performance.\nStrengths And Weaknesses: Strengths:\n\nThe mathematical derivations for connecting policy gradients and distributional policy gradients (DPG),  connecting KL-control and distributional matching, DPG baseline are easy to follow. I appreciate the effort. These derivations provide good perspectives and should be valuable to the community.\nThe main claim of introducing a baseline to reduce variance of DPG is well-justified and supported by evidence (Section 4).\n\nWeaknesses:\n\nI think the contribution on making connection between policy gradients and distributional policy gradients is unnecessarily exaggerated, such as line 77: \"So far, the connections between these two seemingly distinct paradigms have not been thoroughly explored\". I think even the similarity in names already suggest that they are closely related, and they indeed aren't that different from each others. I think this claim actually makes the paper's logic difficult to follow for me. I would suggest focusing more on the contribution of introducing the parametric baseline, which should be the main product of this paper in my opinion.\nI'd like to see a consolidated definition of the control language generation task. Right now, they are scattered in intro, Sec. 4.1, Sec. 4.2. What's the context and desired outcomes of such tasks? How does DPG achieve the desired outcomes (now it's sort of described in Sec. 4.2)? Can the authors give some examples?\nQuestions: Overall, I think the technical contributions are solid and novel, but I have concerns about how these contributions are framed and positioned. Can the authors address or clarify the concerns I raised above?\nLimitations: Limitations and potential negative societal impact are not discussed. Please add relevant pieces to the conclusion section.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper studies controllable text generation with an emphasis on sequence level rewards and distribution matching. It first establishes a connection between reward maximization (RM) with KL control and distribution matching (DM) in a general sense. They show that there is an equivalent formulation of RM in DM terms and also DM can be connected to RM by thinking the importance sampling (IS) term as a reward. Using these connections, the authors highlight that a recent DM method, distributional policy gradient (DPG), suffers from the same high variance of REINFORCE estimators as the latter appears in the loss function of DPG. As is typical in RL, the authors propose using advantage estimations to reduce the variance of the DPG estimator and show that the intuitive expected reward (estimated as mean IS weights) gives unbiased estimates. The authors evaluate the proposed method, GDC++, on 10 controllable generation tasks including pointwise and distributional constraints using moment matching, KL-divergence, BLEU score metrics. When compared to other baselines, GDC++ shows lower divergence from the prior language model while also having competitive constraint matching. Using an advantage estimation is also shown to perform better and more stable results.\nStrengths And Weaknesses: The main strength of the paper is the connection between RM and DM to motivate using a baseline in DPG. There are also several weaknesses that needs clarification. I detail these below.\nStrength\n\nThe paper is well written and easy to follow. \nThe connection between RM and DM to motivate using a baseline in DPG and showing that the particular expected reward baseline is unbiased are interesting.\nExperimental results show improvement compared to GDC and Ziegler et al.\n\nWeaknesses\n\nWhile DM is not exactly the same as RM, I think there are previous work that incorporates KL-divergence between an online distribution and an offline distribution as a reward signal to train a policy using RL. Some of the more recent work are SAC1, SMM2 that induce a reward using a distribution matching and an older work *. While these don't necessarily utilize a KL-control, they study KL-divergence objective with energy based models or reward shaping.\nThe KL-divergence appears in different forms at different places. You define DPG in Line 105 and Algorithm 1 using DKL(p||\u03c0\u03b8) while in Line 135 it is reverse.\nZiegler uses a reward shaping with a KL-control and the model is optimized via PPO. As PPO uses GAE, it also subtracts a baseline from this new reward. I think the relationship between this and the proposed baseline needs to be addressed.\nIt is also not clear how the \u03b2 is tuned in Ziegler baseline. By varying this hyperparameter, Ziegler can do better on DKL(\u03c0\u03b8,a) while doing worse on E\u03c0theta\u03d5(x), performing very similar to GDC++.\nThere is no human evaluation study in the paper and it is not clear how to judge the metrics proposed. For example, does higher KL from the language prior always means worse generation?\n\n1 Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor.\n2 Efficient Exploration via State Marginal Matching.\n* Reinforcement Learning by Probability Matching.\nQuestions: I have several questions regarding my concerns above.\n\nCould you clarify how your derivations are related to prior work on distribution matching and max entropy RL ? \nCan you clarify the form of KL divergence used in the paper?\nWhat is the relationship between the baseline used in the paper and that of Ziegler?\nCould you clarify how Ziegler is trained, especially \u03b2 hyperparameter? Can you get better tradeoff by tuning this hyperparameter?\nCan you discuss how these metrics translate into human satisfaction?\nLimitations: The authors addressed the limitations.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The paper elaborates on the idea of the DPG (Parshakova et al., 2019b) and GDC (Khalifa et al., 2021) paper, explicitly states that \"KL-control\", a specific reward maximization method, is also a distribution matching method with energy-based models. The paper also clearly explains the similarity and difference between distributional gradient descent and standard gradient descent. An advantage-based GDC algorithm is introduced in the paper as a standard technique in RL to reduce the variance of gradient estimates. Numerical experiments show the effectiveness of the proposed method.",
                "Strengths And Weaknesses": "DPG framework could be a powerful tool for fine-tuning LMs to maximize some non-differentiable objectives using RL/EBM, but also prevent the catastrophic forgetting problem. The idea is neat with mostly straightforward derivation. The paper clarifies the key concepts and connections to existing training paradigms. Readers that are perplexed about fine-tuning LMs with reinforcement learning would greatly benefit from this paper.",
                "Questions": "I don't have any critical questions or confusions about the paper.",
                "Limitations": "Limitations and future directions are well discussed at the end of the paper.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper focuses on fine-tuning language models for controllable language generation tasks ( constraining topic, sentiment, gender distributions, etc). The authors derive the connection between distribution matching approaches and approaches that use KL-divergence penalty to prevent distribution shifts. By deriving a parametric reward baseline for Distributional Policy Gradients (DPG) and use it to extend the work by Khalifa et al., a distribution matching approach for nudging autoregressive generation distributions, this work achieves variance reduction and superior performance.",
                "Strengths And Weaknesses": "Strengths:\n\nThe mathematical derivations for connecting policy gradients and distributional policy gradients (DPG),  connecting KL-control and distributional matching, DPG baseline are easy to follow. I appreciate the effort. These derivations provide good perspectives and should be valuable to the community.\nThe main claim of introducing a baseline to reduce variance of DPG is well-justified and supported by evidence (Section 4).\n\nWeaknesses:\n\nI think the contribution on making connection between policy gradients and distributional policy gradients is unnecessarily exaggerated, such as line 77: \"So far, the connections between these two seemingly distinct paradigms have not been thoroughly explored\". I think even the similarity in names already suggest that they are closely related, and they indeed aren't that different from each others. I think this claim actually makes the paper's logic difficult to follow for me. I would suggest focusing more on the contribution of introducing the parametric baseline, which should be the main product of this paper in my opinion.\nI'd like to see a consolidated definition of the control language generation task. Right now, they are scattered in intro, Sec. 4.1, Sec. 4.2. What's the context and desired outcomes of such tasks? How does DPG achieve the desired outcomes (now it's sort of described in Sec. 4.2)? Can the authors give some examples?",
                "Questions": "Overall, I think the technical contributions are solid and novel, but I have concerns about how these contributions are framed and positioned. Can the authors address or clarify the concerns I raised above?",
                "Limitations": "Limitations and potential negative societal impact are not discussed. Please add relevant pieces to the conclusion section.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper studies controllable text generation with an emphasis on sequence level rewards and distribution matching. It first establishes a connection between reward maximization (RM) with KL control and distribution matching (DM) in a general sense. They show that there is an equivalent formulation of RM in DM terms and also DM can be connected to RM by thinking the importance sampling (IS) term as a reward. Using these connections, the authors highlight that a recent DM method, distributional policy gradient (DPG), suffers from the same high variance of REINFORCE estimators as the latter appears in the loss function of DPG. As is typical in RL, the authors propose using advantage estimations to reduce the variance of the DPG estimator and show that the intuitive expected reward (estimated as mean IS weights) gives unbiased estimates. The authors evaluate the proposed method, GDC++, on 10 controllable generation tasks including pointwise and distributional constraints using moment matching, KL-divergence, BLEU score metrics. When compared to other baselines, GDC++ shows lower divergence from the prior language model while also having competitive constraint matching. Using an advantage estimation is also shown to perform better and more stable results.",
                "Strengths And Weaknesses": "The main strength of the paper is the connection between RM and DM to motivate using a baseline in DPG. There are also several weaknesses that needs clarification. I detail these below.\nStrength\n\nThe paper is well written and easy to follow. \nThe connection between RM and DM to motivate using a baseline in DPG and showing that the particular expected reward baseline is unbiased are interesting.\nExperimental results show improvement compared to GDC and Ziegler et al.\n\nWeaknesses\n\nWhile DM is not exactly the same as RM, I think there are previous work that incorporates KL-divergence between an online distribution and an offline distribution as a reward signal to train a policy using RL. Some of the more recent work are SAC1, SMM2 that induce a reward using a distribution matching and an older work *. While these don't necessarily utilize a KL-control, they study KL-divergence objective with energy based models or reward shaping.\nThe KL-divergence appears in different forms at different places. You define DPG in Line 105 and Algorithm 1 using DKL(p||\u03c0\u03b8) while in Line 135 it is reverse.\nZiegler uses a reward shaping with a KL-control and the model is optimized via PPO. As PPO uses GAE, it also subtracts a baseline from this new reward. I think the relationship between this and the proposed baseline needs to be addressed.\nIt is also not clear how the \u03b2 is tuned in Ziegler baseline. By varying this hyperparameter, Ziegler can do better on DKL(\u03c0\u03b8,a) while doing worse on E\u03c0theta\u03d5(x), performing very similar to GDC++.\nThere is no human evaluation study in the paper and it is not clear how to judge the metrics proposed. For example, does higher KL from the language prior always means worse generation?\n\n1 Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor.\n2 Efficient Exploration via State Marginal Matching.\n* Reinforcement Learning by Probability Matching.",
                "Questions": "I have several questions regarding my concerns above.\n\nCould you clarify how your derivations are related to prior work on distribution matching and max entropy RL ? \nCan you clarify the form of KL divergence used in the paper?\nWhat is the relationship between the baseline used in the paper and that of Ziegler?\nCould you clarify how Ziegler is trained, especially \u03b2 hyperparameter? Can you get better tradeoff by tuning this hyperparameter?\nCan you discuss how these metrics translate into human satisfaction?",
                "Limitations": "The authors addressed the limitations.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.667,
        "confidence_avg": 3.667,
        "soundness_avg": 3.333,
        "presentation_avg": 3.0,
        "contribution_avg": 3.0,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the paper makes solid contributions in the field of fine-tuning language models for controllable language generation tasks. The paper establishes connections between reward maximization and distribution matching, and proposes a parametric baseline to reduce the variance of distributional policy gradients. The experimental results demonstrate the effectiveness of the proposed method.\n\nWhile there are some concerns raised by the reviewers, such as the framing and positioning of the contributions, the lack of discussion on potential negative societal impact, and the need for clarification on the relationship between the proposed baseline and previous work, these concerns do not outweigh the strengths of the paper.\n\nOverall, the paper is technically solid and has the potential for high impact in the field. It provides valuable insights and contributions to the community. Therefore, I recommend accepting the paper."
    },
    "Provably_tuning_the_ElasticNet_across_instances": {
        "link": "https://openreview.net//forum?id=ZMFQtvVJr40",
        "pub_url": "https://openreview.net/forum?id=ZMFQtvVJr40",
        "pdf_link": "https://openreview.net//pdf?id=ZMFQtvVJr40",
        "paper_id": "ZMFQtvVJr40",
        "title": "Provably_tuning_the_ElasticNet_across_instances",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nThe reviewers agreed that this paper should be accepted -- it studies an interesting and in someways \"overlooked\" problem and seems like it could be a starting point for others to build on. The paper did have some weaknesses. For example, we feel that the lack of experimental results is a missed opportunity -- the reviewers feel the paper would be made stronger by including at least a simple example where the standard approach of grid search + CV fails. Without such an example, it is a bit hard to be convinced of the importance of the problem being studied.",
        "reviews": [
            "Reviewer 1: \nSummary: This submission derives new generalization bounds for tuning the regularization parameters for ridge-regression, LASSO, and the elastic net methods. \nIn particular, the authors study two settings: (i) tuning based on multiple draws of train/test splits from a fixed (but arbitrary) problem distribution and (ii) online learning, where new train/test splits are provided as problem instances at each time step.\nIn the former setting, the authors show O~(p3/\u03f52) problem samples are required to come within \u03f5 of the best (expected) loss.\nIn the latter setting, the authors impose a smoothness assumptions on the adversary in order to provide a continuous version of the multiplicative weights algorithm with sub-linear regret. \nBoth results rely on a novel characterization of the tuning objective as a piecewise rational function with boundaries given by polynomial curves.\nThe submission concludes with extensions to linear classification problems with a fixed decision threshold and squared loss.\nStrengths And Weaknesses: This is a highly novel paper which tackles an excellent problem: how to properly tune regularization parameters for common algorithms. \nThe standard approach to tuning ridge regression, LASSO, or the elastic net methods is grid-search. \nHowever, as the authors note in the classification setting, some model choices, like thresholding, can induce discontinuities in the tuning objective and make grid-search unreliable.\nThus, developing better alternatives to grid-search is a important topic. \nThe theoretical bounds are novel and cover a range of important settings.\nI was particularly interested to see the online-learning results.\nThe only two potential issues I see with this work are implementability and the focus on problem-sample complexity, rather than example-sample complexity.\nThe apparent non-implementability of the actual methods for tuning the regularization parameters is somewhat disappointing, but not too surprising given the nature of the results.\nAnd, while the authors state that problem-sample complexity is more common, I think the problem sampling (which covers cross-validation) to be far more interesting. \nWriting\nThe paper is very well written. \nI found only a few typos (see Minor Issues below).\nI particularly appreciate that the authors take care to give intuition for each theoretical result as well as discuss their implications. \nCongratulations on a very well-written paper.\nTheory\nSoundness: This paper is outside of my core research area, so I'm not an expert on the theory. However, I briefly looked through the appendices and saw no major issues. \nImplementability: My understanding from the discussion is that the methods for tuning \u03bb are not implementable (see Questions). \nThus, while the paper presents \"efficient algorithms\" (Line 402), efficiency is only in the sense of sample complexity, rather than computational complexity.\nI don't think this is an important issue, but I suggest the authors either comment on the complexity of tuning \u03bb in practice, or clarify that they mean efficiency only in terms of samples. \nExperiments\nN/A\nMinor Comments and Typos:\n\nLine 263: \"rational functions of bounded degrees .\" -- remove extra space before the period.\nLine 286: \"\u03f5-approximation of the loss corresponding parameter selection with arbitrarily...\"  --- I don't understand this sentence; perhaps a word is missing?\nLine 369: \"only polynomially many problem samples to generalize well...\" -> \"only polynomially many problem samples are required to generalize well\"\nQuestions: \nTheorem 3.2/Theorem A.1: Is this result constructive or does it only give the existence of an algorithm?\n  For instance, I agree with the claim that \"our results answer the question \u2018how much 288 cross-validation is enough\u2019 to effectively implement the above techniques\", but this is separate from carrying out the optimization procedure in practice. \n\nAlgorithm 1: The optimization domain C appears to be an uncountable set, in which case the density function wi defines an improper distribution (at least initially) and maybe highly discontinuous during execution of the algorithm. \n  As a result, Algorithm 1 appears to be unimplementable --- is this correct?\n\nAre there any lower bounds for the sample complexity of learning \u03bb in the distributional setting (regression of classification)? If so, it would be excellent to compare Theorem 3.2 to these rates. If not, it might be nice to comment on the challenges in developing these bounds.\nLimitations: The limitations are properly addressed.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 4 excellent\nRating: 8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper studies the validation loss of the elastic net as a function of its two hyperparameters, \u03bb1,\u03bb2. The authors allow \"validation loss\" to be fairly general: it is a function that maps a dataset and a setting of (\u03bb1,\u03bb2) to the validation loss of the elastic net. They characterize this function as a piecewise rational polynomial as a function of (\u03bb1,\u03bb2). They use this characterization to show that, given a set of validation losses and a distribution over this set (e.g. in leave-one-out cross-validation, the validation losses are the leave-one-out losses with the uniform distribution), a possibly small number of draws from this distribution are needed to minimize the average validation loss within \u03f5 accuracy. The authors go on to show that validation losses can be minimized in an online setting, where we view each validation loss one-by-one. Finally, the authors prove similar results for binary classification, where classification is done by thresholding the predictions of the elastic net.\nStrengths And Weaknesses: Strengths\nI think the technical contributions of this paper are pretty strong and original. As far as I know, no one has given this exact a characterization of the loss landscape of things similar to cross-validation for the elastic net. I can see some interesting future work building off of this paper -- e.g. what do the individual pieces of the loss look like? The author's observation about how much subsampling of leave-one-out CV is needed to get an accurate approximation is interesting as well. I actually think this is one of the most immediately practical pieces of advice from this paper, and might warrant a little more highlighting (e.g. as a corollary). I can't really comment on the strengths of their results about online learning, as I'm not as familiar with that literature (in particular, T expected regret for T problems sounds like a lot, but maybe this is near the best you can do?).\nWeaknesses\nI think there are two main directions for improvement of the paper. First, I think the authors have slightly oversold the weakness of their assumptions, and should tone down those claims a little bit. Second, the writing was pretty dense and could use some more discussion and careful definitions.\nOn the assumptions required for the authors' results:\n\nThe abstract states that the results do not require \"strong assumptions on the data distribution\". Assumption 1 (that the covariates and responses are all bounded) is definitely not a weak assumption. I think it wouldn't be unfair to say this is a \"strong\" assumption, as this disallows, say, a well-specified model in which responses are linear functions of the covariates with Gaussian noise.\nThe results are stated as being completely independent of data distribution (e.g. in \"Theorem 1.1 (Informal)\"). However, a number of the lemmas used (Lemmas B.2, B.3, and C.1) require the columns of the data matrix X to be in general position. First, this condition should be stated in the results using these lemmas (e.g. in the statement of Lemma 2.1). Second, it should be clarified in exposition that the paper's results only apply to sets of problems / distributions over problems with covariate matrices with columns in general position.\n\nOn the writing being dense: The paper is pretty technical and uses a number of concepts from algebraic geometry and learning theory. These concepts are sometimes unexplained (e.g. just a definition is given) or lack a definition altogether. I think the results in this paper could be of interest beyond the learning theory community or algebraic statistics community, and so these concepts should be better explained (I think this is especially true of the concepts from algebraic geometry, which I suspect very few NeurIPS readers / attendees have experience with). Here are the things that stood out to me:\n\nPiecewise structured functions could use a simple English description.\nPseudo-dimension should be defined and briefly explained. The abbreviation PDIM should also be explicitly defined.\nSemi-algebraic sets and algebraic curves should be defined.\nA precise statement of Bezout's theorem should be given in the form that is applied here (or, at least, a reference).\nI thought the definition and explanation of \u03b2-dispersion was really clear and helpful.\n\nMiscellaneous things\n\nI think Lemma C.2 needs some conditions to ensure ATA+\u03bbI is invertible (what if A is low rank? what if \u03bb=\u22125345?)\nLine 215: \"based on the observation above\" there are many observations preceding this statement; it's not immediately clear which one this refers to.\nWhat are the asterisks in the proof of Lemma 2.1 (around line 218)? Are these just typos? An asterisk appears on \u03bb1 around line 223 as well, and then disappears in the next equation.\n\"Using simple algebra, the denominator...\" Definitely E depends on \u03bb1 and \u03bb2, and it's not immediately clear to me why that dependence gets canceled out in this expression. I think a proof should be given here.\nAlgorithm 1 is actually never discussed in the paper. I'm guessing it's the algorithm from Theorem 3.3, but this should really be made clear (and discussed).\nQuestions: \nCan the authors provide a proof for the statement \"using simple algebra, the denominator...\"?\n\nI also have a few questions relating to the meaning of the author's results.\n\nIs the algorithm in Theorem 3.3 just Algorithm 1? It's probably worth stating this if so. As-is, Algorithm 1 isn't really discussed in the paper.\nOne of the claims of Theorem 3.3 is about the \u03b2-dispersion of a series of functions. Why is this something readers should care about (i.e. why have the authors put this in the theorem's statement)?\nOn lines 235-237, the authors state that they have solved the problem of optimizing the complex validation loss as a function of (\u03bb1,\u03bb2). Which of their results back up this statement? It seems like Theorem 3.2 is about the number of validation samples required, and Theorem 3.3 has error growing with the square root of the number of samples.\nThe authors state that their \"assumption of smoothness [on y] is much weaker than sub-Gaussian noise assumptions in the literature.\" But this smoothness assumption is paired with assuming y is a bounded random variable; isn't this much weaker than sub-Gaussianity, as boundedness implies sub-Gaussianity? \nWhat exactly does it mean in Theorem 3.3 that l1,\u2026,lT are \"independent\"? Are we assuming the existence of some distribution D over losses, and lt are sampled i.i.d. from D? This should be stated more precisely.\nLimitations: I think the authors have addressed the limitations of their work, with the exception of a few of the points already discussed above.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The authors introduce a theoretical result that bounds the number of problems\nneeded to obtain a particular accuracy of \u03bb1 and \u03bb2 in\nhyper-parameter optimization for the elastic net for both offline and online\nlearning.\nStrengths And Weaknesses: \nThe paper seems to be theoretically sound and follows a logical progression.\nThe literature section on exact (homotopy) methods for the elastic net and\nlasso is lacking and only insofar as I can see included the LARS paper at the\nmoment.\nSection 2.1 and Lemma 2.1 seem to me to be related to the work in [1] and it is not quite clear what\nthe novelty and enhancements of the current work are.\nThe bound on the number of problems needed for a certain accuracy in\nestimating \u03bb1 and \u03bb2 would be a useful addition, although it\nis not clear that the bound is useful in practice.\nSection 4 does not seem to address a useful problem. Classification with the\nordinary (least-squares) elastic net is not a standard (or indeed useful) approach\nto classification as compared to elastic net-regularized logistic regression.\n\n[1]: J. Mairal and B. Yu, \u201cComplexity analysis of the lasso regularization path,\u201d\n    in Proceedings of the 29th International Conference on Machine Learning,\n    Edinburgh, United Kingdom, Jun. 2012, pp. 1835\u20131842. [Online]. Available:\n    https://icml.cc/2012/papers/202.pdf\nQuestions: \nThe authors in [1] state that the regularization path has at worst (3p+1)/2 segments. But you say, if I am understanding correctly, that it is\nexactly 3p (l. 587). Perhaps I am missing something, but why is your result\ndifferent? Should there be an O there?\nWhy is there only a proof sketch and not a full proof for theorem 3.1?\nIf I understand correctly, you arrive at your bound on the number of problems\nneeded by assuming the worst-case situation in terms of path complexity. What\nis the impact of this on the tightness of the bound (and practical\nusefulness)? I would assume that this would make the bound conservative (since\nin practice no paths for real data contain 3p segments).\nLimitations: \nConsider demonstrating with a simple example what your results imply in terms\nof the number of problems you need to solve for some real data set. Also show\nvia some simple experiment that standard approaches (such as 10-fold CV) can\nfail (as you claim they do) and that your method solves this problem.\nMove section 4 to the appendix since ordinary lasso classification is not a\nstandard or useful model.\nState clearly what your contributions are in relation to previous work such as\n[1, 2, 3, 4] and cite their work where appropriate. In particular there\nseems to be overlap with [1] that isn't accounted for in the work.\nConsider amending the literature section in the paper by including some or\nall of [1, 2, 3], and [4] regarding homotopy methods for the lasso.\nInclude at the very least [5] in your literature section on hyper-parameter\ntuning for the lasso.\nIt is not standard to call the Elastic Net (or elastic net) ElasticNet.\nConsider adding a space.\nl. 58. There should be a period at the end of the sentence.\nl. 77. w.h.p. is not a standard abbreviation. Consider spelling it out.\nl. 208. There should be a period at the end of the equation.\nl. 271. There should be a period after \u03f5.\nl. 386. There is an extra space after \"values\".\n\n[2] P. Garrigues and L. Ghaoui, \u201cAn homotopy algorithm for the lasso with online\n    observations,\u201d in Advances in neural information processing systems 21,\n    Vancouver, Canada, Dec. 2008, vol. 21, pp. 489\u2013496. [Online]. Available:\n    https://proceedings.neurips.cc/paper/2008/file/38af86134b65d0f10fe33d30dd76442e-Paper.pdf\n[3] D. M. Malioutov, M. Cetin, and A. S. Willsky, \u201cHomotopy continuation for\n    sparse signal representation,\u201d in Proceedings. (ICASSP \u201905). IEEE\n    International Conference on Acoustics, Speech, and Signal Processing, 2005,\n    Philadelphia, USA, Mar. 2005, vol. 5, pp. v733\u2013v736. doi:\n    10.1109/ICASSP.2005.1416408.\n[4] M. Osborne, B. Presnell, and B. Turlach, \u201cA new approach to variable\n    selection in least squares problems,\u201d IMA Journal of Numerical Analysis,\n    vol. 20, no. 3, pp. 389\u2013403, Jul. 2000, doi: 10.1093/imanum/20.3.389.\n[5] Q. Bertrand, Q. Klopfenstein, M. Blondel, S. Vaiter, A. Gramfort, and J.\n    Salmon, \u201cImplicit differentiation of Lasso-type models for hyperparameter\n    optimization,\u201d in Proceedings of the 37th International Conference on\n    Machine Learning, Nov. 2020, pp. 810\u2013821. Accessed: Jun. 27, 2022. [Online].\n    Available: https://proceedings.mlr.press/v119/bertrand20a.html\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This submission derives new generalization bounds for tuning the regularization parameters for ridge-regression, LASSO, and the elastic net methods. \nIn particular, the authors study two settings: (i) tuning based on multiple draws of train/test splits from a fixed (but arbitrary) problem distribution and (ii) online learning, where new train/test splits are provided as problem instances at each time step.\nIn the former setting, the authors show O~(p3/\u03f52) problem samples are required to come within \u03f5 of the best (expected) loss.\nIn the latter setting, the authors impose a smoothness assumptions on the adversary in order to provide a continuous version of the multiplicative weights algorithm with sub-linear regret. \nBoth results rely on a novel characterization of the tuning objective as a piecewise rational function with boundaries given by polynomial curves.\nThe submission concludes with extensions to linear classification problems with a fixed decision threshold and squared loss.",
                "Strengths And Weaknesses": "This is a highly novel paper which tackles an excellent problem: how to properly tune regularization parameters for common algorithms. \nThe standard approach to tuning ridge regression, LASSO, or the elastic net methods is grid-search. \nHowever, as the authors note in the classification setting, some model choices, like thresholding, can induce discontinuities in the tuning objective and make grid-search unreliable.\nThus, developing better alternatives to grid-search is a important topic. \nThe theoretical bounds are novel and cover a range of important settings.\nI was particularly interested to see the online-learning results.\nThe only two potential issues I see with this work are implementability and the focus on problem-sample complexity, rather than example-sample complexity.\nThe apparent non-implementability of the actual methods for tuning the regularization parameters is somewhat disappointing, but not too surprising given the nature of the results.\nAnd, while the authors state that problem-sample complexity is more common, I think the problem sampling (which covers cross-validation) to be far more interesting. \nWriting\nThe paper is very well written. \nI found only a few typos (see Minor Issues below).\nI particularly appreciate that the authors take care to give intuition for each theoretical result as well as discuss their implications. \nCongratulations on a very well-written paper.\nTheory\nSoundness: This paper is outside of my core research area, so I'm not an expert on the theory. However, I briefly looked through the appendices and saw no major issues. \nImplementability: My understanding from the discussion is that the methods for tuning \u03bb are not implementable (see Questions). \nThus, while the paper presents \"efficient algorithms\" (Line 402), efficiency is only in the sense of sample complexity, rather than computational complexity.\nI don't think this is an important issue, but I suggest the authors either comment on the complexity of tuning \u03bb in practice, or clarify that they mean efficiency only in terms of samples. \nExperiments\nN/A\nMinor Comments and Typos:\n\nLine 263: \"rational functions of bounded degrees .\" -- remove extra space before the period.\nLine 286: \"\u03f5-approximation of the loss corresponding parameter selection with arbitrarily...\"  --- I don't understand this sentence; perhaps a word is missing?\nLine 369: \"only polynomially many problem samples to generalize well...\" -> \"only polynomially many problem samples are required to generalize well\"",
                "Questions": "Theorem 3.2/Theorem A.1: Is this result constructive or does it only give the existence of an algorithm?\n  For instance, I agree with the claim that \"our results answer the question \u2018how much 288 cross-validation is enough\u2019 to effectively implement the above techniques\", but this is separate from carrying out the optimization procedure in practice. \n\nAlgorithm 1: The optimization domain C appears to be an uncountable set, in which case the density function wi defines an improper distribution (at least initially) and maybe highly discontinuous during execution of the algorithm. \n  As a result, Algorithm 1 appears to be unimplementable --- is this correct?\n\nAre there any lower bounds for the sample complexity of learning \u03bb in the distributional setting (regression of classification)? If so, it would be excellent to compare Theorem 3.2 to these rates. If not, it might be nice to comment on the challenges in developing these bounds.",
                "Limitations": "The limitations are properly addressed.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "4 excellent",
                "Rating": "8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper studies the validation loss of the elastic net as a function of its two hyperparameters, \u03bb1,\u03bb2. The authors allow \"validation loss\" to be fairly general: it is a function that maps a dataset and a setting of (\u03bb1,\u03bb2) to the validation loss of the elastic net. They characterize this function as a piecewise rational polynomial as a function of (\u03bb1,\u03bb2). They use this characterization to show that, given a set of validation losses and a distribution over this set (e.g. in leave-one-out cross-validation, the validation losses are the leave-one-out losses with the uniform distribution), a possibly small number of draws from this distribution are needed to minimize the average validation loss within \u03f5 accuracy. The authors go on to show that validation losses can be minimized in an online setting, where we view each validation loss one-by-one. Finally, the authors prove similar results for binary classification, where classification is done by thresholding the predictions of the elastic net.",
                "Strengths And Weaknesses": "Strengths\nI think the technical contributions of this paper are pretty strong and original. As far as I know, no one has given this exact a characterization of the loss landscape of things similar to cross-validation for the elastic net. I can see some interesting future work building off of this paper -- e.g. what do the individual pieces of the loss look like? The author's observation about how much subsampling of leave-one-out CV is needed to get an accurate approximation is interesting as well. I actually think this is one of the most immediately practical pieces of advice from this paper, and might warrant a little more highlighting (e.g. as a corollary). I can't really comment on the strengths of their results about online learning, as I'm not as familiar with that literature (in particular, T expected regret for T problems sounds like a lot, but maybe this is near the best you can do?).\nWeaknesses\nI think there are two main directions for improvement of the paper. First, I think the authors have slightly oversold the weakness of their assumptions, and should tone down those claims a little bit. Second, the writing was pretty dense and could use some more discussion and careful definitions.\nOn the assumptions required for the authors' results:\n\nThe abstract states that the results do not require \"strong assumptions on the data distribution\". Assumption 1 (that the covariates and responses are all bounded) is definitely not a weak assumption. I think it wouldn't be unfair to say this is a \"strong\" assumption, as this disallows, say, a well-specified model in which responses are linear functions of the covariates with Gaussian noise.\nThe results are stated as being completely independent of data distribution (e.g. in \"Theorem 1.1 (Informal)\"). However, a number of the lemmas used (Lemmas B.2, B.3, and C.1) require the columns of the data matrix X to be in general position. First, this condition should be stated in the results using these lemmas (e.g. in the statement of Lemma 2.1). Second, it should be clarified in exposition that the paper's results only apply to sets of problems / distributions over problems with covariate matrices with columns in general position.\n\nOn the writing being dense: The paper is pretty technical and uses a number of concepts from algebraic geometry and learning theory. These concepts are sometimes unexplained (e.g. just a definition is given) or lack a definition altogether. I think the results in this paper could be of interest beyond the learning theory community or algebraic statistics community, and so these concepts should be better explained (I think this is especially true of the concepts from algebraic geometry, which I suspect very few NeurIPS readers / attendees have experience with). Here are the things that stood out to me:\n\nPiecewise structured functions could use a simple English description.\nPseudo-dimension should be defined and briefly explained. The abbreviation PDIM should also be explicitly defined.\nSemi-algebraic sets and algebraic curves should be defined.\nA precise statement of Bezout's theorem should be given in the form that is applied here (or, at least, a reference).\nI thought the definition and explanation of \u03b2-dispersion was really clear and helpful.\n\nMiscellaneous things\n\nI think Lemma C.2 needs some conditions to ensure ATA+\u03bbI is invertible (what if A is low rank? what if \u03bb=\u22125345?)\nLine 215: \"based on the observation above\" there are many observations preceding this statement; it's not immediately clear which one this refers to.\nWhat are the asterisks in the proof of Lemma 2.1 (around line 218)? Are these just typos? An asterisk appears on \u03bb1 around line 223 as well, and then disappears in the next equation.\n\"Using simple algebra, the denominator...\" Definitely E depends on \u03bb1 and \u03bb2, and it's not immediately clear to me why that dependence gets canceled out in this expression. I think a proof should be given here.\nAlgorithm 1 is actually never discussed in the paper. I'm guessing it's the algorithm from Theorem 3.3, but this should really be made clear (and discussed).",
                "Questions": "Can the authors provide a proof for the statement \"using simple algebra, the denominator...\"?\n\nI also have a few questions relating to the meaning of the author's results.\n\nIs the algorithm in Theorem 3.3 just Algorithm 1? It's probably worth stating this if so. As-is, Algorithm 1 isn't really discussed in the paper.\nOne of the claims of Theorem 3.3 is about the \u03b2-dispersion of a series of functions. Why is this something readers should care about (i.e. why have the authors put this in the theorem's statement)?\nOn lines 235-237, the authors state that they have solved the problem of optimizing the complex validation loss as a function of (\u03bb1,\u03bb2). Which of their results back up this statement? It seems like Theorem 3.2 is about the number of validation samples required, and Theorem 3.3 has error growing with the square root of the number of samples.\nThe authors state that their \"assumption of smoothness [on y] is much weaker than sub-Gaussian noise assumptions in the literature.\" But this smoothness assumption is paired with assuming y is a bounded random variable; isn't this much weaker than sub-Gaussianity, as boundedness implies sub-Gaussianity? \nWhat exactly does it mean in Theorem 3.3 that l1,\u2026,lT are \"independent\"? Are we assuming the existence of some distribution D over losses, and lt are sampled i.i.d. from D? This should be stated more precisely.",
                "Limitations": "I think the authors have addressed the limitations of their work, with the exception of a few of the points already discussed above.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors introduce a theoretical result that bounds the number of problems\nneeded to obtain a particular accuracy of \u03bb1 and \u03bb2 in\nhyper-parameter optimization for the elastic net for both offline and online\nlearning.",
                "Strengths And Weaknesses": "The paper seems to be theoretically sound and follows a logical progression.\nThe literature section on exact (homotopy) methods for the elastic net and\nlasso is lacking and only insofar as I can see included the LARS paper at the\nmoment.\nSection 2.1 and Lemma 2.1 seem to me to be related to the work in [1] and it is not quite clear what\nthe novelty and enhancements of the current work are.\nThe bound on the number of problems needed for a certain accuracy in\nestimating \u03bb1 and \u03bb2 would be a useful addition, although it\nis not clear that the bound is useful in practice.\nSection 4 does not seem to address a useful problem. Classification with the\nordinary (least-squares) elastic net is not a standard (or indeed useful) approach\nto classification as compared to elastic net-regularized logistic regression.\n\n[1]: J. Mairal and B. Yu, \u201cComplexity analysis of the lasso regularization path,\u201d\n    in Proceedings of the 29th International Conference on Machine Learning,\n    Edinburgh, United Kingdom, Jun. 2012, pp. 1835\u20131842. [Online]. Available:\n    https://icml.cc/2012/papers/202.pdf",
                "Questions": "The authors in [1] state that the regularization path has at worst (3p+1)/2 segments. But you say, if I am understanding correctly, that it is\nexactly 3p (l. 587). Perhaps I am missing something, but why is your result\ndifferent? Should there be an O there?\nWhy is there only a proof sketch and not a full proof for theorem 3.1?\nIf I understand correctly, you arrive at your bound on the number of problems\nneeded by assuming the worst-case situation in terms of path complexity. What\nis the impact of this on the tightness of the bound (and practical\nusefulness)? I would assume that this would make the bound conservative (since\nin practice no paths for real data contain 3p segments).",
                "Limitations": "Consider demonstrating with a simple example what your results imply in terms\nof the number of problems you need to solve for some real data set. Also show\nvia some simple experiment that standard approaches (such as 10-fold CV) can\nfail (as you claim they do) and that your method solves this problem.\nMove section 4 to the appendix since ordinary lasso classification is not a\nstandard or useful model.\nState clearly what your contributions are in relation to previous work such as\n[1, 2, 3, 4] and cite their work where appropriate. In particular there\nseems to be overlap with [1] that isn't accounted for in the work.\nConsider amending the literature section in the paper by including some or\nall of [1, 2, 3], and [4] regarding homotopy methods for the lasso.\nInclude at the very least [5] in your literature section on hyper-parameter\ntuning for the lasso.\nIt is not standard to call the Elastic Net (or elastic net) ElasticNet.\nConsider adding a space.\nl. 58. There should be a period at the end of the sentence.\nl. 77. w.h.p. is not a standard abbreviation. Consider spelling it out.\nl. 208. There should be a period at the end of the equation.\nl. 271. There should be a period after \u03f5.\nl. 386. There is an extra space after \"values\".\n\n[2] P. Garrigues and L. Ghaoui, \u201cAn homotopy algorithm for the lasso with online\n    observations,\u201d in Advances in neural information processing systems 21,\n    Vancouver, Canada, Dec. 2008, vol. 21, pp. 489\u2013496. [Online]. Available:\n    https://proceedings.neurips.cc/paper/2008/file/38af86134b65d0f10fe33d30dd76442e-Paper.pdf\n[3] D. M. Malioutov, M. Cetin, and A. S. Willsky, \u201cHomotopy continuation for\n    sparse signal representation,\u201d in Proceedings. (ICASSP \u201905). IEEE\n    International Conference on Acoustics, Speech, and Signal Processing, 2005,\n    Philadelphia, USA, Mar. 2005, vol. 5, pp. v733\u2013v736. doi:\n    10.1109/ICASSP.2005.1416408.\n[4] M. Osborne, B. Presnell, and B. Turlach, \u201cA new approach to variable\n    selection in least squares problems,\u201d IMA Journal of Numerical Analysis,\n    vol. 20, no. 3, pp. 389\u2013403, Jul. 2000, doi: 10.1093/imanum/20.3.389.\n[5] Q. Bertrand, Q. Klopfenstein, M. Blondel, S. Vaiter, A. Gramfort, and J.\n    Salmon, \u201cImplicit differentiation of Lasso-type models for hyperparameter\n    optimization,\u201d in Proceedings of the 37th International Conference on\n    Machine Learning, Nov. 2020, pp. 810\u2013821. Accessed: Jun. 27, 2022. [Online].\n    Available: https://proceedings.mlr.press/v119/bertrand20a.html",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.667,
        "confidence_avg": 3.0,
        "soundness_avg": 3.333,
        "presentation_avg": 3.333,
        "contribution_avg": 3.333,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is clear that this paper makes significant contributions to the field of hyper-parameter optimization for the elastic net. The authors provide novel theoretical results and bounds on the number of problems needed to obtain a certain accuracy in estimating the hyper-parameters. The paper is well-written and the results are technically sound.\n\nReviewer 1 highlights the novelty of the paper and praises the authors for tackling an important problem. They also appreciate the well-written nature of the paper and the authors' efforts to provide intuition for the theoretical results. The only potential issues raised by Reviewer 1 are the implementability of the methods and the focus on problem-sample complexity instead of example-sample complexity.\n\nReviewer 2 also recognizes the technical contributions of the paper and finds the results to be strong and original. They suggest toning down the claims about the weakness of the assumptions and providing clearer definitions and explanations for certain concepts. Reviewer 2 also has some questions regarding specific statements and results in the paper.\n\nReviewer 3 acknowledges the theoretical soundness of the paper and the logical progression of the arguments. They suggest addressing some limitations, such as demonstrating the practical implications of the results with simple examples and experiments. Reviewer 3 also recommends moving Section 4 to the appendix and providing clearer explanations and definitions for certain concepts.\n\nOverall, the reviewers have identified some minor issues and have raised questions that can be addressed in a revision. However, the consensus among the reviewers is that the paper is technically solid and makes significant contributions to the field. Therefore, I recommend accepting the paper."
    },
    "LAMP:_Extracting_Text_from_Gradients_with_Language_Model_Priors": {
        "link": "https://openreview.net//forum?id=6iqd9JAVR1z",
        "pub_url": "https://openreview.net/forum?id=6iqd9JAVR1z",
        "pdf_link": "https://openreview.net//pdf?id=6iqd9JAVR1z",
        "paper_id": "6iqd9JAVR1z",
        "title": "LAMP:_Extracting_Text_from_Gradients_with_Language_Model_Priors",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nThis paper describes a novel method to recover the input text based on the computed gradient. This is important in the context of federated learning, which promises to enable learning through gradient sharing while keeping the input text secret. The findings of the paper demonstrate that gradients are sufficient to recover significant parts of the input text questioning the federated learning premise at least in the context of large language models.\nThe approach in novel and technically sound. Empirical results are convincing. The paper is well-written and clear.\nGiven current trends to growing model size, it will be great if the paper can further scale the experimental results to larger models.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper focuses on the attack that tries to recover text data from the gradients, this type of attack is a threat particularly for federated learning where the central server may recover the private client data through gradients. Based on previous work that optimises the input to minimise the distance between gradients, this paper further proposes to alternate continuous optimization and discrete optimization that is guided through a language model prior. The discrete optimization is claimed to help obtain text data that is more like fluent language. The resulting approach, LAMP, greatly outperforms previous approaches on three binary-classification benchmarks.\nStrengths And Weaknesses: Strengths:\n\nThe proposed approach is novel and technically sound. The motivation and contribution are clear \u2013 from the examples in Table 2 and quantitative improvements, it does seem like previous approaches fail to yield grammatical text while the proposed discrete optimization step seems to help it a lot.\nThe empirical results are strong especially with batch size > 1. The ablation study is appreciated as well.\nThe paper is well-written.\n\nWeaknesses:\n\n(minor) The proposed approach adds several additional hyperparameters to tune, for  example, \u03b1lm,\u03b1reg,nc,nd,ninit. This surely adds complexity of the approach and may make the proposed attack difficult to be practically applied. While I appreciate the detailed hyperparameter paragraph in Line 268-274, I think it would be better to report the hyperparameter selection range as well, so that the readers could have an idea how much effort is imposed to tune these hyperparameters.\n\n(major) I am a bit worried that the model comparison is only conducted on a randomly selected set of 100 sentences. 100 sentences sounds too few for me, and I am not sure how robust the model rank is based on only 100 random examples. I feel this point should be justified properly, either through constructing a larger test set, or using different random seeds to generate different sets of 100 test examples and testing on each of them.\n\n(minor) While Line 239 mentions to illustrate the generality of the proposed approach with respect to model size, I don\u2019t think this paper really made that goal by only using tiny and base sizes of BERT \u2013 at least BERT-large should be included to have a relatively complete coverage. I understand that the authors may be limited by resources to use larger models, which is fine. I just wanted to point out the current experiments are not sufficient to indicate generality with respect to model sizes (this is rather a minor point anyway).  \n\n(major) Line 257-259 mentions the baselines use 2500 iterations while the proposed approach uses 2000. Is it in Algorithm 1 2000 (and what are the values of n_c and n_d)? How did you choose these numbers? Do the baselines fully converge? I would like to see more justifications to show that the comparison is fair, because LAMP employs a nested for loop (while the baselines do not?) in optimization and I feel the number of total optimization steps (and the cost/time) in LAMP is actually larger than the baselines, right?\n\n(minor) Line 272 mentions that LAMP additionally adopts a two-step initialization procedure that seems important to me. I would like to see the ablation results on this two-step init in Table 3 to know how much of the improvement over baselines is from this initialization.\n\n\nAfter author response:  \nThe author response addressed most of my concerns, and I would like to increase my score to 7 given that the authors will update the paper accordingly as promised.\nQuestions: I listed all my questions or suggestions in the weaknesses above, I would like to improve my rating if the authors could address them in the rebuttal, particularly the major points.\nLimitations: Yes\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The authors propose a model for recovering user data from gradient updates in a federated learning system for text classification. They achieve this by alternating continuous gradient based optimization with discrete heuristic based token-reshuffling. The authors show that the proposed model outperforms methods that use only gradient based updates to the tokens.\nStrengths And Weaknesses: The primary contribution of the paper is the alternation between gradient-based updates and token reshuffling for reconstructing user text. I am unaware if such an approach has been attempted for adversarial attacks in text. Hence, this can be assumed to be novel.\nThe paper is well-written and easy to follow. The ablation studies confirm the importance of token-reshuffling for learning a good attack. The ablation studies also show the importance of L1+L2 loss (although this was proposed in a different paper).\nFrom a novelty perspective, this alternation between token reshuffling and continuous updates for attacking text classifier appears to be novel. However, I am not an expert in this field.\nSome parts of the paper are unclear. For instance, the authors mention that they use Adam for learning the embeddings for each input during the continuous optimization phase. However, they do not mention how they compute the gradient of the loss with respect to the input embeddings x*. The gradient computation requires second order derivatives which hasn\u2019t been discussed in the paper at all.\nIt is unclear how token-reshuffling with continuous gradient-based updates influences the descent direction. Specifically, I am wondering if token-reshuffling is only performed at the end of all gradient-based updates, how will the performance be affected.\nQuestions: How important is to alternate token-reshuffling updates with continuous optimization? What if the token-reshuffling appears only at the end of the continuous updates?\nLimitations: The limitations haven\u2019t been discussed.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper proposes a novel strategy to attack pretrained models for text models which aims to reconstruct the private user data used to finetune the model through federated learning. The algorithm takes the finetune gradient as well as the target label as the input, then search for the private user input sentence. The general idea is a iterative two-step process, where the first step is a continuous optimization to search for a embedding that leads to similar gradient, and the second step is a discrete optimization that uses GPT models to find a output sentence with the lowest perplexity.\n\nThanks for the authors' response! I think it might be worth it to clarify the main novelty of the paper in the main method section. It would also be nice to clearly discuss the limitation at the end of the paper, as researchers not familiar with this line of research might benefit from some background information about the social impact/limitation of the method.\nStrengths And Weaknesses: strengths:\n\nthe method is very interesting and novel. It also addresses an interesting problem in the pretrain-finetune paradigm that is very popular now.\nthe writing is mostly well structured and easy to understand. \nthe final performance also seems good compared to previous methods. The ablation study and examples are pretty nice addition to the results.\n\nweakness:\n\nthe paper didn't really clarify the main difference between the proposed method and the prior work, such as TAG. Therefore, it is hard to tell what are the exact novelty the paper adds and the effect of the novelty. My understanding is that the random transformation and the use of GPT models allow the output more natural. However, it is really hard to tell from the current structure of the paper.\nthe method can only be applied to classification where label is known, which seems pretty limited. It might be more natural to have unlabeled data for federated learning setting, as one might not be able to annotate the user text.\nQuestions: \nCould you clarify the major difference between your method and prior work?\nHow can this method be extended to the more realistic setting where one does not have labels for the data?\nLimitations: The authors did not address limitations and potential negative impact. There are several points worth mentioning:\n\nWorks on adversarial attack could be exploited by hackers.\nThe method is only limited to classification data.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper focuses on the attack that tries to recover text data from the gradients, this type of attack is a threat particularly for federated learning where the central server may recover the private client data through gradients. Based on previous work that optimises the input to minimise the distance between gradients, this paper further proposes to alternate continuous optimization and discrete optimization that is guided through a language model prior. The discrete optimization is claimed to help obtain text data that is more like fluent language. The resulting approach, LAMP, greatly outperforms previous approaches on three binary-classification benchmarks.",
                "Strengths And Weaknesses": "Strengths:\n\nThe proposed approach is novel and technically sound. The motivation and contribution are clear \u2013 from the examples in Table 2 and quantitative improvements, it does seem like previous approaches fail to yield grammatical text while the proposed discrete optimization step seems to help it a lot.\nThe empirical results are strong especially with batch size > 1. The ablation study is appreciated as well.\nThe paper is well-written.\n\nWeaknesses:\n\n(minor) The proposed approach adds several additional hyperparameters to tune, for  example, \u03b1lm,\u03b1reg,nc,nd,ninit. This surely adds complexity of the approach and may make the proposed attack difficult to be practically applied. While I appreciate the detailed hyperparameter paragraph in Line 268-274, I think it would be better to report the hyperparameter selection range as well, so that the readers could have an idea how much effort is imposed to tune these hyperparameters.\n\n(major) I am a bit worried that the model comparison is only conducted on a randomly selected set of 100 sentences. 100 sentences sounds too few for me, and I am not sure how robust the model rank is based on only 100 random examples. I feel this point should be justified properly, either through constructing a larger test set, or using different random seeds to generate different sets of 100 test examples and testing on each of them.\n\n(minor) While Line 239 mentions to illustrate the generality of the proposed approach with respect to model size, I don\u2019t think this paper really made that goal by only using tiny and base sizes of BERT \u2013 at least BERT-large should be included to have a relatively complete coverage. I understand that the authors may be limited by resources to use larger models, which is fine. I just wanted to point out the current experiments are not sufficient to indicate generality with respect to model sizes (this is rather a minor point anyway).  \n\n(major) Line 257-259 mentions the baselines use 2500 iterations while the proposed approach uses 2000. Is it in Algorithm 1 2000 (and what are the values of n_c and n_d)? How did you choose these numbers? Do the baselines fully converge? I would like to see more justifications to show that the comparison is fair, because LAMP employs a nested for loop (while the baselines do not?) in optimization and I feel the number of total optimization steps (and the cost/time) in LAMP is actually larger than the baselines, right?\n\n(minor) Line 272 mentions that LAMP additionally adopts a two-step initialization procedure that seems important to me. I would like to see the ablation results on this two-step init in Table 3 to know how much of the improvement over baselines is from this initialization.\n\n\nAfter author response:  \nThe author response addressed most of my concerns, and I would like to increase my score to 7 given that the authors will update the paper accordingly as promised.",
                "Questions": "I listed all my questions or suggestions in the weaknesses above, I would like to improve my rating if the authors could address them in the rebuttal, particularly the major points.",
                "Limitations": "Yes",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors propose a model for recovering user data from gradient updates in a federated learning system for text classification. They achieve this by alternating continuous gradient based optimization with discrete heuristic based token-reshuffling. The authors show that the proposed model outperforms methods that use only gradient based updates to the tokens.",
                "Strengths And Weaknesses": "The primary contribution of the paper is the alternation between gradient-based updates and token reshuffling for reconstructing user text. I am unaware if such an approach has been attempted for adversarial attacks in text. Hence, this can be assumed to be novel.\nThe paper is well-written and easy to follow. The ablation studies confirm the importance of token-reshuffling for learning a good attack. The ablation studies also show the importance of L1+L2 loss (although this was proposed in a different paper).\nFrom a novelty perspective, this alternation between token reshuffling and continuous updates for attacking text classifier appears to be novel. However, I am not an expert in this field.\nSome parts of the paper are unclear. For instance, the authors mention that they use Adam for learning the embeddings for each input during the continuous optimization phase. However, they do not mention how they compute the gradient of the loss with respect to the input embeddings x*. The gradient computation requires second order derivatives which hasn\u2019t been discussed in the paper at all.\nIt is unclear how token-reshuffling with continuous gradient-based updates influences the descent direction. Specifically, I am wondering if token-reshuffling is only performed at the end of all gradient-based updates, how will the performance be affected.",
                "Questions": "How important is to alternate token-reshuffling updates with continuous optimization? What if the token-reshuffling appears only at the end of the continuous updates?",
                "Limitations": "The limitations haven\u2019t been discussed.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposes a novel strategy to attack pretrained models for text models which aims to reconstruct the private user data used to finetune the model through federated learning. The algorithm takes the finetune gradient as well as the target label as the input, then search for the private user input sentence. The general idea is a iterative two-step process, where the first step is a continuous optimization to search for a embedding that leads to similar gradient, and the second step is a discrete optimization that uses GPT models to find a output sentence with the lowest perplexity.\n\nThanks for the authors' response! I think it might be worth it to clarify the main novelty of the paper in the main method section. It would also be nice to clearly discuss the limitation at the end of the paper, as researchers not familiar with this line of research might benefit from some background information about the social impact/limitation of the method.",
                "Strengths And Weaknesses": "strengths:\n\nthe method is very interesting and novel. It also addresses an interesting problem in the pretrain-finetune paradigm that is very popular now.\nthe writing is mostly well structured and easy to understand. \nthe final performance also seems good compared to previous methods. The ablation study and examples are pretty nice addition to the results.\n\nweakness:\n\nthe paper didn't really clarify the main difference between the proposed method and the prior work, such as TAG. Therefore, it is hard to tell what are the exact novelty the paper adds and the effect of the novelty. My understanding is that the random transformation and the use of GPT models allow the output more natural. However, it is really hard to tell from the current structure of the paper.\nthe method can only be applied to classification where label is known, which seems pretty limited. It might be more natural to have unlabeled data for federated learning setting, as one might not be able to annotate the user text.",
                "Questions": "Could you clarify the major difference between your method and prior work?\nHow can this method be extended to the more realistic setting where one does not have labels for the data?",
                "Limitations": "The authors did not address limitations and potential negative impact. There are several points worth mentioning:\n\nWorks on adversarial attack could be exploited by hackers.\nThe method is only limited to classification data.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.333,
        "confidence_avg": 3.0,
        "soundness_avg": 3.0,
        "presentation_avg": 3.333,
        "contribution_avg": 3.0,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that the proposed approach in this paper is novel and technically sound. The empirical results show strong performance, especially with batch size > 1. While there are some minor concerns raised by the reviewers, such as the number of test examples and the inclusion of larger models, these do not outweigh the overall strengths of the paper. The authors have addressed most of the concerns raised by the reviewers in their response. Therefore, I recommend accepting this paper."
    },
    "ELIGN:_Expectation_Alignment_as_a_Multi-Agent_Intrinsic_Reward": {
        "link": "https://openreview.net//forum?id=uPyNR2yPoe",
        "pub_url": "https://openreview.net/forum?id=uPyNR2yPoe",
        "pdf_link": "https://openreview.net//pdf?id=uPyNR2yPoe",
        "paper_id": "uPyNR2yPoe",
        "title": "ELIGN:_Expectation_Alignment_as_a_Multi-Agent_Intrinsic_Reward",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nThis paper introduces a novel method for decentralised training in both cooperative and competitive environments. \nThe main insight is that agents should be predictable to their team mates but unpredictable to adversaries.\nCrucially, each agent relies on a local model to optimise this objective, making it compatible with decentralised training.\nThere were a few concerns from reviewers around both how the method applies to the decentralised training regime and regarding the naming. The authors managed to address the concerns appropriately, leading the actively engaged reviewers to increase their scores substantially. Reviewer TEM3 kept their rating at a borderline reject even though the concerns were addressed by the rebuttal. As such I recommend to discard this review. Reviewer whMR stated that they would increase their score but to the best of my knowledge didn't do so. Again, their review should be seen in this context.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper tackles the problem of coordination in multi agent reinforcement learning, particularly in the decentralized training / partial observability setup. The paper proposes to derive a self-supervised reward from alignment. Agents are encouraged to take actions that match other agents' expectations when they cooperate and they are encouraged to do the opposite with competing agents.\nFor each agent the reward is computed using a dynamics model. This model is trained by predicting the next observation given the current action and observation. This model is then used to derive a reward that estimates the neighbors expectations of the agent's next state. The reward is decentralized and does not require the centralized training / decentralized execution which is common in the multi agent reinforcement learning literature.\nThe proposed reward is evaluated across many problems using the multi agent particules environment and Google Research football. The authors compare their algorithm with several existing baselines and the alignment based reward is shown to perform better than existing techniques for cooperative and competitive problems.\nStrengths And Weaknesses: I found this paper to well be written and easy to follow. The authors made an effort to provide many helpful illustrative examples of the behaviour of the proposed technique. The method is simple and appears easy to implement.\nThe empirical evaluation of the paper is solid, it includes cooperative and competitive problems, with decentralized and centralized training and the proposed method is compared with several existing baselines. I found section 5.7 to be useful to understand how alignment reward helps and what are the limitations, particularly that the overall performance of the system decreases when the accuracy of the dynamics model decreases or that the method is less is competitive with heterogenous agents are used.\nQuestions: L282 \"When the number of agents increases, alignment scales well in all multi-agent particle tasks except for heterogenous navigation.\"\nDo you expect this statement to remain true when the number of agents increases to hundreds or even thousands? In that case I would imagine that the summation L159 would make the alignment reward pretty noisy and coordination between agents would be more difficult.\nLimitations: The authors have adequately addressed the limitations and potential negative societal impact of their work.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The authors proposed an intrinsic reward that learns each agent to align with the predictions of neighbors in a fully decentralized way for improving multi-agent coordination. They compared the proposed method with the intrinsic reward-based baselines, e.g. curiosity-based approach in several environments including Google Research football, and provides some investigations to show the performance improvement of the proposed method.\nStrengths And Weaknesses: Strengths \n\n   This paper is well written and easy to follow. \n   This paper deals with enhancing predictability of other agents in a fully decentralized way, which is a significant problem in MARL.\n   This paper provides some experiments to show why the proposed method works.\n\nWeaknesses\n\n   The novelty of this paper is not enough for accepting the venue of NeurIPS.\n   There are some concerns of the proposed method (Please see \u201cQuestions\u201d)\n   The lack of experiments on the popular benchmarks such as SMAC and the sparse environments.\nQuestions: \nThe proposed intrinsic reward is based on how much the neighbors predict the agent well. For the fully decentralized training, the authors replace the neighbors\u2019 dynamic models with their own dynamic models. Eventually, the proposed intrinsic reward is the opposite of the novelty-based intrinsic reward approach, and thus the multiple agents will be trained to visit the familiar states that each agent can predict well. Although the approximation of the neighbors\u2019 dynamic models with a proxy is empirically good, it is not exactly the same as the neighbors\u2019 models. Each neighbor may predict the agent differently. Can we say that the proposed method enhances the alignment? the performance improvement can come from other reasons.\n\nSince the proposed intrinsic reward is the opposite of the novelty-based intrinsic reward, can the proposed intrinsic reward degrade the exploration?  \n\nIn general, the curiosity-based approaches are not good at the dense-reward environment. For a fair comparison, the authors should provide experiments on both dense/sparse environments. \n\nFurthermore, it would be great if the authors provide the performances as the learning processes.\n\nThe authors should provide the experiments on the SMAC environment. Also, the intrinsic reward-based baselines such as [1] are missing. The authors should compare the proposed method with [1]. \n\nIn Section 4.2, the authors restricted the future prediction from j\u2019s point of view by using the portion of j\u2019s observation i can see. The reviewer thinks that for the fully decentralized training, A should be unaware of how much B can observe. Is it okay that Agent i knows o_{i \\and j} in the fully decentralized training?\n\n\n[1] Zheng, Lulu, et al. \"Episodic multi-agent reinforcement learning with curiosity-driven exploration.\" Advances in Neural Information Processing Systems 34 (2021): 3757-3769.\nLimitations: As mentioned in the \u201cQuestions\u201d, the author should provide the experiments on the SMAC environment and compare the proposed method with the state-of-the-art baseline of the intrinsic reward-based MARL algorithm [1].\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: \nThis paper proposes to tackle the problem of multi-agent learning under decentralised training and partial observability through using a novel self-supervised intrinsic reward that encourages agents to behave predictably to their neighbouring teammates and unpredictably to their adversaries.\nA dynamics model (trained on the agent\u2019s own observations as a proxy given training is decentralised), is used to predict future states from other agents\u2019 viewpoints under partial observability. The negative error in this prediction is then used as an intrinsic reward to supplement training in environments with sparse extrinsic rewards.\nThe effectiveness of this approach is compared to curiosity driven intrinsic rewards on 6 cooperative and competitive multi-agent tasks. Further experiments are conducted in regimes of full observability, centralised training, and zero shot coordination.\nStrengths And Weaknesses: \n\nOriginality:\nThe authors frame their work well in the context of the literature on intrinsic motivation in reinforcement learning, and motivate their approach from the natural world. I appreciate that they explicitly state the differences of their approach to closely related work, e.g. Ndousse et al 2021.\nSome references need to be corrected:\nLine 45: \u201cOnly a few attempts explore other forms of multi-agent intrinsic rewards\u201d.   A more specific, referenced statement would be better here.\nLine 33: To my knowledge, there is no reference to decentralised training and partial observability in Lowe 2017. MADDPG is a centralised training, decentralised execution algorithm. The authors should reference more appropriate work for that statement on task-specific reward shaping to motivate their work.\n\n\n\n\nQuality:\nTwo standard coordination and competition benchmark environments are used to evaluate their framework. The same architectures and optimisation algorithms are chosen to provide a fair comparison against other intrinsic rewards. I particularly liked the symmetry breaking experiments to demonstrate learned coordination.\nTable 1 shows promising results in small scale decentralised, partially observable settings. However results are not consistently significantly better than the baselines across tasks and settings. There are claims of superior performance in some tasks in the text but the the baselines have similar performance to the proposed method within standard error. For example, Figure 3 is selective to show results against SPARSE while CURIO performs similarly to ALIGN within error. Table 1 3v1 w/ keeper and Table 2 keep-away - CURIO baseline has similar performance within error. Symmetry-breaking performance is also not significant when scaled (appendix). In general the authors should be careful not to overstate claims unless there is statistical significance to back it up.\nTo improve the clarity of results I would suggest incorporating some learning dynamics curves. Only converged test rewards and task-specific converged metrics are currently given. Does coordination help with sample efficiency of training?\nComparison to Ndousse et al 2021 would also be useful to see whether this reward framing has a benefit over their proposed approach.\nOn line 161 there is a claim that the proxy dynamics model is validated in heterogeneous tasks but in the experiments it is shown that this is not the case in the experiments.\n\n\nClarity:\nThe paper is well written in many parts. Paragraph headings and subsections are used effectively and the paper on the whole reads quite intuitively. Figure 1 is clear and informative to the reader.\nTo improve clarity:\nthe authors mention a gaussian noise experiment in the main text and refers to appendix but I cannot find this section in the results.\nFigure 1: I would suggest increasing the font width for readability (particularly the equation)\nThe tables and figures are quite far away from their relevant sections in the text which hinders readability.\nLine 293-294 : \u201canalyse this in future experiments\u201d - it is unclear if this means later in the paper or in future work.\n\n\nA careful proofread is also required. Some issues I spotted:\nLine 256: \u201ca\u201d not \u201can\u201d goal state\nTable 2 caption: misspelled \u201ctrained\u201d\nIqbal & Sha 2019a and 2019b seem to refer to the same paper.\nLine 160 misspelled \u201cempirically\u201d\nLine 178: misspelled \u201cteam\u201d\nState and action space paragraph starting on Line 194 has a number of grammatical errors.\n\n\n\n\nSignificance:\nThe paper addresses the problem of decentralised training which is less explored in the literature compared to centralised training but important for the scalability of MARL.\nThe alignment idea to use predictability of actions as an intrinsic reward is novel to my knowledge and well motivated. However, as the authors note in the related work section, there is a body of similar work that utilise model-based predictability in different ways e.g. as an auxiliary loss. It is not clear to me yet why using this inductive bias as a reward instead is significant, particularly without an experimental comparison.\nQuestions: \nDid you compare this intrinsic reward based approach to other (non intrinsic reward based) approaches to the sparse learning problem (e.g. Ndousse et al 2021)?\nSome discussion around why the framing as an auxiliary reward instead of an auxiliary loss would be helpful.\n\n\nUnder what conditions do we expect alignment/misalignment to work well? A discussion around why we see that ALIGN self, team and adv have varying quality on different tasks would be helpful. \nFor example, why does modelling from the other agent\u2019s point of view, instead of directly predicting your own future state (which incorporates the other agents action) more helpful? When and why is ALIGN_team better than ALIGN_self? It seems that the team set up is just a partially observed view of the self set up, because the agent\u2019s own dynamics model is used.\nIn the adversarial case, it seems that the agent will learn to be unpredictable to itself (as it uses its own dynamics model as a proxy) so it is unclear to me why this would help. Conversely, ALIGN_team and ALIGN_self seem to work better than ALIGN_adv on some competitive tasks indicating that it is sometimes better to be predictable to an adversary which seems counterintuitive.\nIn the first paragraph of Section 4 there is discussion about gaining information outside of the agent\u2019s receptive field through encountering surprising actions from other agents. How does the alignment reward help convey this information? Does this help at execution time?\n\n\nIn the centralised regime experiments, did you use the actual dynamics model learnt by each agent to calculate the intrinsic reward or did you still use the individual agents dynamics model as a proxy as in the decentralised case?\nDo you have any suggestions for how to improve performance using alignment for heterogenous agents?\nDid you evaluate zero shot coordination with CURIO models as well?\nLimitations: \nThe authors state limitations of their approach, namely:\nthe small action/state spaces of the environments considered.\ndifficulty generalising when there are heterogenous agents due to agents learning only one dynamics model (of themselves). They argue that this enables more scalability, but demonstrate that this leads to decreased performance.\nThe method is reliant on the ability to learn a good dynamics model which may be more difficult in noisy, real-world environments.\n\n\nI have addressed the other limitations in the strengths and weaknesses section.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: The authors propose an auxiliary training reward called ALIGNment. Agents are rewarded when either they (ALIGNself) or their teammates (ALIGNteam) can predict their actions, or when their adversaries (ALIGNadv) cannot predict their actions. The authors use experimental evidence to support the intuition that alignment helps agents coordinate which subtasks to complete and helps agents coordinate zero-shot with new partners. Compared with 3 prior approaches in 6 Google Research football environments and 5 multi-agent particle environments, at least one ALIGN variant achieves state-of-the-art results in every task except for the heterogeneous navigation task.\nStrengths And Weaknesses: Strengths\nOverall, I found the method easy to understand. Algorithm 1 makes the method clear.\nThe experimental evaluation is thorough, comparing against 3 prior approaches and 11 total tasks. At least one ALIGN variant performs best across all but one task.\nThe authors include additional experiments to help study why ALIGNment improves performance.\nAs this is an intuitive approach that is explained clearly and supported by thorough experimental evaluation, I recommend acceptance.\nWeaknesses\nThe word \u201calignment\u201d already has a meaning in artificial intelligence. Specifically, it is used to mean how well an artificial intelligence is aligned to human preferences. See, for example, \u201cThe Alignment Problem\u201d by Brian Christian. I would recommend the authors use a different word for their method, such as \u201cPredictability.\u201d This renaming would respect the existing use of the word \u201calignment\u201d as well as be more specific about what the auxiliary loss is rewarding.\nI didn\u2019t find Figure 1 very helpful for understanding the method. The idea behind alignment \u2013 a predictive loss \u2013 is very simple, yet Figure 1 is quite complex. I\u2019d recommend trying to redesign Figure 1 to make it as simple as possible.\nThe overall results are presented in two dense tables, Table 1 and Table 2. It would be helpful if the authors could present aggregated results in a single figure. If possible, I would recommend normalizing results using the performance of an expert policy and a random policy as is done in the D4RL benchmark [1], i.e., computing (performance - random) / (expert - random). This gives a common scale over which the authors can aggregate.\nOnly the maximum performance is bolded in the results tables. I recommend bolding all results within 5% or 10% of maximum performance, to account for noise, as is done in other work such as [2].\n[1] D4RL: Datasets for Deep Data-Driven Reinforcement Learning\n[2] Offline Reinforcement Learning with Implicit Q-Learning\nQuestions: Did you train the Sparse, Curio-self, and Curio-team methods yourself? Or did you take numbers from prior work? It seems like you trained them yourself, but it would be helpful to make this more clear.  (I think it\u2019s stronger if you can report numbers directly from prior work where applicable, because the authors of prior work have an incentive to tune their algorithms as well as possible.)\nIf you trained prior methods yourself: Did you spend equal effort tuning the prior approaches as you did tuning your own method, and can you quantify this in the paper (eg by having tested the same number of hyperparameter settings)?\nLimitations: The authors note that their method, ALIGN, performs worse than prior methods in Heterogenous navigation. They hypothesize that this is because the differing size and speed of agents in Heterogenous navigation makes it difficult for agents to predict each other. I appreciate that the authors analyze this limitation.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 5: \nSummary: This paper studies a new self-supervised MARL intrinsic reward, called Alignment, to facilitate learning in a decentralized training paradigm under partial observability. Inspired by the self-organization principle in Zoology, the intrinsic reward of Alignment aims to guide agents to match their teammates' expectations in order to emerge cooperative strategies. The experiments are carried out on the multi-agent particle and Google Research football, and the results show that Alignment outperforms sparse and curiosity-based intrinsic rewards.\nStrengths And Weaknesses: The reviewer will list the main strengths and weaknesses as follows:\nSTRENGTHS\n\nThis paper introduces an interesting intrinsic reward, called Alignment, in decentralized training under partial observability. This idea is inspired by Zoology and brings a new heuristic to emerge coordination during decentralized training.\n\nThis paper conducts several experiments on popular MARL benchmarks to show that the Alignment intrinsic reward is a more useful method than curiosity-driven exploration.\n\n\nWEAKNESSES\n\nThe major concern is that the method of Alignment (see Section 4) theoretically conflicts with the decentralized training paradigm. In decentralized training, agents cannot share their expectations. Thus, each agent theoretically cannot match their teammates' expectations because they do not know them. For example, the dynamics model of agent i in line 150 is trained on the oi and ai but the alignment intrinsic reward rin defined in line 155 apply the dynamics model of agent j on the oi and ai. Note that the dynamics model of agent j is trained on the set of oj,aj rather than oi,ai. rin defined in line 155 may induce huge penalty due to this distributional shift from oj,aj to oi,ai.\n\nWhen the agent aims to match their teammates' expectations, what if their teammates do not reach a consensus? For example, in the definition of rin on line 155, if agent i's neighbors have completely different expectations, which expectation does agent i match?\n\nSample efficiency is an important measure for MARL evaluation. Could you provide the learning curve during training to better visualize the sample efficiency in comparison? Tables may not be a natural way to demonstrate the advantage of exploration methods.\nQuestions: The following questions correspond to three points listed in the WEAKNESSES.\n\nHow do the agents share their expectations with teammates during decentralized training?\n\nWhen the teammates have entirely different expectations for agent i, how does agent i match their expectations?\n\nWhy use tables instead of learning curves to visualize learning performance?\nLimitations: The main concerns are listed in the WEAKNESSES. The authors should justify the soundness of the proposed method in Section 4.2.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 4 excellent\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper tackles the problem of coordination in multi agent reinforcement learning, particularly in the decentralized training / partial observability setup. The paper proposes to derive a self-supervised reward from alignment. Agents are encouraged to take actions that match other agents' expectations when they cooperate and they are encouraged to do the opposite with competing agents.\nFor each agent the reward is computed using a dynamics model. This model is trained by predicting the next observation given the current action and observation. This model is then used to derive a reward that estimates the neighbors expectations of the agent's next state. The reward is decentralized and does not require the centralized training / decentralized execution which is common in the multi agent reinforcement learning literature.\nThe proposed reward is evaluated across many problems using the multi agent particules environment and Google Research football. The authors compare their algorithm with several existing baselines and the alignment based reward is shown to perform better than existing techniques for cooperative and competitive problems.",
                "Strengths And Weaknesses": "I found this paper to well be written and easy to follow. The authors made an effort to provide many helpful illustrative examples of the behaviour of the proposed technique. The method is simple and appears easy to implement.\nThe empirical evaluation of the paper is solid, it includes cooperative and competitive problems, with decentralized and centralized training and the proposed method is compared with several existing baselines. I found section 5.7 to be useful to understand how alignment reward helps and what are the limitations, particularly that the overall performance of the system decreases when the accuracy of the dynamics model decreases or that the method is less is competitive with heterogenous agents are used.",
                "Questions": "L282 \"When the number of agents increases, alignment scales well in all multi-agent particle tasks except for heterogenous navigation.\"\nDo you expect this statement to remain true when the number of agents increases to hundreds or even thousands? In that case I would imagine that the summation L159 would make the alignment reward pretty noisy and coordination between agents would be more difficult.",
                "Limitations": "The authors have adequately addressed the limitations and potential negative societal impact of their work.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors proposed an intrinsic reward that learns each agent to align with the predictions of neighbors in a fully decentralized way for improving multi-agent coordination. They compared the proposed method with the intrinsic reward-based baselines, e.g. curiosity-based approach in several environments including Google Research football, and provides some investigations to show the performance improvement of the proposed method.",
                "Strengths And Weaknesses": "Strengths \n\n   This paper is well written and easy to follow. \n   This paper deals with enhancing predictability of other agents in a fully decentralized way, which is a significant problem in MARL.\n   This paper provides some experiments to show why the proposed method works.\n\nWeaknesses\n\n   The novelty of this paper is not enough for accepting the venue of NeurIPS.\n   There are some concerns of the proposed method (Please see \u201cQuestions\u201d)\n   The lack of experiments on the popular benchmarks such as SMAC and the sparse environments.",
                "Questions": "The proposed intrinsic reward is based on how much the neighbors predict the agent well. For the fully decentralized training, the authors replace the neighbors\u2019 dynamic models with their own dynamic models. Eventually, the proposed intrinsic reward is the opposite of the novelty-based intrinsic reward approach, and thus the multiple agents will be trained to visit the familiar states that each agent can predict well. Although the approximation of the neighbors\u2019 dynamic models with a proxy is empirically good, it is not exactly the same as the neighbors\u2019 models. Each neighbor may predict the agent differently. Can we say that the proposed method enhances the alignment? the performance improvement can come from other reasons.\n\nSince the proposed intrinsic reward is the opposite of the novelty-based intrinsic reward, can the proposed intrinsic reward degrade the exploration?  \n\nIn general, the curiosity-based approaches are not good at the dense-reward environment. For a fair comparison, the authors should provide experiments on both dense/sparse environments. \n\nFurthermore, it would be great if the authors provide the performances as the learning processes.\n\nThe authors should provide the experiments on the SMAC environment. Also, the intrinsic reward-based baselines such as [1] are missing. The authors should compare the proposed method with [1]. \n\nIn Section 4.2, the authors restricted the future prediction from j\u2019s point of view by using the portion of j\u2019s observation i can see. The reviewer thinks that for the fully decentralized training, A should be unaware of how much B can observe. Is it okay that Agent i knows o_{i \\and j} in the fully decentralized training?\n\n\n[1] Zheng, Lulu, et al. \"Episodic multi-agent reinforcement learning with curiosity-driven exploration.\" Advances in Neural Information Processing Systems 34 (2021): 3757-3769.",
                "Limitations": "As mentioned in the \u201cQuestions\u201d, the author should provide the experiments on the SMAC environment and compare the proposed method with the state-of-the-art baseline of the intrinsic reward-based MARL algorithm [1].",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposes to tackle the problem of multi-agent learning under decentralised training and partial observability through using a novel self-supervised intrinsic reward that encourages agents to behave predictably to their neighbouring teammates and unpredictably to their adversaries.\nA dynamics model (trained on the agent\u2019s own observations as a proxy given training is decentralised), is used to predict future states from other agents\u2019 viewpoints under partial observability. The negative error in this prediction is then used as an intrinsic reward to supplement training in environments with sparse extrinsic rewards.\nThe effectiveness of this approach is compared to curiosity driven intrinsic rewards on 6 cooperative and competitive multi-agent tasks. Further experiments are conducted in regimes of full observability, centralised training, and zero shot coordination.",
                "Strengths And Weaknesses": "Originality:\nThe authors frame their work well in the context of the literature on intrinsic motivation in reinforcement learning, and motivate their approach from the natural world. I appreciate that they explicitly state the differences of their approach to closely related work, e.g. Ndousse et al 2021.\nSome references need to be corrected:\nLine 45: \u201cOnly a few attempts explore other forms of multi-agent intrinsic rewards\u201d.   A more specific, referenced statement would be better here.\nLine 33: To my knowledge, there is no reference to decentralised training and partial observability in Lowe 2017. MADDPG is a centralised training, decentralised execution algorithm. The authors should reference more appropriate work for that statement on task-specific reward shaping to motivate their work.\n\n\n\n\nQuality:\nTwo standard coordination and competition benchmark environments are used to evaluate their framework. The same architectures and optimisation algorithms are chosen to provide a fair comparison against other intrinsic rewards. I particularly liked the symmetry breaking experiments to demonstrate learned coordination.\nTable 1 shows promising results in small scale decentralised, partially observable settings. However results are not consistently significantly better than the baselines across tasks and settings. There are claims of superior performance in some tasks in the text but the the baselines have similar performance to the proposed method within standard error. For example, Figure 3 is selective to show results against SPARSE while CURIO performs similarly to ALIGN within error. Table 1 3v1 w/ keeper and Table 2 keep-away - CURIO baseline has similar performance within error. Symmetry-breaking performance is also not significant when scaled (appendix). In general the authors should be careful not to overstate claims unless there is statistical significance to back it up.\nTo improve the clarity of results I would suggest incorporating some learning dynamics curves. Only converged test rewards and task-specific converged metrics are currently given. Does coordination help with sample efficiency of training?\nComparison to Ndousse et al 2021 would also be useful to see whether this reward framing has a benefit over their proposed approach.\nOn line 161 there is a claim that the proxy dynamics model is validated in heterogeneous tasks but in the experiments it is shown that this is not the case in the experiments.\n\n\nClarity:\nThe paper is well written in many parts. Paragraph headings and subsections are used effectively and the paper on the whole reads quite intuitively. Figure 1 is clear and informative to the reader.\nTo improve clarity:\nthe authors mention a gaussian noise experiment in the main text and refers to appendix but I cannot find this section in the results.\nFigure 1: I would suggest increasing the font width for readability (particularly the equation)\nThe tables and figures are quite far away from their relevant sections in the text which hinders readability.\nLine 293-294 : \u201canalyse this in future experiments\u201d - it is unclear if this means later in the paper or in future work.\n\n\nA careful proofread is also required. Some issues I spotted:\nLine 256: \u201ca\u201d not \u201can\u201d goal state\nTable 2 caption: misspelled \u201ctrained\u201d\nIqbal & Sha 2019a and 2019b seem to refer to the same paper.\nLine 160 misspelled \u201cempirically\u201d\nLine 178: misspelled \u201cteam\u201d\nState and action space paragraph starting on Line 194 has a number of grammatical errors.\n\n\n\n\nSignificance:\nThe paper addresses the problem of decentralised training which is less explored in the literature compared to centralised training but important for the scalability of MARL.\nThe alignment idea to use predictability of actions as an intrinsic reward is novel to my knowledge and well motivated. However, as the authors note in the related work section, there is a body of similar work that utilise model-based predictability in different ways e.g. as an auxiliary loss. It is not clear to me yet why using this inductive bias as a reward instead is significant, particularly without an experimental comparison.",
                "Questions": "Did you compare this intrinsic reward based approach to other (non intrinsic reward based) approaches to the sparse learning problem (e.g. Ndousse et al 2021)?\nSome discussion around why the framing as an auxiliary reward instead of an auxiliary loss would be helpful.\n\n\nUnder what conditions do we expect alignment/misalignment to work well? A discussion around why we see that ALIGN self, team and adv have varying quality on different tasks would be helpful. \nFor example, why does modelling from the other agent\u2019s point of view, instead of directly predicting your own future state (which incorporates the other agents action) more helpful? When and why is ALIGN_team better than ALIGN_self? It seems that the team set up is just a partially observed view of the self set up, because the agent\u2019s own dynamics model is used.\nIn the adversarial case, it seems that the agent will learn to be unpredictable to itself (as it uses its own dynamics model as a proxy) so it is unclear to me why this would help. Conversely, ALIGN_team and ALIGN_self seem to work better than ALIGN_adv on some competitive tasks indicating that it is sometimes better to be predictable to an adversary which seems counterintuitive.\nIn the first paragraph of Section 4 there is discussion about gaining information outside of the agent\u2019s receptive field through encountering surprising actions from other agents. How does the alignment reward help convey this information? Does this help at execution time?\n\n\nIn the centralised regime experiments, did you use the actual dynamics model learnt by each agent to calculate the intrinsic reward or did you still use the individual agents dynamics model as a proxy as in the decentralised case?\nDo you have any suggestions for how to improve performance using alignment for heterogenous agents?\nDid you evaluate zero shot coordination with CURIO models as well?",
                "Limitations": "The authors state limitations of their approach, namely:\nthe small action/state spaces of the environments considered.\ndifficulty generalising when there are heterogenous agents due to agents learning only one dynamics model (of themselves). They argue that this enables more scalability, but demonstrate that this leads to decreased performance.\nThe method is reliant on the ability to learn a good dynamics model which may be more difficult in noisy, real-world environments.\n\n\nI have addressed the other limitations in the strengths and weaknesses section.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors propose an auxiliary training reward called ALIGNment. Agents are rewarded when either they (ALIGNself) or their teammates (ALIGNteam) can predict their actions, or when their adversaries (ALIGNadv) cannot predict their actions. The authors use experimental evidence to support the intuition that alignment helps agents coordinate which subtasks to complete and helps agents coordinate zero-shot with new partners. Compared with 3 prior approaches in 6 Google Research football environments and 5 multi-agent particle environments, at least one ALIGN variant achieves state-of-the-art results in every task except for the heterogeneous navigation task.",
                "Strengths And Weaknesses": "Strengths\nOverall, I found the method easy to understand. Algorithm 1 makes the method clear.\nThe experimental evaluation is thorough, comparing against 3 prior approaches and 11 total tasks. At least one ALIGN variant performs best across all but one task.\nThe authors include additional experiments to help study why ALIGNment improves performance.\nAs this is an intuitive approach that is explained clearly and supported by thorough experimental evaluation, I recommend acceptance.\nWeaknesses\nThe word \u201calignment\u201d already has a meaning in artificial intelligence. Specifically, it is used to mean how well an artificial intelligence is aligned to human preferences. See, for example, \u201cThe Alignment Problem\u201d by Brian Christian. I would recommend the authors use a different word for their method, such as \u201cPredictability.\u201d This renaming would respect the existing use of the word \u201calignment\u201d as well as be more specific about what the auxiliary loss is rewarding.\nI didn\u2019t find Figure 1 very helpful for understanding the method. The idea behind alignment \u2013 a predictive loss \u2013 is very simple, yet Figure 1 is quite complex. I\u2019d recommend trying to redesign Figure 1 to make it as simple as possible.\nThe overall results are presented in two dense tables, Table 1 and Table 2. It would be helpful if the authors could present aggregated results in a single figure. If possible, I would recommend normalizing results using the performance of an expert policy and a random policy as is done in the D4RL benchmark [1], i.e., computing (performance - random) / (expert - random). This gives a common scale over which the authors can aggregate.\nOnly the maximum performance is bolded in the results tables. I recommend bolding all results within 5% or 10% of maximum performance, to account for noise, as is done in other work such as [2].\n[1] D4RL: Datasets for Deep Data-Driven Reinforcement Learning\n[2] Offline Reinforcement Learning with Implicit Q-Learning",
                "Questions": "Did you train the Sparse, Curio-self, and Curio-team methods yourself? Or did you take numbers from prior work? It seems like you trained them yourself, but it would be helpful to make this more clear.  (I think it\u2019s stronger if you can report numbers directly from prior work where applicable, because the authors of prior work have an incentive to tune their algorithms as well as possible.)\nIf you trained prior methods yourself: Did you spend equal effort tuning the prior approaches as you did tuning your own method, and can you quantify this in the paper (eg by having tested the same number of hyperparameter settings)?",
                "Limitations": "The authors note that their method, ALIGN, performs worse than prior methods in Heterogenous navigation. They hypothesize that this is because the differing size and speed of agents in Heterogenous navigation makes it difficult for agents to predict each other. I appreciate that the authors analyze this limitation.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper studies a new self-supervised MARL intrinsic reward, called Alignment, to facilitate learning in a decentralized training paradigm under partial observability. Inspired by the self-organization principle in Zoology, the intrinsic reward of Alignment aims to guide agents to match their teammates' expectations in order to emerge cooperative strategies. The experiments are carried out on the multi-agent particle and Google Research football, and the results show that Alignment outperforms sparse and curiosity-based intrinsic rewards.",
                "Strengths And Weaknesses": "The reviewer will list the main strengths and weaknesses as follows:\nSTRENGTHS\n\nThis paper introduces an interesting intrinsic reward, called Alignment, in decentralized training under partial observability. This idea is inspired by Zoology and brings a new heuristic to emerge coordination during decentralized training.\n\nThis paper conducts several experiments on popular MARL benchmarks to show that the Alignment intrinsic reward is a more useful method than curiosity-driven exploration.\n\n\nWEAKNESSES\n\nThe major concern is that the method of Alignment (see Section 4) theoretically conflicts with the decentralized training paradigm. In decentralized training, agents cannot share their expectations. Thus, each agent theoretically cannot match their teammates' expectations because they do not know them. For example, the dynamics model of agent i in line 150 is trained on the oi and ai but the alignment intrinsic reward rin defined in line 155 apply the dynamics model of agent j on the oi and ai. Note that the dynamics model of agent j is trained on the set of oj,aj rather than oi,ai. rin defined in line 155 may induce huge penalty due to this distributional shift from oj,aj to oi,ai.\n\nWhen the agent aims to match their teammates' expectations, what if their teammates do not reach a consensus? For example, in the definition of rin on line 155, if agent i's neighbors have completely different expectations, which expectation does agent i match?\n\nSample efficiency is an important measure for MARL evaluation. Could you provide the learning curve during training to better visualize the sample efficiency in comparison? Tables may not be a natural way to demonstrate the advantage of exploration methods.",
                "Questions": "The following questions correspond to three points listed in the WEAKNESSES.\n\nHow do the agents share their expectations with teammates during decentralized training?\n\nWhen the teammates have entirely different expectations for agent i, how does agent i match their expectations?\n\nWhy use tables instead of learning curves to visualize learning performance?",
                "Limitations": "The main concerns are listed in the WEAKNESSES. The authors should justify the soundness of the proposed method in Section 4.2.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "4 excellent",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.8,
        "confidence_avg": 3.6,
        "soundness_avg": 3.0,
        "presentation_avg": 3.4,
        "contribution_avg": 2.6,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is clear that the proposed paper on coordination in multi-agent reinforcement learning with the ALIGNment intrinsic reward has several strengths. The paper is well-written and easy to follow, and the method is simple and easy to implement. The empirical evaluation is solid, with comparisons to existing baselines and thorough experiments on cooperative and competitive problems. The authors have also addressed the limitations and potential negative societal impact of their work.\n\nWhile there are some weaknesses and limitations pointed out by the reviewers, such as the theoretical conflict with the decentralized training paradigm and the lack of learning curves for sample efficiency, the overall positive feedback and the promising results of the ALIGNment intrinsic reward make it a technically solid paper with high impact.\n\nTherefore, I recommend accepting the paper with a high level of confidence."
    },
    "Explicable_Policy_Search": {
        "link": "https://openreview.net//forum?id=82N_rasrUT_",
        "pub_url": "https://openreview.net/forum?id=82N_rasrUT_",
        "pdf_link": "https://openreview.net//pdf?id=82N_rasrUT_",
        "paper_id": "82N_rasrUT_",
        "title": "Explicable_Policy_Search",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nI thank the authors for their submission and active participation in the discussions. This paper studies the problem of devising an RL planner that produces bahviour consistent with human observer preferences. Reviewers remarked that the paper studies a timely problem [VqJ9,gaQq,5GPj], containing clear writing [VqJ9,PBHQ] and useful visualizations [VqJ9], and provides insightful human evaluations [VqJ9,gaQq,5GPj], and that the method is sound and elegant [PBHQ,TX5X]. During AC/reviewer discussion, reviewers TX5X, gaQq and VqJ9 agree that the author response has addressed the main concerns. I am slightly discounting the negative score by reviewer PBHQ as I don't find their suggestion to include more experiments and real world data very concrete or actionable. Thus, I overall see support for accepting the paper and am therefore recommending acceptance while encouraging the authors to further improve their paper based on the reviewer feedback.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper poses a problem for \u201cexplicable policy search,\u201d which is defined as the problem of developing a planner (i.e., via reinforcement learning) that produces behavior that are aligned with the expectations of a human observer. The paper develops an approach that infers the human\u2019s latent objective function through preference-based RL (though a Behavior Cloning objective is described first). The paper evaluates the approach in a computational environment with synthetic humans showing promising results. The paper then conducts a human-subject experiment showing that human\u2019s subjectively rate the proposed approach higher than baselines.\nStrengths And Weaknesses: trengths:\n\nThe paper\u2019s writing is generally clear with some grammatical issues. The figures were helpful.\nThe topic is timely, as researchers express increasing interest in explainable artificial intelligence in general. Policy explicability is an under-studied topic.\nThe problem formulation is clear, and the approach is well-reasoned.\nThe computational results (Table 1) show competitive returns and superior explicability scores.\nThe visualization in Figure 2 helps provide insight into the behavior of the planners.\nThe paper conducts a human-subject experiment to evaluate the approach, showing that it outperforms baselines with statistically significant results. The study was IRB-approved.\n\nWeaknesses:\n-Line 85 states that the surrogate reward function encodes the \u201cnecessary information.\u201d Is that true? Is the information learned truly \u201cnecessary\u201d or are components of the surrogate reward only approximately correct, superfluous, and/or incongruent with the truly-necessary information? What would the sufficient information be?\n-In this paper, the term \u201cexplicable\u201d in regards to planning is defined as a plan that aligns with the human\u2019s expectations for what a plan should look like. This is but one form of explicability, or, colloquially, explainability. For example, the paper seems to miss prior work on value-aligned reinforcement learning, such as:\nNahian, M.S.A., Frazier, S., Harrison, B. and Riedl, M., 2021. Training value-aligned reinforcement learning agents using a normative prior. arXiv preprint arXiv:2104.09469.\nBrown, D.S., Schneider, J., Dragan, A. and Niekum, S., 2021, July. Value alignment verification. In International Conference on Machine Learning (pp. 1105-1115). PMLR.\nThe value-aligned RL work seems to be highly similar in idea: creating RL agents that align with human expectations. The paper is also missing prior work on interpretable reinforcement learning, such as: \nSilva, A., Gombolay, M., Killian, T., Jimenez, I. and Son, S.H., 2020, June. Optimization methods for interpretable differentiable decision trees applied to reinforcement learning. In International Conference on Artificial Intelligence and Statistics (pp. 1855-1865). PMLR.\nPaleja, R., Niu, Y., Silva, A., Ritchie, C., Choi, S. and Gombolay, M., 2022. Learning interpretable, high-performing policies for continuous control problems. arXiv preprint arXiv:2202.02352.\nWhile these other approaches are not \u201cexplicable\u201d in the sense that they do not align with a human\u2019s expectations, they are interpretable, i.e. directly \u201cexplainable.\u201d\nIt would have been helpful to include the Brown et al. (2021) method as a baseline and argue why explicable behavior is better than interpretable behavior (relatively to Silva et al., 2020), considering the position of Rudin (2019).\nRudin, C., 2019. Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead. Nature Machine Intelligence, 1(5), pp.206-215.\nRudin, C., Chen, C., Chen, Z., Huang, H., Semenova, L. and Zhong, C., 2022. Interpretable machine learning: Fundamental principles and 10 grand challenges. Statistics Surveys, 16, pp.1-85.\n-The approach described in Equation 1 seems quite similar to the mechanisms explored in InfoGAIL (Li et al., 2017). In their paper, Equation 4 shows a discriminator loss for a generative-adversarial approach to essentially Behavior Cloning/Dagger, an entropy bonus, a mutual information term, and the reward function. If we throw out the entropy bonus and mutual information term (which is used for aligning with heterogeneous humans), then we basically recover what we have in Equation 2 of this paper: one term for the expected return (or reward function) and one for aligning with human behavior (behavior cloning).\nLi, Y., Song, J. and Ermon, S., 2017. Infogail: Interpretable imitation learning from visual demonstrations. Advances in Neural Information Processing Systems, 30.\n\nFollowing up on the previous point, it is fair to note that replacing the divergence term in Equation 2 and arriving at Equation 6 is literally a different formulation (e.g., replacing imitation learning with a preference-based RL, exponential distribution-type reward function inference setup) than in InfoGAIL. However, the improvement seems incremental to replace the KL divergence with U_H, and it would have been helpful to acknowledge this connection.\n\nFurther, the inclusion of entropy (as described in Lines 205-207 further recreates the setup from InfoGAIL without attribution. \n\nThe equation in referenced from [7] goes back at least a decade further to Lucas et al. (2008) and was leveraged again by Brown et al. (2019 and 2020) for preference-aligned RL.\n\n\nLucas, C., Griffiths, T., Xu, F. and Fawcett, C., 2008. A rational model of preference learning and choice prediction by children. Advances in neural information processing systems, 21.\nBrown, D., Goo, W., Nagarajan, P. and Niekum, S., 2019, May. Extrapolating beyond suboptimal demonstrations via inverse reinforcement learning from observations. In International conference on machine learning (pp. 783-792). PMLR.\nBrown, D.S., Goo, W. and Niekum, S., 2020, May. Better-than-demonstrator imitation learning via automatically-ranked demonstrations. In Conference on robot learning (pp. 330-359). PMLR.\n\nThe design of the Likert scales and analysis could be improved. For example, results of test for the ANOVA assumptions (e.g., normality and homoscedasticity) would be helpful. A useful reference would be Schrum et al. (2020).\n\nSchrum, M.L., Johnson, M., Ghuy, M. and Gombolay, M.C., 2020, March. Four years in review: Statistical practices of likert scales in human-robot interaction studies. In Companion of the 2020 ACM/IEEE International Conference on Human-Robot Interaction (pp. 43-52).\nWriting:\n-There are two uses of the word \u201cit\u201d in Line 4 that may refer to different subjects. Please try to avoid using pronouns with ambiguous antecedents.\n-\u201cbehavior, due\u201d does not need a comma\n-Line 16, \u201cthey\u201d is ambiguous\nQuestions: -Line 14, are the human\u2019s expectations truly \u201chidden\u201d or just partially observable, latent random variable?\n-How is proposition 1 fundamentally different than claims of Maximum Entropy Inverse Reinforcement Learning for learning a unique reward function? How does Proposition 1 eliminate the reward ambiguity problem?\n-Could the authors provide more information about why EPS did not conform to the human\u2019s behavior in D3?\nLimitations: \nThe authors explicitly have a section on limitations and future work, which is helpful. \nThe paper states that the research is \u201cfundamental in nature without notable negative societal impacts.\u201d I appreciate the response, but the response does not seem to be in-line with the expectations for NeurIPS. At one point, GANs might have seemed to be fundamental research, but Deep Fake videos offer the world a tool for disinformation. I would recommend spending additional time pondering whether explicability in planning \u2013 as defined here \u2013 has benefits and potential harms to society and whether the benefits outweigh the harms. For the record, this reviewer believes the research is ethical. The reviewer is only asking for a more full attempt to fulfill the expectations of NeurIPS.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The authors propose Explicable Policy Search (EPS), a method that aligns the behavior of an RL agent with the one expected by a human observer. More precisely, the goal of the method is to learn a policy that reconciles between maximizing the long-term return and minimizing the deviation from the expected behavior. This is achieved by considering a linear combination of two obectives, namely the cumulative reward and a policy explicability score. Since the human's belied about the domain dynamics is hidden to the agent and cannot be queried, the authors demonstrate that it is possible to use a surrogate reward function that encodes the information needed for EPS.\nStrengths And Weaknesses: Strengths\nOverall, the paper describes a nice and interesting work.\nI found the paper very well written and easy to follow. The content is presented in a clear and effective way. \nThe method is sound, simple and elegant.\nThe paper provides a nice formalism to extend explicable planning to a RL setting with continuos state and action spaces.\nWeaknesses\nThe paper is interesting but in the current version the experimental evaluation is a bit lacking. Experiments are mainly performed on synthetic tasks, which are good for a preliminary assessment of the soundness and feasibility of the method, but should be complemented with more analyses. The study with human subjects is interesting but it is only performed on one toy task.\nMoreover, the evaluation assesses the deviation from the human's expected behavior in Table 1 based on the explicability score. However, it looks obvious that EPS achieves a better explicability score compared to the other approaches as it is designed to optimize the explicability score. I understand that it is interesting that the averaged return is still high compared to the baselines, but it would be more interesting to perform a human evaluation of the explicability of the approaches.\nOverall, I think the paper would benefit from more experiments on real-world data, but even more ablation studies would be interesting. For instance, the appendix includes an experiment on the choice of \u03bb for the synthetic domains. I think these experiment could be in the main paper and it would be nice if the paper could include a similar experiment for the autonomous driving task too. Also, more experiments aimed at evaluating the role of the environment entropy (as described in lines 210-215) would be interesting.\nQuestions: \nThe paper mentions that the actions space in the authonomous driving domain consists of 5 actions, but the actions are only reported in the Appendix. I think it would be helpful to the reader if these actions where listed in the main paper in order to better understand the task.\nLimitations: The authors properly described the limitations.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 3 good\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The paper proposes an approach for incorporating human preferences into policy search by shaping the 'original' reward function with a 'preference-based' reward function for the human (other than learning the user belief via a respective policy and transition model). The authors learn the human preference-based reward based on available techniques. The approach is evaluated on environments with cont. state and action spaces (navigation & autonomous driving) based on both synthetic human preferences as well as a user study. The results show that the approach works better than pure RL algorithms as well as a preference-based approach.\nStrengths And Weaknesses: Strengths: The topic of the paper is relevant and up-to-date, focussing on including user feedback into RL while taking into accont possible misjudgments of the end-users when giving preferences. The taken approach is sensible, shaping the agent's reward function with the user-dependent reward function. The emprical evaluation comprises a user study, which is very helpful for interactive ML.\nWeaknesses: While the evaluation is insightful, it does not compare to more recent (and also already referenced) work on interactive RL, e.g. [24] of the paper. Also, it would significantly help the presentation to include the algorithm (available in the suppl. material) into the main paper. Lastly, I am wondering if such combination of agent- and user- reward function is helpful for the general advancement of RL. It feels like the human should remain in control when configuring the system (which seems to be the poinf of explainable, interpretable, safe RL research), but possibly convinced to change her/his perception. So wouldn't a better way be to incrementally suggest improvements to a policy learned via preference-based RL? Maybe this is equal to the direction mentioned in the future work section (pointing to more complex combinations of both reward functions), but it might also be necessary part to generate value.\nBesides, a relevant related work (more into the direction of preference-based RL) is also: Reddy, S., Dragan, A., Levine, S., Legg, S. and Leike, J., 2020, November. Learning human objectives by evaluating hypothetical behavior. In International Conference on Machine Learning (pp. 8020-8029). PMLR.\nQuestions: \nHow does the approach related to multi-objective RL? E.g. Yang, R., Sun, X. and Narasimhan, K., 2019. A generalized algorithm for multi-objective reinforcement learning and policy adaptation. Advances in Neural Information Processing Systems, 32.\n\nHow would the system perform against more recent preference-based RL approaches, improving on the used baseline? Could one (with confidence) state that even with close to optimal approximation of the user reward function, the systems would benefit from the combination with the \"original\" reward?\nLimitations: The central limitation which is discussed deals with: The argumentation for learning a user-specific reward function for shaping states that it is unnecessary to learn the user-dependent transition function. Is this always the case? What is the underlying assumption for this? The discussion is surely userful. \nIt would also be good to discuss the effects of such a straightforward combination of both reward functions. What kind of real world scenarios would this cover? Under which assumptions can a system disregard user preferences (e.g. when safety is incorprated via preferences)?\nUpdate after author response & discussion\nAgain, I thank the reviewers for their answers and changes to the paper. After reading the answers, comments of the other reviewers and especially the changes to the paper, I am wiling to increase my score to above the acceptance threshold. Main concerns have been addressed and approriate changes are in the paper.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper develops both a formulation and solution to the problem of what the authors term Explicable Policy Search (EPS), i.e. how to compute policies that maximize a tradeoff between task reward and how expected (or \"explicable\") a policy is to a human teammate, in order to improve human-robot teaming. The authors formalize this as an objective that combines expected cumulative reward with an \"explicability score\" for the robot's policy, which is defined as the KL divergence between the robot's policy and the policy that would be expected under the human's model of the environment and the reward function they impute to the robot.\nNaively, solving this problem would require access to or inference of the human's model of the environment, and the policy they expect the robot to perform. Instead, the authors show that this latent information can be encoded into an auxiliary reward function, which can be learned from human pairwise comparisons about whether some robot trajectories are more expected than others. Solving the modified MDP with these auxiliary rewards via standard RL methods yields policies that achieve high reward while being \"explicable\". The authors demonstrate this on a continuous RL test domain using simulated human data where each \"human\" has a different belief about the domain dynamics, as well as a self-driving car domain with real human feedback. The EPS algorithm outperformed non-\"explicable\" baselines in terms of the explicability score while still achieving a high amount of cumulative reward, and generated self-driving car trajectories that were more preferred by human raters.\nStrengths And Weaknesses: This paper builds upon prior work on \"explicable\" and legible planning by introducing a clear and intuitive formulation of \"planning in a way that is expected by humans\" in the context of stochastic domains where autonomous agents compute policies (distributions over actions given states) and not just plans (ordered sequences of actions). Given that most real-world domains are in fact stochastic, this extension of explicable planning is undoubtedly a useful and significant one.\nThe mathematical insight used to solve this problem -- showing that human expectations can be encoded as auxiliary rewards -- is also sound, original, clearly explained. The resulting EPS algorithm is well-evaluated on the whole, with clear qualitative demonstrations of how EPS-computed policies lead to more expected behavior given human assumptions about the domain, a user study, and average quantitative performance that is higher in terms of explicability score than a number of baselines (though I have questions about the statistical significance and effect size).\nThe main concern I have about this paper is surrounding the term \"explicable\", and how \"explicability\" is formalized as a (negative) KL-divergence, even though negative KL is better understood as something like \"expectedness\". I understand that this is similar to how the term \"explicable\" has been used in prior work in planning, but I initially found it confusing and poorly chosen, because \"explicable\" evokes the term \"explainable\", and it's not at all obvious how minimizing KL-divergence (or difference from expected behavior in general) makes behavior more explainable.\nUpon further thought however, I do think there is an intuitive sense in which the term \"explicable\" means something like \"minimize KL divergence\", but it requires a bit of justification / explanation: Typically, when we have a (probabilistic) model of some observations or behavior, we say that the observations are \"well-explained\" by the model when the observations are assigned high-probability by the model (i.e. their log-likelihood is high). This sort of language is especially apt when the model in question is causal model of the world, and so assigning high probability to the observations corresponds to having found a good causal explanation of the data. In contrast, when the observations have low probability, we might say that they are \"inexplicable\" with respect to the model.\nIn the context of EPS, the model in question is the human's intuitive causal model of how the world works TAH, and how an approximately rational agent would act in that world to achieve its goals. And so, if a trajectory \u03c4 pursued by an agent has high-probability under the human's model, it is \"well-explained\" under the model, hence \"explicable\". Otherwise it is \"inexplicable\". Hence, the log-likelihood of an agent's trajectory \u03c4 under the human's model pAH(\u03c4) can be treated as an explicability metric.\nNow as the authors point out, we don't just want to evaluate specific agent trajectories or plans, but agent policies \u03c0A, which (when combined with the true environment dynamics) are distributions over trajectories. This motivates taking an expectation over this distribution over how explicable each trajectory is:\n\nIf the explicability of a single trajectory is defined as log\u2061pAH(\u03c4), then expectation is the negative cross-entropy EpA(\u03c4)[log\u2061pAH(\u03c4)] of the human's model over trajectories, relative to the true model.\nIf the explicability of a single trajectory is instead defined as the log odds ratio log\u2061pAH(\u03c4)pA(\u03c4), then the resulting expectation is the negative KL divergence \u2212DKL(pA(\u03c4)||pAH(\u03c4)).\n\nEither of these gives us a way to evaluate how explicable a policy is relative to the human's model. It's interesting to consider the differences -- and I'd be curious what the authors think about using cross-entropy instead -- but I think the more important point is that this sort of justification for using the term \"explicable\" is missing from the paper as currently written. I would highly encourage the authors to reframe how their explicability score is introduced and defined, in order to incorporate something like the above. Otherwise, the conceptual gap between \"expected by the human\" and \"explicable\" is not an obvious one for readers to bridge. In case helpful, [1] is a paper that connects the quantity of log-likelihood to the concept of \"inexplicability\", which is formalized alongside other measures of human surprise.\nApart from the above, I only have a number of other minor questions and suggestions, which I'll list in the next section.\n[1] Zhi-Xuan, T., Gothoskar, N., Pollok, F., Gutfreund, D., Tenenbaum, J. B. & Mansinghka, V. K.  (2022). Solving the Baby Intuitions Benchmark with a Hierarchically Bayesian Theory of Mind. Social Intelligence in Humans and Robots, RSS 2022 Workshop.\nQuestions: \nAs highlighted above, why call formalize \"explicability\" as negative KL-divergence, when that more directly captures \"expectedness under the human model\"? It'd be great if the authors could do more to explain this.\n\nPer the discussion above, have the authors considered using negative cross-entropy EpA(\u03c4)[log\u2061pAH(\u03c4)] as an explicability score, instead of negative KL-divergence? It's not obvious to me that the incentive to maximize environment entropy or policy entropy (Lines 208-215) is always desired, since this means the agent's behavior will be more unpredicatable!\n\nOn Line 130, setting the true domain dynamics TA to be unknown seems unnecessarily strong a requirement. Surely explicable policy search can be applied in the case where the domain dynamics known as well -- you could just use model-based RL / value iteration instead of model-free methods like SAC.\n\nIn equation 6, why approximate the original objective by discounting the surrogate reward uH, along with the other entropy terms? It seems like you could still treat them as additional non-discounted rewards, as long as you're optimizing over finite horizons.\n\nAlso, the phrase \"ignoring the influence of the discount factor on the surrogate reward function and entropy term\" on Lines 197-198 was confusing to me -- aren't you doing the opposite, by applying discounting to the surrogate reward?\n\nAre the standard deviations shown in Table 1 taken over the full set of 100 rollouts (i.e. the sample standard deviation)? Or is that the standard error of the mean? I ask because if it's the latter, then the higher explicability of EPS relative to SAC wouldn't be statistically significant. (No doubt, average-case behavior isn't everything, but is still important).\n\nRelatedly, I'm surprised that SAC does so well in terms of explicability score on average. Is there a reason why this is the case? Is it just because in most case, the most optimal behavior happens to be mostly explicable?\nLimitations: Authors address a number of limitations which are relevant to extending EPS to real settings where human beliefs about the world may change. Another limitation comes to mind is that EPS is currently restricted to the case where agents have a fixed goal known to the human. How to extend EPS to the case where the agent's goal is not predetermined, and the human may have uncertainty with respect to the agent's goal. Can some combination of explicable and legible planning be used here, and how?\nAs for potential negative societal impact, the authors claim their work in fundamental, but in my mind it is fairly close to being applied (in e.g. human robot collaboration contexts). I would suggest adding a few words about potential negative impacts from failing to adequately learn and encode the human model through the surrogate reward, or the downsides of trading off too much performance or safety for explicability (which seems to arise in the autonomous car driving scenario).\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n",
            "Reviewer 5: \nSummary: This paper presents a way to make policy search \"explicable\" to humans, by eliciting their preferences over trajectories and combining a conventional \"engineered\" reward function with those trajectory preferences. The method is validated in empirical experiments as well as a user study in a small autonomous driving example.\nStrengths And Weaknesses: Strengths:\n\nAppears to be a novel niche in a relevant problem.\nInclusion of a user study is a nice addition to this kind of paper.\n\nWeaknesses:\n\nThe initial motivation of the approach is weak and confusing. The positioning against related work in RL could also be better. It wasn't clear until the end of the paper that this might be a valid (if rather narrow) problem and that the approach might work. \nThe mathematical derivation seems needlessly complex and seems to have a typo or mistake (see below). The technical contributions do not appear very significant.\n\nDetails:\n\nMotivation: The \"explicable\" solution in the motivating example (Fig 1a). is actually inexplicable to me. Since the proposed approach attempts to plan w.rt. wind, I assume the wind speed is constant (non-constant wind gusts are almost unpredictable and hence unplannable). Having worked with planning for drones, if the wind is constant, but less than the control authority of the drone (here drawn as a quadrotor), it would deviate some depending on the type/parameters of the controller,  strength of wind, and length of the trajectory. However, without knowing those variables, either of the drawn scenarios could happen. In addition, the \"expected\" dashed line is not straight either but curves in the opposite direction? This example could use a rework as the supposedly explicable and optimal solutions do not appear more explicable or optimal respectively.\n\nAs you appear to use the preference estimation machinery from [25,7], you might want to compare your work against those in the related work. Other RL works have also combined conventional rewards with a KL-divergence objective on trajectories (e.g. variants of Guided Policy Search). Here you are essentially learning this distribution by human preferences learned elicited as in [25,7]?\n\nThe mathematical derivation in 4.1 seems needlessly complicated, you already defined u_H on line 172 to be identical to the log of the human trajectory distribution, so Prop 1 and its proof seems redundant (c.f. e.g. line 172 vs. 188-189).\n\nEq. 6 does not appear to be a reformulation of Eq. 2 as claimed. As the authors note they suddenly made the KL-divergence term use the RL discount factor, but more importantly, if you convert the KL-divergence terms from (2) into entropies, shouldn't they be outside the expectation over p_A? \n\nEliciting reward functions from human observers appears like a slow process, and the empirical benchmarks are all very small toy examples. \n\nThe autonomous driving user study is a nice inclusion that perhaps should have been given more attention earlier on.\n\n\nMinor: \n\nl46: calling it \"business\" seems informal\nl53: \"we assume that the human is nosily rational at generating her expectation of the agent to accommodate her computational limitation\" - noisily rational? I am not familiar with this particular model of rationality, it might be good to explain what this means.\nQuestions: \nIs the actual contribution here the more efficient way of estimating the human beliefs over dynamics + policy by adding them together into a \"surrogate reward function\" directly learned by preference learning over trajectories, or the concept itself of using a linear combination learned preferences from [25,7] with a regular (given) RL reward function, or both? Please clarify positioning vs. earlier work in RL.\n\nShouldn't the entropies in Eq. 6 be outside the expectation over p_A? Is this just a typo?\n\nEstimating the entropy over the true dynamics seems potentially very difficult in the general case for more complex and higher-dimensional state distributions. It is just briefly mentioned that this is done by learning the true dynamics via a NN with a Gaussian head. For more complex state distributions than narrow trajectory distributions, I wonder how reliable this would be. Any error here seems like it could also affect tuning of lambda.\n\nHow to set lambda? The first part of the objective is a reward, the second part is a messy approximation to a KL divergence. It is not obvious to me that even if you elicit trajectory preferences from people that making a good trade off here in the end won't still require human input.\nLimitations: Sufficiently adequate (pending questions above).\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 2 fair\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper poses a problem for \u201cexplicable policy search,\u201d which is defined as the problem of developing a planner (i.e., via reinforcement learning) that produces behavior that are aligned with the expectations of a human observer. The paper develops an approach that infers the human\u2019s latent objective function through preference-based RL (though a Behavior Cloning objective is described first). The paper evaluates the approach in a computational environment with synthetic humans showing promising results. The paper then conducts a human-subject experiment showing that human\u2019s subjectively rate the proposed approach higher than baselines.",
                "Strengths And Weaknesses": "trengths:\n\nThe paper\u2019s writing is generally clear with some grammatical issues. The figures were helpful.\nThe topic is timely, as researchers express increasing interest in explainable artificial intelligence in general. Policy explicability is an under-studied topic.\nThe problem formulation is clear, and the approach is well-reasoned.\nThe computational results (Table 1) show competitive returns and superior explicability scores.\nThe visualization in Figure 2 helps provide insight into the behavior of the planners.\nThe paper conducts a human-subject experiment to evaluate the approach, showing that it outperforms baselines with statistically significant results. The study was IRB-approved.\n\nWeaknesses:\n-Line 85 states that the surrogate reward function encodes the \u201cnecessary information.\u201d Is that true? Is the information learned truly \u201cnecessary\u201d or are components of the surrogate reward only approximately correct, superfluous, and/or incongruent with the truly-necessary information? What would the sufficient information be?\n-In this paper, the term \u201cexplicable\u201d in regards to planning is defined as a plan that aligns with the human\u2019s expectations for what a plan should look like. This is but one form of explicability, or, colloquially, explainability. For example, the paper seems to miss prior work on value-aligned reinforcement learning, such as:\nNahian, M.S.A., Frazier, S., Harrison, B. and Riedl, M., 2021. Training value-aligned reinforcement learning agents using a normative prior. arXiv preprint arXiv:2104.09469.\nBrown, D.S., Schneider, J., Dragan, A. and Niekum, S., 2021, July. Value alignment verification. In International Conference on Machine Learning (pp. 1105-1115). PMLR.\nThe value-aligned RL work seems to be highly similar in idea: creating RL agents that align with human expectations. The paper is also missing prior work on interpretable reinforcement learning, such as: \nSilva, A., Gombolay, M., Killian, T., Jimenez, I. and Son, S.H., 2020, June. Optimization methods for interpretable differentiable decision trees applied to reinforcement learning. In International Conference on Artificial Intelligence and Statistics (pp. 1855-1865). PMLR.\nPaleja, R., Niu, Y., Silva, A., Ritchie, C., Choi, S. and Gombolay, M., 2022. Learning interpretable, high-performing policies for continuous control problems. arXiv preprint arXiv:2202.02352.\nWhile these other approaches are not \u201cexplicable\u201d in the sense that they do not align with a human\u2019s expectations, they are interpretable, i.e. directly \u201cexplainable.\u201d\nIt would have been helpful to include the Brown et al. (2021) method as a baseline and argue why explicable behavior is better than interpretable behavior (relatively to Silva et al., 2020), considering the position of Rudin (2019).\nRudin, C., 2019. Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead. Nature Machine Intelligence, 1(5), pp.206-215.\nRudin, C., Chen, C., Chen, Z., Huang, H., Semenova, L. and Zhong, C., 2022. Interpretable machine learning: Fundamental principles and 10 grand challenges. Statistics Surveys, 16, pp.1-85.\n-The approach described in Equation 1 seems quite similar to the mechanisms explored in InfoGAIL (Li et al., 2017). In their paper, Equation 4 shows a discriminator loss for a generative-adversarial approach to essentially Behavior Cloning/Dagger, an entropy bonus, a mutual information term, and the reward function. If we throw out the entropy bonus and mutual information term (which is used for aligning with heterogeneous humans), then we basically recover what we have in Equation 2 of this paper: one term for the expected return (or reward function) and one for aligning with human behavior (behavior cloning).\nLi, Y., Song, J. and Ermon, S., 2017. Infogail: Interpretable imitation learning from visual demonstrations. Advances in Neural Information Processing Systems, 30.\n\nFollowing up on the previous point, it is fair to note that replacing the divergence term in Equation 2 and arriving at Equation 6 is literally a different formulation (e.g., replacing imitation learning with a preference-based RL, exponential distribution-type reward function inference setup) than in InfoGAIL. However, the improvement seems incremental to replace the KL divergence with U_H, and it would have been helpful to acknowledge this connection.\n\nFurther, the inclusion of entropy (as described in Lines 205-207 further recreates the setup from InfoGAIL without attribution. \n\nThe equation in referenced from [7] goes back at least a decade further to Lucas et al. (2008) and was leveraged again by Brown et al. (2019 and 2020) for preference-aligned RL.\n\n\nLucas, C., Griffiths, T., Xu, F. and Fawcett, C., 2008. A rational model of preference learning and choice prediction by children. Advances in neural information processing systems, 21.\nBrown, D., Goo, W., Nagarajan, P. and Niekum, S., 2019, May. Extrapolating beyond suboptimal demonstrations via inverse reinforcement learning from observations. In International conference on machine learning (pp. 783-792). PMLR.\nBrown, D.S., Goo, W. and Niekum, S., 2020, May. Better-than-demonstrator imitation learning via automatically-ranked demonstrations. In Conference on robot learning (pp. 330-359). PMLR.\n\nThe design of the Likert scales and analysis could be improved. For example, results of test for the ANOVA assumptions (e.g., normality and homoscedasticity) would be helpful. A useful reference would be Schrum et al. (2020).\n\nSchrum, M.L., Johnson, M., Ghuy, M. and Gombolay, M.C., 2020, March. Four years in review: Statistical practices of likert scales in human-robot interaction studies. In Companion of the 2020 ACM/IEEE International Conference on Human-Robot Interaction (pp. 43-52).\nWriting:\n-There are two uses of the word \u201cit\u201d in Line 4 that may refer to different subjects. Please try to avoid using pronouns with ambiguous antecedents.\n-\u201cbehavior, due\u201d does not need a comma\n-Line 16, \u201cthey\u201d is ambiguous",
                "Questions": "-Line 14, are the human\u2019s expectations truly \u201chidden\u201d or just partially observable, latent random variable?\n-How is proposition 1 fundamentally different than claims of Maximum Entropy Inverse Reinforcement Learning for learning a unique reward function? How does Proposition 1 eliminate the reward ambiguity problem?\n-Could the authors provide more information about why EPS did not conform to the human\u2019s behavior in D3?",
                "Limitations": "The authors explicitly have a section on limitations and future work, which is helpful. \nThe paper states that the research is \u201cfundamental in nature without notable negative societal impacts.\u201d I appreciate the response, but the response does not seem to be in-line with the expectations for NeurIPS. At one point, GANs might have seemed to be fundamental research, but Deep Fake videos offer the world a tool for disinformation. I would recommend spending additional time pondering whether explicability in planning \u2013 as defined here \u2013 has benefits and potential harms to society and whether the benefits outweigh the harms. For the record, this reviewer believes the research is ethical. The reviewer is only asking for a more full attempt to fulfill the expectations of NeurIPS.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors propose Explicable Policy Search (EPS), a method that aligns the behavior of an RL agent with the one expected by a human observer. More precisely, the goal of the method is to learn a policy that reconciles between maximizing the long-term return and minimizing the deviation from the expected behavior. This is achieved by considering a linear combination of two obectives, namely the cumulative reward and a policy explicability score. Since the human's belied about the domain dynamics is hidden to the agent and cannot be queried, the authors demonstrate that it is possible to use a surrogate reward function that encodes the information needed for EPS.",
                "Strengths And Weaknesses": "Strengths\nOverall, the paper describes a nice and interesting work.\nI found the paper very well written and easy to follow. The content is presented in a clear and effective way. \nThe method is sound, simple and elegant.\nThe paper provides a nice formalism to extend explicable planning to a RL setting with continuos state and action spaces.\nWeaknesses\nThe paper is interesting but in the current version the experimental evaluation is a bit lacking. Experiments are mainly performed on synthetic tasks, which are good for a preliminary assessment of the soundness and feasibility of the method, but should be complemented with more analyses. The study with human subjects is interesting but it is only performed on one toy task.\nMoreover, the evaluation assesses the deviation from the human's expected behavior in Table 1 based on the explicability score. However, it looks obvious that EPS achieves a better explicability score compared to the other approaches as it is designed to optimize the explicability score. I understand that it is interesting that the averaged return is still high compared to the baselines, but it would be more interesting to perform a human evaluation of the explicability of the approaches.\nOverall, I think the paper would benefit from more experiments on real-world data, but even more ablation studies would be interesting. For instance, the appendix includes an experiment on the choice of \u03bb for the synthetic domains. I think these experiment could be in the main paper and it would be nice if the paper could include a similar experiment for the autonomous driving task too. Also, more experiments aimed at evaluating the role of the environment entropy (as described in lines 210-215) would be interesting.",
                "Questions": "The paper mentions that the actions space in the authonomous driving domain consists of 5 actions, but the actions are only reported in the Appendix. I think it would be helpful to the reader if these actions where listed in the main paper in order to better understand the task.",
                "Limitations": "The authors properly described the limitations.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper proposes an approach for incorporating human preferences into policy search by shaping the 'original' reward function with a 'preference-based' reward function for the human (other than learning the user belief via a respective policy and transition model). The authors learn the human preference-based reward based on available techniques. The approach is evaluated on environments with cont. state and action spaces (navigation & autonomous driving) based on both synthetic human preferences as well as a user study. The results show that the approach works better than pure RL algorithms as well as a preference-based approach.",
                "Strengths And Weaknesses": "Strengths: The topic of the paper is relevant and up-to-date, focussing on including user feedback into RL while taking into accont possible misjudgments of the end-users when giving preferences. The taken approach is sensible, shaping the agent's reward function with the user-dependent reward function. The emprical evaluation comprises a user study, which is very helpful for interactive ML.\nWeaknesses: While the evaluation is insightful, it does not compare to more recent (and also already referenced) work on interactive RL, e.g. [24] of the paper. Also, it would significantly help the presentation to include the algorithm (available in the suppl. material) into the main paper. Lastly, I am wondering if such combination of agent- and user- reward function is helpful for the general advancement of RL. It feels like the human should remain in control when configuring the system (which seems to be the poinf of explainable, interpretable, safe RL research), but possibly convinced to change her/his perception. So wouldn't a better way be to incrementally suggest improvements to a policy learned via preference-based RL? Maybe this is equal to the direction mentioned in the future work section (pointing to more complex combinations of both reward functions), but it might also be necessary part to generate value.\nBesides, a relevant related work (more into the direction of preference-based RL) is also: Reddy, S., Dragan, A., Levine, S., Legg, S. and Leike, J., 2020, November. Learning human objectives by evaluating hypothetical behavior. In International Conference on Machine Learning (pp. 8020-8029). PMLR.",
                "Questions": "How does the approach related to multi-objective RL? E.g. Yang, R., Sun, X. and Narasimhan, K., 2019. A generalized algorithm for multi-objective reinforcement learning and policy adaptation. Advances in Neural Information Processing Systems, 32.\n\nHow would the system perform against more recent preference-based RL approaches, improving on the used baseline? Could one (with confidence) state that even with close to optimal approximation of the user reward function, the systems would benefit from the combination with the \"original\" reward?",
                "Limitations": "The central limitation which is discussed deals with: The argumentation for learning a user-specific reward function for shaping states that it is unnecessary to learn the user-dependent transition function. Is this always the case? What is the underlying assumption for this? The discussion is surely userful. \nIt would also be good to discuss the effects of such a straightforward combination of both reward functions. What kind of real world scenarios would this cover? Under which assumptions can a system disregard user preferences (e.g. when safety is incorprated via preferences)?\nUpdate after author response & discussion\nAgain, I thank the reviewers for their answers and changes to the paper. After reading the answers, comments of the other reviewers and especially the changes to the paper, I am wiling to increase my score to above the acceptance threshold. Main concerns have been addressed and approriate changes are in the paper.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper develops both a formulation and solution to the problem of what the authors term Explicable Policy Search (EPS), i.e. how to compute policies that maximize a tradeoff between task reward and how expected (or \"explicable\") a policy is to a human teammate, in order to improve human-robot teaming. The authors formalize this as an objective that combines expected cumulative reward with an \"explicability score\" for the robot's policy, which is defined as the KL divergence between the robot's policy and the policy that would be expected under the human's model of the environment and the reward function they impute to the robot.\nNaively, solving this problem would require access to or inference of the human's model of the environment, and the policy they expect the robot to perform. Instead, the authors show that this latent information can be encoded into an auxiliary reward function, which can be learned from human pairwise comparisons about whether some robot trajectories are more expected than others. Solving the modified MDP with these auxiliary rewards via standard RL methods yields policies that achieve high reward while being \"explicable\". The authors demonstrate this on a continuous RL test domain using simulated human data where each \"human\" has a different belief about the domain dynamics, as well as a self-driving car domain with real human feedback. The EPS algorithm outperformed non-\"explicable\" baselines in terms of the explicability score while still achieving a high amount of cumulative reward, and generated self-driving car trajectories that were more preferred by human raters.",
                "Strengths And Weaknesses": "This paper builds upon prior work on \"explicable\" and legible planning by introducing a clear and intuitive formulation of \"planning in a way that is expected by humans\" in the context of stochastic domains where autonomous agents compute policies (distributions over actions given states) and not just plans (ordered sequences of actions). Given that most real-world domains are in fact stochastic, this extension of explicable planning is undoubtedly a useful and significant one.\nThe mathematical insight used to solve this problem -- showing that human expectations can be encoded as auxiliary rewards -- is also sound, original, clearly explained. The resulting EPS algorithm is well-evaluated on the whole, with clear qualitative demonstrations of how EPS-computed policies lead to more expected behavior given human assumptions about the domain, a user study, and average quantitative performance that is higher in terms of explicability score than a number of baselines (though I have questions about the statistical significance and effect size).\nThe main concern I have about this paper is surrounding the term \"explicable\", and how \"explicability\" is formalized as a (negative) KL-divergence, even though negative KL is better understood as something like \"expectedness\". I understand that this is similar to how the term \"explicable\" has been used in prior work in planning, but I initially found it confusing and poorly chosen, because \"explicable\" evokes the term \"explainable\", and it's not at all obvious how minimizing KL-divergence (or difference from expected behavior in general) makes behavior more explainable.\nUpon further thought however, I do think there is an intuitive sense in which the term \"explicable\" means something like \"minimize KL divergence\", but it requires a bit of justification / explanation: Typically, when we have a (probabilistic) model of some observations or behavior, we say that the observations are \"well-explained\" by the model when the observations are assigned high-probability by the model (i.e. their log-likelihood is high). This sort of language is especially apt when the model in question is causal model of the world, and so assigning high probability to the observations corresponds to having found a good causal explanation of the data. In contrast, when the observations have low probability, we might say that they are \"inexplicable\" with respect to the model.\nIn the context of EPS, the model in question is the human's intuitive causal model of how the world works TAH, and how an approximately rational agent would act in that world to achieve its goals. And so, if a trajectory \u03c4 pursued by an agent has high-probability under the human's model, it is \"well-explained\" under the model, hence \"explicable\". Otherwise it is \"inexplicable\". Hence, the log-likelihood of an agent's trajectory \u03c4 under the human's model pAH(\u03c4) can be treated as an explicability metric.\nNow as the authors point out, we don't just want to evaluate specific agent trajectories or plans, but agent policies \u03c0A, which (when combined with the true environment dynamics) are distributions over trajectories. This motivates taking an expectation over this distribution over how explicable each trajectory is:\n\nIf the explicability of a single trajectory is defined as log\u2061pAH(\u03c4), then expectation is the negative cross-entropy EpA(\u03c4)[log\u2061pAH(\u03c4)] of the human's model over trajectories, relative to the true model.\nIf the explicability of a single trajectory is instead defined as the log odds ratio log\u2061pAH(\u03c4)pA(\u03c4), then the resulting expectation is the negative KL divergence \u2212DKL(pA(\u03c4)||pAH(\u03c4)).\n\nEither of these gives us a way to evaluate how explicable a policy is relative to the human's model. It's interesting to consider the differences -- and I'd be curious what the authors think about using cross-entropy instead -- but I think the more important point is that this sort of justification for using the term \"explicable\" is missing from the paper as currently written. I would highly encourage the authors to reframe how their explicability score is introduced and defined, in order to incorporate something like the above. Otherwise, the conceptual gap between \"expected by the human\" and \"explicable\" is not an obvious one for readers to bridge. In case helpful, [1] is a paper that connects the quantity of log-likelihood to the concept of \"inexplicability\", which is formalized alongside other measures of human surprise.\nApart from the above, I only have a number of other minor questions and suggestions, which I'll list in the next section.\n[1] Zhi-Xuan, T., Gothoskar, N., Pollok, F., Gutfreund, D., Tenenbaum, J. B. & Mansinghka, V. K.  (2022). Solving the Baby Intuitions Benchmark with a Hierarchically Bayesian Theory of Mind. Social Intelligence in Humans and Robots, RSS 2022 Workshop.",
                "Questions": "As highlighted above, why call formalize \"explicability\" as negative KL-divergence, when that more directly captures \"expectedness under the human model\"? It'd be great if the authors could do more to explain this.\n\nPer the discussion above, have the authors considered using negative cross-entropy EpA(\u03c4)[log\u2061pAH(\u03c4)] as an explicability score, instead of negative KL-divergence? It's not obvious to me that the incentive to maximize environment entropy or policy entropy (Lines 208-215) is always desired, since this means the agent's behavior will be more unpredicatable!\n\nOn Line 130, setting the true domain dynamics TA to be unknown seems unnecessarily strong a requirement. Surely explicable policy search can be applied in the case where the domain dynamics known as well -- you could just use model-based RL / value iteration instead of model-free methods like SAC.\n\nIn equation 6, why approximate the original objective by discounting the surrogate reward uH, along with the other entropy terms? It seems like you could still treat them as additional non-discounted rewards, as long as you're optimizing over finite horizons.\n\nAlso, the phrase \"ignoring the influence of the discount factor on the surrogate reward function and entropy term\" on Lines 197-198 was confusing to me -- aren't you doing the opposite, by applying discounting to the surrogate reward?\n\nAre the standard deviations shown in Table 1 taken over the full set of 100 rollouts (i.e. the sample standard deviation)? Or is that the standard error of the mean? I ask because if it's the latter, then the higher explicability of EPS relative to SAC wouldn't be statistically significant. (No doubt, average-case behavior isn't everything, but is still important).\n\nRelatedly, I'm surprised that SAC does so well in terms of explicability score on average. Is there a reason why this is the case? Is it just because in most case, the most optimal behavior happens to be mostly explicable?",
                "Limitations": "Authors address a number of limitations which are relevant to extending EPS to real settings where human beliefs about the world may change. Another limitation comes to mind is that EPS is currently restricted to the case where agents have a fixed goal known to the human. How to extend EPS to the case where the agent's goal is not predetermined, and the human may have uncertainty with respect to the agent's goal. Can some combination of explicable and legible planning be used here, and how?\nAs for potential negative societal impact, the authors claim their work in fundamental, but in my mind it is fairly close to being applied (in e.g. human robot collaboration contexts). I would suggest adding a few words about potential negative impacts from failing to adequately learn and encode the human model through the surrogate reward, or the downsides of trading off too much performance or safety for explicability (which seems to arise in the autonomous car driving scenario).",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper presents a way to make policy search \"explicable\" to humans, by eliciting their preferences over trajectories and combining a conventional \"engineered\" reward function with those trajectory preferences. The method is validated in empirical experiments as well as a user study in a small autonomous driving example.",
                "Strengths And Weaknesses": "Strengths:\n\nAppears to be a novel niche in a relevant problem.\nInclusion of a user study is a nice addition to this kind of paper.\n\nWeaknesses:\n\nThe initial motivation of the approach is weak and confusing. The positioning against related work in RL could also be better. It wasn't clear until the end of the paper that this might be a valid (if rather narrow) problem and that the approach might work. \nThe mathematical derivation seems needlessly complex and seems to have a typo or mistake (see below). The technical contributions do not appear very significant.\n\nDetails:\n\nMotivation: The \"explicable\" solution in the motivating example (Fig 1a). is actually inexplicable to me. Since the proposed approach attempts to plan w.rt. wind, I assume the wind speed is constant (non-constant wind gusts are almost unpredictable and hence unplannable). Having worked with planning for drones, if the wind is constant, but less than the control authority of the drone (here drawn as a quadrotor), it would deviate some depending on the type/parameters of the controller,  strength of wind, and length of the trajectory. However, without knowing those variables, either of the drawn scenarios could happen. In addition, the \"expected\" dashed line is not straight either but curves in the opposite direction? This example could use a rework as the supposedly explicable and optimal solutions do not appear more explicable or optimal respectively.\n\nAs you appear to use the preference estimation machinery from [25,7], you might want to compare your work against those in the related work. Other RL works have also combined conventional rewards with a KL-divergence objective on trajectories (e.g. variants of Guided Policy Search). Here you are essentially learning this distribution by human preferences learned elicited as in [25,7]?\n\nThe mathematical derivation in 4.1 seems needlessly complicated, you already defined u_H on line 172 to be identical to the log of the human trajectory distribution, so Prop 1 and its proof seems redundant (c.f. e.g. line 172 vs. 188-189).\n\nEq. 6 does not appear to be a reformulation of Eq. 2 as claimed. As the authors note they suddenly made the KL-divergence term use the RL discount factor, but more importantly, if you convert the KL-divergence terms from (2) into entropies, shouldn't they be outside the expectation over p_A? \n\nEliciting reward functions from human observers appears like a slow process, and the empirical benchmarks are all very small toy examples. \n\nThe autonomous driving user study is a nice inclusion that perhaps should have been given more attention earlier on.\n\n\nMinor: \n\nl46: calling it \"business\" seems informal\nl53: \"we assume that the human is nosily rational at generating her expectation of the agent to accommodate her computational limitation\" - noisily rational? I am not familiar with this particular model of rationality, it might be good to explain what this means.",
                "Questions": "Is the actual contribution here the more efficient way of estimating the human beliefs over dynamics + policy by adding them together into a \"surrogate reward function\" directly learned by preference learning over trajectories, or the concept itself of using a linear combination learned preferences from [25,7] with a regular (given) RL reward function, or both? Please clarify positioning vs. earlier work in RL.\n\nShouldn't the entropies in Eq. 6 be outside the expectation over p_A? Is this just a typo?\n\nEstimating the entropy over the true dynamics seems potentially very difficult in the general case for more complex and higher-dimensional state distributions. It is just briefly mentioned that this is done by learning the true dynamics via a NN with a Gaussian head. For more complex state distributions than narrow trajectory distributions, I wonder how reliable this would be. Any error here seems like it could also affect tuning of lambda.\n\nHow to set lambda? The first part of the objective is a reward, the second part is a messy approximation to a KL divergence. It is not obvious to me that even if you elicit trajectory preferences from people that making a good trade off here in the end won't still require human input.",
                "Limitations": "Sufficiently adequate (pending questions above).",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.2,
        "confidence_avg": 3.6,
        "soundness_avg": 2.4,
        "presentation_avg": 2.8,
        "contribution_avg": 2.8,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is clear that the paper presents a novel and relevant approach to the problem of explicable policy search. The reviewers generally agree that the paper is well-written and the approach is well-reasoned. The experimental evaluation, although limited, shows promising results and the inclusion of a user study is a valuable addition.\n\nThere are some concerns raised by the reviewers regarding the clarity of the motivation and the formalization of \"explicability\". The authors are encouraged to provide a clearer explanation of the term \"explicability\" and its connection to expected behavior. Additionally, it would be beneficial to position the work more explicitly in relation to related work in reinforcement learning.\n\nOverall, the contributions of the paper are considered to be significant, although not groundbreaking. The limitations and future work are appropriately discussed. The reviewers have raised some minor questions and suggestions, but they do not significantly impact the overall assessment of the paper.\n\nTherefore, based on the positive feedback from the reviewers and the overall quality of the paper, I recommend accepting it for publication."
    },
    "A_Practical,_Progressively-Expressive_GNN": {
        "link": "https://openreview.net//forum?id=WBv9Z6qpA8x",
        "pub_url": "https://openreview.net/forum?id=WBv9Z6qpA8x",
        "pdf_link": "https://openreview.net//pdf?id=WBv9Z6qpA8x",
        "paper_id": "WBv9Z6qpA8x",
        "title": "A_Practical,_Progressively-Expressive_GNN",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Less certain\nThe papers recognizes an important open question in GNNs: expressiveness-complexity tradeoff. Current more expressive GNNs (k-WL equivalent GNNs) are not practical for even small values of k, and several works have found great empirical success in graph learning tasks without highly expressive models. This paper puts forth a more \u201cfine-grained ruler,\u201d which can more gradually increase expressiveness to investigate the expressiveness-complexity tradeoff. \nThe paper addresses an important problem of going beyond 1-WL, however, in such a manner such that expressivity is improved in a progressive way while runtime is still manageable. Experimental results on graph classification and substructure identification as well as regression Zinc12k are promising.\nHowever, the committee has concerns on the presentation of the paper. The authors are suggested to make the paper more accessible by providing more high-level descriptions and interpretations of the results.",
        "reviews": [
            "Reviewer 1: \nSummary: The paper deals with supervised learning on graph structured data for which the most common framework of GNN is limited in expressivity by 1-WL test in terms of its identifying capacity of graphs. \nHigher order K-WL hierarchy of algorithms are well-known to improve the expressivity of GNN models with increasing K. However, the complexity of the K-WL increases exponentially with increasing K, making it infeasible to apply in practice. The authors propose (k,c)(\u2264)-SetWL hierarchy in place of WL-hierarchy. a It is a \u201cfiner-grained ruler\u201d than WL-hierarchy and mainly depends on sets (size \u2264k) instead of tuples of nodes and connected components (\u2264c). The authors develop the method moving from tuples in WL to multisets, then to sets and then to sets with connected components and design its neural counterpart (k,c)(\u2264)-SETGNN. Experimental results on both synthetic and real datasets show that the method is promising.\nStrengths And Weaknesses: Strengths:\n\nThe paper addresses an important problem of going beyond 1-WL, however, in such a manner such that expressivity is improved in a progressive way while runtime is still manageable \nThe idea naturally follows from K-WL models of moving from tuples to multisets, then to sets. The paper rigorously explores this.\nExperimental results on graph classification and substructure identification as well as regression Zinc12k are promising.\nThe paper is well-written with needed rigor. However, the presentation could be improved for better readability.\n\nWeaknesses/Comments:\n\nThe result in Theorem-1 of k-Multiset-WL being equal to K-WL is surprising. I think this should have been discussed with some intuitive figures to show where exactly is the redundancy in K-WL that is being exploited by K-Multiset-WL. I could not follow the proof properly, however it seems to me that with the perm[] function, you would spend same amount of time as K-WL in updating the node colors. Exact number of supernodes in K-Multiset-WL in comparison with K-WL is also missing.\nRuntime analysis is not complete. Though it is nice to see the exact ratio of speedup of K-SETWL with respect to WL, it would be much clearer if we see the runtime of WL, Multiset-WL, SET-WL,  in BigO notation. Further, what is the cost with respect to c in (k,c)(\\leq)-SETWL is also not clear. Asymptotic runtime would also help in visualizing where exactly the speedup comes from.\nThe empirical evaluation should include additional recent expressive GNN models to properly understand the benefits of SET-GNN in comparison with other more expressive models like GraphSNN (Wijesinghe, et al. (2021)), PF-GNN (Dupty et al. (2021)), GNNML3 (Balcilar et al. (2021)) etc. This would also be important since these methods employ different techniques to achieve expressivity and SETGNN can be analysed in perspective.\nThe paper can be significantly improved in readability if some pictures are added to describe the key points where redundancy is removed from tuple to multisets, then multisets to sets.\nLine 238: derivation not in Appendix\nLine 183, it should n_u in place of n_n\n\nOverall, I find the idea of the paper novel as well as very significant for improving the expressivity of GNNs. Also, the idea is systematically and rigorously developed towards providing a finer scale for measuring expressivity. \nHowever, I could not fully grasp the proofs and hence I\u2019m less confident, especially since the results are somewhat surprising. Furthermore, experimental results need to be properly placed with respect to the recent literature.\nReferences:\n\n[1] Wijesinghe, et al. (2021).  A New Perspective on\" How Graph Neural Networks Go Beyond Weisfeiler-Lehman?\". In International Conference on Learning Representations.\n[2] Dupty et al. (2021) \"PF-GNN: Differentiable particle filtering based approximation of universal graph representations.\" International Conference on Learning Representations.\n[3] Balcilar et al. (2021)  \"Breaking the limits of message passing graph neural networks.\" International Conference on Machine Learning. PMLR.\nQuestions: Please address the weakness mentioned above.\nLimitations: The authors have discussed some limitations. There is no potential negative societal impact.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 4 excellent\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This work proposes a more fine-grained graph isomorphism test hierarchy, namely (k,c)(<=)-SetWL, by further considering removing order, removing repetition, and graph sparsity over the original k-WL algorithm. Based on the obtained graph isomorphism test algorithm, it further develops a progressively expressive GNN accordingly. Experiments on synthetic and real datasets are performed to evaluate the effectiveness of the proposed GNN.\nStrengths And Weaknesses: +++ Pros\n(1) It is technically sound to consider removing order, removing repetition, and graph sparsity over the original k-WL algorithm. The step-by-step derivation is sound and clearly present.\n(2) This work also characterizes the expressiveness of the obtained k-WL variants clearly. It is impressive to me to know that k-MultisetWL is as expressive as the original k-WL. This result might have impact to the community.\n(3) The presentation of this work is great. Although it has a lot of math, the flow is generally easy to follow.\n(4) The empirical results are strong to demonstrate the effectiveness of the proposed GNN.\n+++ Cons\n(1) Although the presentation is good enough, there are several places which are hard to understand, given that this is a math-heavy work. For example, the result given in Theorem 1 is amazing, it would be great to provide some intuitive explanation of the proof in the main text. This can also help readers to understand why we consider removing orders.\n(2) Similarly, the derivation of Theorem 4 is also unclear to me. Please see the following question for details.\nQuestions: (1) I am not fully understand the derivation of Theorem 4 ((k,c)(<=)-SetGNN is as expressive as (k,c)(<=)-SetWL). In the given proof, it is mainly based on the results of DeepSet. In other words, MLP with summation is universal so that it can learn the desired injective function. However, this may not prove that Eq. (9) is injective directly, since the input of the outer MLP in Eq. (9) has four parts. It is unclear and non-trivial that how to ensure that this MLP can learn an injective function.\n+++minor points\nLine 182, a should be an\nLimitations: Not applicable.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 4 excellent\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The goal of this paper is to develop more expressive GNNs using the k-WL hierarchy. While the one-dimensional Weisfeiler Leman (1-WL) helps to distinguish isomorphic graphs, the use of k-WL hierarchy helps build more expressive GNNs.  The authors propose (k,c) <= SETWL which reduces the complexity of the k-WL hierarchy. Tweaking k and c in this model, helps develop practical and progressively expressive GNNs.\nStrengths And Weaknesses: Strengths\n\nThe paper is well written with both theoretical and empirical work. \nAn interesting problem on expressiveness of GNNs is explored using set theoretic tools along with message passing algorithms\n\nWeakness\n\nThe problem needs to be better motivated -- how is expressiveness related to generalization performance? Why use (k,c) (<=)-SETGNN at all?\nThe paper assumes an audience well versed with graph isomorphism, Weisfeiler Leman hierarchy, and other kinds of isomorphism test. A reader unfamiliar with these concepts would wonder why even this is relevant. Motivating with concrete real world examples would perhaps make it easier to see why this is an important problem to solve.\nQuestions: \nWhat is the basic definition of \"expressiveness\" of a GNN model? Does increased expressiveness of the super-graph imply better generalization performance?\n\nIs expressiveness related to interpretability of the model? If not, what marks the fundamental difference between them?\n\nWhy is the work consistently using GNNs when the literature is replete with many other kinds of neural networks whose expressiveness can be studied and interpreted?\n\nThe motivation for (k,c) (<=)-SETGNN has not been well discussed.\n\nSection 5: What is a SOTA expressive GNN? The acronym has not been defined.\n -For ease of readability, consider having a notation table instead of the section 3\n -Table 1,2,3,4 and 5 should simply use two places of decimals for ease of readability\n\n\n The authors claim \"Such a hierarchy could enable us to gradually build more expressive models which admit improved scaling, and avoid unnecessary leaps in model complexity for tasks which do not require them, guarding against overfitting.\"\n What is the relation between expressivity of a graph and graph isomorphism?\n In Table 2, with k=3 or 4, and more than one connected components, the performance on the test set is much worse than on the train set. So for these highly expressive graphs, how is generalization performance demonstrated to be better?\nLimitations: Complexity of the proposed technique in addition to scalability are clearly limitations which the authors try to solve and are successful to a good extent.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: The paper introduces a family of models, namely (k, c)(\u2264)-SETGNN, whose expressiveness increases with k and c.\nThe expressiveness is measured in terms of the newly proposed hierarchy (k, c)(\u2264)-SETWL which is more \"granular\" than the standard k-WL hierarchy.\nThe presentation guides the reader to the derivation of the (k, c)(\u2264)-SETWL by iteratively refining the k-WL hierarchy.\nThe paper comes with proofs relating the various refinements and experiments that investigate the progressive expressiveness of the proposed architecture for varying k and c.\nStrengths And Weaknesses: Strengths\n\nThe empirical evaluation shows increased performance wrt existing methods\nThe proposed architecture's expressiveness can be modulated easily through the k and c parameters.\n\nWeaknesses\n\nIt's unclear whether one can use the new proposed \"ruler\" (the (k, c)(\u2264)-SETWL hierarchy) to compare existing models and whether new models other than (k, c)(\u2264)-SETGNN can be built around it. Consequently, the significance appears rather limited.\n\nMinor comments:\n\ns is not defined in line 135 but introduced much later in line 175\nFig. 1 needs a few more iterations. Many edges are disconnected from their endpoints and the labels (1, 5 etc.) of the nodes are not centered.\nQuestions: \nIs it possible to analyse the expressiveness of existing approaches in term on the new hierarchy?\nDid you use the parameter budget (100K or 500K) as prescribed by ZINC-12K?\nThe linked repository is empty, please update it.\nLimitations: n/a\nEthics Flag: No\nEthics Review Area: I don\u2019t know\nSoundness: 2 fair\nPresentation: 1 poor\nContribution: 1 poor\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The paper deals with supervised learning on graph structured data for which the most common framework of GNN is limited in expressivity by 1-WL test in terms of its identifying capacity of graphs. \nHigher order K-WL hierarchy of algorithms are well-known to improve the expressivity of GNN models with increasing K. However, the complexity of the K-WL increases exponentially with increasing K, making it infeasible to apply in practice. The authors propose (k,c)(\u2264)-SetWL hierarchy in place of WL-hierarchy. a It is a \u201cfiner-grained ruler\u201d than WL-hierarchy and mainly depends on sets (size \u2264k) instead of tuples of nodes and connected components (\u2264c). The authors develop the method moving from tuples in WL to multisets, then to sets and then to sets with connected components and design its neural counterpart (k,c)(\u2264)-SETGNN. Experimental results on both synthetic and real datasets show that the method is promising.",
                "Strengths And Weaknesses": "Strengths:\n\nThe paper addresses an important problem of going beyond 1-WL, however, in such a manner such that expressivity is improved in a progressive way while runtime is still manageable \nThe idea naturally follows from K-WL models of moving from tuples to multisets, then to sets. The paper rigorously explores this.\nExperimental results on graph classification and substructure identification as well as regression Zinc12k are promising.\nThe paper is well-written with needed rigor. However, the presentation could be improved for better readability.\n\nWeaknesses/Comments:\n\nThe result in Theorem-1 of k-Multiset-WL being equal to K-WL is surprising. I think this should have been discussed with some intuitive figures to show where exactly is the redundancy in K-WL that is being exploited by K-Multiset-WL. I could not follow the proof properly, however it seems to me that with the perm[] function, you would spend same amount of time as K-WL in updating the node colors. Exact number of supernodes in K-Multiset-WL in comparison with K-WL is also missing.\nRuntime analysis is not complete. Though it is nice to see the exact ratio of speedup of K-SETWL with respect to WL, it would be much clearer if we see the runtime of WL, Multiset-WL, SET-WL,  in BigO notation. Further, what is the cost with respect to c in (k,c)(\\leq)-SETWL is also not clear. Asymptotic runtime would also help in visualizing where exactly the speedup comes from.\nThe empirical evaluation should include additional recent expressive GNN models to properly understand the benefits of SET-GNN in comparison with other more expressive models like GraphSNN (Wijesinghe, et al. (2021)), PF-GNN (Dupty et al. (2021)), GNNML3 (Balcilar et al. (2021)) etc. This would also be important since these methods employ different techniques to achieve expressivity and SETGNN can be analysed in perspective.\nThe paper can be significantly improved in readability if some pictures are added to describe the key points where redundancy is removed from tuple to multisets, then multisets to sets.\nLine 238: derivation not in Appendix\nLine 183, it should n_u in place of n_n\n\nOverall, I find the idea of the paper novel as well as very significant for improving the expressivity of GNNs. Also, the idea is systematically and rigorously developed towards providing a finer scale for measuring expressivity. \nHowever, I could not fully grasp the proofs and hence I\u2019m less confident, especially since the results are somewhat surprising. Furthermore, experimental results need to be properly placed with respect to the recent literature.\nReferences:\n\n[1] Wijesinghe, et al. (2021).  A New Perspective on\" How Graph Neural Networks Go Beyond Weisfeiler-Lehman?\". In International Conference on Learning Representations.\n[2] Dupty et al. (2021) \"PF-GNN: Differentiable particle filtering based approximation of universal graph representations.\" International Conference on Learning Representations.\n[3] Balcilar et al. (2021)  \"Breaking the limits of message passing graph neural networks.\" International Conference on Machine Learning. PMLR.",
                "Questions": "Please address the weakness mentioned above.",
                "Limitations": "The authors have discussed some limitations. There is no potential negative societal impact.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "4 excellent",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This work proposes a more fine-grained graph isomorphism test hierarchy, namely (k,c)(<=)-SetWL, by further considering removing order, removing repetition, and graph sparsity over the original k-WL algorithm. Based on the obtained graph isomorphism test algorithm, it further develops a progressively expressive GNN accordingly. Experiments on synthetic and real datasets are performed to evaluate the effectiveness of the proposed GNN.",
                "Strengths And Weaknesses": "+++ Pros\n(1) It is technically sound to consider removing order, removing repetition, and graph sparsity over the original k-WL algorithm. The step-by-step derivation is sound and clearly present.\n(2) This work also characterizes the expressiveness of the obtained k-WL variants clearly. It is impressive to me to know that k-MultisetWL is as expressive as the original k-WL. This result might have impact to the community.\n(3) The presentation of this work is great. Although it has a lot of math, the flow is generally easy to follow.\n(4) The empirical results are strong to demonstrate the effectiveness of the proposed GNN.\n+++ Cons\n(1) Although the presentation is good enough, there are several places which are hard to understand, given that this is a math-heavy work. For example, the result given in Theorem 1 is amazing, it would be great to provide some intuitive explanation of the proof in the main text. This can also help readers to understand why we consider removing orders.\n(2) Similarly, the derivation of Theorem 4 is also unclear to me. Please see the following question for details.",
                "Questions": "(1) I am not fully understand the derivation of Theorem 4 ((k,c)(<=)-SetGNN is as expressive as (k,c)(<=)-SetWL). In the given proof, it is mainly based on the results of DeepSet. In other words, MLP with summation is universal so that it can learn the desired injective function. However, this may not prove that Eq. (9) is injective directly, since the input of the outer MLP in Eq. (9) has four parts. It is unclear and non-trivial that how to ensure that this MLP can learn an injective function.\n+++minor points\nLine 182, a should be an",
                "Limitations": "Not applicable.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "4 excellent",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The goal of this paper is to develop more expressive GNNs using the k-WL hierarchy. While the one-dimensional Weisfeiler Leman (1-WL) helps to distinguish isomorphic graphs, the use of k-WL hierarchy helps build more expressive GNNs.  The authors propose (k,c) <= SETWL which reduces the complexity of the k-WL hierarchy. Tweaking k and c in this model, helps develop practical and progressively expressive GNNs.",
                "Strengths And Weaknesses": "Strengths\n\nThe paper is well written with both theoretical and empirical work. \nAn interesting problem on expressiveness of GNNs is explored using set theoretic tools along with message passing algorithms\n\nWeakness\n\nThe problem needs to be better motivated -- how is expressiveness related to generalization performance? Why use (k,c) (<=)-SETGNN at all?\nThe paper assumes an audience well versed with graph isomorphism, Weisfeiler Leman hierarchy, and other kinds of isomorphism test. A reader unfamiliar with these concepts would wonder why even this is relevant. Motivating with concrete real world examples would perhaps make it easier to see why this is an important problem to solve.",
                "Questions": "What is the basic definition of \"expressiveness\" of a GNN model? Does increased expressiveness of the super-graph imply better generalization performance?\n\nIs expressiveness related to interpretability of the model? If not, what marks the fundamental difference between them?\n\nWhy is the work consistently using GNNs when the literature is replete with many other kinds of neural networks whose expressiveness can be studied and interpreted?\n\nThe motivation for (k,c) (<=)-SETGNN has not been well discussed.\n\nSection 5: What is a SOTA expressive GNN? The acronym has not been defined.\n -For ease of readability, consider having a notation table instead of the section 3\n -Table 1,2,3,4 and 5 should simply use two places of decimals for ease of readability\n\n\n The authors claim \"Such a hierarchy could enable us to gradually build more expressive models which admit improved scaling, and avoid unnecessary leaps in model complexity for tasks which do not require them, guarding against overfitting.\"\n What is the relation between expressivity of a graph and graph isomorphism?\n In Table 2, with k=3 or 4, and more than one connected components, the performance on the test set is much worse than on the train set. So for these highly expressive graphs, how is generalization performance demonstrated to be better?",
                "Limitations": "Complexity of the proposed technique in addition to scalability are clearly limitations which the authors try to solve and are successful to a good extent.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper introduces a family of models, namely (k, c)(\u2264)-SETGNN, whose expressiveness increases with k and c.\nThe expressiveness is measured in terms of the newly proposed hierarchy (k, c)(\u2264)-SETWL which is more \"granular\" than the standard k-WL hierarchy.\nThe presentation guides the reader to the derivation of the (k, c)(\u2264)-SETWL by iteratively refining the k-WL hierarchy.\nThe paper comes with proofs relating the various refinements and experiments that investigate the progressive expressiveness of the proposed architecture for varying k and c.",
                "Strengths And Weaknesses": "Strengths\n\nThe empirical evaluation shows increased performance wrt existing methods\nThe proposed architecture's expressiveness can be modulated easily through the k and c parameters.\n\nWeaknesses\n\nIt's unclear whether one can use the new proposed \"ruler\" (the (k, c)(\u2264)-SETWL hierarchy) to compare existing models and whether new models other than (k, c)(\u2264)-SETGNN can be built around it. Consequently, the significance appears rather limited.\n\nMinor comments:\n\ns is not defined in line 135 but introduced much later in line 175\nFig. 1 needs a few more iterations. Many edges are disconnected from their endpoints and the labels (1, 5 etc.) of the nodes are not centered.",
                "Questions": "Is it possible to analyse the expressiveness of existing approaches in term on the new hierarchy?\nDid you use the parameter budget (100K or 500K) as prescribed by ZINC-12K?\nThe linked repository is empty, please update it.",
                "Limitations": "n/a",
                "Ethics Flag": "No",
                "Ethics Review Area": "I don\u2019t know",
                "Soundness": "2 fair",
                "Presentation": "1 poor",
                "Contribution": "1 poor",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "soundness_avg": 2.75,
        "presentation_avg": 3.0,
        "contribution_avg": 3.0,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is clear that the paper addresses an important problem of improving the expressivity of GNNs beyond the 1-WL framework. The proposed (k,c)(\u2264)-SetWL hierarchy and its neural counterpart (k,c)(\u2264)-SETGNN show promising results in terms of expressiveness and performance on both synthetic and real datasets. \n\nWhile there are some weaknesses and limitations pointed out by the reviewers, such as the need for better motivation, clearer explanations of the proofs, and comparisons with other expressive GNN models, the overall consensus is that the paper is technically solid and has the potential for high impact in the field. \n\nConsidering the strictness of the conference, which is set at 0.5, it is recommended to accept the paper. The confidence in this recommendation is certain, as the strengths of the paper outweigh the weaknesses and limitations mentioned by the reviewers."
    },
    "The_Impact_of_Task_Underspecification_in_Evaluating_Deep_Reinforcement_Learning": {
        "link": "https://openreview.net//forum?id=F_9w7Wl78IH",
        "pub_url": "https://openreview.net/forum?id=F_9w7Wl78IH",
        "pdf_link": "https://openreview.net//pdf?id=F_9w7Wl78IH",
        "paper_id": "F_9w7Wl78IH",
        "title": "The_Impact_of_Task_Underspecification_in_Evaluating_Deep_Reinforcement_Learning",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Less certain\nThis paper proposes to evaluate deep RL algorithms on a family of MDPs, rather than single 'point' MDPs.  This seems a reasonable way to reduce performance variance, though I found the paper to be quite lacking in terms of depth, realism, and real impact.\nIn particular, the construction of the family of MDPs seems like a hard problem in general, which does not get a deep treatment in this paper. For instance, for many 'point' MDPs that might actually be of real-world interested it might be quite easy to construct a family of MDPs in a seemingly reasonable way, but for which change the conclusions in such a way that they do not generalise to problems of actual interest anymore.  Furthermore, as also raised by reviewers, if the goal is to evaluate generality of an algorithm, it would seem much better to evaluate on a benchmark of carefully-chosen (e.g., actually-interesting) diverse point MDPs than on a family of similar MDPs constructed around a single point.  Finally, many 'point' MDPs might contain substantial randomness themselves, and the distinction and similarlities between sampling multiple random (task) seeds on a single point MDP versus sampling from a family of MDPs is not sufficiently discussed.\nDespite these limitations, I think it is good for the community to engage into discussions on how best to evaluate its methods.  I will therefore take the recommendation of the reviewers, and accept this paper.  I hope the comments on limitations above will resonate with the authors, or might inspire reasonable pushback about parts on which I'm perhaps being naive, given the authors will likely have thought about these issues a great deal.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper presents the issue of task underspecification in evaluating reinforcement learning algorithms. This issues emerges when an RL algorithm is evaluated on a single instance of an underlying (often implicit) task family, and then that performance is implicitly assumed to be robust to the choice of instance in the task family. The paper shows that this robustness is often not the case, and in some cases the ordering between different algorithms can change when different task instances from the task family are chosen. Recommendations for ensuring a more robust evaluation of algorithms are provided, although the core problem of the computational burden of robust evaluations still somewhat remains (and is seemingly unavoidable).\nStrengths And Weaknesses: I think the issue of task underspecification, especially in the traffic control domain used, is a real one. The demonstration of this phenomena is valuable and significant. The paper is generally well-written and clear. I think the recommendations for more robust evaluation are beneficial, and the results in section 4 are interesting and beneficial to the research community, especially in the RL traffic control literature (which I'm less familiar with).\nTo me, the key issue arising from task underspecification is when the relative performance or ordering of different methods changes when making choices that were implicitly assumed not to change the relative performance or ordering. This is what is demonstrated very clearly in the traffic control domain, where the experiments demonstrate that when performing a more robust evaluation, the non-RL methods are preferred. Further, I think the results in observation 2 are unsurprising (different point MDPs are difficult); and we don't really care about absolute performance of algorithms on these toy benchmarks, as it's not that useful as information about how well they'll do on some other down-stream task. Performance relative to other algorithms (to enable an informed choice of which algorithm to use for a downstream task), or to a human expert on the task (so as to have a notion of whether the algorithm can outperform humans on some narrow domain), are more important.\nGiven this, it would be beneficial to highlight this precise phenomena in the other experiments. Figure 1 doesn't make it easy to see if choosing a different point MDP changes the preferred algorithm, or if it would also change if averaging over the performance across all point MDPs. More broadly, I'd prefer to see more of an emphasis and investigation of the possibility of this phenomena of reordering algorithms, for example another problem settings and with other algorithms. I imagine a key place where this could occur is in more complicated continuous control settings such as MuJoCo/DMControl/Brax. Investigating whether changing the physical parameters or agent morphology parameters (in a similar way to the experiments in section 2) also changes the SOTA algorithm would provide more evidence of the conclusions drawn in the paper.\nWhile this paper focused entirely on different point MDPs within an MDP family, a common method of evaluation is to consider a task family, such as a variety of MuJoCo, Atari or Procgen tasks, to ensure that evaluation of the algorithm is robust. A comparison of the discussion in this paper to works with that evaluation protocol would be beneficial; crucially, demonstrating that the problem of non-robust evaluation demonstrated in the toy settings and the traffic control setting aren't just specific to those settings, and that evaluation on a range of (point MDPs from) different tasks solves the problem that's caused by task underspecification in terms of robust evaluation.\nOverall, I'm currently recommending a weak reject, due to the fact that I don't think the scientific contribution of the paper is sufficient. I think the most interesting results are those presented in section 4, and if similar results could be demonstrated in other domains (as mentioned above) and with more algorithms, then I would raise my score to recommending acceptance. I realise this requires a high computational workload. If these results were demonstrated, and the recommendations for improving the robustness of evaluations were applied to them successfully, then I think the paper would be a robust and worthwhile contribution worthy of acceptance.\nEDIT: I thank the authors for their diligent efforts in responding to my comments. Given the new experimental results seem to validate this phenomena across a sufficiently wide variety of environments, I'll raise my score from 4 to 6.\nQuestions: What do you mean when you say that \"not all parallel runs succeed\" in footnote 1? Do you mean they don't converge? If so, I think it's more representative to also plot the failing (i.e. non-converging) runs also, so as not to give a skewed picture of the performance of different algorithms.\nIn figure 1, is each algorithm trained once on each MDP, and then tested on all the MDPs labelled on the x axis? Also, it would be good to see which random MDP is chosen in each case, as that would explain the performance of each algorithm trained on this MDP.\nLimitations: I think a more explicit discussion of the fact that the experiments are limited to two specific domains (traffic control and small-scale continuous control) would be beneficial: either discussing this limitation, or addressing it through further experiments.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 2 fair\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper identifies a largely overlooked issue of task underspecification in the deep reinforcement learning (DRL) community: the performance of DRL approaches has been typically assessed on point MDPs, which are only special instances of the corresponding MDP families in many real-world problems. The paper empirically demonstrates that this selection bias can result in significant discrepancies in the relative performance of DRL approaches across different point MDPs in control benchmarks and a real-world traffic signal control problem, and suggests a series of recommendations for designing more accurate and efficient performance evaluation protocols.\nStrengths And Weaknesses: Strengths\n\nThis paper contributes to the well-known and important problem in the DRL community of performance evaluations of DRL algorithms.\nThe identified task underspecification issue is interesting and not covered by prior work on performance evaluations of RL as far as I can tell.\nThe paper is well-organized and well-written.\n\nWeaknesses\n\nI am a little doubtful about whether the suggested three techniques (random sampling with or without replacements & k-means clustering) for evaluating DRL methods on a family of MDPs are generally practical. While they would clearly be better than the traditional protocol of evaluating DRL algorithms only on point MDPs, balancing the efficiency and the reliability of these evaluations (e.g., deciding the sampling number or the number of clusters) still seems to be a non-trivial task without sufficient domain knowledge.\nCompared with prior work on the evaluation protocols of RL algorithms, the evaluation in this paper is less extensive. I agree that using a real-world problem where RL algorithms are actually employed is beneficial for highlighting the pitfalls of the current protocol in realistic scenarios. However, given that the authors have argued that the task underspecification issue is prevalent in common DRL benchmarks, it would be great if more empirical results (e.g., on some of the environments listed in Table 1 in the appendix) are reported to show the generality of such pitfalls.\nQuestions: \nHow are the parameters of different point MDPs selected for each MDP family in Table 2 in the appendix? Are they selected by some sort of randomization or according to the prior knowledge of the tasks?\nIn general, what is the main advantage of random sampling from a family of MDPs with replacements over random sampling without replacements? My current intuition is that if different point MDPs are of sufficiently different probabilities when being sampled, then random sampling with replacements may be better than random sampling without replacements since the latter may excessively alter the inherent distribution of point MDPs. Are there other explanations?\n\nMinor\n\nLine 72: pifalls \u2192 pitfalls\nTable 2, last row: MPDs \u2192 MDPs\nLine 88 in the appendix: missing reference\nLimitations: No concern.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper argues that RL algorithms should be evaluated on a suite of families of similar tasks (e.g., Mujoco benchmark that includes several parameterizations of Hopper with different limb lengths / weights / rewards, etc.) as opposed to a suite of individual tasks (e.g., Mujoco benchmark that includes only one particular parameterization of Hopper). It shows that the same algorithm can have different performance under different parameterizations of individual environments and argues that good evaluation in deep RL should therefore measure performance based on families of tasks. It provides recommendations for evaluating deep RL algorithms going forward, which include the creation of benchmarks that depict families of tasks.\nStrengths And Weaknesses: Originality: This is definitely an original take. The authors seem to adopt a single MDP approach (rather than a robust RL / domain randomization approach / OOD generalization approach), but assert that algorithms should be evaluated on several similar single MDPs. \nQuality/Significance: I was not persuaded by the authors that the problem they are addressing affects deep RL as a whole or that it can accurately be termed \u201ctask underspecification\u201d, or that their proposed approach is necessary or helpful in the evaluation of deep RL algorithms (as opposed to the suites of tasks that they recommend modifying at line 209). I buy the Section 4 case example, as one instance where, if we seek to make conclusions about the performance of RL algorithms on the family of tasks, then we should evaluate the RL algorithms on the family of tasks, but this is an argument against relying on a single task to evaluate an RL algorithm, rather than an argument for using a family of tasks vs a suite of tasks. For this reason, it is difficult for me to give this a high score on quality and significance. My reasoning is as follows; responses appreciated.\n\nBenchmarks already include a variety of tasks/MDPs. Not only do these tasks/MDPs differ, but they are quite diverse, with entirely different setups. It is unclear why evaluating on a family of similar MDPs (the \u201cfamily of MDPs\u201d) is superior to evaluating on a suite of tasks  (Atari has 57 games; do we need to add noise to all 57 to get a suite of 5700 games, where there are very similar sets of 100?). Of course, you can say it is because there are more tasks, but that would change the scope/thesis of the paper.\nThe tasks are not underspecified\u2026 they are precisely specified. Pendulum is a specific pendulum, with a particular mass and length. Of course they are chosen somewhat arbitrarily, but that\u2019s the point\u2026 that a good RL algorithm should perform well on any reasonable/solvable MDP. Choosing a family of tasks would be similarly arbitrary, and may involve creating unreasonable/unsolvable MDPs.\nThere is insufficient evidence to support the hypothesis at lines 41-43. I do not see anywhere in Sections 2 where there is error in the evaluation due to the use of a point MDP rather than a familiar of MDPs. It is known that DRL methods are noisy, and that\u2019s why we test them on a benchmark suite of several envs. On the other hand, Section 4 is a nice example, and while it is indeed \u201cevidence of pitfalls in point MDP-based evaluations\u201d (Footnote 4), I don\u2019t see as providing sufficient support for the bolded hypothesis at lines 41-43, or the comment/recommendation at line 209. \nRe: lines 99-106 about Figure 1... The observations (1)-(2) are obvious. In my view, the observation (3) simply lacks evidence. How many seeds were tested, where are the confidence bounds? In any case, noise in one task that shows up when evaluating it on the task family, would also show up when evaluating the algorithm on the full suite. Also it is unclear why TD3 is used in one figure, but TRPO in the others.\nSection 2 Observation 2 would also apply to across tasks in a suite (they don\u2019t need to be part of the same task family). \nLine 193: Is anyone claiming that these RL algorithms generalize to the model family? I would think not, because that is what multi-task RL / robust RL are about.\n\nI recognize that a large part of my criticism has to do with the framing of the paper. I think if the thesis of this paper were modified to be less \"all encompassing\", and more along the lines of the more specific thesis of robust RL (that when seeking to transfer RL algorithms to similar scenarios, we should change our approach to training/evaluation), that might fix the issues. But in that case, the recommendations may need to be modified. To maintain the current thesis, I would want to see the paper demonstrate an advantage of using families of similar tasks, over suites of different tasks. I suspect such an advantage would be hard to demonstrate. Alternatively, the authors could demonstrate that the recommendation is easy to implement, by modifying one of the suites themselves (Mujoco control suite is probably easiest since there are only a few environments --- would it change the usual empirical results; e.g., re: DDPG, TD3, SAC, or model-based RL?) \nClarity: Overall the paper is well written / clear.\nQuestions: Why is a suite of different tasks insufficient, as opposed to a family of tasks?\nLimitations: Yes\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper presents the issue of task underspecification in evaluating reinforcement learning algorithms. This issues emerges when an RL algorithm is evaluated on a single instance of an underlying (often implicit) task family, and then that performance is implicitly assumed to be robust to the choice of instance in the task family. The paper shows that this robustness is often not the case, and in some cases the ordering between different algorithms can change when different task instances from the task family are chosen. Recommendations for ensuring a more robust evaluation of algorithms are provided, although the core problem of the computational burden of robust evaluations still somewhat remains (and is seemingly unavoidable).",
                "Strengths And Weaknesses": "I think the issue of task underspecification, especially in the traffic control domain used, is a real one. The demonstration of this phenomena is valuable and significant. The paper is generally well-written and clear. I think the recommendations for more robust evaluation are beneficial, and the results in section 4 are interesting and beneficial to the research community, especially in the RL traffic control literature (which I'm less familiar with).\nTo me, the key issue arising from task underspecification is when the relative performance or ordering of different methods changes when making choices that were implicitly assumed not to change the relative performance or ordering. This is what is demonstrated very clearly in the traffic control domain, where the experiments demonstrate that when performing a more robust evaluation, the non-RL methods are preferred. Further, I think the results in observation 2 are unsurprising (different point MDPs are difficult); and we don't really care about absolute performance of algorithms on these toy benchmarks, as it's not that useful as information about how well they'll do on some other down-stream task. Performance relative to other algorithms (to enable an informed choice of which algorithm to use for a downstream task), or to a human expert on the task (so as to have a notion of whether the algorithm can outperform humans on some narrow domain), are more important.\nGiven this, it would be beneficial to highlight this precise phenomena in the other experiments. Figure 1 doesn't make it easy to see if choosing a different point MDP changes the preferred algorithm, or if it would also change if averaging over the performance across all point MDPs. More broadly, I'd prefer to see more of an emphasis and investigation of the possibility of this phenomena of reordering algorithms, for example another problem settings and with other algorithms. I imagine a key place where this could occur is in more complicated continuous control settings such as MuJoCo/DMControl/Brax. Investigating whether changing the physical parameters or agent morphology parameters (in a similar way to the experiments in section 2) also changes the SOTA algorithm would provide more evidence of the conclusions drawn in the paper.\nWhile this paper focused entirely on different point MDPs within an MDP family, a common method of evaluation is to consider a task family, such as a variety of MuJoCo, Atari or Procgen tasks, to ensure that evaluation of the algorithm is robust. A comparison of the discussion in this paper to works with that evaluation protocol would be beneficial; crucially, demonstrating that the problem of non-robust evaluation demonstrated in the toy settings and the traffic control setting aren't just specific to those settings, and that evaluation on a range of (point MDPs from) different tasks solves the problem that's caused by task underspecification in terms of robust evaluation.\nOverall, I'm currently recommending a weak reject, due to the fact that I don't think the scientific contribution of the paper is sufficient. I think the most interesting results are those presented in section 4, and if similar results could be demonstrated in other domains (as mentioned above) and with more algorithms, then I would raise my score to recommending acceptance. I realise this requires a high computational workload. If these results were demonstrated, and the recommendations for improving the robustness of evaluations were applied to them successfully, then I think the paper would be a robust and worthwhile contribution worthy of acceptance.\nEDIT: I thank the authors for their diligent efforts in responding to my comments. Given the new experimental results seem to validate this phenomena across a sufficiently wide variety of environments, I'll raise my score from 4 to 6.",
                "Questions": "What do you mean when you say that \"not all parallel runs succeed\" in footnote 1? Do you mean they don't converge? If so, I think it's more representative to also plot the failing (i.e. non-converging) runs also, so as not to give a skewed picture of the performance of different algorithms.\nIn figure 1, is each algorithm trained once on each MDP, and then tested on all the MDPs labelled on the x axis? Also, it would be good to see which random MDP is chosen in each case, as that would explain the performance of each algorithm trained on this MDP.",
                "Limitations": "I think a more explicit discussion of the fact that the experiments are limited to two specific domains (traffic control and small-scale continuous control) would be beneficial: either discussing this limitation, or addressing it through further experiments.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper identifies a largely overlooked issue of task underspecification in the deep reinforcement learning (DRL) community: the performance of DRL approaches has been typically assessed on point MDPs, which are only special instances of the corresponding MDP families in many real-world problems. The paper empirically demonstrates that this selection bias can result in significant discrepancies in the relative performance of DRL approaches across different point MDPs in control benchmarks and a real-world traffic signal control problem, and suggests a series of recommendations for designing more accurate and efficient performance evaluation protocols.",
                "Strengths And Weaknesses": "Strengths\n\nThis paper contributes to the well-known and important problem in the DRL community of performance evaluations of DRL algorithms.\nThe identified task underspecification issue is interesting and not covered by prior work on performance evaluations of RL as far as I can tell.\nThe paper is well-organized and well-written.\n\nWeaknesses\n\nI am a little doubtful about whether the suggested three techniques (random sampling with or without replacements & k-means clustering) for evaluating DRL methods on a family of MDPs are generally practical. While they would clearly be better than the traditional protocol of evaluating DRL algorithms only on point MDPs, balancing the efficiency and the reliability of these evaluations (e.g., deciding the sampling number or the number of clusters) still seems to be a non-trivial task without sufficient domain knowledge.\nCompared with prior work on the evaluation protocols of RL algorithms, the evaluation in this paper is less extensive. I agree that using a real-world problem where RL algorithms are actually employed is beneficial for highlighting the pitfalls of the current protocol in realistic scenarios. However, given that the authors have argued that the task underspecification issue is prevalent in common DRL benchmarks, it would be great if more empirical results (e.g., on some of the environments listed in Table 1 in the appendix) are reported to show the generality of such pitfalls.",
                "Questions": "How are the parameters of different point MDPs selected for each MDP family in Table 2 in the appendix? Are they selected by some sort of randomization or according to the prior knowledge of the tasks?\nIn general, what is the main advantage of random sampling from a family of MDPs with replacements over random sampling without replacements? My current intuition is that if different point MDPs are of sufficiently different probabilities when being sampled, then random sampling with replacements may be better than random sampling without replacements since the latter may excessively alter the inherent distribution of point MDPs. Are there other explanations?\n\nMinor\n\nLine 72: pifalls \u2192 pitfalls\nTable 2, last row: MPDs \u2192 MDPs\nLine 88 in the appendix: missing reference",
                "Limitations": "No concern.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper argues that RL algorithms should be evaluated on a suite of families of similar tasks (e.g., Mujoco benchmark that includes several parameterizations of Hopper with different limb lengths / weights / rewards, etc.) as opposed to a suite of individual tasks (e.g., Mujoco benchmark that includes only one particular parameterization of Hopper). It shows that the same algorithm can have different performance under different parameterizations of individual environments and argues that good evaluation in deep RL should therefore measure performance based on families of tasks. It provides recommendations for evaluating deep RL algorithms going forward, which include the creation of benchmarks that depict families of tasks.",
                "Strengths And Weaknesses": "Originality: This is definitely an original take. The authors seem to adopt a single MDP approach (rather than a robust RL / domain randomization approach / OOD generalization approach), but assert that algorithms should be evaluated on several similar single MDPs. \nQuality/Significance: I was not persuaded by the authors that the problem they are addressing affects deep RL as a whole or that it can accurately be termed \u201ctask underspecification\u201d, or that their proposed approach is necessary or helpful in the evaluation of deep RL algorithms (as opposed to the suites of tasks that they recommend modifying at line 209). I buy the Section 4 case example, as one instance where, if we seek to make conclusions about the performance of RL algorithms on the family of tasks, then we should evaluate the RL algorithms on the family of tasks, but this is an argument against relying on a single task to evaluate an RL algorithm, rather than an argument for using a family of tasks vs a suite of tasks. For this reason, it is difficult for me to give this a high score on quality and significance. My reasoning is as follows; responses appreciated.\n\nBenchmarks already include a variety of tasks/MDPs. Not only do these tasks/MDPs differ, but they are quite diverse, with entirely different setups. It is unclear why evaluating on a family of similar MDPs (the \u201cfamily of MDPs\u201d) is superior to evaluating on a suite of tasks  (Atari has 57 games; do we need to add noise to all 57 to get a suite of 5700 games, where there are very similar sets of 100?). Of course, you can say it is because there are more tasks, but that would change the scope/thesis of the paper.\nThe tasks are not underspecified\u2026 they are precisely specified. Pendulum is a specific pendulum, with a particular mass and length. Of course they are chosen somewhat arbitrarily, but that\u2019s the point\u2026 that a good RL algorithm should perform well on any reasonable/solvable MDP. Choosing a family of tasks would be similarly arbitrary, and may involve creating unreasonable/unsolvable MDPs.\nThere is insufficient evidence to support the hypothesis at lines 41-43. I do not see anywhere in Sections 2 where there is error in the evaluation due to the use of a point MDP rather than a familiar of MDPs. It is known that DRL methods are noisy, and that\u2019s why we test them on a benchmark suite of several envs. On the other hand, Section 4 is a nice example, and while it is indeed \u201cevidence of pitfalls in point MDP-based evaluations\u201d (Footnote 4), I don\u2019t see as providing sufficient support for the bolded hypothesis at lines 41-43, or the comment/recommendation at line 209. \nRe: lines 99-106 about Figure 1... The observations (1)-(2) are obvious. In my view, the observation (3) simply lacks evidence. How many seeds were tested, where are the confidence bounds? In any case, noise in one task that shows up when evaluating it on the task family, would also show up when evaluating the algorithm on the full suite. Also it is unclear why TD3 is used in one figure, but TRPO in the others.\nSection 2 Observation 2 would also apply to across tasks in a suite (they don\u2019t need to be part of the same task family). \nLine 193: Is anyone claiming that these RL algorithms generalize to the model family? I would think not, because that is what multi-task RL / robust RL are about.\n\nI recognize that a large part of my criticism has to do with the framing of the paper. I think if the thesis of this paper were modified to be less \"all encompassing\", and more along the lines of the more specific thesis of robust RL (that when seeking to transfer RL algorithms to similar scenarios, we should change our approach to training/evaluation), that might fix the issues. But in that case, the recommendations may need to be modified. To maintain the current thesis, I would want to see the paper demonstrate an advantage of using families of similar tasks, over suites of different tasks. I suspect such an advantage would be hard to demonstrate. Alternatively, the authors could demonstrate that the recommendation is easy to implement, by modifying one of the suites themselves (Mujoco control suite is probably easiest since there are only a few environments --- would it change the usual empirical results; e.g., re: DDPG, TD3, SAC, or model-based RL?) \nClarity: Overall the paper is well written / clear.",
                "Questions": "Why is a suite of different tasks insufficient, as opposed to a family of tasks?",
                "Limitations": "Yes",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.333,
        "confidence_avg": 3.667,
        "soundness_avg": 3.333,
        "presentation_avg": 2.667,
        "contribution_avg": 3.0,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the paper addresses an important issue of task underspecification in evaluating reinforcement learning algorithms. The paper provides valuable insights and empirical evidence to demonstrate the impact of task underspecification on the relative performance of different algorithms. While there are some concerns raised by the reviewers regarding the practicality of the proposed evaluation techniques and the scope of the problem, the overall consensus is that the paper makes a technically solid contribution with moderate-to-high impact.\n\nReviewer 1 highlights the significance of the issue and suggests further investigations in different domains and with more algorithms to strengthen the conclusions. The reviewer initially recommends a weak reject but raises the score after the authors provide additional experimental results. \n\nReviewer 2 acknowledges the originality of the paper and agrees with the importance of evaluating RL algorithms on families of tasks. However, they express doubts about the practicality of the proposed evaluation techniques and suggest more empirical results to demonstrate the generality of the problem.\n\nReviewer 3 raises concerns about the framing of the paper and questions the superiority of evaluating on families of tasks compared to suites of different tasks. They also point out the lack of evidence to support the hypothesis and recommendations. However, they acknowledge that the paper is well-written and clear.\n\nTaking into account the strengths and weaknesses identified by the reviewers, I believe that the paper makes a valuable contribution to the field and addresses an important issue. While there are some concerns raised by the reviewers, the overall consensus is positive. Therefore, I recommend accepting the paper."
    },
    "Chaotic_Dynamics_are_Intrinsic_to_Neural_Network_Training_with_SGD": {
        "link": "https://openreview.net//forum?id=ffy-h0GKZbK",
        "pub_url": "https://openreview.net/forum?id=ffy-h0GKZbK",
        "pdf_link": "https://openreview.net//pdf?id=ffy-h0GKZbK",
        "paper_id": "ffy-h0GKZbK",
        "title": "Chaotic_Dynamics_are_Intrinsic_to_Neural_Network_Training_with_SGD",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Less certain\nThis paper studies the role of (local) chaos in determining the training dynamics of neural networks. The authors first introduce a standard global notion of chaos via the Lyapunov matrix and introduce a greedy local version which determines whether the dynamics are \u201clocally chaotic\u201d. The authors relate these dynamics to the eigenvalues of the hessian. The authors close with interesting experiments showing that the chaotic, negative, eigenvalues of the hessian are important for training.\nThis paper generated some debate and ultimately two reviewers favored acceptance, while one reviewer wanted to reject the paper. The two reviewers who wanted to accept the paper appreciated the new emphasis that the paper brought to the negative eigenvalues of the hessian.  The negative reviewer focused on weak experiments and thought the analysis was too similar to the noisy quadratic model. Ultimately, I do think the analysis done here might provide some insight not present in the NQM, since as the authors note, they consider the spectrum throughout training whereas the NQM considers a noise model on top of a fixed hessian. I share the positive reviewers\u2019 feeling that the results about the negative eigenvalues seem quite interesting. At the same time, I do share the negative reviewer\u2019s issue that the experiments might be too simplistic to draw interesting inferences from. \nUltimately, I do think the pros probably outweigh the cons of accepting this paper. However, I would ask the authors whether the description in terms of chaos makes sense since, as they note, they generally only discuss the local behavior for which the notion of chaos doesn\u2019t necessarily make sense.",
        "reviews": [
            "Reviewer 1: \nSummary: The authors conduct a thorough hessian-related analysis of training dynamics in neural network training in several medium-sized tasks.  They analyze the eigenspectrum of the hessian throughout training, and investigate the effects of screening descent directions by various criteria related to properties of the hessian.  Additionally, they provide a bevy of theoretical results on their studied dynamics.\nStrengths And Weaknesses: Originality: while studying hessian eigenspectra is not a new idea, the approach considered by the authors does appear novel (i.e., screening of particular directions during training), and has yielded interesting results\nQuality/Clarity: The paper is quite high quality and clear\nSignificance: I expect this paper to be significant, as it gestures at negative components of the hessian being more important than folks otherwise suspected.\nQuestions: There is a sense in which components of this work are somewhat tautological, and other results might be slightly overstated.  As an example, the authors state:\nIn this paper, we have shown that chaotic dynamics of ANN training by SGD are linked to negative curvature.\n\nThe authors seem to have defined \u201cpresence of chaotic dynamics\u201d to be \u201clocal hessian has negative eigenvalues\u201d.  Consider the following alternative: it could be the case that essentially parabolic regions of the loss landscape are stitched together by a small number of hyperbolic descent directions.  Restricting oneself to only the strictly positive eigenvalues then somewhat definitionally traps the performance of a model to within some locally-minimum basin, whereas restricting oneself to the negative-hessian directions is more akin to a kind of truncated BFGS iteration, where descent to the lowest minima is never truly ruled out.\nIt is not, then, anything particularly \u201cchaotic\u201d about the presence of these negative eigenvalues\u2014only that they\u2019re conduits between more locally quadratic regions.  This would likewise explain why learning trajectories tend to correlate more with the positive curative directions.\nDo the authors have evidence that there is something more \u201cchaotic\u201d going on here, other than eigenvalues being negative?\nAs for the author\u2019s definition of \u201cchaos\u201d:\nGiven a small deviation in the parameter state of a model at any point of the optimization, one should hope to obtain a similar solution at the end of the optimization procedure, and by extension a solution that performs similarly well both on training and validation data. Therefore, we use chaotic to refer to the sensitivity to initial conditions.\n\nIt might be that the community simply needs a different word to describe what is going on with neural network training.  A model whose training dynamics were purely diffusive would also seem to satisfy the author\u2019s notion of \u201cchaotic\u201d.  I suppose we can identify \u201csensitive to initial conditions\u201d with \u201cchaotic\u201d, but this might be overloading the word.\nRegardless, stepping back for a moment and taking a more thousand foot view, here: it seems that the author\u2019s primary result is that \u201cperformance of neural networks degrades when we restrict neural networks to not be able to descend along directions with negative hessian eigenvalues\u201d.  Do the authors agree with this characterization?  Do the authors agree that restricting learning dynamics to positive-semi-definite subspaces of the hessian traps the learning dynamics near a local minimum / saddle point?\nLimitations: Beyond the comments above, many of the training curves in the paper seem not to be fully converged, but given the extreme numerical expense of running this analysis, I don\u2019t think it\u2019s the end of the world.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper studies neural network training dynamics via the lens of the Hessian eigenspectrum. In particular, the authors show that the chaotic dynamics in neural network training are largely determined by the negative eigenvalue of the Hessian. Furthermore, the authors empirically demonstrate that the negative eigenvalue direction is important for making progress in training.\nStrengths And Weaknesses: Strengths:\n\nThe discussion about the role of negative eigenspectrum in optimization is interesting.\n\nWeaknesses:\n\nThe theoretical model of Lyapunov exponent offers no further insights into the training dynamics compared to standard quadratic models or linearized models.\nThe fact that negative eigenvalues would lead to chaotic dynamics is well known in the optimization community. Basically, I feel the whole section 2 is just background and I don't really know what's the contribution of this work.\nAll experiments are done in very toy settings. The authors only conducted experiments on FashionMNIST and USPS, which I don't think very convincing.\nQuestions: See the weaknesses mentioned above.\nOther questions and suggestions:\n\nI suggest the authors clarify the main advantages of Lyapunov exponent analysis over existing analyses. If I understand correctly, most results derived in section 2 can be obtained in a toy quadratic model.\nTo scale up to larger datasets, the authors could check out literature about the Lanczos algorithm and its stochastic version (see e.g. [1]).\n\nReferences:    \n\nAn Investigation into Neural Net Optimization via Hessian Eigenvalue Density\nLimitations: The authors discussed the limitations at the end of the paper. I don't see any negative societal impact of this work as it is an \"understanding\" paper.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 2 fair\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This manuscript mainly investigates a theoretical link between the curvature of the loss function and (local) chaotic dynamics in neural networks training through demonstrating the negative eigenvalue spectrum of the Hessian. Their empirical evidence verifies that the negative eigenspectrum and so the directions of local chaos cannot be removed from SGD without hurting training performance.\nStrengths And Weaknesses: Strengths\nThe main idea of the paper is interesting and it is nice to see a paper that is theoretically principled, and goes about formalizing some dynamical behavior arising in neural networks training. \nWeaknesses\n I checked most of the proofs in detail and spot some errors; for instance:\n\nIt seems that Theorem 2.1 cannot hold in a general case (as is), and some assumptions on the Hessian of the loss (H) are required to be considered. More clear, in the proof of this theorem (Appendix A.5, line 522) it is mentioned that \"Since all eigenvalues of (I\u2212\u03b3H)2 are positive, the matrix is positive definite\". But, all eigenvalues of (I\u2212\u03b3H)2 are not necessarily positive; e.g. when \u03b3H has some eigenvalues equal to 1. I mean let H be a matrix such that  det(I\u2212\u03b3H)=0, then (I\u2212\u03b3H)2 can have zero eigenvalues. For example, let H=diag(1\u03b3,b,c), then (I\u2212\u03b3H)2 obviously has at least one zero eigenvalue. This affects the rest of the proof.\n\nAppendix A.1: In Eq. (19), from right to left, the second term should be \"\u2202\u03b8i(t)\u2202\u03b8j(t)\".\n\nAppendix A.2: It seems that Eq. (22) is written for t=0? So it needs to be modified for t=1. Also is there the assumption v(0)=0 for obtaining Eq. (22)?\n\n\nThere are also some minor issues and typos: \n\nThe definition of chaotic systems (line 47) is for \"smooth\" dynamical systems (DS), but (it is well known that) it is no longer true for \"non-smooth\" DS such as RNNs with ReLU activation function (as piecewise linear DS). Especially, since piecewise linear DS can observe a specific kind of chaos called \"Robust Chaos\" in the absence of periodic windows and coexisting attractors; please see for instance the paper by Banerjee, Yorke and Grebogi: https://doi.org/10.1103/PhysRevLett.80.3049.\n\nPositive mLCE is a standard signature of chaos provided that the system's invariant set is bounded (as in this case two nearby orbits separate exponentially fast, but at the same time their mutual separation cannot go to infinity so that there are also folds). Otherwise a positive mLCE could be related to a diverging orbit which is not chaotic. Therefore, the authors should consider the assumption of \"boundedness\" and perhaps add it to Section 2.2.\n\nIs the reference \" Robbins, H. E. (2007). A stochastic approximation method. Annals of Mathematical Statistics, 22:400\u2013407\" (line 369) correct? I couldn't find such a reference. \n\nLine 89, A.3 ---> A.2\nQuestions: Some effects of the local chaotic dynamics on the training performance is discussed through some experiments. However, I would like to see:  can the relation between local and long-term chaos be proven (mathematically) to demonstrate some problematic effects of local chaos on the training theoretically as well?\nLimitations: The authors have discussed the limitations of the work and there is no potential negative societal impact.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The authors conduct a thorough hessian-related analysis of training dynamics in neural network training in several medium-sized tasks.  They analyze the eigenspectrum of the hessian throughout training, and investigate the effects of screening descent directions by various criteria related to properties of the hessian.  Additionally, they provide a bevy of theoretical results on their studied dynamics.",
                "Strengths And Weaknesses": "Originality: while studying hessian eigenspectra is not a new idea, the approach considered by the authors does appear novel (i.e., screening of particular directions during training), and has yielded interesting results\nQuality/Clarity: The paper is quite high quality and clear\nSignificance: I expect this paper to be significant, as it gestures at negative components of the hessian being more important than folks otherwise suspected.",
                "Questions": "There is a sense in which components of this work are somewhat tautological, and other results might be slightly overstated.  As an example, the authors state:\nIn this paper, we have shown that chaotic dynamics of ANN training by SGD are linked to negative curvature.\n\nThe authors seem to have defined \u201cpresence of chaotic dynamics\u201d to be \u201clocal hessian has negative eigenvalues\u201d.  Consider the following alternative: it could be the case that essentially parabolic regions of the loss landscape are stitched together by a small number of hyperbolic descent directions.  Restricting oneself to only the strictly positive eigenvalues then somewhat definitionally traps the performance of a model to within some locally-minimum basin, whereas restricting oneself to the negative-hessian directions is more akin to a kind of truncated BFGS iteration, where descent to the lowest minima is never truly ruled out.\nIt is not, then, anything particularly \u201cchaotic\u201d about the presence of these negative eigenvalues\u2014only that they\u2019re conduits between more locally quadratic regions.  This would likewise explain why learning trajectories tend to correlate more with the positive curative directions.\nDo the authors have evidence that there is something more \u201cchaotic\u201d going on here, other than eigenvalues being negative?\nAs for the author\u2019s definition of \u201cchaos\u201d:\nGiven a small deviation in the parameter state of a model at any point of the optimization, one should hope to obtain a similar solution at the end of the optimization procedure, and by extension a solution that performs similarly well both on training and validation data. Therefore, we use chaotic to refer to the sensitivity to initial conditions.\n\nIt might be that the community simply needs a different word to describe what is going on with neural network training.  A model whose training dynamics were purely diffusive would also seem to satisfy the author\u2019s notion of \u201cchaotic\u201d.  I suppose we can identify \u201csensitive to initial conditions\u201d with \u201cchaotic\u201d, but this might be overloading the word.\nRegardless, stepping back for a moment and taking a more thousand foot view, here: it seems that the author\u2019s primary result is that \u201cperformance of neural networks degrades when we restrict neural networks to not be able to descend along directions with negative hessian eigenvalues\u201d.  Do the authors agree with this characterization?  Do the authors agree that restricting learning dynamics to positive-semi-definite subspaces of the hessian traps the learning dynamics near a local minimum / saddle point?",
                "Limitations": "Beyond the comments above, many of the training curves in the paper seem not to be fully converged, but given the extreme numerical expense of running this analysis, I don\u2019t think it\u2019s the end of the world.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper studies neural network training dynamics via the lens of the Hessian eigenspectrum. In particular, the authors show that the chaotic dynamics in neural network training are largely determined by the negative eigenvalue of the Hessian. Furthermore, the authors empirically demonstrate that the negative eigenvalue direction is important for making progress in training.",
                "Strengths And Weaknesses": "Strengths:\n\nThe discussion about the role of negative eigenspectrum in optimization is interesting.\n\nWeaknesses:\n\nThe theoretical model of Lyapunov exponent offers no further insights into the training dynamics compared to standard quadratic models or linearized models.\nThe fact that negative eigenvalues would lead to chaotic dynamics is well known in the optimization community. Basically, I feel the whole section 2 is just background and I don't really know what's the contribution of this work.\nAll experiments are done in very toy settings. The authors only conducted experiments on FashionMNIST and USPS, which I don't think very convincing.",
                "Questions": "See the weaknesses mentioned above.\nOther questions and suggestions:\n\nI suggest the authors clarify the main advantages of Lyapunov exponent analysis over existing analyses. If I understand correctly, most results derived in section 2 can be obtained in a toy quadratic model.\nTo scale up to larger datasets, the authors could check out literature about the Lanczos algorithm and its stochastic version (see e.g. [1]).\n\nReferences:    \n\nAn Investigation into Neural Net Optimization via Hessian Eigenvalue Density",
                "Limitations": "The authors discussed the limitations at the end of the paper. I don't see any negative societal impact of this work as it is an \"understanding\" paper.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This manuscript mainly investigates a theoretical link between the curvature of the loss function and (local) chaotic dynamics in neural networks training through demonstrating the negative eigenvalue spectrum of the Hessian. Their empirical evidence verifies that the negative eigenspectrum and so the directions of local chaos cannot be removed from SGD without hurting training performance.",
                "Strengths And Weaknesses": "Strengths\nThe main idea of the paper is interesting and it is nice to see a paper that is theoretically principled, and goes about formalizing some dynamical behavior arising in neural networks training. \nWeaknesses\n I checked most of the proofs in detail and spot some errors; for instance:\n\nIt seems that Theorem 2.1 cannot hold in a general case (as is), and some assumptions on the Hessian of the loss (H) are required to be considered. More clear, in the proof of this theorem (Appendix A.5, line 522) it is mentioned that \"Since all eigenvalues of (I\u2212\u03b3H)2 are positive, the matrix is positive definite\". But, all eigenvalues of (I\u2212\u03b3H)2 are not necessarily positive; e.g. when \u03b3H has some eigenvalues equal to 1. I mean let H be a matrix such that  det(I\u2212\u03b3H)=0, then (I\u2212\u03b3H)2 can have zero eigenvalues. For example, let H=diag(1\u03b3,b,c), then (I\u2212\u03b3H)2 obviously has at least one zero eigenvalue. This affects the rest of the proof.\n\nAppendix A.1: In Eq. (19), from right to left, the second term should be \"\u2202\u03b8i(t)\u2202\u03b8j(t)\".\n\nAppendix A.2: It seems that Eq. (22) is written for t=0? So it needs to be modified for t=1. Also is there the assumption v(0)=0 for obtaining Eq. (22)?\n\n\nThere are also some minor issues and typos: \n\nThe definition of chaotic systems (line 47) is for \"smooth\" dynamical systems (DS), but (it is well known that) it is no longer true for \"non-smooth\" DS such as RNNs with ReLU activation function (as piecewise linear DS). Especially, since piecewise linear DS can observe a specific kind of chaos called \"Robust Chaos\" in the absence of periodic windows and coexisting attractors; please see for instance the paper by Banerjee, Yorke and Grebogi: https://doi.org/10.1103/PhysRevLett.80.3049.\n\nPositive mLCE is a standard signature of chaos provided that the system's invariant set is bounded (as in this case two nearby orbits separate exponentially fast, but at the same time their mutual separation cannot go to infinity so that there are also folds). Otherwise a positive mLCE could be related to a diverging orbit which is not chaotic. Therefore, the authors should consider the assumption of \"boundedness\" and perhaps add it to Section 2.2.\n\nIs the reference \" Robbins, H. E. (2007). A stochastic approximation method. Annals of Mathematical Statistics, 22:400\u2013407\" (line 369) correct? I couldn't find such a reference. \n\nLine 89, A.3 ---> A.2",
                "Questions": "Some effects of the local chaotic dynamics on the training performance is discussed through some experiments. However, I would like to see:  can the relation between local and long-term chaos be proven (mathematically) to demonstrate some problematic effects of local chaos on the training theoretically as well?",
                "Limitations": "The authors have discussed the limitations of the work and there is no potential negative societal impact.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.0,
        "confidence_avg": 3.667,
        "soundness_avg": 2.667,
        "presentation_avg": 2.667,
        "contribution_avg": 2.667,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that this paper makes a significant contribution to the understanding of neural network training dynamics. The authors provide a novel approach by analyzing the eigenspectrum of the hessian and investigating the effects of screening descent directions. While there are some concerns raised by the reviewers regarding the definition of \"chaotic dynamics\" and the limitations of the experiments, overall the paper is technically solid and has moderate-to-high impact. The errors pointed out in the proofs should be addressed, but they do not undermine the main findings of the paper. Therefore, I recommend accepting this paper."
    },
    "A_PAC-Bayesian_Generalization_Bound_for_Equivariant_Networks": {
        "link": "https://openreview.net//forum?id=6dfYc2IUj4",
        "pub_url": "https://openreview.net/forum?id=6dfYc2IUj4",
        "pdf_link": "https://openreview.net//pdf?id=6dfYc2IUj4",
        "paper_id": "6dfYc2IUj4",
        "title": "A_PAC-Bayesian_Generalization_Bound_for_Equivariant_Networks",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Less certain\nThis is a borderline paper studying an interesting question around generalization bounds for equivariant networks. Initially there were significant concerns around presentation of the key results and related work. During the rebuttal phase authors updated the manuscript as per reviewers suggestions, resulting in a significantly better manuscript. I applaud the efforts of all the reviewers who engaged with authors leading to a better submission. One reviewer still kept their negative score, but other reviewers and I believe their concerns were addressed in the updated manuscript. \nOverall I recommend acceptance and it is important that the authors revise the manuscript highlighting the key assumptions upfront about the Fourier space following Reviewer fd7r's suggestions.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper gives generalization bounds on equivariant models for general groups.\nGeneralization bounds for equivariant models in the case of finite groups were given by Sannai et al. but generalization bounds for general groups were not known. The boundary is described by an invariant called multiplicity.\nThis attempt is new to the best of my knowledge.\nStrengths And Weaknesses: The author should first note and cite that generalization bounds are given for finite groups by Sannai et al.\nStrengths\nThis paper differs from Sannai et al. in that it deals with equivariant models that are not limited to finite groups.\nFurthermore, the bounds in this paper use information on the multiplicity of irreducible representations used in the model. This is commendable.\nWeaknesses\nOn the other hand, the right-hand side still has some parts that have not been fully calculated, such as multiplicities.\nAs it is, I do not believe that any useful findings have been obtained.\nOverall, the results are not considered significant.\nQuestions: According to Sannai et al. the generalization gap is obtained by the number of coverings of the quotient space for the group action. Can you see that it is tighter than its bounds?\nLimitations: Properly addressed.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 2 fair\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The authors provide a generalization bound for a class of equivariant neural networks. The generalization bound extends prior bounds in the PAC Bayes literature. The prior PAC Bayes bounds were achieved by applying perturbations to weight matrices and studying the overlap of the posterior with the prior in the standard PAC Bayes setting. Here, perturbations are applied to parameters in the Fourier regime, which is parameterized much more sparsely than the real regime due to properties of linear equivariant layers as a consequence of Schur's Lemma. Their results indicate that the generalization bound they construct scales better with \"group-related\" parameters and may help explain generalization for invariant and equivariant models.\nStrengths And Weaknesses: I was asked to review this paper under short notice and only over a couple of days; therefore, I was only able to read through the main paper. Proofs and mathematical details were not checked. \nOverall, I commend the authors for taking on the task of obtaining generalization bounds for equivariant neural networks. A theoretical understanding of GCNNs is mostly lacking and the results here would take a relatively big step in helping to explain why generalization occurs. The results are definitely new and interesting, but I fear at times the organization and presentation of the paper lets it down. In the short time I had to review this paper, I struggled to understand the main theorem enough to really analyze it in full. The notation and basic setting also took too long for me to comprehend. The mathematical results in this paper are potentially very strong, but I think the authors need to re-organize and write the paper more cleanly for the insights to come through. For this reason, I slightly lean towards rejecting the paper, but welcome a discussion from the authors. Since I only have had a very short time to review this paper, I am open to changing my mind.\nStrengths:\n\nGeneralization bounds, specifically for GCNNs, are hard to find. I, at least, am not familiar with any that specifically look at the architectures the authors analyze. To me, this is an original contribution of the authors' paper.\nIt can be challenging to analyze GCNNs theoretically since the group equivariance property adds yet another constraint to the theoretical analysis. The overall framework and mathematical tools the authors use to attack the problem may be applicable beyond the specific problem of generalization that the authors study.\n\nWeaknesses:\n\nAs a general point, there is little in the way of examples or intuition in this paper. The formula for the generalization bound is quite long. To add onto this, there are multiple norms within the generalization bound which can be challenging to understand even for readers who are familiar with GCNN literature. Comparing this to the bound in the Neyshabur et al. paper, it seems the major difference is in the Frobenius norm term with the dimension of the irrep dividing this factor. Is there anything else that has changed significantly? Is there a simple example where the authors can mathematically show their bound improves upon the Neyshabur et al. bound? For example, what happens with the cyclic group where we know all irreps are dimension 1? \nAfter reading through the choice of equivariant neural network in section 3.2 (and a brief foray into appendix B), it took me a very long time to understand the setup of the basic equivariant layer. As I understand, the authors chose the given parameterization to be as general as possible with their equivariant layer. However, it is very challenging to understand this parameterization without digging into the details of the appendix. It would be nice if this part of the paper were self-standing and a visual example would help greatly to understand notation. \nIt seems that the equivariant parameters here are taken in Fourier space. This may be needed for proofs but as far as I can tell, this is only way to parameterize layers and not necessarily the most common. For example, even in standard convolution (i.e. over cyclic group), filters are parameterized over a sparse set of local elements. This is not necessarily \"easy\" to reconstruct in the Fourier domain as it would require enforcing parameter sharing across frequencies (i.e. just training over parameters in Fourier space will break the locality). Resulting perturbations to obtain generalization bounds may also ignore this locality in this case as enforcing perturbations in Fourier regime will not maintain the locality of the filter. The authors should at least comment on this point and be clear about the parameterization and its relevance to the models used in practice. This, after all, has obvious implications on generalization.\n\nSmaller comments:\n\nThe authors should at least state one commonly used architecture which follows the parameterization that they have selected both to aid intuition and to better ground the findings. \nFigure 3 is hard to read. The font size is very small and the 3-D plots are hard to follow.\nSimilarly, figure 2 is quite crowded and in need of simplification and larger font.\nLine 188: [18] should be [7]?\nLine 240: section reference ??\nLine 218: two periods\n\u03b2 in equation 12 is raised to the power 2L but then in the definition of \u03b2, it is taken to the power 1/L. Why not just ignore the added L factor?\n\nMy recommendations to the authors on how to make the paper more readable:\n\nAdjust section 3.2 to make it clearer how equivariant operations are parameterized. Start from basic definitions of convolution (e.g. in Fourier or real regimes) and then explain how the parameterization that they choose is equivalent to a specific parameterization in the Fourier or real regime. Give an example of an existing architecture to aid intuition. State whether parameterization in the form analyzed can be restricted locally (e.g., restricting to sparse set of irreps is not necessarily equivalent to a sparse real support as stated earlier). Some of the information currently there can be relegated to appendix (e.g. only look at c\u03c8=1 case and relegate rest to appendix).\nProvide intuition behind the generalization bound by perhaps bounding further parameters or looking at a special case where some of the terms become constant. E.g. fix a certain number of layers and then look at the dependence on the other parameters.\nFigures are too crowded right now. it is hard to read any of the figures as they stand and they take up too much space. I would have preferred to have more details on the architecture used to train networks and how that architecture varied for the various points in the figures. Also, a more complete description of how the comparison bound was calculated would be helpful.\n\n\nPost-feedback changes \nI am upgrading my score to a weak accept after the authors' valuable update to the paper and their comments to my feedback. I still have some concerns about the presentation of the paper and the limitations which I have listed in my response to the authors' comments below.\nQuestions: \nHave the authors compared to existing generalization bounds for CNNs? This could be a nice empirical analysis to compare to a special case of equivariant models.\nAre the y-axis values in figure 1 and figure 2 interpretable in any way. It seems that the complexity quantity is actually an order of magnitude or more smaller for the non-equivariant bound. Perhaps constant factors are not included here? This is concerning if the authors are trying to argue that the equivariant generalization bound outperforms the non-equivariant one it is inspired from.\nI assume results here only hold for finite groups? If so, this should be stated explicitly.\nDo bounds here inherently rely on invariance in the underlying model class one wants to learn? For example, if the final layer is fully connected making the network not invariant to the group action, does the bound suffer?\nFrom my understanding, it seems the bound is stronger when the dimension of an irrep in the parameterization is large and the multiplicities are small. Is this correct? On a related point, when all mulitplicities are 1 and all irreps are dimension 1 like in standard convolution over cyclic group, is there any advantage to the proposed bound in theorem 4? It seems that case reduces to the Neyshabur et al. bound as far as I can tell. If so, this would be nice to point out for intuition. Also, it would be interesting to explore whether architectures used in practice actually follow this type of structure.\nLimitations: All limitations are stated in other parts of this review.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 2 fair\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This work introduces a novel PAC-Bayes bound for equivariant networks in which the feature transformation is determined in terms of groups irreps. \u2028\nThe authors propose experiments in which the bound is shown to correlate with the generalization error, and the effect of group size, multiplicity and degree of the layers\u2019 irreps is studied.\nStrengths And Weaknesses: The paper, despite the technical nature of the topic, is mostly clearly written. The assumptions are clearly stated and the proofs in the appendix relatively easy to follow, although I did not check every single step. The paper addresses an interesting topic, that is, the derivation of PAC-Bayes bound for equivariant networks. \nI find it relatively hard to understand the motivation behind some technical assumptions (see section below for an example) about the setting for proving the theorem. I would appreciate if the authors could provide some more motivation behind their choices, or highlight choices that are made purely for a technical standpoint (i.e., it is possible to prove).\nQuestions: I wonder if the assumption of homogeneity is too restricive. Can a bound be derived while relaxing this condition?\nI would invite the authors to include some more relevant literature in their related work section. For instance:\n\u201cGeneralization bounds for deep learning\u201d, Valle-Perez and Louis and reference therein.\nLimitations: The authors point out that, experimentally, their bounds do not decrease with the size of the training size, a fact that should be actually expected. Do the authors have a theoretical explanations/hypothesis for it?\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper studies the generalization bounds of equivariant networks using the PAC-Bayes framework. The principal contribution of this work is an extension of the generalization bound from Neyshabur et. al 2018 to incorporate equivariant architectures by leveraging group and representation theory which allow the authors to characterize the bound using irreducible representations and their multiplicities. The authors also provide an empirical investigation of their generalization bounds on synthetic datasets as well variations of the MNIST dataset.\nStrengths And Weaknesses: The main enjoys many strengths, the first of which is that the main contribution is presented in a clear and coherent way. Characterizing the generalization properties of equivariant networks is both an interesting direction and a needed one as the role of symmetry as powerful inductive biases are missing in the generalization literature. The main theorem and surrounding lemmas seem to be correct---although I did not check the technical details of Theorem 4.4 for correctness in the appendix as I did for the lemmas---and provide a sharp reduction in the hypothesis space and thus give tighter bounds. \nThe main weakness of this paper is that it seems that the authors missed the page limit for this year's NeurIPS is 9 pages and the current draft of the paper is considerably shorter (7.5 pages roughly). This is problematic because there are certain areas in the writing which could benefit from more detail. Chief among these is the experimental section, the plots in Fig 1 and 2 are incomprehensible and their explanations in the text don't add important details. For example, it seems row 2 in Fig 1 has a smaller generalization bound but the caption says that this is the bound obtained from a naive application by Neyshabur et. al 2018? There are also minor grievances that add to an overall lack of polish such as Equation 18 referenced in the main text to be an inequality is not the correct one being referenced in the appendix. There are also broken references (e.g. line 240 in the main text) and minor grammar mistakes all over. Given the additional page limit I encourage the authors to do the following, expand the experiment section and add more clarity. Add the details or bound of Appendix E to the main text as a way to contrast the tighter bound derived in the main text. Finally, provide a better proof sketch of the main theorem to the main text as much of the detail is completely committed (e.g. \u03b7 is not defined in the theorem). My current score is a reflection of the current status of this paper which appears to be a bit rushed and not complete. If the authors can adequately improve upon these the score may change accordingly.\nQuestions: From a technical point of view, the authors primarily work with \u03c1reg in the experiments which amount to the use of group convolutions as in Cohen et. al 2016. How does the current generalization theory change when we move to Steerable G-CNNs that do not use these representations but are built using say irreps, quotient reps, etc ... Secondly, another important symmetry group for ML purposes is Sn which is the symmetric group on n-elements. These can be used to define general permutation equivariant networks [1]. Can the authors bridge how their theory applies to these networks?\n[1] H. Maron, H. Ben-Hamu, N. Shamir, and Y. Lipman. Invariant and equivariant graph networks. In\nICLR, 2019\nLimitations: N/A\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper gives generalization bounds on equivariant models for general groups.\nGeneralization bounds for equivariant models in the case of finite groups were given by Sannai et al. but generalization bounds for general groups were not known. The boundary is described by an invariant called multiplicity.\nThis attempt is new to the best of my knowledge.",
                "Strengths And Weaknesses": "The author should first note and cite that generalization bounds are given for finite groups by Sannai et al.\nStrengths\nThis paper differs from Sannai et al. in that it deals with equivariant models that are not limited to finite groups.\nFurthermore, the bounds in this paper use information on the multiplicity of irreducible representations used in the model. This is commendable.\nWeaknesses\nOn the other hand, the right-hand side still has some parts that have not been fully calculated, such as multiplicities.\nAs it is, I do not believe that any useful findings have been obtained.\nOverall, the results are not considered significant.",
                "Questions": "According to Sannai et al. the generalization gap is obtained by the number of coverings of the quotient space for the group action. Can you see that it is tighter than its bounds?",
                "Limitations": "Properly addressed.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors provide a generalization bound for a class of equivariant neural networks. The generalization bound extends prior bounds in the PAC Bayes literature. The prior PAC Bayes bounds were achieved by applying perturbations to weight matrices and studying the overlap of the posterior with the prior in the standard PAC Bayes setting. Here, perturbations are applied to parameters in the Fourier regime, which is parameterized much more sparsely than the real regime due to properties of linear equivariant layers as a consequence of Schur's Lemma. Their results indicate that the generalization bound they construct scales better with \"group-related\" parameters and may help explain generalization for invariant and equivariant models.",
                "Strengths And Weaknesses": "I was asked to review this paper under short notice and only over a couple of days; therefore, I was only able to read through the main paper. Proofs and mathematical details were not checked. \nOverall, I commend the authors for taking on the task of obtaining generalization bounds for equivariant neural networks. A theoretical understanding of GCNNs is mostly lacking and the results here would take a relatively big step in helping to explain why generalization occurs. The results are definitely new and interesting, but I fear at times the organization and presentation of the paper lets it down. In the short time I had to review this paper, I struggled to understand the main theorem enough to really analyze it in full. The notation and basic setting also took too long for me to comprehend. The mathematical results in this paper are potentially very strong, but I think the authors need to re-organize and write the paper more cleanly for the insights to come through. For this reason, I slightly lean towards rejecting the paper, but welcome a discussion from the authors. Since I only have had a very short time to review this paper, I am open to changing my mind.\nStrengths:\n\nGeneralization bounds, specifically for GCNNs, are hard to find. I, at least, am not familiar with any that specifically look at the architectures the authors analyze. To me, this is an original contribution of the authors' paper.\nIt can be challenging to analyze GCNNs theoretically since the group equivariance property adds yet another constraint to the theoretical analysis. The overall framework and mathematical tools the authors use to attack the problem may be applicable beyond the specific problem of generalization that the authors study.\n\nWeaknesses:\n\nAs a general point, there is little in the way of examples or intuition in this paper. The formula for the generalization bound is quite long. To add onto this, there are multiple norms within the generalization bound which can be challenging to understand even for readers who are familiar with GCNN literature. Comparing this to the bound in the Neyshabur et al. paper, it seems the major difference is in the Frobenius norm term with the dimension of the irrep dividing this factor. Is there anything else that has changed significantly? Is there a simple example where the authors can mathematically show their bound improves upon the Neyshabur et al. bound? For example, what happens with the cyclic group where we know all irreps are dimension 1? \nAfter reading through the choice of equivariant neural network in section 3.2 (and a brief foray into appendix B), it took me a very long time to understand the setup of the basic equivariant layer. As I understand, the authors chose the given parameterization to be as general as possible with their equivariant layer. However, it is very challenging to understand this parameterization without digging into the details of the appendix. It would be nice if this part of the paper were self-standing and a visual example would help greatly to understand notation. \nIt seems that the equivariant parameters here are taken in Fourier space. This may be needed for proofs but as far as I can tell, this is only way to parameterize layers and not necessarily the most common. For example, even in standard convolution (i.e. over cyclic group), filters are parameterized over a sparse set of local elements. This is not necessarily \"easy\" to reconstruct in the Fourier domain as it would require enforcing parameter sharing across frequencies (i.e. just training over parameters in Fourier space will break the locality). Resulting perturbations to obtain generalization bounds may also ignore this locality in this case as enforcing perturbations in Fourier regime will not maintain the locality of the filter. The authors should at least comment on this point and be clear about the parameterization and its relevance to the models used in practice. This, after all, has obvious implications on generalization.\n\nSmaller comments:\n\nThe authors should at least state one commonly used architecture which follows the parameterization that they have selected both to aid intuition and to better ground the findings. \nFigure 3 is hard to read. The font size is very small and the 3-D plots are hard to follow.\nSimilarly, figure 2 is quite crowded and in need of simplification and larger font.\nLine 188: [18] should be [7]?\nLine 240: section reference ??\nLine 218: two periods\n\u03b2 in equation 12 is raised to the power 2L but then in the definition of \u03b2, it is taken to the power 1/L. Why not just ignore the added L factor?\n\nMy recommendations to the authors on how to make the paper more readable:\n\nAdjust section 3.2 to make it clearer how equivariant operations are parameterized. Start from basic definitions of convolution (e.g. in Fourier or real regimes) and then explain how the parameterization that they choose is equivalent to a specific parameterization in the Fourier or real regime. Give an example of an existing architecture to aid intuition. State whether parameterization in the form analyzed can be restricted locally (e.g., restricting to sparse set of irreps is not necessarily equivalent to a sparse real support as stated earlier). Some of the information currently there can be relegated to appendix (e.g. only look at c\u03c8=1 case and relegate rest to appendix).\nProvide intuition behind the generalization bound by perhaps bounding further parameters or looking at a special case where some of the terms become constant. E.g. fix a certain number of layers and then look at the dependence on the other parameters.\nFigures are too crowded right now. it is hard to read any of the figures as they stand and they take up too much space. I would have preferred to have more details on the architecture used to train networks and how that architecture varied for the various points in the figures. Also, a more complete description of how the comparison bound was calculated would be helpful.\n\n\nPost-feedback changes \nI am upgrading my score to a weak accept after the authors' valuable update to the paper and their comments to my feedback. I still have some concerns about the presentation of the paper and the limitations which I have listed in my response to the authors' comments below.",
                "Questions": "Have the authors compared to existing generalization bounds for CNNs? This could be a nice empirical analysis to compare to a special case of equivariant models.\nAre the y-axis values in figure 1 and figure 2 interpretable in any way. It seems that the complexity quantity is actually an order of magnitude or more smaller for the non-equivariant bound. Perhaps constant factors are not included here? This is concerning if the authors are trying to argue that the equivariant generalization bound outperforms the non-equivariant one it is inspired from.\nI assume results here only hold for finite groups? If so, this should be stated explicitly.\nDo bounds here inherently rely on invariance in the underlying model class one wants to learn? For example, if the final layer is fully connected making the network not invariant to the group action, does the bound suffer?\nFrom my understanding, it seems the bound is stronger when the dimension of an irrep in the parameterization is large and the multiplicities are small. Is this correct? On a related point, when all mulitplicities are 1 and all irreps are dimension 1 like in standard convolution over cyclic group, is there any advantage to the proposed bound in theorem 4? It seems that case reduces to the Neyshabur et al. bound as far as I can tell. If so, this would be nice to point out for intuition. Also, it would be interesting to explore whether architectures used in practice actually follow this type of structure.",
                "Limitations": "All limitations are stated in other parts of this review.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This work introduces a novel PAC-Bayes bound for equivariant networks in which the feature transformation is determined in terms of groups irreps. \u2028\nThe authors propose experiments in which the bound is shown to correlate with the generalization error, and the effect of group size, multiplicity and degree of the layers\u2019 irreps is studied.",
                "Strengths And Weaknesses": "The paper, despite the technical nature of the topic, is mostly clearly written. The assumptions are clearly stated and the proofs in the appendix relatively easy to follow, although I did not check every single step. The paper addresses an interesting topic, that is, the derivation of PAC-Bayes bound for equivariant networks. \nI find it relatively hard to understand the motivation behind some technical assumptions (see section below for an example) about the setting for proving the theorem. I would appreciate if the authors could provide some more motivation behind their choices, or highlight choices that are made purely for a technical standpoint (i.e., it is possible to prove).",
                "Questions": "I wonder if the assumption of homogeneity is too restricive. Can a bound be derived while relaxing this condition?\nI would invite the authors to include some more relevant literature in their related work section. For instance:\n\u201cGeneralization bounds for deep learning\u201d, Valle-Perez and Louis and reference therein.",
                "Limitations": "The authors point out that, experimentally, their bounds do not decrease with the size of the training size, a fact that should be actually expected. Do the authors have a theoretical explanations/hypothesis for it?",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper studies the generalization bounds of equivariant networks using the PAC-Bayes framework. The principal contribution of this work is an extension of the generalization bound from Neyshabur et. al 2018 to incorporate equivariant architectures by leveraging group and representation theory which allow the authors to characterize the bound using irreducible representations and their multiplicities. The authors also provide an empirical investigation of their generalization bounds on synthetic datasets as well variations of the MNIST dataset.",
                "Strengths And Weaknesses": "The main enjoys many strengths, the first of which is that the main contribution is presented in a clear and coherent way. Characterizing the generalization properties of equivariant networks is both an interesting direction and a needed one as the role of symmetry as powerful inductive biases are missing in the generalization literature. The main theorem and surrounding lemmas seem to be correct---although I did not check the technical details of Theorem 4.4 for correctness in the appendix as I did for the lemmas---and provide a sharp reduction in the hypothesis space and thus give tighter bounds. \nThe main weakness of this paper is that it seems that the authors missed the page limit for this year's NeurIPS is 9 pages and the current draft of the paper is considerably shorter (7.5 pages roughly). This is problematic because there are certain areas in the writing which could benefit from more detail. Chief among these is the experimental section, the plots in Fig 1 and 2 are incomprehensible and their explanations in the text don't add important details. For example, it seems row 2 in Fig 1 has a smaller generalization bound but the caption says that this is the bound obtained from a naive application by Neyshabur et. al 2018? There are also minor grievances that add to an overall lack of polish such as Equation 18 referenced in the main text to be an inequality is not the correct one being referenced in the appendix. There are also broken references (e.g. line 240 in the main text) and minor grammar mistakes all over. Given the additional page limit I encourage the authors to do the following, expand the experiment section and add more clarity. Add the details or bound of Appendix E to the main text as a way to contrast the tighter bound derived in the main text. Finally, provide a better proof sketch of the main theorem to the main text as much of the detail is completely committed (e.g. \u03b7 is not defined in the theorem). My current score is a reflection of the current status of this paper which appears to be a bit rushed and not complete. If the authors can adequately improve upon these the score may change accordingly.",
                "Questions": "From a technical point of view, the authors primarily work with \u03c1reg in the experiments which amount to the use of group convolutions as in Cohen et. al 2016. How does the current generalization theory change when we move to Steerable G-CNNs that do not use these representations but are built using say irreps, quotient reps, etc ... Secondly, another important symmetry group for ML purposes is Sn which is the symmetric group on n-elements. These can be used to define general permutation equivariant networks [1]. Can the authors bridge how their theory applies to these networks?\n[1] H. Maron, H. Ben-Hamu, N. Shamir, and Y. Lipman. Invariant and equivariant graph networks. In\nICLR, 2019",
                "Limitations": "N/A",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "soundness_avg": 2.5,
        "presentation_avg": 2.25,
        "contribution_avg": 2.75,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is clear that this paper makes a significant contribution to the field by providing generalization bounds for equivariant models. The authors address an important gap in the literature by extending the bounds to cover equivariant models for general groups, rather than just finite groups. The use of irreducible representations and their multiplicities in the bounds is commendable and adds to the novelty of the paper.\n\nWhile there are some weaknesses pointed out by the reviewers, such as the lack of fully calculated parts and the need for clearer presentation and organization, these weaknesses do not outweigh the strengths and contributions of the paper. The reviewers also acknowledge the technical soundness and potential impact of the paper.\n\nTherefore, I recommend accepting this paper. The authors should address the minor issues raised by the reviewers, such as improving the clarity of the experimental section and fixing broken references, to further enhance the quality of the paper."
    },
    "Autoregressive_Perturbations_for_Data_Poisoning": {
        "link": "https://openreview.net//forum?id=1vusesyN7E",
        "pub_url": "https://openreview.net/forum?id=1vusesyN7E",
        "pdf_link": "https://openreview.net//pdf?id=1vusesyN7E",
        "paper_id": "1vusesyN7E",
        "title": "Autoregressive_Perturbations_for_Data_Poisoning",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nThe paper proposed a novel auto-regressive perturbation method to make the data unlearning. The method is independent to models and data, making it more easy to be used. Reviewers found the idea is novel and intuitively reasonable. The authors responded to reviewers' detailed questions about the method and experiments. The rebuttal succeeded to remove the confusions and convince us about the empirical significance. We suggest the authors improve the paper according to the review comments in the next version.",
        "reviews": [
            "Reviewer 1: \nSummary: Paper considers a setting of `unlearnable examples' where a given dataset is perturbed in a way to make it hard to learn the true task. In essence, data here gets perturbed with correlated noise such that when learning is attempted, models learn to focus on the noise rather than on the true features useful for generalisation. While prior work focused on generating class-wise poisons, in this work the noise is generated per sample using a Markov process, producing linearly separatable noise. Paper thoroughly evaluates the setting and demonstrates that the approach effectively stops generalisation when the whole dataset is poisoned and struggles in a similar way in presence of adversrail training or dilution with clean data.\nStrengths And Weaknesses: Strengths:\n\nInteresting setting\nIdea of hardness of learning is rather fascinating\n\nWeaknesses:\n\nUnclear how much of the evaluation is an artifact of chosen optimisation hyperparameters\nUnclear how one compares performance of different correlated noises\nQuestions: Thank you very much for the paper, it is a very interesting read! I only have a handful of questions:\n\nAre tables 4 and 5 computed over a number of models? Given how close the numbers are, it would be great to know if the differences are observed on distributional level, not just per model\nGiven that we can produce arbitrary correlated noise of different flavors, how should one think about it? What is the fundamental difference between the noises in the related literature and the one produced in the paper? This naturally leads to my final question.\nGiven the argument of easier learnability of different noises, it turns the question to how much observed behaviour is an artifact of the optimisation procedure itself? Did you try running the experiments with different lr/optimiser options?\n\nMinor:\n\nPunctuation missing around eqs in some places\nLimitations: N/a\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper proposes a new data poisoning attack to prevent data scraping. The proposed method adds class conditional autoregressive (AR) noise to training data to prevent people from using the data for training, and the method is data and model independent, which means that the same noise can be used to poison different datasets and models of different architectures.\nThe intuition behind the idea is that easy to learn noise is more effective at data poisoning, and AR noise generated in the proposed way is easy for neural network to learn. The authors show that a manually specified 3-layer CNN with AR filter can easily learn class information from the AR noise. Experiments on four benchmark datasets (CIFAR10, STL10, SVHN, CIFAR100) show that the proposed method performs better than other four baselines (Error-min, Error-max, Regions, Random noise).\nStrengths And Weaknesses: Strengths:\n\nThe proposed method is novel as autoregressive process hasn't been used before to do data poisoning. The method is easy to implement and the same AR coefficients can be used for different datasets and architectures as long as the numbers of classes are the same. Though code is not available, pseudo code (algorithms) and implementation details are provided. It is better that if actual code can be provided for reproduction of the results.\n\nThe paper is well-written and easy to follow. Empirical results on four different datasets show that the method performs better than other baselines, both under normal setting and defense settings.\n\n\nWeakness:\n\nThough the proposed method performs better than other baselines compared in the paper, when tested against adversarial training, the performance is not satisfactory. It performs similarly to other baselines under this setting and the poisoning effect is not good, especially when the radii is large.\n\nAs pointed out in the paper, assuming that all the data can be poisoned is not realistic. In section 4.3.3, the poisoning methods are evaluated using a mix of poisoned and clean data. Under this setting, the performance of the proposed method is not good and similar to those of other baselines.\nQuestions: About the process of AR noise generation:\n\nIt is clear how to generate AR noise at the beginning inside the sliding window. How about the subsequent steps? Take the example in Figure 2 as an example, if the sliding window slides one step to the right, there are three values to be generated. Are xt\u22127 up to xt used to generate the next one (xt+1)? Then xt\u22126 up to xt+1 are used to generate xt+2, and so on.\nLimitations: The author points out that the method does not perform well against adversarial training and experiments show that when evaluated using a mix of poisoned and clean data, the performance is also not good.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper proposed autoregressive poisoning techniques to protect data from being exploited by unauthorized machine learning models. The proposed method does not rely on optimizations while generic towards different model architectures and different datasets. This paper also provides insight into why the proposed method is effective.\nStrengths And Weaknesses: Strengths:\n\nThe proposed method is efficient and technically sound. Existing works rely on optimizations which is the bottleneck. The proposed method does not rely on optimizations, and the parameters for AR are easy to find.  \nThe existing works are also shown that do not transfer well between model architectures or datasets. Experiment results show that one set of AR is generic across different architectures or datasets. \nThe efficient and generic can be very practical considering real-world applications.\nExperiment results also demonstrated AR generated unlearnable examples are more robust towards augmentations.\n\n\nLimitations:\n\nOnce the data is released, the defender may not modifies the data anymore, and the model trainer can retroactively apply new models/methods [1]. The adaptive case should be carefully examined. Consider that if the parameters for AR are leaked, can it be used to recover the original image? Or if a portion of the clean images are leaked, using pair of clean and unlearnable versions, is it possible to reverse the AR process? \nIn section 3.3, the assertion that the noises are easy to learn is more effective for poisoning, this could also mean they are easy to detect. Such as calculating sample-specific loss at the end of each training epoch. Although only detecting such samples does not make them \"learnable,\" but adaptive method (if there are any) can be applied to these samples. Or the model trainer could wait for future advancement for the recovery method as mentioned in [1].\n\n[1] Data Poisoning Won\u2019t Save You From Facial Recognition, ICML 2021 Workshop AML\n\nAfter the author's response, I increased my rating score to 7. My main concerns over possible reverse operation if parameters are leaked have been well addressed.\nQuestions: \nIn experiments section line210:  \"We say that poisoning effectiveness drops from setup A to setup B if the network from poison-trained on setup B has higher test set accuracy than the network poison-trained on setup A. \" I find this is confusing.\nFor experiments in Table 4, for clean only, is it the same subset of data as in mixing poisons/clean?\nLimitations: Please address the potential limitations in the Strengths And Weaknesses section.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper proposes to use autoregressive processes to generate perturbations for data poisoning. The generated perturbations, despite looking complex, are actually very simple. One advantage of the proposed method is that its generated perturbations are dataset and architecture independent. The paper evaluates the proposed method on multiple datasets and networks, showing the effectiveness of the perturbations when the poison rate is high.\nStrengths And Weaknesses: The strengths of this paper include\n\nThe proposed attack method is interesting.\nThe proposed method has good transferability.\n\nBut I still have the following concerns:\n\nIs the proposed method only applicable to \u21132 norm? The paper uses the sentence \"We measure AR perturbations\nin \u21132 because measuring in \u2113\u221e would underestimate the extent to which these perturbations are less perceptible than purely  \u2113\u221e random noise\" to explain why it uses \u21132 norm. But this sentence is hard to follow, and this short explanation is not convincing. The paper should provide more clear and convincing explanation about why it only uses \u21132 norm.\n\nThe proposed attack requires high poison rate to be effective? In most experiments, the paper uses poison rate 1. In Table, the lowest poison rate is 0.6. The assumption of high poison rate is very strong. In practice, if the data is collected from multiple sources, then the attack is not effective? In the case that the data is collected from one source (the adversary), the entity who trains the model would be more cautious about the quality of data due to the high risk when the data only comes from one source.\n\nSection 3.3 is not easy to follow, and the logic is not very clear. I think Section 3.3 is one of the most important parts in the paper since it explains why the proposed method works. After reading Section 3.3, I am still very confused. The relation between Lemma 3.1 and the effectiveness of the proposed method in poisoning attacks is not obvious.\nQuestions: \nIs the proposed method only applicable to \u21132 norm?\nThe proposed attack requires high poison rate to be effective?\nIs the proposed method only applicable to computer vision tasks?\nLimitations: \nThe paper only studies \u21132 norm.\nThe poison rate is high. The lowest poison rate studied in the paper is 0.6.\nThe theoretical analysis is not sufficient. The relation between Lemma 3.1 and the effectiveness of the proposed method in poisoning attacks is not obvious.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "Paper considers a setting of `unlearnable examples' where a given dataset is perturbed in a way to make it hard to learn the true task. In essence, data here gets perturbed with correlated noise such that when learning is attempted, models learn to focus on the noise rather than on the true features useful for generalisation. While prior work focused on generating class-wise poisons, in this work the noise is generated per sample using a Markov process, producing linearly separatable noise. Paper thoroughly evaluates the setting and demonstrates that the approach effectively stops generalisation when the whole dataset is poisoned and struggles in a similar way in presence of adversrail training or dilution with clean data.",
                "Strengths And Weaknesses": "Strengths:\n\nInteresting setting\nIdea of hardness of learning is rather fascinating\n\nWeaknesses:\n\nUnclear how much of the evaluation is an artifact of chosen optimisation hyperparameters\nUnclear how one compares performance of different correlated noises",
                "Questions": "Thank you very much for the paper, it is a very interesting read! I only have a handful of questions:\n\nAre tables 4 and 5 computed over a number of models? Given how close the numbers are, it would be great to know if the differences are observed on distributional level, not just per model\nGiven that we can produce arbitrary correlated noise of different flavors, how should one think about it? What is the fundamental difference between the noises in the related literature and the one produced in the paper? This naturally leads to my final question.\nGiven the argument of easier learnability of different noises, it turns the question to how much observed behaviour is an artifact of the optimisation procedure itself? Did you try running the experiments with different lr/optimiser options?\n\nMinor:\n\nPunctuation missing around eqs in some places",
                "Limitations": "N/a",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposes a new data poisoning attack to prevent data scraping. The proposed method adds class conditional autoregressive (AR) noise to training data to prevent people from using the data for training, and the method is data and model independent, which means that the same noise can be used to poison different datasets and models of different architectures.\nThe intuition behind the idea is that easy to learn noise is more effective at data poisoning, and AR noise generated in the proposed way is easy for neural network to learn. The authors show that a manually specified 3-layer CNN with AR filter can easily learn class information from the AR noise. Experiments on four benchmark datasets (CIFAR10, STL10, SVHN, CIFAR100) show that the proposed method performs better than other four baselines (Error-min, Error-max, Regions, Random noise).",
                "Strengths And Weaknesses": "Strengths:\n\nThe proposed method is novel as autoregressive process hasn't been used before to do data poisoning. The method is easy to implement and the same AR coefficients can be used for different datasets and architectures as long as the numbers of classes are the same. Though code is not available, pseudo code (algorithms) and implementation details are provided. It is better that if actual code can be provided for reproduction of the results.\n\nThe paper is well-written and easy to follow. Empirical results on four different datasets show that the method performs better than other baselines, both under normal setting and defense settings.\n\n\nWeakness:\n\nThough the proposed method performs better than other baselines compared in the paper, when tested against adversarial training, the performance is not satisfactory. It performs similarly to other baselines under this setting and the poisoning effect is not good, especially when the radii is large.\n\nAs pointed out in the paper, assuming that all the data can be poisoned is not realistic. In section 4.3.3, the poisoning methods are evaluated using a mix of poisoned and clean data. Under this setting, the performance of the proposed method is not good and similar to those of other baselines.",
                "Questions": "About the process of AR noise generation:\n\nIt is clear how to generate AR noise at the beginning inside the sliding window. How about the subsequent steps? Take the example in Figure 2 as an example, if the sliding window slides one step to the right, there are three values to be generated. Are xt\u22127 up to xt used to generate the next one (xt+1)? Then xt\u22126 up to xt+1 are used to generate xt+2, and so on.",
                "Limitations": "The author points out that the method does not perform well against adversarial training and experiments show that when evaluated using a mix of poisoned and clean data, the performance is also not good.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposed autoregressive poisoning techniques to protect data from being exploited by unauthorized machine learning models. The proposed method does not rely on optimizations while generic towards different model architectures and different datasets. This paper also provides insight into why the proposed method is effective.",
                "Strengths And Weaknesses": "Strengths:\n\nThe proposed method is efficient and technically sound. Existing works rely on optimizations which is the bottleneck. The proposed method does not rely on optimizations, and the parameters for AR are easy to find.  \nThe existing works are also shown that do not transfer well between model architectures or datasets. Experiment results show that one set of AR is generic across different architectures or datasets. \nThe efficient and generic can be very practical considering real-world applications.\nExperiment results also demonstrated AR generated unlearnable examples are more robust towards augmentations.\n\n\nLimitations:\n\nOnce the data is released, the defender may not modifies the data anymore, and the model trainer can retroactively apply new models/methods [1]. The adaptive case should be carefully examined. Consider that if the parameters for AR are leaked, can it be used to recover the original image? Or if a portion of the clean images are leaked, using pair of clean and unlearnable versions, is it possible to reverse the AR process? \nIn section 3.3, the assertion that the noises are easy to learn is more effective for poisoning, this could also mean they are easy to detect. Such as calculating sample-specific loss at the end of each training epoch. Although only detecting such samples does not make them \"learnable,\" but adaptive method (if there are any) can be applied to these samples. Or the model trainer could wait for future advancement for the recovery method as mentioned in [1].\n\n[1] Data Poisoning Won\u2019t Save You From Facial Recognition, ICML 2021 Workshop AML\n\nAfter the author's response, I increased my rating score to 7. My main concerns over possible reverse operation if parameters are leaked have been well addressed.",
                "Questions": "In experiments section line210:  \"We say that poisoning effectiveness drops from setup A to setup B if the network from poison-trained on setup B has higher test set accuracy than the network poison-trained on setup A. \" I find this is confusing.\nFor experiments in Table 4, for clean only, is it the same subset of data as in mixing poisons/clean?",
                "Limitations": "Please address the potential limitations in the Strengths And Weaknesses section.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposes to use autoregressive processes to generate perturbations for data poisoning. The generated perturbations, despite looking complex, are actually very simple. One advantage of the proposed method is that its generated perturbations are dataset and architecture independent. The paper evaluates the proposed method on multiple datasets and networks, showing the effectiveness of the perturbations when the poison rate is high.",
                "Strengths And Weaknesses": "The strengths of this paper include\n\nThe proposed attack method is interesting.\nThe proposed method has good transferability.\n\nBut I still have the following concerns:\n\nIs the proposed method only applicable to \u21132 norm? The paper uses the sentence \"We measure AR perturbations\nin \u21132 because measuring in \u2113\u221e would underestimate the extent to which these perturbations are less perceptible than purely  \u2113\u221e random noise\" to explain why it uses \u21132 norm. But this sentence is hard to follow, and this short explanation is not convincing. The paper should provide more clear and convincing explanation about why it only uses \u21132 norm.\n\nThe proposed attack requires high poison rate to be effective? In most experiments, the paper uses poison rate 1. In Table, the lowest poison rate is 0.6. The assumption of high poison rate is very strong. In practice, if the data is collected from multiple sources, then the attack is not effective? In the case that the data is collected from one source (the adversary), the entity who trains the model would be more cautious about the quality of data due to the high risk when the data only comes from one source.\n\nSection 3.3 is not easy to follow, and the logic is not very clear. I think Section 3.3 is one of the most important parts in the paper since it explains why the proposed method works. After reading Section 3.3, I am still very confused. The relation between Lemma 3.1 and the effectiveness of the proposed method in poisoning attacks is not obvious.",
                "Questions": "Is the proposed method only applicable to \u21132 norm?\nThe proposed attack requires high poison rate to be effective?\nIs the proposed method only applicable to computer vision tasks?",
                "Limitations": "The paper only studies \u21132 norm.\nThe poison rate is high. The lowest poison rate studied in the paper is 0.6.\nThe theoretical analysis is not sufficient. The relation between Lemma 3.1 and the effectiveness of the proposed method in poisoning attacks is not obvious.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.0,
        "confidence_avg": 4.25,
        "soundness_avg": 2.75,
        "presentation_avg": 3.0,
        "contribution_avg": 2.75,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is evident that the proposed method of using autoregressive processes for data poisoning is novel and technically sound. The paper provides clear explanations and thorough evaluations of the method's effectiveness on multiple datasets and networks. While there are some concerns raised by reviewers regarding the applicability of the method to different norms, the high poison rate requirement, and the clarity of the theoretical analysis, these concerns do not outweigh the strengths of the paper. Overall, the paper makes a significant contribution to the field and has the potential for high impact. Therefore, I recommend accepting the paper."
    },
    "Near-Optimal_No-Regret_Learning_Dynamics_for_General_Convex_Games": {
        "link": "https://openreview.net//forum?id=SiSv_XDMksL",
        "pub_url": "https://openreview.net/forum?id=SiSv_XDMksL",
        "pdf_link": "https://openreview.net//pdf?id=SiSv_XDMksL",
        "paper_id": "SiSv_XDMksL",
        "title": "Near-Optimal_No-Regret_Learning_Dynamics_for_General_Convex_Games",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nReviewers are all positive and appreciate the theoretical contributions. Good work! Please make sure you address all the reviewers' comments and incorporate them (and any new experimental results, if applicable) in your camera-ready.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper proposes a new novel algorithm named LRL-OFTRL which can achieve near-optimal for general convex games. In particular, when all players employ LRL-OFTRL, the regret of each player grows in logarithm speed. Their results significantly extend the result derived by Daskalakis et al. [2021] and can be applied to many subareas such as normal-form games, extensive-form games, splittable routing games, and Cournot competition.\nStrengths And Weaknesses: Originality: This paper proposes a new novel algorithm named LRL-OFTRL which can achieve near-optimal for general convex games.  \nQuality: The theory is technically solid and is supported by proof. This is complete work. \nClarity: this paper is well written and organized. The main theorems are supported by proof, but I\nSignificance: This paper proposes a new algorithm with a novel technique that significantly extends and improves the prior works. I think it is novel. \nThere are no experiments in this paper. It would make the result more significant if the authors could add some experiments (simulated and/or real data), which (1). shows that the proposed algorithm is implementable, and (2). if possible, show the advantage compared with Kernelized OMWU [Farina et al., 2022].\nQuestions: Since I am not familiar with the area of convex games, I have no technical criticism for this paper.\nLimitations: The authors have addressed their work's limitations and potential negative social impact.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 4 excellent\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 1: Your assessment is an educated guess. The submission is not in your area or the submission was difficult to understand. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper studies online learning for general convex games, where the decision set of each player is general convex. The authors propose an algorithm and prove an O(log\u2061T) regret each player, where T is the number of rounds. It improves the best T1/4 regret achieved by OMD. At the core of their algorithm is a lifting strategy with a regularized FTRL framework that updates both the utility and the regularization parameter simultaneously.\nStrengths And Weaknesses: Strengths:\n\nThe results are important in theory since it provides the first log\u2061(T) type regret for general convex games.\nThe discussion is comprehensive. \nThe proof is technically sound.\n\nWeaknesses:\n\nThere can be more explanation about the problem setting. See questions.\nQuestions: \nThe authors mention that their algorithm will achieve an T regret under the adversarial setting. Can the authors explain what the adversarial setting is since I do not find the definition in the main text?\n\nFrom the algorithm description and the proof, it seems that both the theoretical result and the algorithm can be regarded as those counterparts for a 'single-player' setting, since the regret reg_i cares nothing but the relative optimality of player i, and the algorithm also deals nothing with other players. Can the authors explain more about that?\nLimitations: Yes.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The paper considers a convex game (i.e., utility functions that are smooth, and convex given the other actions) between n players, where each player gets the gradient of its utility function at the end of every turn (i.e., full information). An optimistic follow-the-regularized-leader variation is proposed such that if all players use this algorithm with the same tuning, they all achieve a regret of O(logT). If this is not the case, each player can detect that and switch to an algorithm that achieves O(sqrt(T)) against an adversary. The algorithm requires to solve an optimization problem, and the paper proposes two oracles that can provide good approximate solutions to this problem, and analyzes the complexity and the implication for the regret bound.\nStrengths And Weaknesses: The paper is very well-written and the results are novel and explained well. General convex games are indeed a very broad and interesting class of games. The math is sound and the technical derivations are neat. I'm a bit hesitant regarding the significance or relevance of the results. Some of these issues can be mitigated or at least be presented more accurately, while others are inherent to the type of question the paper is interested in. I do believe that assuming that this question is interesting, the results of the paper are impressive. \nThe first issue is with the motivation: why would anybody need an algorithm with the (impressive) guarantees proven here. Using the same definition of regret for this game scenario is not obvious to me. It compares the sum of rewards of the players with something completely artificial - the sum of rewards the players would have gotten by playing a fixed action, while all players still follow their sequence of play. However, this sequence of play was generated partly in response to the player's actions. The paper does mention one possible motivation, which is to compute the coarse correlated equilibrium of the game. I think that's a good motivation overall, but if the motivation is computational, it sets some different priorities. Most importantly, I'm not sure if the computational complexity offered by this algorithm makes it a good choice (which I discuss below). \nThe second issue is with the feedback. Being able to evaluate the gradient in a data-driven scenario is one thing, but being able to do so (with no error) in a game is a different thing. The gradient of player i's utility with respect to its action depends on the actions of other players and this function depends on the structure of the game. I find it a very strong assumption. Even if the algorithm is used to compute a coarse correlated equilibrium (CCE), it's only interesting when the utility functions are unknown - otherwise computing the CCE can be done directly. Providing examples where one easily knows the gradient but not the utility function would help to justify this model, and by that, the motivation of the paper. The examples provided in Section 2.2 are for convex games, and indeed the convexity assumptions are very mild: but the feedback assumption isn't, and I'm not sure how and when it would be satisfied in the given examples. In terms of presentation, the paper claims that the proposed algorithm is an \"uncoupled learning algorithm\", where uncoupled is defined as \"every player is oblivious to the other players\u2019 utilities\". First, this definition is soft and vague. Then, it is claimed that the algorithm is even \"strongly uncoupled\" since players need not have any prior knowledge about the game whatsoever. I don't see how this is the case here if the gradient of the utility function of each player is (indirectly) highly related to the other players' utilities. Is this fair to say the algorithm is uncoupled where all that couples a player to others is given to this player for free, as an arbitrary modeling assumption? Additionally, it seems like the players need to know the Lipschitz parameter L, and the number of players, so I'm not sure if this statement is accurate. \nThe third issue, which can be easily fixed, is that the paper makes some over statements or just vague technical ones:\n\nThe statement that the dynamics are \"efficiently implementable\" is puzzling to me. The number of oracle calls per iteration is T-dependent. Then, each oracle call needs to give an approximate solution with an error of O(1/T), which will require again T-dependent complexity. The proximal oracle requires O(log(log(T)) calls which is nice, but each call will be complicated to implement (providing more detail here is recommended). There, an alternative linear optimization oracle is proposed, but this one needs poly(T) calls per iteration. Now, T needs to be very large to make the regret improvement from O(log^4(T)) significant. In light of this, in what sense is this efficient? numerical simulations could have helped to demonstrate the that algorithm runs in a reasonable time. I find this issue very important if the motivation of the paper is to compute coarse correlated equilibrium. If the overall computation is infeasible, then it's unclear why the  O(log(T)) regret is worst the struggle. I can see why improving the state-of-the-art regret bound for games might require heavy computational machinery like these oracles, but it looks like the paper is claiming that this computational disadvantage is in fact an advantage.\n\nThe line about the \"best-response oracle\" is a bit misleading. Usually, best-response is used in finite discrete games where the \"oracle\" is just going over the actions. In continuous convex games, best-response amounts to solving a convex problem, so it's not any easier or more common. \nTogether with the \"uncoupling issue\" above,  I think that claiming that the algorithm is both uncoupled and efficiently implementable (which is the main presented research question here) is an overstatement (also line 69 and other places). \n\nThe assumption that the product of the norms, in line 193, is at most 1, is not exactly without the loss of generality. Indeed, one can always rescale the rewards, but as discussed in lines 275-280, this adds a factor to the regret. This factor is recognized in the comparison in Table 1, but not in other places. I don't see why this assumption is needed, instead of just including this factor. This assumption holds for the simplex as the action space, but not, for example, in a multi-dimensional Cournot competition. It's also easy to miss this assumption which is not given near the assumption on the game or the statement of the results, which makes the regret bounds look better than they are in general action spaces. \n\nThe statement that the algorithm can be adaptive so that if player i is instead facing adversarial utilities the regret is O(sqrt(T)) is a bit vague. The meaning of this adaptivity only becomes clear when reading the proof of the Theorem. But then, it looks like this adaptivity requires each player to know the number of players n, and the Lipschitz parameter L. The step size also requires the player to know these parameters, but at least then one imagine what can be done if they don't know them (or what's the resulting factor in the regret). Since, against an adversary, there are no players at all, this means that the player excepts to play against n-1 other players, and if it finds himself playing against any other number (or players with different tuning), the regret can jump to O(sqrt(T)). I still think that this adaptivity is nice, but I think that the statement in the theorem needs to be more rigorous and include all detail and implicit assumptions. \n\nThe comparison to Piliouras et al. [2021] is perhaps a bit unfair. Their paper does claim their algorithm is uncoupled, which line 117 here refutes. This seems a very subtle issue given that I'm not sure if the proposed algorithm is uncoupled. I think that discussing how the proposed algorithm is at least \"more uncoupled\" than Piliouras et al. [2021] is necessary. Then, Table 1 is very confusing with regard to Piliouras et al. [2021]. Where is the T dependence of the regret bound? Also, isn't Piliouras et al. [2021] for finite discrete games, whereas this paper is for continuous games?\n\n\nI would be happy if I missed some critical details that can mitigate some of these issues. Disconnected from the confusing motivation, the proposed algorithm is creative and neat. Providing some intuition so why and how this lifting and regularizer do the trick can be interesting. \nMinor Comments:\nThe title of Section 2.3 seems inappropriate. This should be the problem formulation. \nline 539 - saying that G is defined in (11) can help.\nmissing period before line 599.\nI wasn't able to follow the proof of Proposition 5. What vector is used as the fixed (lambda,y) -star vector here? how come the additional term in the regret bound has the 2 factor, without the 1/(27*eta)?\nQuestions: \nWhat do you mean by \"efficiently implantable\"? especially in light of algorithms like OMWU that seem far more efficient? \n\nIs there any concrete motivation that I missed, other than computing the coarse correlated equilibrium? would the regret make sense as a benchmark in some game scenarios? \n\nAre there examples for applications where the \"full game information\" assumption is reasonable?\nLimitations: This is a theory pape so there is no societal impact. The technical limitations could be better discussed, as I explain above.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 3 good\nContribution: 2 fair\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper studies the uncoupled learning for general convex games, which is absolutely of interest to the audience in the community of online learning and game theory. The paper presents novel algorithms equipped with strong regret guarantee in the sense that only poly log T regret is incurred for each player; and also the algorithm can be efficiently implemented given a certain oracle. The crucial novelty in the technical stuff lies in the usage of the lifting to ensure nonengativeity of the regret and also the log barrier function to enhance the stability.\nStrengths And Weaknesses: The problem studied in this paper is very interesting and challenging. This paper studies the uncoupled learning for general convex games, which is absolutely of interest to the audience in the community of online learning and game theory. The paper presents novel algorithms equipped with strong regret guarantee in the sense that only poly log T regret is incurred for each player; and also the algorithm can be efficiently implemented given a certain oracle. The crucial novelty in the technical stuff lies in the usage of the lifting to ensure nonengativeity of the regret and also the log barrier function to enhance the stability. To the best of my knowledge, there is no similar result of uncoupled learning for convex games even though there is a large body of researches in this thread. The paper writing is of high quality and make the reader feel enjoyable.\nThe usage of lifting to ensure the nonnegativity is very interesting. Although the lifting idea was used in earlier studies [1,2], using it in uncoupled learning dynamics is very new to the best of my knowledge.\nIt is a pity that authors fail to cite the two prior works that also use the lifting ideas (in other bandit problems though).\n[1] Bias no more: high-probability data-dependent regret bounds for adversarial bandits and MDPs. NeurIPS 2020.\n[2] Adaptive Bandit Convex Optimization with Heterogeneous Curvature. COLT 2022.\nThe authors are suggested to explain more on the lifting operation as stated in Eq. (2). Note that the augmented dimension \u03bb also affects the remaining dimensions due to the constraint y\u2208\u03bbX, which exhibits salient difference to earlier papers [1,2] that only pave a constant 1 in the augmented dimension. \nUsing the self-concordant barrier function for full-information game setting is interesting. This will introduce strengthened stability as argued and proven in the paper, while the log barrier function will also make the dimensional dependency worse. \nminor comments: Line 191. players need not have any prior --> need not to have\nQuestions: See above.\nLimitations: See above.\nEthics Flag: No\nEthics Review Area: I don\u2019t know\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper proposes a new novel algorithm named LRL-OFTRL which can achieve near-optimal for general convex games. In particular, when all players employ LRL-OFTRL, the regret of each player grows in logarithm speed. Their results significantly extend the result derived by Daskalakis et al. [2021] and can be applied to many subareas such as normal-form games, extensive-form games, splittable routing games, and Cournot competition.",
                "Strengths And Weaknesses": "Originality: This paper proposes a new novel algorithm named LRL-OFTRL which can achieve near-optimal for general convex games.  \nQuality: The theory is technically solid and is supported by proof. This is complete work. \nClarity: this paper is well written and organized. The main theorems are supported by proof, but I\nSignificance: This paper proposes a new algorithm with a novel technique that significantly extends and improves the prior works. I think it is novel. \nThere are no experiments in this paper. It would make the result more significant if the authors could add some experiments (simulated and/or real data), which (1). shows that the proposed algorithm is implementable, and (2). if possible, show the advantage compared with Kernelized OMWU [Farina et al., 2022].",
                "Questions": "Since I am not familiar with the area of convex games, I have no technical criticism for this paper.",
                "Limitations": "The authors have addressed their work's limitations and potential negative social impact.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "4 excellent",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "1: Your assessment is an educated guess. The submission is not in your area or the submission was difficult to understand. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper studies online learning for general convex games, where the decision set of each player is general convex. The authors propose an algorithm and prove an O(log\u2061T) regret each player, where T is the number of rounds. It improves the best T1/4 regret achieved by OMD. At the core of their algorithm is a lifting strategy with a regularized FTRL framework that updates both the utility and the regularization parameter simultaneously.",
                "Strengths And Weaknesses": "Strengths:\n\nThe results are important in theory since it provides the first log\u2061(T) type regret for general convex games.\nThe discussion is comprehensive. \nThe proof is technically sound.\n\nWeaknesses:\n\nThere can be more explanation about the problem setting. See questions.",
                "Questions": "The authors mention that their algorithm will achieve an T regret under the adversarial setting. Can the authors explain what the adversarial setting is since I do not find the definition in the main text?\n\nFrom the algorithm description and the proof, it seems that both the theoretical result and the algorithm can be regarded as those counterparts for a 'single-player' setting, since the regret reg_i cares nothing but the relative optimality of player i, and the algorithm also deals nothing with other players. Can the authors explain more about that?",
                "Limitations": "Yes.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper considers a convex game (i.e., utility functions that are smooth, and convex given the other actions) between n players, where each player gets the gradient of its utility function at the end of every turn (i.e., full information). An optimistic follow-the-regularized-leader variation is proposed such that if all players use this algorithm with the same tuning, they all achieve a regret of O(logT). If this is not the case, each player can detect that and switch to an algorithm that achieves O(sqrt(T)) against an adversary. The algorithm requires to solve an optimization problem, and the paper proposes two oracles that can provide good approximate solutions to this problem, and analyzes the complexity and the implication for the regret bound.",
                "Strengths And Weaknesses": "The paper is very well-written and the results are novel and explained well. General convex games are indeed a very broad and interesting class of games. The math is sound and the technical derivations are neat. I'm a bit hesitant regarding the significance or relevance of the results. Some of these issues can be mitigated or at least be presented more accurately, while others are inherent to the type of question the paper is interested in. I do believe that assuming that this question is interesting, the results of the paper are impressive. \nThe first issue is with the motivation: why would anybody need an algorithm with the (impressive) guarantees proven here. Using the same definition of regret for this game scenario is not obvious to me. It compares the sum of rewards of the players with something completely artificial - the sum of rewards the players would have gotten by playing a fixed action, while all players still follow their sequence of play. However, this sequence of play was generated partly in response to the player's actions. The paper does mention one possible motivation, which is to compute the coarse correlated equilibrium of the game. I think that's a good motivation overall, but if the motivation is computational, it sets some different priorities. Most importantly, I'm not sure if the computational complexity offered by this algorithm makes it a good choice (which I discuss below). \nThe second issue is with the feedback. Being able to evaluate the gradient in a data-driven scenario is one thing, but being able to do so (with no error) in a game is a different thing. The gradient of player i's utility with respect to its action depends on the actions of other players and this function depends on the structure of the game. I find it a very strong assumption. Even if the algorithm is used to compute a coarse correlated equilibrium (CCE), it's only interesting when the utility functions are unknown - otherwise computing the CCE can be done directly. Providing examples where one easily knows the gradient but not the utility function would help to justify this model, and by that, the motivation of the paper. The examples provided in Section 2.2 are for convex games, and indeed the convexity assumptions are very mild: but the feedback assumption isn't, and I'm not sure how and when it would be satisfied in the given examples. In terms of presentation, the paper claims that the proposed algorithm is an \"uncoupled learning algorithm\", where uncoupled is defined as \"every player is oblivious to the other players\u2019 utilities\". First, this definition is soft and vague. Then, it is claimed that the algorithm is even \"strongly uncoupled\" since players need not have any prior knowledge about the game whatsoever. I don't see how this is the case here if the gradient of the utility function of each player is (indirectly) highly related to the other players' utilities. Is this fair to say the algorithm is uncoupled where all that couples a player to others is given to this player for free, as an arbitrary modeling assumption? Additionally, it seems like the players need to know the Lipschitz parameter L, and the number of players, so I'm not sure if this statement is accurate. \nThe third issue, which can be easily fixed, is that the paper makes some over statements or just vague technical ones:\n\nThe statement that the dynamics are \"efficiently implementable\" is puzzling to me. The number of oracle calls per iteration is T-dependent. Then, each oracle call needs to give an approximate solution with an error of O(1/T), which will require again T-dependent complexity. The proximal oracle requires O(log(log(T)) calls which is nice, but each call will be complicated to implement (providing more detail here is recommended). There, an alternative linear optimization oracle is proposed, but this one needs poly(T) calls per iteration. Now, T needs to be very large to make the regret improvement from O(log^4(T)) significant. In light of this, in what sense is this efficient? numerical simulations could have helped to demonstrate the that algorithm runs in a reasonable time. I find this issue very important if the motivation of the paper is to compute coarse correlated equilibrium. If the overall computation is infeasible, then it's unclear why the  O(log(T)) regret is worst the struggle. I can see why improving the state-of-the-art regret bound for games might require heavy computational machinery like these oracles, but it looks like the paper is claiming that this computational disadvantage is in fact an advantage.\n\nThe line about the \"best-response oracle\" is a bit misleading. Usually, best-response is used in finite discrete games where the \"oracle\" is just going over the actions. In continuous convex games, best-response amounts to solving a convex problem, so it's not any easier or more common. \nTogether with the \"uncoupling issue\" above,  I think that claiming that the algorithm is both uncoupled and efficiently implementable (which is the main presented research question here) is an overstatement (also line 69 and other places). \n\nThe assumption that the product of the norms, in line 193, is at most 1, is not exactly without the loss of generality. Indeed, one can always rescale the rewards, but as discussed in lines 275-280, this adds a factor to the regret. This factor is recognized in the comparison in Table 1, but not in other places. I don't see why this assumption is needed, instead of just including this factor. This assumption holds for the simplex as the action space, but not, for example, in a multi-dimensional Cournot competition. It's also easy to miss this assumption which is not given near the assumption on the game or the statement of the results, which makes the regret bounds look better than they are in general action spaces. \n\nThe statement that the algorithm can be adaptive so that if player i is instead facing adversarial utilities the regret is O(sqrt(T)) is a bit vague. The meaning of this adaptivity only becomes clear when reading the proof of the Theorem. But then, it looks like this adaptivity requires each player to know the number of players n, and the Lipschitz parameter L. The step size also requires the player to know these parameters, but at least then one imagine what can be done if they don't know them (or what's the resulting factor in the regret). Since, against an adversary, there are no players at all, this means that the player excepts to play against n-1 other players, and if it finds himself playing against any other number (or players with different tuning), the regret can jump to O(sqrt(T)). I still think that this adaptivity is nice, but I think that the statement in the theorem needs to be more rigorous and include all detail and implicit assumptions. \n\nThe comparison to Piliouras et al. [2021] is perhaps a bit unfair. Their paper does claim their algorithm is uncoupled, which line 117 here refutes. This seems a very subtle issue given that I'm not sure if the proposed algorithm is uncoupled. I think that discussing how the proposed algorithm is at least \"more uncoupled\" than Piliouras et al. [2021] is necessary. Then, Table 1 is very confusing with regard to Piliouras et al. [2021]. Where is the T dependence of the regret bound? Also, isn't Piliouras et al. [2021] for finite discrete games, whereas this paper is for continuous games?\n\n\nI would be happy if I missed some critical details that can mitigate some of these issues. Disconnected from the confusing motivation, the proposed algorithm is creative and neat. Providing some intuition so why and how this lifting and regularizer do the trick can be interesting. \nMinor Comments:\nThe title of Section 2.3 seems inappropriate. This should be the problem formulation. \nline 539 - saying that G is defined in (11) can help.\nmissing period before line 599.\nI wasn't able to follow the proof of Proposition 5. What vector is used as the fixed (lambda,y) -star vector here? how come the additional term in the regret bound has the 2 factor, without the 1/(27*eta)?",
                "Questions": "What do you mean by \"efficiently implantable\"? especially in light of algorithms like OMWU that seem far more efficient? \n\nIs there any concrete motivation that I missed, other than computing the coarse correlated equilibrium? would the regret make sense as a benchmark in some game scenarios? \n\nAre there examples for applications where the \"full game information\" assumption is reasonable?",
                "Limitations": "This is a theory pape so there is no societal impact. The technical limitations could be better discussed, as I explain above.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper studies the uncoupled learning for general convex games, which is absolutely of interest to the audience in the community of online learning and game theory. The paper presents novel algorithms equipped with strong regret guarantee in the sense that only poly log T regret is incurred for each player; and also the algorithm can be efficiently implemented given a certain oracle. The crucial novelty in the technical stuff lies in the usage of the lifting to ensure nonengativeity of the regret and also the log barrier function to enhance the stability.",
                "Strengths And Weaknesses": "The problem studied in this paper is very interesting and challenging. This paper studies the uncoupled learning for general convex games, which is absolutely of interest to the audience in the community of online learning and game theory. The paper presents novel algorithms equipped with strong regret guarantee in the sense that only poly log T regret is incurred for each player; and also the algorithm can be efficiently implemented given a certain oracle. The crucial novelty in the technical stuff lies in the usage of the lifting to ensure nonengativeity of the regret and also the log barrier function to enhance the stability. To the best of my knowledge, there is no similar result of uncoupled learning for convex games even though there is a large body of researches in this thread. The paper writing is of high quality and make the reader feel enjoyable.\nThe usage of lifting to ensure the nonnegativity is very interesting. Although the lifting idea was used in earlier studies [1,2], using it in uncoupled learning dynamics is very new to the best of my knowledge.\nIt is a pity that authors fail to cite the two prior works that also use the lifting ideas (in other bandit problems though).\n[1] Bias no more: high-probability data-dependent regret bounds for adversarial bandits and MDPs. NeurIPS 2020.\n[2] Adaptive Bandit Convex Optimization with Heterogeneous Curvature. COLT 2022.\nThe authors are suggested to explain more on the lifting operation as stated in Eq. (2). Note that the augmented dimension \u03bb also affects the remaining dimensions due to the constraint y\u2208\u03bbX, which exhibits salient difference to earlier papers [1,2] that only pave a constant 1 in the augmented dimension. \nUsing the self-concordant barrier function for full-information game setting is interesting. This will introduce strengthened stability as argued and proven in the paper, while the log barrier function will also make the dimensional dependency worse. \nminor comments: Line 191. players need not have any prior --> need not to have",
                "Questions": "See above.",
                "Limitations": "See above.",
                "Ethics Flag": "No",
                "Ethics Review Area": "I don\u2019t know",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.5,
        "confidence_avg": 3.0,
        "soundness_avg": 3.5,
        "presentation_avg": 3.5,
        "contribution_avg": 3.0,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is evident that this paper proposes a novel algorithm, LRL-OFTRL, for general convex games with near-optimal performance. The theoretical analysis is technically solid and supported by proofs. The paper significantly extends and improves upon prior works in the field. While there are some minor concerns raised by the reviewers regarding the problem setting, motivation, and computational complexity, the overall consensus is that the paper is technically solid and has moderate-to-high impact. Therefore, I recommend accepting this paper."
    },
    "Learning_the_Structure_of_Large_Networked_Systems_Obeying_Conservation_Laws": {
        "link": "https://openreview.net//forum?id=WcxJooGBCc",
        "pub_url": "https://openreview.net/forum?id=WcxJooGBCc",
        "pdf_link": "https://openreview.net//pdf?id=WcxJooGBCc",
        "paper_id": "WcxJooGBCc",
        "title": "Learning_the_Structure_of_Large_Networked_Systems_Obeying_Conservation_Laws",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Less certain\nThe reviewers and the area chair judged the paper as technically sound and found that the problem treated is an interesting variant in the spirit of (but different from) the well-known group-LASSO. The range of applicability of the approach was considered promising. While the narrative of the proof leading to a convex problem was judged standard and by itself perhaps less interesting, overall the contribution was judged as valuable to the community and we recommend acceptance of the paper.",
        "reviews": [
            "Reviewer 1: \nSummary: This submission studies how to learn the structure of large network that obeys conservation law, a l1-regularized formulation is introduced, and the problem is convex.\nStrengths And Weaknesses: weakness:\n\nthe motivation is not well-established.\n2.the novelty compared with previous works is not sufficient\nQuestions: 1.what is the exact novelty and challenge compared with GLASSO? \nIt seems to the reviewer, and also confirmed by the authors that the formulation in (2) is the same as GLASSO, the only difference is B instead of Theta is being estimated. However, this makes the problem convex, and henceforth it seems to be simpler than GLASSO, Given that the problem formulation is simpler and the solving is easier, the novelty and challenge need to be further discussed.\n\nthe experiments only show synthetic and real power grids data, are there any other application domains? if so, should be discussed and more experimental results in other applications should be include to show the generality of the proposed framework. If not, then the applicability of the framework is quite limited.\nLimitations: lack of discussion about the novelty\napplicability of the proposed framework seems to be limited to power grids.\nsocietal limitation not discussed\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper deals with the estimation of graphical models under the constraints of conservation laws of network flow. The paper focuses on the problem of estimation of Laplacian matrices using the log-likelihood of multivariate Gaussian distributions. The paper considers solving an optimization problem involving penalized log-likelihood of Gaussian distribution extending the graphical lasso methods. The paper also provides theoretical results on the consistency of the estimated Laplacian matrices as well as support recovery under sparsity conditions. The paper provides both theoretical conditions on the error bounds on the estimates as well as a simulation study demonstrating the effectiveness of the penalized estimation.\nStrengths And Weaknesses: Strength:\n(1) Formulation of a convex problem using penalized log-likelihood for estimation of Laplacian matrices under the conservation laws of the network flow.\n(2) Theoretical results on the error bounds on estimated Laplacian using \u2113\u221e, Frobenius, and operator norms.\n(3) Theoretical results on the support recovery of Laplacian matrices under the condition of sparsity in the Laplacian population matrix.\nWeakness:\n(1) The situation of the unknown covariance matrix in Remark 1 requires more explanations. Rigorous statements on how the problem change in this case, and how the estimation of B\u2217 can still be possible should be mentioned in more detail.\n(1) The innovations in the proof techniques for proving Theorems 1 and 2 have not been properly explained. The assumptions of [A1]-[A3], as well as the primal-dual witness construction, are standard in the literature, so a bit more explanation on the difficulty and innovations in section 3.3 would be appealing.\nQuestions: \nIs it possible to address the situation of unknown covariance matrices (which is pretty natural in real data contexts) in more detail?\nWhat are the computational costs of these methods and up to what size of networks can be handled by this method?\nLimitations: N/A\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The paper developed a \u21131-regularized MLE of the sparsity structure of B\u2217 in the conservation laws X=B\u2217Y observed in many networked systems. The authors assumed that the covariance matrix \u03a3X of the node injections X is known, and the proposed MLE can recover the topology of the structure of the graph from B\u2217 with high probability. With appropriate choices of the regularization coefficient \u03bbn and the sample size n\u226ap, the proposed estimator is theoretically sound and proved to be effective on synthetic datasets and a real power distribution network. The authors provided detailed proofs to reach the conclusions on the support recovery performance. Also, they compared the proposed MLE against the baselines GLASSOR+2HR and GLASSOR+SR, and the proposed MLE outperformed.\nStrengths And Weaknesses: Strengths:\n\nThe paper is well-written and developed a \u21131-regularized MLE for the support of B\u2217 from limited potential samples. \nThe proposed estimator is proved to be convex in B, therefore, it has a unique solution regardless of the size of problem. \nIt is consistent to the true B\u2217 in terms of elementwise maximum, Frobenius and operator norms. \nTheorems of the support recovery are given for Gaussian, sub-Gaussian node potentials and the ones with bounded moments. \nRelatively, it requires less number of potentials samples than the baseline GLASSOR+SR.\n\nWeaknesses:\nThe developed estimator claimed to be able to avoid the assumptions that are imposed on prior works, such as triangle-freeness of G, no correlation between the node injections, and the invertibility of the empirical covariance matrix. However, it relies on three necessary assumptions [A1,A2 and A3]. How to verify that these conditions hold in practice?\nQuestions: Minors:\n\nLast sentence in the caption of Fig1: ... there are no spuruious edges in it -> ... there are no spurious edges in it.\nL125: \u2016A\u2016\u221e has two more vertical lines?\nL187: ...might not be be strictly convex. -> ...might not be strictly convex.\nAn explicit definition of the support of B\u2217 will be better.\nLimitations: YES.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper proposes a \u21131-regularized log-determinant program for estimating the graph structure encoded in a matrix B from a conservation law BX=Y, where the node potentials Y are measured and the injected signals X are Gaussian.\nGiven the sample covariance of Y, the objective function is recast into a \u21131-regularized log-determinant program on B. The new objective function is shown to be convex with a unique minimizer B^.\nFurthermore, under relatively standard assumptions, the solution B^ is shown to match several properties of the actual graph matrix.\nSome experiments are presented to show the practical benefits of the proposed optimization problem\nStrengths And Weaknesses: The paper well written and the contribution is well presented. The whole theoretical machinery quite tightly follows previous work on high-dimensional covariance estimation in [39], the main difference being the fact that the objective function is quadratic in the variable B. While this certainly complicates the analysis with respect to [39], the novelty with respect to [39] from the theoretical point of view may be limited.\nAt the same time, when compared with previous GLASSO technique(s) for recovering the graph structure based on the same \u21131-regularized log-determinant program (e.g. [54,16,13]), the proposed approach provides interesting novelties. In particular, while GLASSO allows to reconstruct the graph pattern only for paths of length two, and thus requires O(d4log\u2061p) samples to reconstruct the graph, the proposed estimator recovers the graph with only O(d2log\u2061p) samples. \nThe statements of the main theorems/results seem correct and reasonable, although I did not check the proofs in details.\nQuestions: I find Figure 1 difficult to understand. Why do (c) and (d) have a missing edge? In what way are the spurious edges removed in (d)? I believe the presentation would improve significantly with a more detailed discussion here on the related work and approaches.\nL65-71: This example is not clear. The equation B\u2217=(\u2211lhlAL)\u22121 seems odd as AL does not depend on l. Also what does it mean that L=3 and B\u2217=(I\u2212\u03b1A)\u22121 are reasonable choices? B\u2217 is a function of L and this function does not coincide with (I\u2212\u03b1A)\u22121 when L=3. Finally, I believe that in most cases the matrix B\u2217=(I\u2212\u03b1A)\u22121 is almost full, so it does not seem like a good example of application of your approach\nThe experiments only consider very small graphs (up to 64 nodes) but this is claimed to be a method for high-dimensional networks. I find this a little odd, please explain.\nOnly a very small set of (three) graphs is considered in the experiments. The paper would highly benefit from a more extensive experimental section where a larger number of graphs with different structural properties is considered. \nIn the experiments it should be highlighted whether or not the assumptions of Thm 1 are satisfied.\nIn the synthetic experiments B is chosen as the adjacency matrix of the graph, and it is then perturbed to become pd. More details on the precise perturbation made are needed here.\nL361: The empirical support recovery probability should be defined more precisely\nFigure 3 should report vertical lines to highlight the value of d2log\u2061p and d4log\u2061p. \nThe IEEE 33 network is not regular, so what is d?\nThe experiments only verify the sparsity structure. How about sign consistency and norm distance |B^\u2212B\u2217|? \nIt is not clear to me whether your derivations and approach work also for weighted (non-binary) graphs.\nL121: T1,T2 are subsets of [p] not [p]\u00d7[p].\nL125: the sentence is not clear\nL:135: \u0398\u2217 requires some inverse\nLimitations: It seems like one limitation of the approach is that it works for relatively small graphs only. This should be clarified in the paper.\nAlso, it is not clear whether the assumptions of Theorem 1 and its corollaries are verified in practice and how stringent they are. This should be discussed in more details and verified on the graphs the method is tested on.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This submission studies how to learn the structure of large network that obeys conservation law, a l1-regularized formulation is introduced, and the problem is convex.",
                "Strengths And Weaknesses": "weakness:\n\nthe motivation is not well-established.\n2.the novelty compared with previous works is not sufficient",
                "Questions": "1.what is the exact novelty and challenge compared with GLASSO? \nIt seems to the reviewer, and also confirmed by the authors that the formulation in (2) is the same as GLASSO, the only difference is B instead of Theta is being estimated. However, this makes the problem convex, and henceforth it seems to be simpler than GLASSO, Given that the problem formulation is simpler and the solving is easier, the novelty and challenge need to be further discussed.\n\nthe experiments only show synthetic and real power grids data, are there any other application domains? if so, should be discussed and more experimental results in other applications should be include to show the generality of the proposed framework. If not, then the applicability of the framework is quite limited.",
                "Limitations": "lack of discussion about the novelty\napplicability of the proposed framework seems to be limited to power grids.\nsocietal limitation not discussed",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper deals with the estimation of graphical models under the constraints of conservation laws of network flow. The paper focuses on the problem of estimation of Laplacian matrices using the log-likelihood of multivariate Gaussian distributions. The paper considers solving an optimization problem involving penalized log-likelihood of Gaussian distribution extending the graphical lasso methods. The paper also provides theoretical results on the consistency of the estimated Laplacian matrices as well as support recovery under sparsity conditions. The paper provides both theoretical conditions on the error bounds on the estimates as well as a simulation study demonstrating the effectiveness of the penalized estimation.",
                "Strengths And Weaknesses": "Strength:\n(1) Formulation of a convex problem using penalized log-likelihood for estimation of Laplacian matrices under the conservation laws of the network flow.\n(2) Theoretical results on the error bounds on estimated Laplacian using \u2113\u221e, Frobenius, and operator norms.\n(3) Theoretical results on the support recovery of Laplacian matrices under the condition of sparsity in the Laplacian population matrix.\nWeakness:\n(1) The situation of the unknown covariance matrix in Remark 1 requires more explanations. Rigorous statements on how the problem change in this case, and how the estimation of B\u2217 can still be possible should be mentioned in more detail.\n(1) The innovations in the proof techniques for proving Theorems 1 and 2 have not been properly explained. The assumptions of [A1]-[A3], as well as the primal-dual witness construction, are standard in the literature, so a bit more explanation on the difficulty and innovations in section 3.3 would be appealing.",
                "Questions": "Is it possible to address the situation of unknown covariance matrices (which is pretty natural in real data contexts) in more detail?\nWhat are the computational costs of these methods and up to what size of networks can be handled by this method?",
                "Limitations": "N/A",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper developed a \u21131-regularized MLE of the sparsity structure of B\u2217 in the conservation laws X=B\u2217Y observed in many networked systems. The authors assumed that the covariance matrix \u03a3X of the node injections X is known, and the proposed MLE can recover the topology of the structure of the graph from B\u2217 with high probability. With appropriate choices of the regularization coefficient \u03bbn and the sample size n\u226ap, the proposed estimator is theoretically sound and proved to be effective on synthetic datasets and a real power distribution network. The authors provided detailed proofs to reach the conclusions on the support recovery performance. Also, they compared the proposed MLE against the baselines GLASSOR+2HR and GLASSOR+SR, and the proposed MLE outperformed.",
                "Strengths And Weaknesses": "Strengths:\n\nThe paper is well-written and developed a \u21131-regularized MLE for the support of B\u2217 from limited potential samples. \nThe proposed estimator is proved to be convex in B, therefore, it has a unique solution regardless of the size of problem. \nIt is consistent to the true B\u2217 in terms of elementwise maximum, Frobenius and operator norms. \nTheorems of the support recovery are given for Gaussian, sub-Gaussian node potentials and the ones with bounded moments. \nRelatively, it requires less number of potentials samples than the baseline GLASSOR+SR.\n\nWeaknesses:\nThe developed estimator claimed to be able to avoid the assumptions that are imposed on prior works, such as triangle-freeness of G, no correlation between the node injections, and the invertibility of the empirical covariance matrix. However, it relies on three necessary assumptions [A1,A2 and A3]. How to verify that these conditions hold in practice?",
                "Questions": "Minors:\n\nLast sentence in the caption of Fig1: ... there are no spuruious edges in it -> ... there are no spurious edges in it.\nL125: \u2016A\u2016\u221e has two more vertical lines?\nL187: ...might not be be strictly convex. -> ...might not be strictly convex.\nAn explicit definition of the support of B\u2217 will be better.",
                "Limitations": "YES.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposes a \u21131-regularized log-determinant program for estimating the graph structure encoded in a matrix B from a conservation law BX=Y, where the node potentials Y are measured and the injected signals X are Gaussian.\nGiven the sample covariance of Y, the objective function is recast into a \u21131-regularized log-determinant program on B. The new objective function is shown to be convex with a unique minimizer B^.\nFurthermore, under relatively standard assumptions, the solution B^ is shown to match several properties of the actual graph matrix.\nSome experiments are presented to show the practical benefits of the proposed optimization problem",
                "Strengths And Weaknesses": "The paper well written and the contribution is well presented. The whole theoretical machinery quite tightly follows previous work on high-dimensional covariance estimation in [39], the main difference being the fact that the objective function is quadratic in the variable B. While this certainly complicates the analysis with respect to [39], the novelty with respect to [39] from the theoretical point of view may be limited.\nAt the same time, when compared with previous GLASSO technique(s) for recovering the graph structure based on the same \u21131-regularized log-determinant program (e.g. [54,16,13]), the proposed approach provides interesting novelties. In particular, while GLASSO allows to reconstruct the graph pattern only for paths of length two, and thus requires O(d4log\u2061p) samples to reconstruct the graph, the proposed estimator recovers the graph with only O(d2log\u2061p) samples. \nThe statements of the main theorems/results seem correct and reasonable, although I did not check the proofs in details.",
                "Questions": "I find Figure 1 difficult to understand. Why do (c) and (d) have a missing edge? In what way are the spurious edges removed in (d)? I believe the presentation would improve significantly with a more detailed discussion here on the related work and approaches.\nL65-71: This example is not clear. The equation B\u2217=(\u2211lhlAL)\u22121 seems odd as AL does not depend on l. Also what does it mean that L=3 and B\u2217=(I\u2212\u03b1A)\u22121 are reasonable choices? B\u2217 is a function of L and this function does not coincide with (I\u2212\u03b1A)\u22121 when L=3. Finally, I believe that in most cases the matrix B\u2217=(I\u2212\u03b1A)\u22121 is almost full, so it does not seem like a good example of application of your approach\nThe experiments only consider very small graphs (up to 64 nodes) but this is claimed to be a method for high-dimensional networks. I find this a little odd, please explain.\nOnly a very small set of (three) graphs is considered in the experiments. The paper would highly benefit from a more extensive experimental section where a larger number of graphs with different structural properties is considered. \nIn the experiments it should be highlighted whether or not the assumptions of Thm 1 are satisfied.\nIn the synthetic experiments B is chosen as the adjacency matrix of the graph, and it is then perturbed to become pd. More details on the precise perturbation made are needed here.\nL361: The empirical support recovery probability should be defined more precisely\nFigure 3 should report vertical lines to highlight the value of d2log\u2061p and d4log\u2061p. \nThe IEEE 33 network is not regular, so what is d?\nThe experiments only verify the sparsity structure. How about sign consistency and norm distance |B^\u2212B\u2217|? \nIt is not clear to me whether your derivations and approach work also for weighted (non-binary) graphs.\nL121: T1,T2 are subsets of [p] not [p]\u00d7[p].\nL125: the sentence is not clear\nL:135: \u0398\u2217 requires some inverse",
                "Limitations": "It seems like one limitation of the approach is that it works for relatively small graphs only. This should be clarified in the paper.\nAlso, it is not clear whether the assumptions of Theorem 1 and its corollaries are verified in practice and how stringent they are. This should be discussed in more details and verified on the graphs the method is tested on.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.0,
        "confidence_avg": 2.5,
        "soundness_avg": 3.0,
        "presentation_avg": 3.25,
        "contribution_avg": 2.5,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that this paper presents a technically solid contribution in the field of estimating graphical models under the constraints of conservation laws of network flow. The paper introduces a novel \u21131-regularized formulation that is convex and provides theoretical results on the consistency of the estimated Laplacian matrices as well as support recovery under sparsity conditions. \n\nWhile there are some weaknesses and limitations pointed out by the reviewers, such as the limited evaluation and the applicability of the proposed framework to power grids, the strengths of the paper outweigh these concerns. The paper is well-written and the proposed estimator is theoretically sound. The experiments, although limited in scope, demonstrate the effectiveness of the proposed optimization problem.\n\nOverall, this paper is a technically solid contribution with high impact in the field. Therefore, I recommend accepting it for publication."
    },
    "Neural_Payoff_Machines:_Predicting_Fair_and_Stable_Payoff_Allocations_Among_Team_Members": {
        "link": "https://openreview.net//forum?id=CLMuNJSJfhv",
        "pub_url": "https://openreview.net/forum?id=CLMuNJSJfhv",
        "pdf_link": "https://openreview.net//pdf?id=CLMuNJSJfhv",
        "paper_id": "CLMuNJSJfhv",
        "title": "Neural_Payoff_Machines:_Predicting_Fair_and_Stable_Payoff_Allocations_Among_Team_Members",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Less certain\nThis paper proposes a deep learning approach to computing agent/feature importance in complex cooperative game theoretic settings.  The reviewers are overall positive, albeit some are a bit lukewarm, about the paper.  Overall, the consensus after the discussion is that the idea of studying how well neural computation can be used to approximate the relevant quantities (hard to solve exactly) in cooperative game theory is itself a contribution, and this paper has done a decent job in analyzing the approach and establishing its validity. We would encourage the authors to incorporate the reviewer comments (e.g., move the many vs one discussion to the main paper to strengthen the motivation, include comparisons with more baselines, etc) into the final version and produce a stronger paper.",
        "reviews": [
            "Reviewer 1: \nSummary: The authors propose a heuristic, deep learning approach to computing agent/feature importance in complex cooperative game theoretic settings. Such setting are known to be hard to solve and understand exactly (for example computing the Shapley value in voting games is #P-complete), motivating the study of the paper.\nStrengths And Weaknesses: \nThe authors\u2019 algorithms seem to perform well according to the experiments\nThe authors\u2019 proposed framework has several proposed and illustrated applications, including solving voting games and understanding feature importance in hard-to-understand models\nThe authors look at several metrics of interest for measure contribution/importance, including shapley values, Banzhaf indexes, and cores. The flexibility provided by the framework seems nice and useful.\n\nWeaknesses:\n\nMy main question and \u201cissue\u201d with the paper is that I do not get a good sense here of whether the neural net approach is actually necessary, or if it is actually overkill. For example, if the goal were just to compute Shapley values fast, approaches based on sampling are known and seem to be relatively efficient. How does the current work compare to those? \nMaybe things are more complicated when it comes to compute the actual outcomes rather than just computing shapley values, but this needs to be discussed more. There is indeed motivation for a heuristic approach in that these problems are hard to solve exactly, but it seems the authors jumped to a neural net before exploring simpler heuristics on very structured problems/it is not clear to me why this brings compared to possible simpler approaches. \nRelated to the point above, the paper makes no comparison with previous work, when other heuristics I believe exist for at least some of the questions asked in the paper\nQuestions: \nCan the authors compare their results to previous work/non deep learning based results? Does the deep learning approach lead to significant improvement which warrants the downsides of having to use a black-box, hard to understand algorithm?\nLimitations: In terms of societal impact, I think it is nice that the authors have applications to interpretability. Limitations are discussed in Section 4.1.2.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper discusses using neural computation to compute values of cooperative game theory in weighted voting games and feature importance games.  For weighted voting games, models for both fixed and variable numbers of players are given.  While fixed models outperformed variable models, results on random games indicates that both models do relatively well.  Furthermore, predictions fro feature importance games are quite good after training on only a small amount of training data.\nStrengths And Weaknesses: Strengths:\n\nThe paper does a good job of describing and introducing the problem.\n\nThe presentation of the paper is clear and clean.\n\nThis paper implements and tests a good, simple, and useful idea: Can neural computation to computer values of cooperative game theory.  \n\nThe analysis of the results is good and detailed.\n\n\nWeaknesses:\n\nIt would be fun to illustrate how well the trained neural networks perform on known problems rather than on just random games.\n\n(Table 1) Suggestion: I think it would be good to understand how significant the failures are when the neural network fails (e.g., significantly out of distribution).  Is there any way to detect when it would fail?\n\n\nA few minor nitpicks:\n\nIt\u2019s probably right in front of my eyes, but I could see where p(C) was defined on line 111\n\nLine 260: fix \u201cat a the cost\u201d \u2014 there\u2019s clearly an extra word\nQuestions: See comments in the previous section.\nLimitations: I think further exploration of failure cases would be appropriate at some point\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 4 excellent\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper applies a multi-layer perceptron to learning to approximate the Shapley value of a weighted voting game (where the input is a description of the voting weights of each player, and the output is a vector of Shapley values for each voter).  The fixed-dimension case (for which the number of voters is constant) and variable dimension case are both considered; the variable dimension case is handled simply by zero-padding (i.e., non-players are added with weight 0 to every empty slot).\nAlthough weighted voting games are simple, approximating their Shapley value within a multiplicative factor is known to be intractable in the worst case.\nStrengths And Weaknesses: The basic idea is sound: we sometimes want the Shapley value (to estimate the relative influence of different input features on the output of an ML model, or to estimate the relative power of different voters).  However, it's intractable to compute exactly.  So let's try approximating it by training a neural network on small instances.  It seems to work pretty well on the instances that they test on.\nOne of the main motivations for this work is scalability.  It can be exponentially expensive to compute the Shapley value as the number of participants increases, making an approximation approach valuable.  Clearly the network with a fixed number of participants won't be much use in large-scale situations, since the training data needs to be as large as the test data.  On the other hand, the paper shows that you can get decent performance by training on a dataset with about half as many participants as in the test set (using the zero-padding variable-dimension approach).  This is of course better than nothing, but I'm skeptical that an approximate doubling of the feasible size of input is going to be sufficient in settings that actually need scale.\nThe paper is clearly written, with the exception of the material on explainable AI.  This domain is an important part of the paper's motivation, but its treatment feels like something of an afterthought.   I can take a guess at what is going on here (the \"value\" created by a given agent is going to be either the average change in a binary classification, or the average change in regression output, averaged over all orderings), but it would be nice if this were somehow made explicit.  Section 3.2 doesn't really give any details about the actual procedure (what is a \"sampled sub-dataset\"?  Are you sampling rows (instances) or columns (features)?  Appendix D.2 doesn't refer to this at all.).  Section 2.2 is similarly vague.\nOverall, I don't think this work clears the significance bar for publication at NeurIPS.  It proposes a standard feedforward architecture for prediction in a specific scenario.  The scenario is interesting but not really deeply explored.  There is no explicit comparison to baselines, so it's hard to tell what we actually gain.  In particular, we don't see any performance numbers at all.  How large is the performance difference vs standard techniques?  Are you able to do well on instances that take SHAP weeks, for example?\nminor comments\n\np.5: \"we redistribute the payoffs allocated to non-player entries\": How necessary does this turn out to be?  (I.e., is a substantial fraction of payoff often allocated to non-players?)\n\np.6: The first paragraph of s.3.2 is very repetitive\n\nOn a related note, it's not clear from the main text what the ground truth for figure 7 is meant to be.\n\nFigure 2 is unreadably small, and also seems to make the PDF very slow to render.\nQuestions: Do you have performance numbers (both timing and prediction quality) for any scenario where the use of something like SHAP would be intractable?\nLimitations: see strengths/weaknesses\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The authors propose a heuristic, deep learning approach to computing agent/feature importance in complex cooperative game theoretic settings. Such setting are known to be hard to solve and understand exactly (for example computing the Shapley value in voting games is #P-complete), motivating the study of the paper.",
                "Strengths And Weaknesses": "The authors\u2019 algorithms seem to perform well according to the experiments\nThe authors\u2019 proposed framework has several proposed and illustrated applications, including solving voting games and understanding feature importance in hard-to-understand models\nThe authors look at several metrics of interest for measure contribution/importance, including shapley values, Banzhaf indexes, and cores. The flexibility provided by the framework seems nice and useful.\n\nWeaknesses:\n\nMy main question and \u201cissue\u201d with the paper is that I do not get a good sense here of whether the neural net approach is actually necessary, or if it is actually overkill. For example, if the goal were just to compute Shapley values fast, approaches based on sampling are known and seem to be relatively efficient. How does the current work compare to those? \nMaybe things are more complicated when it comes to compute the actual outcomes rather than just computing shapley values, but this needs to be discussed more. There is indeed motivation for a heuristic approach in that these problems are hard to solve exactly, but it seems the authors jumped to a neural net before exploring simpler heuristics on very structured problems/it is not clear to me why this brings compared to possible simpler approaches. \nRelated to the point above, the paper makes no comparison with previous work, when other heuristics I believe exist for at least some of the questions asked in the paper",
                "Questions": "Can the authors compare their results to previous work/non deep learning based results? Does the deep learning approach lead to significant improvement which warrants the downsides of having to use a black-box, hard to understand algorithm?",
                "Limitations": "In terms of societal impact, I think it is nice that the authors have applications to interpretability. Limitations are discussed in Section 4.1.2.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper discusses using neural computation to compute values of cooperative game theory in weighted voting games and feature importance games.  For weighted voting games, models for both fixed and variable numbers of players are given.  While fixed models outperformed variable models, results on random games indicates that both models do relatively well.  Furthermore, predictions fro feature importance games are quite good after training on only a small amount of training data.",
                "Strengths And Weaknesses": "Strengths:\n\nThe paper does a good job of describing and introducing the problem.\n\nThe presentation of the paper is clear and clean.\n\nThis paper implements and tests a good, simple, and useful idea: Can neural computation to computer values of cooperative game theory.  \n\nThe analysis of the results is good and detailed.\n\n\nWeaknesses:\n\nIt would be fun to illustrate how well the trained neural networks perform on known problems rather than on just random games.\n\n(Table 1) Suggestion: I think it would be good to understand how significant the failures are when the neural network fails (e.g., significantly out of distribution).  Is there any way to detect when it would fail?\n\n\nA few minor nitpicks:\n\nIt\u2019s probably right in front of my eyes, but I could see where p(C) was defined on line 111\n\nLine 260: fix \u201cat a the cost\u201d \u2014 there\u2019s clearly an extra word",
                "Questions": "See comments in the previous section.",
                "Limitations": "I think further exploration of failure cases would be appropriate at some point",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "4 excellent",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper applies a multi-layer perceptron to learning to approximate the Shapley value of a weighted voting game (where the input is a description of the voting weights of each player, and the output is a vector of Shapley values for each voter).  The fixed-dimension case (for which the number of voters is constant) and variable dimension case are both considered; the variable dimension case is handled simply by zero-padding (i.e., non-players are added with weight 0 to every empty slot).\nAlthough weighted voting games are simple, approximating their Shapley value within a multiplicative factor is known to be intractable in the worst case.",
                "Strengths And Weaknesses": "The basic idea is sound: we sometimes want the Shapley value (to estimate the relative influence of different input features on the output of an ML model, or to estimate the relative power of different voters).  However, it's intractable to compute exactly.  So let's try approximating it by training a neural network on small instances.  It seems to work pretty well on the instances that they test on.\nOne of the main motivations for this work is scalability.  It can be exponentially expensive to compute the Shapley value as the number of participants increases, making an approximation approach valuable.  Clearly the network with a fixed number of participants won't be much use in large-scale situations, since the training data needs to be as large as the test data.  On the other hand, the paper shows that you can get decent performance by training on a dataset with about half as many participants as in the test set (using the zero-padding variable-dimension approach).  This is of course better than nothing, but I'm skeptical that an approximate doubling of the feasible size of input is going to be sufficient in settings that actually need scale.\nThe paper is clearly written, with the exception of the material on explainable AI.  This domain is an important part of the paper's motivation, but its treatment feels like something of an afterthought.   I can take a guess at what is going on here (the \"value\" created by a given agent is going to be either the average change in a binary classification, or the average change in regression output, averaged over all orderings), but it would be nice if this were somehow made explicit.  Section 3.2 doesn't really give any details about the actual procedure (what is a \"sampled sub-dataset\"?  Are you sampling rows (instances) or columns (features)?  Appendix D.2 doesn't refer to this at all.).  Section 2.2 is similarly vague.\nOverall, I don't think this work clears the significance bar for publication at NeurIPS.  It proposes a standard feedforward architecture for prediction in a specific scenario.  The scenario is interesting but not really deeply explored.  There is no explicit comparison to baselines, so it's hard to tell what we actually gain.  In particular, we don't see any performance numbers at all.  How large is the performance difference vs standard techniques?  Are you able to do well on instances that take SHAP weeks, for example?\nminor comments\n\np.5: \"we redistribute the payoffs allocated to non-player entries\": How necessary does this turn out to be?  (I.e., is a substantial fraction of payoff often allocated to non-players?)\n\np.6: The first paragraph of s.3.2 is very repetitive\n\nOn a related note, it's not clear from the main text what the ground truth for figure 7 is meant to be.\n\nFigure 2 is unreadably small, and also seems to make the PDF very slow to render.",
                "Questions": "Do you have performance numbers (both timing and prediction quality) for any scenario where the use of something like SHAP would be intractable?",
                "Limitations": "see strengths/weaknesses",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.333,
        "confidence_avg": 3.667,
        "soundness_avg": 3.333,
        "presentation_avg": 3.333,
        "contribution_avg": 2.667,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that the paper proposes a sound and technically solid approach to computing agent/feature importance in complex cooperative game theoretic settings. The authors' algorithms perform well according to the experiments and the proposed framework has several useful applications. While there are some concerns raised by the reviewers regarding the necessity of the neural net approach and the lack of comparison with previous work, overall the paper presents a valuable contribution to the field. The limitations and potential ethical considerations are adequately discussed. Therefore, I recommend accepting the paper."
    },
    "Implicit_Neural_Representations_with_Levels-of-Experts": {
        "link": "https://openreview.net//forum?id=St5q10aqLTO",
        "pub_url": "https://openreview.net/forum?id=St5q10aqLTO",
        "pdf_link": "https://openreview.net//pdf?id=St5q10aqLTO",
        "paper_id": "St5q10aqLTO",
        "title": "Implicit_Neural_Representations_with_Levels-of-Experts",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nThis paper presents a framework for position-dependent MLPs where the weights in each layer depend on the input coordinate periodically, with hierarchically tiled periodic weight patterns across successive layers. The paper shows that such models outperform prior work on a variety of tasks involving data representation. The reviewers all agree that the proposed approach is novel and highly effective, and the paper is clear and compelling. I accordingly recommend acceptance.",
        "reviews": [
            "Reviewer 1: \nSummary: A Mixture of Experts framework is proposed that uses a dynamic weight MLP with position-dependent weights for solving various coordinate based tasks such as signal fitting, novel view synthesis and generative modeling. Unlike other hybrid representations that divide the space to use different MLPs, the proposed method uses layer-level tiling in the network architecture which produces smoother boundary interpolations. The results adequately establish the efficacy of the approach on 4 challenging tasks compared to strong baselines.\nStrengths And Weaknesses: Strengths:\n\nThe paper is very well-written, with relevant references and easy-to-follow narration.\nThe method is simple and general enough such that can be plugged into many different coordinate based tasks, as shown in the experiments.\nThe evaluations show significant gains in accuracy as compared to the prior art.\n\nWeaknesses:\n\nThe paper claims that the LoE formulation could be used to model large-scale signals. None of the experiments reflect this claim.  \nThe network design of hierarchical and tiled weights seem handcrafted. It is not clear if there is a way to come up with the correct pattern without trial-and-error.\nIt will be interesting to see comparison to more recent encoding strategies such as Instant-NGP's multi-resolution hash encoding etc.\nQuestions: \nHow did you come up with the optimal hierarchical tiling pattern.\nWhat are the ranges of alpha and beta. How do these hyperparameters affect the continuity at the boundaries.\nLimitations: The limitations have been adequately addressed in the paper.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 3 good\nRating: 8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper addresses the compactness and efficiency issue in grid based signal representations and propose a Levels-of-Experts (LoE) framework that hierarchically arrange the weights of the MLP from a set of candidate weight matrix for high fidelity data (image, video, volume) representation.\nStrengths And Weaknesses: What's good:\n\nThe paper organization and presentation are clear.\nThe idea of position-dependent weight is novel and interesting.\nThe paper provides qualitative and quantitated evaluations on image and video regression, radiance field reconstruction and image generation. The experiments are sufficient to demonstrate the effectiveness.\n\nTo be improved:\n\nThe abstract claims that the key advance of the proposed method is its compact global latent representation compared to most recent grid based approaches, however, I couldn't find any related discussion or experiment on why global representation is better. Maybe a continue or high order derivative could be one of the advantages?\nMore comparison results and details discussions with recent approaches would be appreciated, such as BACON[23], MFN [9] and instant-NGP [33].\nSeems the reference to TensoRF is incorrect, please check.\nQuestions: I do not fully understand why the proposed representation is able to reduce computational costs compared to prior works (L296). If I understand it correctly, the linear interpolation between weights is extremely consumed (k times number of layer times nodes of each layer), and the computational costs can be significantly larger for high dimensional data (dim>1).\nLimitations: Limitations have been discussed in detail.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The submission proposes a new Neural Architecture for coordinate-based networks.\nMotivated by previous work that decomposes the domain and trains distinct networks within them, a so-called\"Level of Experts\" architecture is proposed.\nInstead of distinct networks for each subarea, the authors propose to assign each weight matrix of a layer to multiple parts of the signal domain with periodic recurrence via a query function. The number of available weight matrices and the frequency of their occurrence can vary for each layer of the architecture, i.e. the result is a hierarchy of position-dependent and periodic weights. \nThis is accomplished via first shifting and scaling the position, and then passing it through a modulo-based operation that maps the position to a grid of weight matrices.\nTo avoid discontinuities, the query function does not return a single weight matrix, but instead a linear or bilinear interpolation of the 'nearest' (with respect to the query function) weight matrices.\nNotably, the proposed architecture does not require an additional positional encoding at the input.\nExperiments:\n\nThe expressivity of the architecture for fitting a high-resolution (8192x8192) image as well as a video (512x512; 300 frames) is demonstrated. Comparisons are made with related architectures such as MLPs with positional encoding and MLPs with sinusoidal activations (SIREN).\nDifferent settings for the query function are evaluated, each of which corresponds to different \"patterns\" in the signal space.\nA Novel View Synthesis task (\"Tanks and Temples dataset\") using NERF. Comparisons include MLPs+positional encoding and a nonhierarchical setting (i.e. a decomposition of the domain into chunks for independent networks). Focus is drawn to the spatial artifacts of the simple domain decomposition, whereas the proposed method resolves these issues with the interpolation of the weights.\nImage Generation using GANs, with the proposed architecture as the generator.\n\nIn all settings of 1.) and 2.) the \"Level of Experts\" architecture provides higher PSNR and SSIM while having comparable computational cost to a simple MLP with positional encoding.\nSimilar results are obtained for the generative model in 3.), here showing a higher FID with comparable computational costs.\nFor the interpolation between the weight matrices, the linear interpolation shows similar performance to the bilinear case, while having significantly lower computational costs.\nStrengths And Weaknesses: Significance:\n\n(Medium) An general architecture for coordinate-based Neural Networks is proposed, outperforming comparable state-of-the-art in a wide range of tasks while preserving low computational costs.\n(Medium) The proposed framework is mostly orthogonal to existing methods for improving implicit representations and appears to be relatively simple to implement, offering itself to practical use and future work.\n\nOriginality\n\nTo the best of my knowledge, the proposed use of periodically reoccurring weight matrices in each layer of the \"Levels-of-Experts\" is novel.\nThe related work seems to sufficiently cover the existing literature and competitive methods. It should however be noted that I have limited familiarity with this specific subfield and might not be aware of newer work.\n\nQuality\n\nThe paper seems to the best of my knowledge to be technically sound, however, it is mostly of a practical nature providing a novel architecture/framework.\nThe experiments cover a wide range of tasks, and are generally sound, showcasing both quantitative and qualitative results and advantages compared to existing approaches.\nNo code is included, although later publication is indicated. This disagrees with the given answer in Checklist 3. a).\n\nClarity\n\nThe paper is well written, clearly structured, and in general enjoyable to read.\nThe method is clearly described. It should be clear how to reimplement the proposed levels of experts given the paper.\n\nIn summary, the paper is well written and the proposed method is sound.\nThe contribution is of mainly practical nature, but its clear advantages are shown in extensive experiments.\nQuestions: The method of [1] is mentioned to have a similar high-level idea, and its limitations are indirectly shown with the chunked settings.  I think the argument for the advantage of the \"Levels-of-Experts\" could be made even stronger, by highlighting that the architecture of [1] requires the \"Chunked\" network to be distilled from a pre-trained network. \n[1] Reiser, Christian, et al. \"Kilonerf: Speeding up neural radiance fields with thousands of tiny mlps.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021.\nLimitations: The authors sufficiently address the limitations in terms of the required prior information about the signal for selecting the grid scales.\nIn addition, the limited applicability to settings that require (higher-order) derivatives (e.g. Physics Informed Neural Networks) is mentioned, which is a result of the underlying interpolation method between the weight matrices.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: The paper proposes an algorithm for performing implicit neural representation in a hybrid fashion, trading off between the discrete and continuous counterpart through a hierarchical tiling structure. The authors propose a fast tiling mechanism determining which MLP system to use at what hierarchical level (layer). The authors showcase that this methodology of using multiple experts at every layer with a fast expert-accessing mechanism leads to performance benefits on modelling high resolution images and videos, and ultimately outperforms the baseline counterparts on the tasks of novel view synthesis as well as GAN-based image generation tasks.\nStrengths And Weaknesses: Strengths\n\nThe authors propose an intuitive extension to coordinate-based MLP systems by allowing for coordinate-dependent weight matrices.\nThe choice of expert chosen at any point in the grid and hierarchy is obtained through an extremely fast algorithm.\nThe results show improvements of the proposed approach over the baselines, often with lower memory cost.\n\nWeaknesses\n\nThe proposed work introduces certain additional hyper-parameters, namely (\u03b1i,\u03b2i), ablations regarding which are lacking in the draft.\nThe authors claim that their approach leads to dynamic expert selection; however the proposed algorithm only lays out a static tiling based on which expert selection is done. I would recommend the readers to refer to Is a Modular Architecture Enough? (Mittal et. al 2022) or Recurrent Independent Mechanisms (Goyal et. al 2019) as some of the works that look into dynamic expert selection, as opposed to a static grid tiling.\nAre the results of the experiments in Section 4.1 - 4.3 averaged over different high resolution images or different video samples or is it only based on a single example?\nThe work is lacking in quantifying the variance of the results, which can be obtained through multiple seeded runs as well as multiple data-points.\nQuestions: I have a few clarification questions that might help me understand the work better.\n\nWhy is there such a big difference in the number of parameters between PE MLP system and the others?\nFurther, why are the number of parameters same in PE + CE with the proposed models? The proposed model introduces N different weight matrices at every layer, so I would assume that the number of parameters would grow by \u00d7N\nIn the novel view synthesis, how is only indirect supervision provided? Is there not ground-truth supervision based on the true color and density at the different points on the ray? Some clarification on this would be helpful.\nLimitations: The work can be substantially improved by averaging the performance of the proposed algorithm over multiple different data-points as opposed to just a single example. Further, the authors should do some form of variance analysis to make sure that the results are statistically significant. Finally, for some reason a lot of the Figures have captions that talk about top and bottom row, while the figure only has one row (eg. Figure 4)\nBeyond this, there are no potential negative societal impacts that I can think of which stem from this work.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "A Mixture of Experts framework is proposed that uses a dynamic weight MLP with position-dependent weights for solving various coordinate based tasks such as signal fitting, novel view synthesis and generative modeling. Unlike other hybrid representations that divide the space to use different MLPs, the proposed method uses layer-level tiling in the network architecture which produces smoother boundary interpolations. The results adequately establish the efficacy of the approach on 4 challenging tasks compared to strong baselines.",
                "Strengths And Weaknesses": "Strengths:\n\nThe paper is very well-written, with relevant references and easy-to-follow narration.\nThe method is simple and general enough such that can be plugged into many different coordinate based tasks, as shown in the experiments.\nThe evaluations show significant gains in accuracy as compared to the prior art.\n\nWeaknesses:\n\nThe paper claims that the LoE formulation could be used to model large-scale signals. None of the experiments reflect this claim.  \nThe network design of hierarchical and tiled weights seem handcrafted. It is not clear if there is a way to come up with the correct pattern without trial-and-error.\nIt will be interesting to see comparison to more recent encoding strategies such as Instant-NGP's multi-resolution hash encoding etc.",
                "Questions": "How did you come up with the optimal hierarchical tiling pattern.\nWhat are the ranges of alpha and beta. How do these hyperparameters affect the continuity at the boundaries.",
                "Limitations": "The limitations have been adequately addressed in the paper.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper addresses the compactness and efficiency issue in grid based signal representations and propose a Levels-of-Experts (LoE) framework that hierarchically arrange the weights of the MLP from a set of candidate weight matrix for high fidelity data (image, video, volume) representation.",
                "Strengths And Weaknesses": "What's good:\n\nThe paper organization and presentation are clear.\nThe idea of position-dependent weight is novel and interesting.\nThe paper provides qualitative and quantitated evaluations on image and video regression, radiance field reconstruction and image generation. The experiments are sufficient to demonstrate the effectiveness.\n\nTo be improved:\n\nThe abstract claims that the key advance of the proposed method is its compact global latent representation compared to most recent grid based approaches, however, I couldn't find any related discussion or experiment on why global representation is better. Maybe a continue or high order derivative could be one of the advantages?\nMore comparison results and details discussions with recent approaches would be appreciated, such as BACON[23], MFN [9] and instant-NGP [33].\nSeems the reference to TensoRF is incorrect, please check.",
                "Questions": "I do not fully understand why the proposed representation is able to reduce computational costs compared to prior works (L296). If I understand it correctly, the linear interpolation between weights is extremely consumed (k times number of layer times nodes of each layer), and the computational costs can be significantly larger for high dimensional data (dim>1).",
                "Limitations": "Limitations have been discussed in detail.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The submission proposes a new Neural Architecture for coordinate-based networks.\nMotivated by previous work that decomposes the domain and trains distinct networks within them, a so-called\"Level of Experts\" architecture is proposed.\nInstead of distinct networks for each subarea, the authors propose to assign each weight matrix of a layer to multiple parts of the signal domain with periodic recurrence via a query function. The number of available weight matrices and the frequency of their occurrence can vary for each layer of the architecture, i.e. the result is a hierarchy of position-dependent and periodic weights. \nThis is accomplished via first shifting and scaling the position, and then passing it through a modulo-based operation that maps the position to a grid of weight matrices.\nTo avoid discontinuities, the query function does not return a single weight matrix, but instead a linear or bilinear interpolation of the 'nearest' (with respect to the query function) weight matrices.\nNotably, the proposed architecture does not require an additional positional encoding at the input.\nExperiments:\n\nThe expressivity of the architecture for fitting a high-resolution (8192x8192) image as well as a video (512x512; 300 frames) is demonstrated. Comparisons are made with related architectures such as MLPs with positional encoding and MLPs with sinusoidal activations (SIREN).\nDifferent settings for the query function are evaluated, each of which corresponds to different \"patterns\" in the signal space.\nA Novel View Synthesis task (\"Tanks and Temples dataset\") using NERF. Comparisons include MLPs+positional encoding and a nonhierarchical setting (i.e. a decomposition of the domain into chunks for independent networks). Focus is drawn to the spatial artifacts of the simple domain decomposition, whereas the proposed method resolves these issues with the interpolation of the weights.\nImage Generation using GANs, with the proposed architecture as the generator.\n\nIn all settings of 1.) and 2.) the \"Level of Experts\" architecture provides higher PSNR and SSIM while having comparable computational cost to a simple MLP with positional encoding.\nSimilar results are obtained for the generative model in 3.), here showing a higher FID with comparable computational costs.\nFor the interpolation between the weight matrices, the linear interpolation shows similar performance to the bilinear case, while having significantly lower computational costs.",
                "Strengths And Weaknesses": "Significance:\n\n(Medium) An general architecture for coordinate-based Neural Networks is proposed, outperforming comparable state-of-the-art in a wide range of tasks while preserving low computational costs.\n(Medium) The proposed framework is mostly orthogonal to existing methods for improving implicit representations and appears to be relatively simple to implement, offering itself to practical use and future work.\n\nOriginality\n\nTo the best of my knowledge, the proposed use of periodically reoccurring weight matrices in each layer of the \"Levels-of-Experts\" is novel.\nThe related work seems to sufficiently cover the existing literature and competitive methods. It should however be noted that I have limited familiarity with this specific subfield and might not be aware of newer work.\n\nQuality\n\nThe paper seems to the best of my knowledge to be technically sound, however, it is mostly of a practical nature providing a novel architecture/framework.\nThe experiments cover a wide range of tasks, and are generally sound, showcasing both quantitative and qualitative results and advantages compared to existing approaches.\nNo code is included, although later publication is indicated. This disagrees with the given answer in Checklist 3. a).\n\nClarity\n\nThe paper is well written, clearly structured, and in general enjoyable to read.\nThe method is clearly described. It should be clear how to reimplement the proposed levels of experts given the paper.\n\nIn summary, the paper is well written and the proposed method is sound.\nThe contribution is of mainly practical nature, but its clear advantages are shown in extensive experiments.",
                "Questions": "The method of [1] is mentioned to have a similar high-level idea, and its limitations are indirectly shown with the chunked settings.  I think the argument for the advantage of the \"Levels-of-Experts\" could be made even stronger, by highlighting that the architecture of [1] requires the \"Chunked\" network to be distilled from a pre-trained network. \n[1] Reiser, Christian, et al. \"Kilonerf: Speeding up neural radiance fields with thousands of tiny mlps.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021.",
                "Limitations": "The authors sufficiently address the limitations in terms of the required prior information about the signal for selecting the grid scales.\nIn addition, the limited applicability to settings that require (higher-order) derivatives (e.g. Physics Informed Neural Networks) is mentioned, which is a result of the underlying interpolation method between the weight matrices.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper proposes an algorithm for performing implicit neural representation in a hybrid fashion, trading off between the discrete and continuous counterpart through a hierarchical tiling structure. The authors propose a fast tiling mechanism determining which MLP system to use at what hierarchical level (layer). The authors showcase that this methodology of using multiple experts at every layer with a fast expert-accessing mechanism leads to performance benefits on modelling high resolution images and videos, and ultimately outperforms the baseline counterparts on the tasks of novel view synthesis as well as GAN-based image generation tasks.",
                "Strengths And Weaknesses": "Strengths\n\nThe authors propose an intuitive extension to coordinate-based MLP systems by allowing for coordinate-dependent weight matrices.\nThe choice of expert chosen at any point in the grid and hierarchy is obtained through an extremely fast algorithm.\nThe results show improvements of the proposed approach over the baselines, often with lower memory cost.\n\nWeaknesses\n\nThe proposed work introduces certain additional hyper-parameters, namely (\u03b1i,\u03b2i), ablations regarding which are lacking in the draft.\nThe authors claim that their approach leads to dynamic expert selection; however the proposed algorithm only lays out a static tiling based on which expert selection is done. I would recommend the readers to refer to Is a Modular Architecture Enough? (Mittal et. al 2022) or Recurrent Independent Mechanisms (Goyal et. al 2019) as some of the works that look into dynamic expert selection, as opposed to a static grid tiling.\nAre the results of the experiments in Section 4.1 - 4.3 averaged over different high resolution images or different video samples or is it only based on a single example?\nThe work is lacking in quantifying the variance of the results, which can be obtained through multiple seeded runs as well as multiple data-points.",
                "Questions": "I have a few clarification questions that might help me understand the work better.\n\nWhy is there such a big difference in the number of parameters between PE MLP system and the others?\nFurther, why are the number of parameters same in PE + CE with the proposed models? The proposed model introduces N different weight matrices at every layer, so I would assume that the number of parameters would grow by \u00d7N\nIn the novel view synthesis, how is only indirect supervision provided? Is there not ground-truth supervision based on the true color and density at the different points on the ray? Some clarification on this would be helpful.",
                "Limitations": "The work can be substantially improved by averaging the performance of the proposed algorithm over multiple different data-points as opposed to just a single example. Further, the authors should do some form of variance analysis to make sure that the results are statistically significant. Finally, for some reason a lot of the Figures have captions that talk about top and bottom row, while the figure only has one row (eg. Figure 4)\nBeyond this, there are no potential negative societal impacts that I can think of which stem from this work.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.75,
        "confidence_avg": 3.0,
        "soundness_avg": 3.25,
        "presentation_avg": 3.25,
        "contribution_avg": 2.75,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the proposed Mixture of Experts framework using dynamic weight MLP with position-dependent weights for coordinate-based tasks is a technically strong and novel approach. The paper is well-written and easy to follow, with relevant references. The experiments demonstrate the efficacy of the approach compared to strong baselines in various tasks.\n\nWhile there are some limitations and areas for improvement mentioned by the reviewers, such as the need for more comparisons with recent approaches and a better understanding of the optimal hierarchical tiling pattern, these do not outweigh the strengths and contributions of the paper.\n\nOverall, the paper presents a technically solid and impactful contribution, with good evaluation, resources, and reproducibility. Therefore, I recommend accepting the paper."
    },
    "LieGG:_Studying_Learned_Lie_Group_Generators": {
        "link": "https://openreview.net//forum?id=9sKZ60VtRmi",
        "pub_url": "https://openreview.net/forum?id=9sKZ60VtRmi",
        "pdf_link": "https://openreview.net//pdf?id=9sKZ60VtRmi",
        "paper_id": "9sKZ60VtRmi",
        "title": "LieGG:_Studying_Learned_Lie_Group_Generators",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nThe paper proposes a novel technique to extract symmetry inductive biases from data that can be applied to any neural network architecture. Please include more discussions with the related work and possible experimental comparisons in the updated version.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper proposes learned Lie Group Generators (LieGGs) to investigate symmetries encoded in neural networks inversely. It is based on the Lie group-Lie algebra correspondence, which describes an arbitrary matrix Lie group as an exponential map of the corresponding Lie algebra. The authors exploit the fact that infinitesimal generators of a Lie algebra g of a matrix Lie group G acts on data D should satisfy a certain algebraic equation (Theorem 3.1) when there is a G-invariant mapping function F:X\u2192R that satisfies F(x)=0 where x\u2208D. Because a neural network is an approximation of such F (if the underlying data is G-invariant and the neural network learns the data well), the learned symmetries encoded in neural networks can be inversely retrieved by using the proposed method. The authors validate their proposed approach for a simple synthetic problem and rotated MNIST. Also, the authors formulate two metrics that can measure a degree of encoded symmetries, i.e., symmetry bias and variance, based on their approach.\nStrengths And Weaknesses: [Strengths]\nExtracting as well as learning symmetries is a definitely crucial problem in the modern deep learning field. While most of the previous works focus on the latter problem, this paper addresses the former one based on a theoretically convincing method, namely Lie algebra. The paper is well-written and the presentation is easy-to-follow. The proposed symmetry bias and variance might be potentially useful metrics to measure the degree of symmetries when building a new G-invariant model.\n[Weaknesses]\nI did not find any critical drawback in this paper. Possible weaknesses include:\nThere is no comparison with competitors. Especially, a comparison with the following paper might be important:\nN. Dehmamy, R. Walters, Y. Liu, D. Wang, and R. Yu. Automatic Symmetry Discovery with Lie Algebra Convolutional Network. NeurIPS 2021.\nDehmamy et al. also use the concept of Lie algebra to deal with arbitrary group symmetries, and as its title indicates, it seems their method might be used for the recovery of underlying symmetries encoded (if I am wrong please correct me). I think the lack of the comparison is not a critical issue because the proposed method is more general, i.e., can be applied to arbitrary neural network architectures - but at least a simple comparison with Lie algebra CNN for the rotation MNIST seems to need for the completeness of the work.\nRotated MNIST is only a dataset benchmarked in this paper. Because both MNIST and SO(2) are under relatively simple settings, I am not fully convinced whether the proposed method works well for other datasets or group structures. Possible benchmark candidates might include more complicated images with SE(2).\nQuestions: As I mentioned, I am generally satisfied with the paper. Some minor comments are the followings:\n\nCan the authors elaborate on the effect of the Gaussian smoothing, e.g., is it critical when using the binary rotated MNIST directly?\nIn (2), isn't i=j=n?\nIn (3), it seems that the underlying group structure is assumed to be a one-parameter sub-group exp\u2061(th) parameterized by t\u2208R which is not fully general. Please elaborate on whether the proposed method is applicable for a general GL(n) or its one-parameter subgroup only.\nAssume a subset of the rotated MNIST consists of '6's and '9's. '6's and '9's yield identical G-orbits while they are not G-invariant with respect to the labeling distribution. Can the proposed method work well for such a subset?\nCan the proposed method be used for investigating G-equivariance?\nLimitations: The authors state the limitation (limited to GL(n) group) of the proposed method in the section Conclusion. I think that this is an acceptable limitation considering GL(n) is a major and interesting group structure for various problems.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The authors propose LieGG, a method for recovering the Lie group generators corresponding to the symmetries of a trained network. Using their approach, the authors can measure how close a recovered generator is to the true symmetry and to what degree a network is invariant to that transformation. The authors evaluate on synthetic data and MNIST using MLP networks of different depth with known symmetries in the data.\nStrengths And Weaknesses: Strengths\n\nThe authors propose a theoretically motivated algorithm for recovering a Lie group generator from a deep neural network that is novel to the best of my knowledge. They evaluate the efficacy of their algorithm on MNIST rotation to show that a deep network trained on rotated MNIST digits implicitly becomes invariant to rotation.\nThe authors propose valuable metrics to evaluate the quality of a learned Lie group and to measure how invariant a model is to a given Lie group.\n\nWeaknesses\n\nThe authors argue that networks trained with \u201chard [coded] symmetry\u201d may \u201cnot always lead to a better generalization\u201d on lines 20-21, but they never support this claim with experimental data. It would be nice for the authors to compare using their proposed metrics between deep networks that implicitly learn symmetry and those that explicitly incorporate symmetry, such as (Finzi et al. 2021).\nThe experimental results on the invariance of MLPs at different depths are of moderate significance. I would have hoped the authors test their method with larger models and datasets with more advanced invariances. For example, it would be interesting to apply an augmentation to samples from a dataset like CIFAR10 and use LieGG to measure whether the deep network becomes invariant to that augmentation.\n\nMisc fixes:\n\nThere are several spelling and grammatical mistakes in the experiments section. Please re-read and revise. Here are a few:\n\u201cWe the MLP\u201d line 178\n\u201ccloses\u201d line 182\n\u201cHow the ability of the network to learn\u201d line 193\n\u201cThe symmetry learn by the\u201d line 220\n\n\nThe authors should consider references to a part of the literature on learning Lie group generators from data & incorporating them into networks to encourage invariance (a different, yet related task to recovering Lie group generators from a network to evaluate invariance), such as (\"Learning Lie Groups for Invariant Visual Perception,\u201d Rao et al. 1999), (\u201cLearning transport operators for image manifold,\u201d Culpepper and Olshausen 2009), (\u201cAn Unsupervised Algorithm For Learning Lie Groups,\u201d Sohl-Dickstein et al. 2010), and (\u201cRepresenting Closed Transformation Paths in Encoded Network Latent Space,\u201d Connor and Rozell 2020).\nPlease explicitly state which training scenario corresponds with each entry in the legend of Figure 5.\nQuestions: \nWhat is v_p in equation 3? \nHow does LieGG perform without pre-processing with Gaussian smoothing? Is spatial smoothness of the input data a requirement for LieGG to perform well? This ablation would be nice to have.\nWhat is the p-value corresponding to the correlations in Figure 4b? Please report these in the manuscript.\nHow does this approach scale with dataset size (computational complexity of SVD + sample complexity of LieGG)? It would be nice to include experiments that measure these properties.\nIs it possible use LieGG to co-train with network weights to decrease the symmetry variance of a network? For example, (Connor and Rozell 2020) show that after a fine-tuning step with learned Lie group generators, the corresponding Lie group provides a significantly better model of MNIST digit rotation.\nLimitations: \nThe authors metric for symmetry variance seems to fall off in performance as the depth of a network is increased. Perhaps this can be attributed to the approximation to the matrix exponential employed on line 163. The weakness of this approximation has been noted in the literature before in (Rao et al. 1999) vs (Culpepper and Olshausen 2009).\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 2 fair\nContribution: 2 fair\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The paper presents a method, LieGG, for identifying learned in variances in a trained model.  Specifically, by differentiating the model with respect to its inputs and looking at these derivatives at various inputs points, a polarization matrix is constructed which has as its nullspace, generators of a Lie algebra of invariances. This can be learned using SVD.  The authors apply their method to MLPs trained on a sythentic function with O(5) symmetry and Rotated MNIST which has SO(2) symmetry.  In both cases, the learned model displays the expected invariance.  The authors also analyze the effect of network size, shape, and trained on learned symmetry.\nStrengths And Weaknesses: Strength\n\nThis work is very timely and the question is important.  It is becoming increasingly clear that symmetry is a key part of deep learning and the idea that symmetry can be learned directly from data has motivated several recent works on symmetry discovery.  The hope is that neural networks may be useful in e.g. scientific domains for discovering interpretable findings about different systems from data.\nThe method is an effective application of the theory of symmetries of differential equations.  The background is clearly presented and theorem 2.8 form [37] is nicely explained with an example.   \nThe method is able to explicitly find symmetries of learned models.  These symmetries are in the form of Lie algebra generators.  This is similar to the form of the symmetries found by (Dehmamy, 2021), however, an advantage of the current work is that no special architecture is necessary in order to learn the symmetry.  \nIt could be said the proposed method is not really for demonstrating that neural networks learn symmetry (see first weakness/question), but for learning invariances of the ground truth function from data.  At first, I wondered if these invariances could be estimated directly from data without training a neural network first.  However, it seems that training a neural network gives an effective way to estimate df/dx_i in equation 2 which would otherwise be difficult to do directly from data alone.  In this light, I think the proposed method is quite an effective way to discover invariances in data indirectly. \nThe finding (Line 244-245) that deeper networks learn symmetry better as the capacity is increased versus shallow networks is interesting and seems useful in network design.\n\nWeakness / Questions\n\nMy main question about the method is that it's unclear what it means for a model to learn symmetry independently of learning the task function accurately.  Consider a regression problem.  If the model F trains well to approximate a ground truth function which is invariant with RMSE error at most \\epsilon, then it seems to me the symmetry variance (invariance error) is bounded by 2\\epsilon.  That is, the model has symmetry because it learned the ground truth and that has symmetry.  In this case, I would not really say the model did any particular invariance learning.  If it could be demonstrated that the model had even lower symmetry variance that expected given the accuracy or was capable of extrapolation based on the invariance, then I would grant the model had learned symmetry.  This question is somewhat examined in \"Symmetry vs. accuracy\" (Line 250), but here the conclusion seems to support my suspicion that any learned symmetry is really an emergent consequence of accurately fitting the ground truth function.      \nI don't understand the second sentence of the abstract.  If a network first learns symmetry wouldn't it be starting to learn from no symmetry?  I presume the point of this sentence is perhaps to contrast with methods such as equivariant neural networks in which symmetry is encoded into the network as a prior, but I don't think it is very clear. \nTheorem 3.1, Line 107-108. I looked at the reference [37] from which this theorem is quoted.  This statement appears to be a special case of the generality stated there, but with some missing assumptions.  The hypothesis here says n-dimensional manifold X, however, the equation given does not refer to local coordinates and so I believe assumes X=R^k and G \\subset GL_k(R) and acts by matrix multiplication on X.  If I understand correctly, this puts in the setting of [37, Example 1.28b] with a linear vector field.  That is, we are assuming symmetries are global linear symmetries of the space.  This is definitely still a useful level of generality to consider, but it does exclude some cases.  For example, F(x,y) = y - x^2.  I'd recommend clarifying the assumptions and deriving the special case from the general theorem in the appendix.  \nSection 4.1 has some unclear writing.  The idea of image as function (Line 140-141) can be clearer.  Line 141:  A function should be defined either in terms of spaces, X\u2192Y or elements x\u21a6y or both.  This mixes both.  The notation in the equation between Line 146 and Line 147 is unclear.  Is the goal actually to describe a group action on the space of images?  In that case, I would define (g\u22c5f)(x)=f(g\u22121\u22c5x).  In particular, I would not use the same notation for the the group G and the action map a:G\u00d7X\u2192X.  Lastly, what is really going on here (it seems to me) is that the space of potential symmetries on the full space of images is too high-dimensional for the current method to be effective and so you have limited yourself to the 4-dimensional subgroup of spatial symmetries.  This is a strong prior over the potential invariances you are looking for. \nLine 161:  It would be very helpful to include a formal definition of symmetry bias and symmetry variance. \nLine 224-225: I'm not sure I agree with the conclusion about the smoothness of the spectrum of the polarization matrix or with the conclusion that the method can robustly find noisy symmetries.  In this case there is a very strong prior of the symmetry group being within a 4-dimensional subgroup of spatial symmetries. It's hard to evaluate smoothness over only 4 data points and the strength of this inductive bias could be the reason the model performs well here.    \n\"Intermediate Symmetries\" (Line 276): In an equivariant neural network, only the last layer or last layers are usually used to project to an invariant representation.  Intermediate representations usually display equivariance instead of invariance with respect to some latent group representation type.  In that sense, it is perhaps not surprising that intermediate layers do not show invariance.\nQuestions: Minor Points\n\nLine 93: Technically, it is not enough to know the Lie algebra to know the symmetry group.  For example, we discard any discrete symmetries.\nLine 114: 2 is missing from the equation\nLine 126: call it the network ...\nEquation 3 after Line 150: There is no sum over images only over pixel locations.  Should there be a sum over images f as well?\nEquations after Line 163: How is t sampled?  \nEquations after Line 163: In the second line of the equation, I think it should be t^2\nEquations after Line 163: In the third line of the equation, I think there is a missing parenthesis. \nEquation after Line 164: Should it be O(t^4)?  \nLine 165: Why is this only an estimate?\nEquation after Line 167: Should h_l be squared? \nLine 170: \"Last\" singular values is imprecise. \nLine 182: with a closest \nLine 188: the input space is R10 or R2\u00d75. It doesn't really make sense to use both multiplicative and exponential notation for the same thing.  \nFigure 5: describe abbreviations in caption\n\nPost-Response Edit\nI appreciate the authors response to my questions and maintain my positive score.\nLimitations: The limitations section is good, but the authors could be clearer about what \"more complex transformations\" means.  The assumptions in Theorem 3 and resulting limitations should also be clarified.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper proposes learned Lie Group Generators (LieGGs) to investigate symmetries encoded in neural networks inversely. It is based on the Lie group-Lie algebra correspondence, which describes an arbitrary matrix Lie group as an exponential map of the corresponding Lie algebra. The authors exploit the fact that infinitesimal generators of a Lie algebra g of a matrix Lie group G acts on data D should satisfy a certain algebraic equation (Theorem 3.1) when there is a G-invariant mapping function F:X\u2192R that satisfies F(x)=0 where x\u2208D. Because a neural network is an approximation of such F (if the underlying data is G-invariant and the neural network learns the data well), the learned symmetries encoded in neural networks can be inversely retrieved by using the proposed method. The authors validate their proposed approach for a simple synthetic problem and rotated MNIST. Also, the authors formulate two metrics that can measure a degree of encoded symmetries, i.e., symmetry bias and variance, based on their approach.",
                "Strengths And Weaknesses": "[Strengths]\nExtracting as well as learning symmetries is a definitely crucial problem in the modern deep learning field. While most of the previous works focus on the latter problem, this paper addresses the former one based on a theoretically convincing method, namely Lie algebra. The paper is well-written and the presentation is easy-to-follow. The proposed symmetry bias and variance might be potentially useful metrics to measure the degree of symmetries when building a new G-invariant model.\n[Weaknesses]\nI did not find any critical drawback in this paper. Possible weaknesses include:\nThere is no comparison with competitors. Especially, a comparison with the following paper might be important:\nN. Dehmamy, R. Walters, Y. Liu, D. Wang, and R. Yu. Automatic Symmetry Discovery with Lie Algebra Convolutional Network. NeurIPS 2021.\nDehmamy et al. also use the concept of Lie algebra to deal with arbitrary group symmetries, and as its title indicates, it seems their method might be used for the recovery of underlying symmetries encoded (if I am wrong please correct me). I think the lack of the comparison is not a critical issue because the proposed method is more general, i.e., can be applied to arbitrary neural network architectures - but at least a simple comparison with Lie algebra CNN for the rotation MNIST seems to need for the completeness of the work.\nRotated MNIST is only a dataset benchmarked in this paper. Because both MNIST and SO(2) are under relatively simple settings, I am not fully convinced whether the proposed method works well for other datasets or group structures. Possible benchmark candidates might include more complicated images with SE(2).",
                "Questions": "As I mentioned, I am generally satisfied with the paper. Some minor comments are the followings:\n\nCan the authors elaborate on the effect of the Gaussian smoothing, e.g., is it critical when using the binary rotated MNIST directly?\nIn (2), isn't i=j=n?\nIn (3), it seems that the underlying group structure is assumed to be a one-parameter sub-group exp\u2061(th) parameterized by t\u2208R which is not fully general. Please elaborate on whether the proposed method is applicable for a general GL(n) or its one-parameter subgroup only.\nAssume a subset of the rotated MNIST consists of '6's and '9's. '6's and '9's yield identical G-orbits while they are not G-invariant with respect to the labeling distribution. Can the proposed method work well for such a subset?\nCan the proposed method be used for investigating G-equivariance?",
                "Limitations": "The authors state the limitation (limited to GL(n) group) of the proposed method in the section Conclusion. I think that this is an acceptable limitation considering GL(n) is a major and interesting group structure for various problems.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors propose LieGG, a method for recovering the Lie group generators corresponding to the symmetries of a trained network. Using their approach, the authors can measure how close a recovered generator is to the true symmetry and to what degree a network is invariant to that transformation. The authors evaluate on synthetic data and MNIST using MLP networks of different depth with known symmetries in the data.",
                "Strengths And Weaknesses": "Strengths\n\nThe authors propose a theoretically motivated algorithm for recovering a Lie group generator from a deep neural network that is novel to the best of my knowledge. They evaluate the efficacy of their algorithm on MNIST rotation to show that a deep network trained on rotated MNIST digits implicitly becomes invariant to rotation.\nThe authors propose valuable metrics to evaluate the quality of a learned Lie group and to measure how invariant a model is to a given Lie group.\n\nWeaknesses\n\nThe authors argue that networks trained with \u201chard [coded] symmetry\u201d may \u201cnot always lead to a better generalization\u201d on lines 20-21, but they never support this claim with experimental data. It would be nice for the authors to compare using their proposed metrics between deep networks that implicitly learn symmetry and those that explicitly incorporate symmetry, such as (Finzi et al. 2021).\nThe experimental results on the invariance of MLPs at different depths are of moderate significance. I would have hoped the authors test their method with larger models and datasets with more advanced invariances. For example, it would be interesting to apply an augmentation to samples from a dataset like CIFAR10 and use LieGG to measure whether the deep network becomes invariant to that augmentation.\n\nMisc fixes:\n\nThere are several spelling and grammatical mistakes in the experiments section. Please re-read and revise. Here are a few:\n\u201cWe the MLP\u201d line 178\n\u201ccloses\u201d line 182\n\u201cHow the ability of the network to learn\u201d line 193\n\u201cThe symmetry learn by the\u201d line 220\n\n\nThe authors should consider references to a part of the literature on learning Lie group generators from data & incorporating them into networks to encourage invariance (a different, yet related task to recovering Lie group generators from a network to evaluate invariance), such as (\"Learning Lie Groups for Invariant Visual Perception,\u201d Rao et al. 1999), (\u201cLearning transport operators for image manifold,\u201d Culpepper and Olshausen 2009), (\u201cAn Unsupervised Algorithm For Learning Lie Groups,\u201d Sohl-Dickstein et al. 2010), and (\u201cRepresenting Closed Transformation Paths in Encoded Network Latent Space,\u201d Connor and Rozell 2020).\nPlease explicitly state which training scenario corresponds with each entry in the legend of Figure 5.",
                "Questions": "What is v_p in equation 3? \nHow does LieGG perform without pre-processing with Gaussian smoothing? Is spatial smoothness of the input data a requirement for LieGG to perform well? This ablation would be nice to have.\nWhat is the p-value corresponding to the correlations in Figure 4b? Please report these in the manuscript.\nHow does this approach scale with dataset size (computational complexity of SVD + sample complexity of LieGG)? It would be nice to include experiments that measure these properties.\nIs it possible use LieGG to co-train with network weights to decrease the symmetry variance of a network? For example, (Connor and Rozell 2020) show that after a fine-tuning step with learned Lie group generators, the corresponding Lie group provides a significantly better model of MNIST digit rotation.",
                "Limitations": "The authors metric for symmetry variance seems to fall off in performance as the depth of a network is increased. Perhaps this can be attributed to the approximation to the matrix exponential employed on line 163. The weakness of this approximation has been noted in the literature before in (Rao et al. 1999) vs (Culpepper and Olshausen 2009).",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper presents a method, LieGG, for identifying learned in variances in a trained model.  Specifically, by differentiating the model with respect to its inputs and looking at these derivatives at various inputs points, a polarization matrix is constructed which has as its nullspace, generators of a Lie algebra of invariances. This can be learned using SVD.  The authors apply their method to MLPs trained on a sythentic function with O(5) symmetry and Rotated MNIST which has SO(2) symmetry.  In both cases, the learned model displays the expected invariance.  The authors also analyze the effect of network size, shape, and trained on learned symmetry.",
                "Strengths And Weaknesses": "Strength\n\nThis work is very timely and the question is important.  It is becoming increasingly clear that symmetry is a key part of deep learning and the idea that symmetry can be learned directly from data has motivated several recent works on symmetry discovery.  The hope is that neural networks may be useful in e.g. scientific domains for discovering interpretable findings about different systems from data.\nThe method is an effective application of the theory of symmetries of differential equations.  The background is clearly presented and theorem 2.8 form [37] is nicely explained with an example.   \nThe method is able to explicitly find symmetries of learned models.  These symmetries are in the form of Lie algebra generators.  This is similar to the form of the symmetries found by (Dehmamy, 2021), however, an advantage of the current work is that no special architecture is necessary in order to learn the symmetry.  \nIt could be said the proposed method is not really for demonstrating that neural networks learn symmetry (see first weakness/question), but for learning invariances of the ground truth function from data.  At first, I wondered if these invariances could be estimated directly from data without training a neural network first.  However, it seems that training a neural network gives an effective way to estimate df/dx_i in equation 2 which would otherwise be difficult to do directly from data alone.  In this light, I think the proposed method is quite an effective way to discover invariances in data indirectly. \nThe finding (Line 244-245) that deeper networks learn symmetry better as the capacity is increased versus shallow networks is interesting and seems useful in network design.\n\nWeakness / Questions\n\nMy main question about the method is that it's unclear what it means for a model to learn symmetry independently of learning the task function accurately.  Consider a regression problem.  If the model F trains well to approximate a ground truth function which is invariant with RMSE error at most \\epsilon, then it seems to me the symmetry variance (invariance error) is bounded by 2\\epsilon.  That is, the model has symmetry because it learned the ground truth and that has symmetry.  In this case, I would not really say the model did any particular invariance learning.  If it could be demonstrated that the model had even lower symmetry variance that expected given the accuracy or was capable of extrapolation based on the invariance, then I would grant the model had learned symmetry.  This question is somewhat examined in \"Symmetry vs. accuracy\" (Line 250), but here the conclusion seems to support my suspicion that any learned symmetry is really an emergent consequence of accurately fitting the ground truth function.      \nI don't understand the second sentence of the abstract.  If a network first learns symmetry wouldn't it be starting to learn from no symmetry?  I presume the point of this sentence is perhaps to contrast with methods such as equivariant neural networks in which symmetry is encoded into the network as a prior, but I don't think it is very clear. \nTheorem 3.1, Line 107-108. I looked at the reference [37] from which this theorem is quoted.  This statement appears to be a special case of the generality stated there, but with some missing assumptions.  The hypothesis here says n-dimensional manifold X, however, the equation given does not refer to local coordinates and so I believe assumes X=R^k and G \\subset GL_k(R) and acts by matrix multiplication on X.  If I understand correctly, this puts in the setting of [37, Example 1.28b] with a linear vector field.  That is, we are assuming symmetries are global linear symmetries of the space.  This is definitely still a useful level of generality to consider, but it does exclude some cases.  For example, F(x,y) = y - x^2.  I'd recommend clarifying the assumptions and deriving the special case from the general theorem in the appendix.  \nSection 4.1 has some unclear writing.  The idea of image as function (Line 140-141) can be clearer.  Line 141:  A function should be defined either in terms of spaces, X\u2192Y or elements x\u21a6y or both.  This mixes both.  The notation in the equation between Line 146 and Line 147 is unclear.  Is the goal actually to describe a group action on the space of images?  In that case, I would define (g\u22c5f)(x)=f(g\u22121\u22c5x).  In particular, I would not use the same notation for the the group G and the action map a:G\u00d7X\u2192X.  Lastly, what is really going on here (it seems to me) is that the space of potential symmetries on the full space of images is too high-dimensional for the current method to be effective and so you have limited yourself to the 4-dimensional subgroup of spatial symmetries.  This is a strong prior over the potential invariances you are looking for. \nLine 161:  It would be very helpful to include a formal definition of symmetry bias and symmetry variance. \nLine 224-225: I'm not sure I agree with the conclusion about the smoothness of the spectrum of the polarization matrix or with the conclusion that the method can robustly find noisy symmetries.  In this case there is a very strong prior of the symmetry group being within a 4-dimensional subgroup of spatial symmetries. It's hard to evaluate smoothness over only 4 data points and the strength of this inductive bias could be the reason the model performs well here.    \n\"Intermediate Symmetries\" (Line 276): In an equivariant neural network, only the last layer or last layers are usually used to project to an invariant representation.  Intermediate representations usually display equivariance instead of invariance with respect to some latent group representation type.  In that sense, it is perhaps not surprising that intermediate layers do not show invariance.",
                "Questions": "Minor Points\n\nLine 93: Technically, it is not enough to know the Lie algebra to know the symmetry group.  For example, we discard any discrete symmetries.\nLine 114: 2 is missing from the equation\nLine 126: call it the network ...\nEquation 3 after Line 150: There is no sum over images only over pixel locations.  Should there be a sum over images f as well?\nEquations after Line 163: How is t sampled?  \nEquations after Line 163: In the second line of the equation, I think it should be t^2\nEquations after Line 163: In the third line of the equation, I think there is a missing parenthesis. \nEquation after Line 164: Should it be O(t^4)?  \nLine 165: Why is this only an estimate?\nEquation after Line 167: Should h_l be squared? \nLine 170: \"Last\" singular values is imprecise. \nLine 182: with a closest \nLine 188: the input space is R10 or R2\u00d75. It doesn't really make sense to use both multiplicative and exponential notation for the same thing.  \nFigure 5: describe abbreviations in caption\n\nPost-Response Edit\nI appreciate the authors response to my questions and maintain my positive score.",
                "Limitations": "The limitations section is good, but the authors could be clearer about what \"more complex transformations\" means.  The assumptions in Theorem 3 and resulting limitations should also be clarified.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.333,
        "confidence_avg": 3.333,
        "soundness_avg": 2.667,
        "presentation_avg": 2.667,
        "contribution_avg": 2.667,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is evident that the proposed method, LieGG, for investigating symmetries encoded in neural networks has several strengths. The paper addresses an important problem in deep learning and provides a theoretically convincing approach based on the concept of Lie algebra. The proposed method is novel and does not require a special architecture to learn symmetries. The evaluation on synthetic data and rotated MNIST demonstrates the effectiveness of the method in recovering symmetries. The proposed metrics for measuring the degree of symmetries are valuable.\n\nWhile there are some minor weaknesses and questions raised by the reviewers, such as the lack of comparison with competitors and the unclear definition of symmetry variance, these do not significantly impact the overall quality and contribution of the paper. The limitations of the proposed method are acknowledged by the authors themselves.\n\nOverall, the paper is technically solid and has moderate-to-high impact. It provides valuable insights into the problem of symmetry learning in neural networks. The evaluation is well-conducted, and the resources and reproducibility are satisfactory. There are no major concerns regarding evaluation, resources, reproducibility, or ethical considerations.\n\nTherefore, I recommend accepting the paper with a high level of confidence."
    },
    "Local_Bayesian_optimization_via_maximizing_probability_of_descent": {
        "link": "https://openreview.net//forum?id=YRDXX4IIA9",
        "pub_url": "https://openreview.net/forum?id=YRDXX4IIA9",
        "pdf_link": "https://openreview.net//pdf?id=YRDXX4IIA9",
        "paper_id": "YRDXX4IIA9",
        "title": "Local_Bayesian_optimization_via_maximizing_probability_of_descent",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nAll reviewers are positive and agree that the paper should be accepted. The primary question raised about the poor performance on Hopper was adequately addressed by the author response. Please integrate the changes and reviewer suggestions around clarity into the final paper.",
        "reviews": [
            "Reviewer 1: \nSummary: The paper develops a new approach for local Bayesian optimization by incorporating gradient into the Bayesian optimization as in the work by Muller et al [13] but instead of moving in the direction of the expected gradient, the paper proposes to identify the direction of most likely descent, and then move in that direction. To do so, the paper derives a closed-form solution for the direction of most likely descent at a given location in the input space under a GP belief about the objective function. A corresponding closed-form acquisition function that optimizes (an upper bound of) the one-step maximum descent probability is also developed to form the optimization scheme. Experiments on both synthetic and real-world tasks are conducted to demonstrate the performance of the proposed approach.\n################################ AFTER REBUTTAL ###################################\nThanks authors for your detailed response. I understand more about the behaviours of the proposed approach and I do not have any concerns about the Hopper function anymore. I have been thinking again about the work, and I think maybe I'm indeed picky, so I decided to increase my score to 6.\nStrengths And Weaknesses: Strengths: The paper is very well-written. All the concepts and the proposed approach are described clearly and easy to understand. The idea of incorporating the gradient information into the optimization process and move to the direction of most likely descent is sound and reasonable. Rigorous mathematical formulas are developed to derive the key components of the proposed approach (the direction of most likely descent and the acquisition function). The proposed approach has good performance in some objective functions.\nWeaknesses: Some of the weaknesses of the paper are as follows:\n\u2022\tMaybe I'm picky but I think the idea is not too novel as it feels like it just fixes a particular issue of an existing BO approach. I do appreciate all the analysis conducted to show the issue of the approach in Muller et al [13] and all the derivations to find the most likely descent direction and to compute the new acquisition function. However, I normally expect the key idea to be more novel, and if it's not too novel, I expect the experiment results to be very impressive. In this case, the experiment results are not really that impressive. The proposed approach does have some very good performance on some objective functions; however, it also performs on par with other baselines in multiple objective functions, and it performs worse for some objective functions. \n\u2022\tThe proposed approach is developed for the batch setting; however, only sequential setting (batch 1) is conducted in the experiments. \n\u2022\tThe paper seems to lack of the discussion about some benchmarks on Bayesian optimization with gradient, for example the work Bayesian Optimization with Gradients by Wu et al (NeurIPS 2017).\n\u2022\tI expect more sensitivity analysis and discussions on some hyperparameters of the proposed approach such as p^*.\nQuestions: Apart from my comments in the Weakness section which the authors can response, I have the following additional questions:\n\u2022\tHow does the hyperparameter p^* affect the performance of the proposed approach?\n\u2022\tWhat can be the reasons that the proposed approach performs badly for the objective function 33D Hopper?\nLimitations: The paper has some discussions on the societal impact of their work.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper studies local Bayesian optimization in which a GP surrogate is used to give a model for the gradient at a point, an acquisition function is used to select points that are informative about the gradient, and then gradient steps are taken to select the next point for evaluation. Past work has used information gain about gradient for acquisition, and the direction of negative expected gradient for taking the gradient step. This paper builds on that work by showing that it is better to move in the direction that maximizes the probability of descent, which because of posterior uncertainty in the gradient, is not necessarily the negative expected gradient. It shows how this quantity can be computed, and then proposes an analytic acquisition function that targets the same quantity. Empirical results show strong performance relative to the work that this builds on, as well as other related work in this same problem space.\nStrengths And Weaknesses: I found this paper to be very interesting. It studies an important problem (high-dimensional BO). While it does build directly on top of existing work and so does not present an entirely new approach to the problem, it gives a very insightful analysis into the failure cases for that existing work and does a great job at motivating the new method. The paper is very clearly written and the work is of high quality.\nThe new method is surprisingly elegant, and is strongly motivated by a very clear mathematical analysis as well as a great illustration in Fig. 1.\nThe empirical results are very strong and compare to what I think are the most appropriate baselines. An ablation study is included, as are real-world problems.\nBelow I give a few questions that I had that I expect other readers may be interested in as well, though I consider these all to be minor issues.\nQuestions: When we observe the new value f(x_{t+1}), do we always accept the move from x_{t} to x_{t+1} or do we accept it only if f(x_{t+1}) < f(x_{t})? I imagine that observing x_{t+1} will update the gradient information at x_{t}, so even if we do not accept the step and we repeat the acquisition optimization around the same x_{t} as in the previous optimization, we should take different steps. It sounds from the paper that we are always accepting steps, but I wonder if that is the best strategy.\nIs there anything about the 33D Hopper problem that explains why it performs worse?\nWas the RBF kernel ARD?\nThe paper gives results on sensitivity to p* but only for more conservative choices; what about e.g. 0.5?\nLimitations: N/A\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 3 good\nRating: 8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper proposes a local Bayesian optimization strategy via maximizing a probability of descent.  Unlike the previous work (Muller et al. 2021), this work computes the most likely descent direction by considering the problem of the expected gradient.  More precisely, as described in the paper, the expected gradient is not necessarily the direction maximizing the probability of descent.  The proposed method solves this problem by computing the most likely descent direction.  Finally, the authors demonstrate that the proposed method works well in various experiments.\nStrengths And Weaknesses: Strengths\n\nIt solves an interesting topic on local Bayesian optimization.\n\nIt suggests a novel method by raising the drawbacks of the existing method.\n\nExperimental results do not always show the best results, which is very reasonable.  But please describe more thorough analyses on these results.\n\n\nWeaknesses\n\nI do not have specific weaknesses, but writing and presentation can be improved to clearly demonstrate the contributions of this work.\n\nPlease see the text box described below.\nQuestions: I would like to ask the authors some questions.\n\nIn Line 88, a sentence, Our work addresses this gap. should be re-written.  Please clearly write the sentence by including what this gap is in the sentence.  I understand that it is not a final version, but please fix it in the final version.\n\nIn Equation 4, why is an acquisition function over a batch of potential query points?  I think that an acquisition function over a single query is tested (as in Algorithm 1).\n\nPlease add line numbers in Algorithm 1.\n\nIn experiments, why are some results fluctuated?  Why are not the best minimum (or maximum) values plotted?\nLimitations: I do not think that this work has any negative societal impacts and any specific limitations.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: The paper aims to improve Bayesian optimization in high-dimensional search spaces by proposing a new technique for local optimization. The authors build on prior work on local policy search with bayesian optimization (GIBO) by 1) showing that the expected value of the gradient may not coincide with the maximum probability of descent, and 2) proposing an optimization scheme which directly optimizes the probability of descent. In experiments, the approach tends to outperform GIBO as well as other more complicated baselines proposed in the literature.\nStrengths And Weaknesses: Clarity\nThe paper was a pleasure to read. Very well-written, easy to follow and self-contained, with enough background on both general and local Bayesian optimization to bring the reader up to speed. It also includes great visualizations (Figure 1) that help build intuition on the behavior of the proposed approach.\nOriginality / Significance\nThe problem of scaling up Bayesian optimization to high dimensional spaces is significant and the paper builds on the success of local optimization techniques. Showing that the most likely descent direction does not always coincide with the negative expected gradient is an interesting result, worth of value on its own even if unplugged from the resulting method.\nWhile to some extent the work incrementally builds on GIBO, the results improving the local optimization routine are general and can be plugged in any existing approach relying on local optimization (e.g., McLeod et al., Wang et al.). As such, the impact of the method is broader as improved results could potentially be observed for each of these baselines. For this reason, I would have liked to see experiments validating the hypothesis that the proposal is in fact a useful subroutine to replace previous local optimization across the board. This would have further increased the significance and breadth of impact of the paper.\nQuality\nThe paper's quality is overall high. The experimental evaluation is carefully carried out and includes ablation studies aiming at separating out the two key contributions of the proposed MPD approach (i.e., the learning phase or the update phase). From these results, it turns out that MPD does not perform consistently better against GIBO when one of the two new components is removed. This shows that both components need to be used in tandem to achieve improved results.\nThe proposal is theoretically grounded and the empirical evaluation is overall solid. The results show that the proposed approach tends to outperform baselines and particularly so as the dimensionality of the space grows on synthetic functions. While very promising and clearly outperforming baselines on these examples, the gap is not as pronounced on real-world objectives (Figure 3) and MPD is clearly worse on 33D Hopper. It is expected that not 100% of problems will show the benefits of MPD, but I would have liked the authors to elaborate and give intuition as to why there is such a clear drop in 33D Hopper.\nBeyond that, I particularly appreciated the results on interesting real-world problems. This sets an example for work in the BO space to evaluate the proposed methods beyond standard problems, such as those from hyperparameter optimization.\nQuestions: \nDo the authors have any intuition as to why swapping either of the components of MPD does not consistently improve over GIBO in the ablation study? Would we not have expected either one of the two components in isolation to already be an improvement? This may or may not be the case, but I would have liked the authors to give more intuition on this result.\nHave the authors considered additional ablation studies to quantify the advantages of MPD's local search when plugged as the local routine in McLeod et al. or Wang et al.? While not strictly within the scope of the paper, demonstrating the benefits of MPD as a general technique that can boost existing local optimization method would step up the impact of the paper.\n[key question] How did the authors come up with the default policy using p\u2217 = 65%? Since the ablation studies show that the results are to some extent sensitive to this choice, it is important to understand if 1) this is a general purpose default recommendation, and 2) how the recommendation was obtained (i.e., whether it was obtained on a given validation set before comparing to the baselines in Table 1).\nHave the authors also run ablation studies on the step size, which was set to \u03b4 = 0.001? Any insights on the impact of larger and lower step size values?\nMinor: Some of the compared baselines in Figure 2 do not seem to have fully \"converged\" (e.g., ARS on the 100D objective). If run for more queries, do all methods get to the same optimum? Do we observe any changes in ranking? While the used budget is arguably already very high, this would be interesting to confirm that on top of being the more query-efficient approach, MPD also tends to consistently converge to th best solution in the long run.\nDo the authors have any insights into what makes 33D Hopper so different from the other problems that lead MPD to be subpar compared to all three baselines? This is surprising as for very high dimensional spaces, the advantage of MPD was more pronounced on the synthetic functions.\nThe evaluation considers number of queries on the x axis. What's the computational cost of the MPD local optimization step compared to baselines such as GIBO? What would the results look like with wall-clock time no the x axis?\nLimitations: The authors have adequately discussed the potential negative societal impact of the work, which coincides with the risks of any BO and generally AutoML black-box system (i.e., it can be exploited for malicious purposes). I agree with the authors that the benefits of the proposal outweight these risks.\nBeyond that, I believe the main limitations lie in the empirical section, due to some mixed results and the lack of clarity on the process that led to the choice of the method settings (probability of descent and delta). More details in the questions above. I am ready to increase my score if these questions are addressed.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The paper develops a new approach for local Bayesian optimization by incorporating gradient into the Bayesian optimization as in the work by Muller et al [13] but instead of moving in the direction of the expected gradient, the paper proposes to identify the direction of most likely descent, and then move in that direction. To do so, the paper derives a closed-form solution for the direction of most likely descent at a given location in the input space under a GP belief about the objective function. A corresponding closed-form acquisition function that optimizes (an upper bound of) the one-step maximum descent probability is also developed to form the optimization scheme. Experiments on both synthetic and real-world tasks are conducted to demonstrate the performance of the proposed approach.\n################################ AFTER REBUTTAL ###################################\nThanks authors for your detailed response. I understand more about the behaviours of the proposed approach and I do not have any concerns about the Hopper function anymore. I have been thinking again about the work, and I think maybe I'm indeed picky, so I decided to increase my score to 6.",
                "Strengths And Weaknesses": "Strengths: The paper is very well-written. All the concepts and the proposed approach are described clearly and easy to understand. The idea of incorporating the gradient information into the optimization process and move to the direction of most likely descent is sound and reasonable. Rigorous mathematical formulas are developed to derive the key components of the proposed approach (the direction of most likely descent and the acquisition function). The proposed approach has good performance in some objective functions.\nWeaknesses: Some of the weaknesses of the paper are as follows:\n\u2022\tMaybe I'm picky but I think the idea is not too novel as it feels like it just fixes a particular issue of an existing BO approach. I do appreciate all the analysis conducted to show the issue of the approach in Muller et al [13] and all the derivations to find the most likely descent direction and to compute the new acquisition function. However, I normally expect the key idea to be more novel, and if it's not too novel, I expect the experiment results to be very impressive. In this case, the experiment results are not really that impressive. The proposed approach does have some very good performance on some objective functions; however, it also performs on par with other baselines in multiple objective functions, and it performs worse for some objective functions. \n\u2022\tThe proposed approach is developed for the batch setting; however, only sequential setting (batch 1) is conducted in the experiments. \n\u2022\tThe paper seems to lack of the discussion about some benchmarks on Bayesian optimization with gradient, for example the work Bayesian Optimization with Gradients by Wu et al (NeurIPS 2017).\n\u2022\tI expect more sensitivity analysis and discussions on some hyperparameters of the proposed approach such as p^*.",
                "Questions": "Apart from my comments in the Weakness section which the authors can response, I have the following additional questions:\n\u2022\tHow does the hyperparameter p^* affect the performance of the proposed approach?\n\u2022\tWhat can be the reasons that the proposed approach performs badly for the objective function 33D Hopper?",
                "Limitations": "The paper has some discussions on the societal impact of their work.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper studies local Bayesian optimization in which a GP surrogate is used to give a model for the gradient at a point, an acquisition function is used to select points that are informative about the gradient, and then gradient steps are taken to select the next point for evaluation. Past work has used information gain about gradient for acquisition, and the direction of negative expected gradient for taking the gradient step. This paper builds on that work by showing that it is better to move in the direction that maximizes the probability of descent, which because of posterior uncertainty in the gradient, is not necessarily the negative expected gradient. It shows how this quantity can be computed, and then proposes an analytic acquisition function that targets the same quantity. Empirical results show strong performance relative to the work that this builds on, as well as other related work in this same problem space.",
                "Strengths And Weaknesses": "I found this paper to be very interesting. It studies an important problem (high-dimensional BO). While it does build directly on top of existing work and so does not present an entirely new approach to the problem, it gives a very insightful analysis into the failure cases for that existing work and does a great job at motivating the new method. The paper is very clearly written and the work is of high quality.\nThe new method is surprisingly elegant, and is strongly motivated by a very clear mathematical analysis as well as a great illustration in Fig. 1.\nThe empirical results are very strong and compare to what I think are the most appropriate baselines. An ablation study is included, as are real-world problems.\nBelow I give a few questions that I had that I expect other readers may be interested in as well, though I consider these all to be minor issues.",
                "Questions": "When we observe the new value f(x_{t+1}), do we always accept the move from x_{t} to x_{t+1} or do we accept it only if f(x_{t+1}) < f(x_{t})? I imagine that observing x_{t+1} will update the gradient information at x_{t}, so even if we do not accept the step and we repeat the acquisition optimization around the same x_{t} as in the previous optimization, we should take different steps. It sounds from the paper that we are always accepting steps, but I wonder if that is the best strategy.\nIs there anything about the 33D Hopper problem that explains why it performs worse?\nWas the RBF kernel ARD?\nThe paper gives results on sensitivity to p* but only for more conservative choices; what about e.g. 0.5?",
                "Limitations": "N/A",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposes a local Bayesian optimization strategy via maximizing a probability of descent.  Unlike the previous work (Muller et al. 2021), this work computes the most likely descent direction by considering the problem of the expected gradient.  More precisely, as described in the paper, the expected gradient is not necessarily the direction maximizing the probability of descent.  The proposed method solves this problem by computing the most likely descent direction.  Finally, the authors demonstrate that the proposed method works well in various experiments.",
                "Strengths And Weaknesses": "Strengths\n\nIt solves an interesting topic on local Bayesian optimization.\n\nIt suggests a novel method by raising the drawbacks of the existing method.\n\nExperimental results do not always show the best results, which is very reasonable.  But please describe more thorough analyses on these results.\n\n\nWeaknesses\n\nI do not have specific weaknesses, but writing and presentation can be improved to clearly demonstrate the contributions of this work.\n\nPlease see the text box described below.",
                "Questions": "I would like to ask the authors some questions.\n\nIn Line 88, a sentence, Our work addresses this gap. should be re-written.  Please clearly write the sentence by including what this gap is in the sentence.  I understand that it is not a final version, but please fix it in the final version.\n\nIn Equation 4, why is an acquisition function over a batch of potential query points?  I think that an acquisition function over a single query is tested (as in Algorithm 1).\n\nPlease add line numbers in Algorithm 1.\n\nIn experiments, why are some results fluctuated?  Why are not the best minimum (or maximum) values plotted?",
                "Limitations": "I do not think that this work has any negative societal impacts and any specific limitations.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper aims to improve Bayesian optimization in high-dimensional search spaces by proposing a new technique for local optimization. The authors build on prior work on local policy search with bayesian optimization (GIBO) by 1) showing that the expected value of the gradient may not coincide with the maximum probability of descent, and 2) proposing an optimization scheme which directly optimizes the probability of descent. In experiments, the approach tends to outperform GIBO as well as other more complicated baselines proposed in the literature.",
                "Strengths And Weaknesses": "Clarity\nThe paper was a pleasure to read. Very well-written, easy to follow and self-contained, with enough background on both general and local Bayesian optimization to bring the reader up to speed. It also includes great visualizations (Figure 1) that help build intuition on the behavior of the proposed approach.\nOriginality / Significance\nThe problem of scaling up Bayesian optimization to high dimensional spaces is significant and the paper builds on the success of local optimization techniques. Showing that the most likely descent direction does not always coincide with the negative expected gradient is an interesting result, worth of value on its own even if unplugged from the resulting method.\nWhile to some extent the work incrementally builds on GIBO, the results improving the local optimization routine are general and can be plugged in any existing approach relying on local optimization (e.g., McLeod et al., Wang et al.). As such, the impact of the method is broader as improved results could potentially be observed for each of these baselines. For this reason, I would have liked to see experiments validating the hypothesis that the proposal is in fact a useful subroutine to replace previous local optimization across the board. This would have further increased the significance and breadth of impact of the paper.\nQuality\nThe paper's quality is overall high. The experimental evaluation is carefully carried out and includes ablation studies aiming at separating out the two key contributions of the proposed MPD approach (i.e., the learning phase or the update phase). From these results, it turns out that MPD does not perform consistently better against GIBO when one of the two new components is removed. This shows that both components need to be used in tandem to achieve improved results.\nThe proposal is theoretically grounded and the empirical evaluation is overall solid. The results show that the proposed approach tends to outperform baselines and particularly so as the dimensionality of the space grows on synthetic functions. While very promising and clearly outperforming baselines on these examples, the gap is not as pronounced on real-world objectives (Figure 3) and MPD is clearly worse on 33D Hopper. It is expected that not 100% of problems will show the benefits of MPD, but I would have liked the authors to elaborate and give intuition as to why there is such a clear drop in 33D Hopper.\nBeyond that, I particularly appreciated the results on interesting real-world problems. This sets an example for work in the BO space to evaluate the proposed methods beyond standard problems, such as those from hyperparameter optimization.",
                "Questions": "Do the authors have any intuition as to why swapping either of the components of MPD does not consistently improve over GIBO in the ablation study? Would we not have expected either one of the two components in isolation to already be an improvement? This may or may not be the case, but I would have liked the authors to give more intuition on this result.\nHave the authors considered additional ablation studies to quantify the advantages of MPD's local search when plugged as the local routine in McLeod et al. or Wang et al.? While not strictly within the scope of the paper, demonstrating the benefits of MPD as a general technique that can boost existing local optimization method would step up the impact of the paper.\n[key question] How did the authors come up with the default policy using p\u2217 = 65%? Since the ablation studies show that the results are to some extent sensitive to this choice, it is important to understand if 1) this is a general purpose default recommendation, and 2) how the recommendation was obtained (i.e., whether it was obtained on a given validation set before comparing to the baselines in Table 1).\nHave the authors also run ablation studies on the step size, which was set to \u03b4 = 0.001? Any insights on the impact of larger and lower step size values?\nMinor: Some of the compared baselines in Figure 2 do not seem to have fully \"converged\" (e.g., ARS on the 100D objective). If run for more queries, do all methods get to the same optimum? Do we observe any changes in ranking? While the used budget is arguably already very high, this would be interesting to confirm that on top of being the more query-efficient approach, MPD also tends to consistently converge to th best solution in the long run.\nDo the authors have any insights into what makes 33D Hopper so different from the other problems that lead MPD to be subpar compared to all three baselines? This is surprising as for very high dimensional spaces, the advantage of MPD was more pronounced on the synthetic functions.\nThe evaluation considers number of queries on the x axis. What's the computational cost of the MPD local optimization step compared to baselines such as GIBO? What would the results look like with wall-clock time no the x axis?",
                "Limitations": "The authors have adequately discussed the potential negative societal impact of the work, which coincides with the risks of any BO and generally AutoML black-box system (i.e., it can be exploited for malicious purposes). I agree with the authors that the benefits of the proposal outweight these risks.\nBeyond that, I believe the main limitations lie in the empirical section, due to some mixed results and the lack of clarity on the process that led to the choice of the method settings (probability of descent and delta). More details in the questions above. I am ready to increase my score if these questions are addressed.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 7.0,
        "confidence_avg": 4.0,
        "soundness_avg": 3.0,
        "presentation_avg": 3.5,
        "contribution_avg": 2.75,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the paper presents a technically solid and well-written approach for local Bayesian optimization. The proposed method addresses an important problem and provides a novel solution by considering the direction of most likely descent. The paper includes rigorous mathematical derivations and empirical evaluations that demonstrate the effectiveness of the proposed approach.\n\nWhile some reviewers have raised concerns about the novelty of the idea and the performance on certain objective functions, these concerns are outweighed by the strengths of the paper. The approach is well-motivated and the experimental results show strong performance compared to relevant baselines. The limitations and weaknesses mentioned by the reviewers are relatively minor and can be addressed in future work.\n\nOverall, the paper makes a significant contribution to the field of Bayesian optimization and deserves to be accepted."
    },
    "A_Closer_Look_at_Learned_Optimization:_Stability,_Robustness,_and_Inductive_Biases": {
        "link": "https://openreview.net//forum?id=cxZEBQFDoFK",
        "pub_url": "https://openreview.net/forum?id=cxZEBQFDoFK",
        "pdf_link": "https://openreview.net//pdf?id=cxZEBQFDoFK",
        "paper_id": "cxZEBQFDoFK",
        "title": "A_Closer_Look_at_Learned_Optimization:_Stability,_Robustness,_and_Inductive_Biases",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nAll 4 knowledgeable reviewers recommended acceptance of the paper (2x accept, 1x weak accept, 1x borderline accept), appreciating the the importance of the studied problem, the first principles approach and the obtained theoretical and empirical results. I mainly agree and recommend acceptance of the paper. Still, I ask the authors to carefully consider the reviewers' comments when preparing the final version of the paper and in particular improve the presentation in line with the suggestions. Also, some of the raised points on limitations should be included in a revised discussion.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper aims to find the inductive biases and properties for a good optimizer and hence improves upon the existing learnt optimizers.\nStrengths And Weaknesses: Strenths\n\u2013 An analysis of stability of the learnt optimizers.\n\u2013 Designs new optimizer based on the properties that effect the stability.\nWeakness\n\u2013 Based on the definition of stability, convergence is not guaranteed. As the limit T->\\inf L(\\theta;T) can be finite even when the loss is oscillating.\n\u2013 The results do improve on the existing optimizer, the results are shown on very limited setting.\n\u2013 The results fail on high resolution imagenet and on bigger architectures.\n\u2013 Due to the above reason, this is not useful in the practical settings.\nQuestions: Can the authors present a reason why the optimizers fail to stabilize when the input is of high resolution as shown in Appendix\nLimitations: None\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper studies the stability of the learning process from the lens of dynamical systems and characterizes the stability of the optimization process in terms of the eigenvalues of the training dynamics. They use the resulting insights to propose modifications to the learned optimizer\u2019s architecture and the meta-learning procedure to improve its stability and generalization properties. They demonstrate the effectiveness of their modifications by testing the learnt optimizer on a variety of tasks. Importantly, they show that the resulting learned optimizer generalizes much better to tasks very different from the tasks it was meta-trained on.\nStrengths And Weaknesses: Strengths\n\nI liked the first principles approach of analyzing the stability of the existing learned optimizers presented by the paper. Moreover, the paper used the analysis to propose well motivated improvements to the architecture which resulted in significant performance gains. \nThe paper demonstrates impressive results on various tasks. The improvements on tasks that the optimizer wasn\u2019t trained on were particularly impressive!\nThe paper was also clearly written and easy to follow.\n\nWeaknesses\n\nAblation/analysis of the stability of the optimizer and validate if it was indeed the stability causing the issues.\nThe experiments show that the optimizer does reasonably well when tested on tasks very different from the tasks it was trained on. However, I would also like to see how well the optimizer performs when trained on a very wide range of tasks. Does it perform better than the standard optimizers (like adam) across all possible tasks? How much better/worse does it perform compared to an optimizer trained for the specific task? etc.\nQuestions: I think both the points in the Weaknesses sections are fixable and would appreciate the authors making amends along those directions.\nMinor Comments\n\nIn line 299 of the paper, the authors say \u201cSTAR\u2019s performance is comparable (and occasionally substantially better, 300 as in Figure 4a) to heavily hyperparameter-tuned Adam-based model\u201d. From looking at the plots though, this sounds a bit disingenuous. STAR seems to be doing better on the CIFAR plots but worse on the other datasets (which is reasonable btw, I don\u2019t expect it to work better, but I think it should be made clear in the text). So I would prefer if the paper talked about the differences in performance between tasks and the plausible causes.\nTypos - line 217 \u201cthe a\u201d -> \u201ca\u201d\nLimitations: The paper discusses certain limitations of the current approach w.r.t the assumptions regarding the convexity of the optimization problem and the need for baking in more inductive biases in order to generalize across tasks. However, I would like to see a deeper discussion on why the proposed learned optimizer still fails to outperform standard optimizers like Adam/NAdamW on a variety of tasks.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper proposes a method to improve learned optimizer generalization by heavily regularizing both training and the architecture of the learned optimizer. These regularizations are derived from a theoretical analysis of the noisy quadratic problem from the perspective of dynamical systems. Using these insights, the paper presents experiments demonstrating the ability to generalize to much larger and very different problems, as well as much longer optimization depths.\nStrengths And Weaknesses: Strengths\n\nThe theoretical analysis provides good insight that leads to regularization techniques that will be useful for the area of learned optimization\nExperiments show reasonable improvements over a tuned Adam optimizer.\n\nWeaknesses\n\nEvaluations are all on models much smaller than used in practice. The largest model used appears to be a \u201cResnet Like\u201d ConvNet on CIFAR and a small transformer.\nThe actual, exact regularizations that are constructed based on the theoretical analysis are far too obfuscated, given that this is the primary contribution of the paper. Tracking down a good summary of the actual method made takes quite a while and ends in the appendix, for example, section B.1 should probably be in the main text, since this is very important for readers who are considering applying this method.\nQuestions: \nWhat is the computational/memory overhead of the learned optimizer used? How does the training curve compare when plotted against training time instead of iteration/epoch?\nIs the blackbox magnitude term also an output head of the MLP, so the 3 heads are m_g, m_b, d?\nLimitations: \nEvaluations are relatively limited in scale, with small architectures and datasets.\nThe efficacy of this method in practice as an actual optimizer is questionable, though it seems positioned more as a path to eventual efficacy.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 2 fair\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: Learned optimizers suffer from being unable to extrapolate for a greater number of steps than they were trained on, and further the learning of these optimizers themselves are unstable. The authors propose that these learned optimizers can be studied under the lens of linear dynamical system, and by constraining the eigenvalues of the update map A via introducing a nominal term, weight decay and preconditioning, the training of such learned optimizers become much more stable and are better able to generalize across greater time steps and even other domains.\nStrengths And Weaknesses: Strengths\n\nThe perspective of viewing learned optimizers through the lens of linear dynamical systems is refreshing and enlightening, and could potentially explain why they diverge, and the authors provide theoretical substantiation as well\nStrong empirical results in both generalizing across time (in terms of additional time steps optimized) and across different domains\n\nWeaknesses\n\nThe flow of the paper is rough on the edges and could use a bit more intuition in some areas, particularly on the section on applying the preconditioning to the output vs to the input gradient\nMinor typos in the paper (e.g. \"Incorporating a nominal terms\" in pg. 3 Fig 1a, \"to the a hyperparameter\" in line 217, \"inner trainin\" in pg 8)\nQuestions: I was curious if learned optimizers did indeed diverge (or are more likely to diverge) when \u03c1(A)>1. Do we find that this is true empirically for existing learned optimizers? \nGeneralization of the learned optimizer is interesting and I would expect the preconditioner matrix P and nominal term \u03b1 provided by the learned optimizer to be domain dependent, and would be expecting more of the divergence in Fig. 4c, STAR (WD=0.1). Do you have an explanation why your method generalizes rather than diverge?\nThe Hyperparam experimental setting doesn't seem to be properly described in the paper, and it would be good if you could provide some details on that.\nPost Rebuttal The authors clarified in detail the questions above, and I have changed my rating to reflect that.\nLimitations: N/A\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper aims to find the inductive biases and properties for a good optimizer and hence improves upon the existing learnt optimizers.",
                "Strengths And Weaknesses": "Strenths\n\u2013 An analysis of stability of the learnt optimizers.\n\u2013 Designs new optimizer based on the properties that effect the stability.\nWeakness\n\u2013 Based on the definition of stability, convergence is not guaranteed. As the limit T->\\inf L(\\theta;T) can be finite even when the loss is oscillating.\n\u2013 The results do improve on the existing optimizer, the results are shown on very limited setting.\n\u2013 The results fail on high resolution imagenet and on bigger architectures.\n\u2013 Due to the above reason, this is not useful in the practical settings.",
                "Questions": "Can the authors present a reason why the optimizers fail to stabilize when the input is of high resolution as shown in Appendix",
                "Limitations": "None",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper studies the stability of the learning process from the lens of dynamical systems and characterizes the stability of the optimization process in terms of the eigenvalues of the training dynamics. They use the resulting insights to propose modifications to the learned optimizer\u2019s architecture and the meta-learning procedure to improve its stability and generalization properties. They demonstrate the effectiveness of their modifications by testing the learnt optimizer on a variety of tasks. Importantly, they show that the resulting learned optimizer generalizes much better to tasks very different from the tasks it was meta-trained on.",
                "Strengths And Weaknesses": "Strengths\n\nI liked the first principles approach of analyzing the stability of the existing learned optimizers presented by the paper. Moreover, the paper used the analysis to propose well motivated improvements to the architecture which resulted in significant performance gains. \nThe paper demonstrates impressive results on various tasks. The improvements on tasks that the optimizer wasn\u2019t trained on were particularly impressive!\nThe paper was also clearly written and easy to follow.\n\nWeaknesses\n\nAblation/analysis of the stability of the optimizer and validate if it was indeed the stability causing the issues.\nThe experiments show that the optimizer does reasonably well when tested on tasks very different from the tasks it was trained on. However, I would also like to see how well the optimizer performs when trained on a very wide range of tasks. Does it perform better than the standard optimizers (like adam) across all possible tasks? How much better/worse does it perform compared to an optimizer trained for the specific task? etc.",
                "Questions": "I think both the points in the Weaknesses sections are fixable and would appreciate the authors making amends along those directions.\nMinor Comments\n\nIn line 299 of the paper, the authors say \u201cSTAR\u2019s performance is comparable (and occasionally substantially better, 300 as in Figure 4a) to heavily hyperparameter-tuned Adam-based model\u201d. From looking at the plots though, this sounds a bit disingenuous. STAR seems to be doing better on the CIFAR plots but worse on the other datasets (which is reasonable btw, I don\u2019t expect it to work better, but I think it should be made clear in the text). So I would prefer if the paper talked about the differences in performance between tasks and the plausible causes.\nTypos - line 217 \u201cthe a\u201d -> \u201ca\u201d",
                "Limitations": "The paper discusses certain limitations of the current approach w.r.t the assumptions regarding the convexity of the optimization problem and the need for baking in more inductive biases in order to generalize across tasks. However, I would like to see a deeper discussion on why the proposed learned optimizer still fails to outperform standard optimizers like Adam/NAdamW on a variety of tasks.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposes a method to improve learned optimizer generalization by heavily regularizing both training and the architecture of the learned optimizer. These regularizations are derived from a theoretical analysis of the noisy quadratic problem from the perspective of dynamical systems. Using these insights, the paper presents experiments demonstrating the ability to generalize to much larger and very different problems, as well as much longer optimization depths.",
                "Strengths And Weaknesses": "Strengths\n\nThe theoretical analysis provides good insight that leads to regularization techniques that will be useful for the area of learned optimization\nExperiments show reasonable improvements over a tuned Adam optimizer.\n\nWeaknesses\n\nEvaluations are all on models much smaller than used in practice. The largest model used appears to be a \u201cResnet Like\u201d ConvNet on CIFAR and a small transformer.\nThe actual, exact regularizations that are constructed based on the theoretical analysis are far too obfuscated, given that this is the primary contribution of the paper. Tracking down a good summary of the actual method made takes quite a while and ends in the appendix, for example, section B.1 should probably be in the main text, since this is very important for readers who are considering applying this method.",
                "Questions": "What is the computational/memory overhead of the learned optimizer used? How does the training curve compare when plotted against training time instead of iteration/epoch?\nIs the blackbox magnitude term also an output head of the MLP, so the 3 heads are m_g, m_b, d?",
                "Limitations": "Evaluations are relatively limited in scale, with small architectures and datasets.\nThe efficacy of this method in practice as an actual optimizer is questionable, though it seems positioned more as a path to eventual efficacy.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "Learned optimizers suffer from being unable to extrapolate for a greater number of steps than they were trained on, and further the learning of these optimizers themselves are unstable. The authors propose that these learned optimizers can be studied under the lens of linear dynamical system, and by constraining the eigenvalues of the update map A via introducing a nominal term, weight decay and preconditioning, the training of such learned optimizers become much more stable and are better able to generalize across greater time steps and even other domains.",
                "Strengths And Weaknesses": "Strengths\n\nThe perspective of viewing learned optimizers through the lens of linear dynamical systems is refreshing and enlightening, and could potentially explain why they diverge, and the authors provide theoretical substantiation as well\nStrong empirical results in both generalizing across time (in terms of additional time steps optimized) and across different domains\n\nWeaknesses\n\nThe flow of the paper is rough on the edges and could use a bit more intuition in some areas, particularly on the section on applying the preconditioning to the output vs to the input gradient\nMinor typos in the paper (e.g. \"Incorporating a nominal terms\" in pg. 3 Fig 1a, \"to the a hyperparameter\" in line 217, \"inner trainin\" in pg 8)",
                "Questions": "I was curious if learned optimizers did indeed diverge (or are more likely to diverge) when \u03c1(A)>1. Do we find that this is true empirically for existing learned optimizers? \nGeneralization of the learned optimizer is interesting and I would expect the preconditioner matrix P and nominal term \u03b1 provided by the learned optimizer to be domain dependent, and would be expecting more of the divergence in Fig. 4c, STAR (WD=0.1). Do you have an explanation why your method generalizes rather than diverge?\nThe Hyperparam experimental setting doesn't seem to be properly described in the paper, and it would be good if you could provide some details on that.\nPost Rebuttal The authors clarified in detail the questions above, and I have changed my rating to reflect that.",
                "Limitations": "N/A",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "soundness_avg": 3.5,
        "presentation_avg": 3.0,
        "contribution_avg": 2.75,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that this paper makes a significant contribution to the field of learned optimizers. The theoretical analysis and insights provided by the authors are highly valuable and lead to improvements in the stability and generalization properties of the learned optimizer. The empirical results demonstrate the effectiveness of the proposed modifications, especially in terms of generalizing to tasks that are different from the ones the optimizer was trained on. While there are some limitations and areas for improvement mentioned by the reviewers, they do not outweigh the overall positive impact and technical solidity of the paper. Therefore, I recommend accepting this paper."
    },
    "Empirical_Gateaux_Derivatives_for_Causal_Inference": {
        "link": "https://openreview.net//forum?id=8gUjpEsLCU",
        "pub_url": "https://openreview.net/forum?id=8gUjpEsLCU",
        "pdf_link": "https://openreview.net//pdf?id=8gUjpEsLCU",
        "paper_id": "8gUjpEsLCU",
        "title": "Empirical_Gateaux_Derivatives_for_Causal_Inference",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nThe authors make a solid contribution in the literature on computerized estimation of gateaux derivatives and automatic debiasing, with applications to causal inference, providing theorems on the level of numerical approximation that preserves root-n statistical rates. Therefore this should be an interesting paper for the causal ml community. The authors have addressed most major concerns raised by reviewers in their original evaluation.\nOn a minor note the authors should also relate to the recent prior work on automatic debiased machine learning for dynamic effects https://arxiv.org/abs/2203.13887 which seems to be capturing their main application, contrary to what is claimed in their related work.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper discusses the Gateaux derivative for a parameter functional of a probability distribution. The authors propose a method for approximating the Gateaux derivative empirically, with applications to causal inference. The authors also suggest dynamic treatment regimes as an interesting application.\nStrengths And Weaknesses: First, I could not fully understand this study. In particular, I would like the authors to elaborate on the motivation more. Therefore, I would like to make a final evaluation after a discussion with the authors.\nI think that the authors' proposed method for approximating the Gateaux derivative is interesting. As the authors mention, the Gateaux derivative and the influence function play an important role in statistical inference. For example, in (semiparametric) counterfactual mean estimation, we usually analytically derive the (semiparametric) influence function and use it as a lower bound of the asymptotic variance; then, we propose an estimator that achieves the lower bound. However, I could not understand what it means to approximate the Gateaux derivative empirically, and I would appreciate a careful explanation.\nThe influence function is helpful in constructing the estimator, but I do not think it is necessary to be concerned with its estimation as long as it can be analytically derived. For example, Hirano, Imbens, and Ridder (2003) propose an IPW-based estimator that achieves the lower bound derived from Hahn (1998)'s (AIPW-style) influence function. Of course, defining the influence function for a broad class of estimators is an important issue, and several previous studies have attempted it. However, once the Gateaux derivative is defined, it is not clear to what extent its empirical approximation needs to be discussed. At least, it does not seem to be necessary for counterfactual mean estimation and many OPE tasks.\nIn summary, while I acknowledge the contribution of the method, I would like to know more about the motivation.\nQuestions: Following on from the above question, I have the following minor question.\n\nIs it possible to apply the proposed method to robust statistics, such as Koh and Liang (2017)?\nI think one of the parentheses in Lemma 1 is not closed.\nWhat estimator (method) is used to estimate the nuisance parameter in the counterfactual mean estimation in Section 4.1?\nLimitations: See the above comments.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 2 fair\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 1: Your assessment is an educated guess. The submission is not in your area or the submission was difficult to understand. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: Gateaux derivatives arise in a number of statistical estimation problems, and are used to improve asymptotic efficiency in estimation (e.g., in one-step estimators).  For a given problem, the form of the Gateaux derivative is typically derived analytically, and the relevant components then estimated from data (e.g., certain conditional expectations).  Here, the form of the derivative is known, and typical analysis focuses on how different rates of estimation (in the relevant nuisance parameters) lead to appropriate rates of convergence in the original problem.\nThis paper considers \"empirical\" Gateaux derivatives, which do not involve such analytic derivations, but instead directly seek to estimate the derivative via finite-differencing.  This introduces an additional source of error in computing the Gateaux derivatives (numerical approximation error), but has the potential to broader the utility of one-step estimators, by not requiring explicit derivations in the case of new statistical functionals.\nWhile other work has considered the problem of numerical approximation error, this work analyzes how both numerical and statistical errors interact in the context of several examples: One of the main results, for instance, gives rates on numerical approximation hyperparameters that preserve parametric rates in the one-step estimator for a standard causal inference problem (counterfactual mean estimation).  Two other illustrative estimation problems are considered as well.\nStrengths And Weaknesses: [REBUTTAL UPDATE: See discussion below.  My main concerns were addressed during the response, and I am convinced that the relevant clarifications are straightforward to incorporate into a camera-ready, if accepted.  My score has been updated as follows:\n\nPresentation: 2 -> 3\nOverall Score: 5 (borderline accept) -> 7 (accept)\n]\n\nStrengths\nThis paper tackles an interesting and highly relevant problem, and provides novel technical results. Theorem 1 in particular is a clean and informative result, characterizing rates of perturbation and smoothing that preserve n-consistency of counterfactual mean estimation with empirical Gateaux derivatives.  Overall, one of the main take-away messages is that the structure of the statistical problem can lead to weaker approximation requirements (e.g., rates on (\u03f5,\u03bb)) in some cases, but not in others, which I thought was an interesting point.\nWeaknesses\nThe clarity and quality of presentation could be improved, which is a weakness that is hopefully straightforward to fix.  Below, I will detail some points that were particularly unclear to me, in the hope that it is useful for the authors as they craft a response. I put explicit questions in \"bullet points\", with the remaining text as context.  I am willing to increase my score if these points can be sufficiently clarified.\n(1) Unclear significance of analysis of required rates for (\u03f5,\u03bb)\nAs I understand it, the main goal of the analysis is to understand the extra error incurred by using a finite-differencing approach, above and beyond using analytic derivatives:  As in Theorem 1, if this error decays fast enough, then one can use empirical derivatives while preserving Op(n\u22121/2) rates of estimation.  This seems like a very clear type of result, but for an application where the analytic derivative is already well known.  Meanwhile, the results in the remaining sections do not go \"all the way\" to a result like Theorem 1, but instead stop at giving some side-by-side comparison of the analytic and empirical derivatives.\nIt seems that there are two conclusions the reader is supposed to draw from this analysis, in the context of the remainder of the work:  First, that (\u03f5,\u03bb) can decay slower than we might generically \"expect\", for problems with special structure. Second, that this special structure is present in the dynamic treatment regime (DTR) functional, but not in the policy optimization functional.  This second point is implied to be surprising, because all three problems exhibit some double-robustness structure (see lines 279-280).\nI had trouble drawing such conclusions, though I suspect this is mostly an issue of presentation / clarity.\n(1a) First, it seems in several places that the reader should have a \"baseline\" result in mind, to contrast with the results presented here, but this baseline was not entirely clear.  A few examples:\n\nLine 188: \"can be a slower rate than implied by the generic analysis of finite differences\".  What kind of rate would that be, and is there a reference for such results?\nLines 190-191: \"potential improvement...could be on the order of generic rate improvements implied by a central difference scheme\".  What is this referring to?\nLines 278-280: \"does not appear that rate-double robustness would admit weaker numerical requirements on \u03f5\".  Weaker requirements than what?  The \"generic analysis\" referenced above?\nAre there \"conservative\" rates on (\u03f5,\u03bb) that will always preserve OP(n\u22121/2) rates of estimation, obtainable via some generic analysis?\n\nThe first three questions are about contextualizing the results, but the last one this is important for clarifying whether (a) there is always a generic approach to derive rates on (\u03f5,\u03bb) that preserve OP(n\u22121/2) convergence, and this is just an improved analysis for specific estimands that shows slower rates are possible, or (b) it is generally necessary to do a \"Theorem 1-style\" analysis to verify OP(n\u22121/2) convergence.  The latter conclusion seems much more restrictive than the former.\n(1b) Second, conclusions are often made by comparing the form of the empirical and analytical derivatives directly, but these were somewhat difficult to follow:\n\nProposition 2 (DTR) \"verifies that the requirements...are similar in \u03f5 as in the case of a single-timestep\", but there is no O(\u03f52) term in either Proposition 1 or Corollary 1.  Could you clarify what is meant here?\nPropositions 3 & 4 differ not only in an additive term, but also in the usage of perturbed nuisances, which makes them difficult to compare directly (this also applies to Corollary 1, as noted on line 170).  Is there a reason why a direct comparison (e.g., isolating only an additive difference) is unnecessary here?\n\n(2) Unclear significance of limitations of Empirical Gateaux derivatives: \nAs outlined in the introduction, constructive / algorithmic approaches to bias adjustment are very appealing, particularly for problems where small changes require re-derivation of the analytic derivative. This paper strikes an appropriate note of humility in the conclusion, giving limitations of Empirical Gateaux derivatives as a \"completely general approach\" (lines 329-335), namely the fact that (a) pathwise differentiability and (b) the second-order nature of the remainder must be verified analytically. However, these limitations do seem to undercut the general value of the approach. With that in mind, a few relevant questions\n\nAre there existing scenarios where the analytic form of the gateaux derivative is non-obvious, but where these conditions (pathwise differentiability, second-order remainder) can nonetheless be verified to hold? Or does verifying these conditions always require derivation of the analytic form?\nMore broadly, are there scenarios where we can apply this approach (with appropriately conservative rates on (\u03f5,\u03bb)) and have confidence in achieving OP(n\u22121/2) rates, without deriving the analytic derivative?  E.g., would the constrained MDP with arbitrary linear constraints be such an example?\n\nIf there exist some space of problems where the answer to these questions is \"yes\", then it would go a long way towards mitigating the impact of these limitations.\nComments on soundness: Regarding technical soundness, I have a (hopefully minor) question or two on Lemma 1\n\nIn the display following line 563, it is claimed that the following holds due to Cauchy-Schwarz.  I'm not sure I see the application of CS here: Is there another reason why we would expect the cross term 2E[(\u03bc~\u03f5(X)\u2212\u03bc~(X))(\u03bc~(X)\u2212\u03bc(X))] to be non-positive?\n\nE(\u03bc~\u03f5(X)\u2212\u03bc(X))2\u2264E(\u03bc~\u03f5(X)\u2212\u03bc~(X))2+E(\u03bc~(X)\u2212\u03bc(X))2\n\nIn the display following line 562, the last inequality seems like a non-trivial jump, would you mind walking through the logic explicitly?\n\nOtherwise, the proofs seem correct to me.  Note that I only read through the proofs for Section 3 in depth, and only skimmed the proofs of other relevant results (e.g., Propositions 3 and 4).  While I am well-versed in the causal inference literature, I am not otherwise an expert on non-parametric / semi-parametric statistics, so I may have missed something. \nAs an aside, it may be helpful to include a citation in the proof for some of the assumed results regarding kernels. [58] is referenced in the main text, referring to kernel smoothing more broadly, but it seems some of the prerequisite results could be cited more precisely (e.g., Lemma 25.1 of [58] appears to be a relevant result)\nOther Minor Feedback\nI consider the following points to be minor feedback re: presentation / notation / possible typos, and they did not meaningfully influence my score, and they do not require an explicit response from the authors (some are stated as questions only because I am unsure if they are typos).\nSuggestions on clarity:\n\n(Lines 15-19) This and some other sentences are a bit long and difficult to parse, and could perhaps be split into multiple sentences.\n(Line 71) Is the introduction of projections onto the semi-parametric model necessary, given Remark 1's statement that this work focuses on nonparametric models?  CLvdL (Equation 2.2) seems to refers to Luedtke, Carone, and van der Laan (2015) as a reference for the equation on between lines 71-72 holding generally in a non-parametric model.\n\nOther typos / inconsistencies\n\nExample 1 uses EP for the outer expectation, but not for the inner expectation.\nProposition 1 uses E~P~\u03f5 in one place, perhaps the tilde on E was not intended?\nLine 65, what is the observation o~?  This is not referenced anywhere, I assume this is meant to be o\u2032.\nFootnote 1, should the kernel be \u03bb\u2212dK(u/\u03bb) instead of h\u2212dK(u/\u03bb)?  There is also a reference to an O(hJ) error term on line 568 that should perhaps be O(\u03bb\u03b2)?\nAlgorithm 1: Should it be P~ on lines 3-4?  Should it likewise be P\u03f5,\u03bbi instead of P\u03f5i?\nLemma 1: Should e~\u03f5(X)=p~\u03f5(A=1,X)/p~(X) instead of the current formulation, which uses p~\u03f5(A=1\u2223X) in the numerator?  This would also make it consistent with usage in the proof (see e.g., line 561)\nLine 154, there seems to be a missing parenthesis\nLine 149 \"analyses of from kernel density estimation\"\nAssumption 1 (iv), should the equation refer to \u03bc~\u03f5 or just \u03bc~?  Additionally, should the product-rate condition be op(n\u22121) as written or op(n\u22121/2)?\nLine 561, says to bound perturbed e one should \"argue similarly\", seemingly in reference to the (later) bound on the perturbed \u03bc, perhaps the order was swapped.\nLine 562, following equation, third equality, missing a square on the final p~(A=1,x) term.\nLine 572, E[\u0393(O;e\u03f5,\u03bc)] should be E[\u0393(O;e~\u03f5,\u03bc~)] \nLine 637, indicator is missing an \u03f5 on the left-hand side\nSupplement, Section D.2, the reference is to citation [20], but I believe this should be citation [18]\n\nUndefined notation:\n\nLine 66, I did not see a definition of the function g(u).\nI'm unsure if the dimension d was precisely defined prior to usage in Lemma 1, though it is fairly obvious from context.\nEq. 7: I'm not sure if \u03bca is defined anywhere, aside from being the optimization variable, and similar for \u03bc\u2217(s,a) in Equation 8.\n\u03bd is used a few times in the proofs without being defined (end of equation starting on 576, end of equation starting on 562), presumably referring to a strong-overlap constant.\nQuestions: My questions can be found in the \"Strengths and Weaknesses\" section, where every bullet point corresponds to a question.  I collect them (verbatim) below.\n\nLine 188: \"can be a slower rate than implied by the generic analysis of finite differences\".  What kind of rate would that be, and is there a reference for such results?\nLines 190-191: \"potential improvement...could be on the order of generic rate improvements implied by a central difference scheme\".  What is this referring to?\nLines 278-280: \"does not appear that rate-double robustness would admit weaker numerical requirements on \u03f5\".  Weaker requirements than what?  The \"generic analysis\" referenced above?\nAre there \"conservative\" rates on (\u03f5,\u03bb) that will always preserve OP(n\u22121/2) rates of estimation, obtainable via some generic analysis?\nProposition 2 (DTR) \"verifies that the requirements...are similar in \u03f5 as in the case of a single-timestep\", but there is no O(\u03f52) term in either Proposition 1 or Corollary 1.  Could you clarify what is meant here?\nPropositions 3 & 4 differ not only in an additive term, but also in the usage of perturbed nuisances, which makes them difficult to compare directly (this also applies to Corollary 1, as noted on line 170).  Is there a reason why a direct comparison (e.g., isolating only an additive difference) is unnecessary here?\nAre there existing scenarios where the analytic form of the gateaux derivative is non-obvious, but where these conditions (pathwise differentiability, second-order remainder) can nonetheless be verified to hold? Or does verifying these conditions always require derivation of the analytic form?\nMore broadly, are there scenarios where we can apply this approach (with appropriately conservative rates on (\u03f5,\u03bb)) and have confidence in achieving OP(n\u22121/2) rates, without deriving the analytic derivative?  E.g., would the constrained MDP with arbitrary linear constraints be such an example?\nIn the display following line 563, it is claimed that the following holds due to Cauchy-Schwarz.  I'm not sure I see the application of CS here: Is there another reason why we would expect the cross term 2E[(\u03bc~\u03f5(X)\u2212\u03bc~(X))(\u03bc~(X)\u2212\u03bc(X))] to be non-positive?\n\nE(\u03bc~\u03f5(X)\u2212\u03bc(X))2\u2264E(\u03bc~\u03f5(X)\u2212\u03bc~(X))2+E(\u03bc~(X)\u2212\u03bc(X))2\n\nIn the display following line 562, the last inequality seems like a non-trivial jump, would you mind walking through the logic explicitly?\nLimitations: I think the authors do a fine job of explaining limitations of the approach.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: Efficient / doubly-robust estimation in causal inference typically requires constructing estimators based on the (efficient) influence function, which is derived case by case. The paper considers numerical approximation to the influence function with empirical Gateaux derivatives, which are obtained through finite differencing and smoothed perturbation. The approximation uses plugin estimate of the probability density. The paper studies conditions on the smoothing and perturbation parameter such that the resulting one-step estimator retains desired statistical properties. The paper first examines the case of estimating the counterfactual mean and then extends to more complex dynamic settings.\nStrengths And Weaknesses: Strengths\n\nThe paper is built upon recent efforts in \"automating / computerizing\" influence-function-based estimation and studies an important question. \nThe paper provides a clean analysis for the basic case of estimating the counterfactual mean.\n\nWeaknesses\n\nThe approximation is based on a density estimator of the underlying data distribution, which seems to bear serious practical limitations. It is unclear if this choice is necessary, and if so, how to overcome the limitations. \nThe conditions impose a product-form rate condition on the smoothed estimates; see (iv) of Assumption 1. It is unclear when these conditions can be met in practice. \nOther than a simple simulation, the paper does not seem to provide concrete practical recipes for the running example that can flexibly incorporate different underlying distributions, dimensions, smoothness, etc. This weakens the relevance for the results developed for the more complex, dynamic settings. \nThe clarity of certain sections can be improved.\nQuestions: \nGateaux differentiable vs influence function\n\n(1) The definition of the influence function (\u00a7\u00a72) in terms of Gateaux derivative comes from the robust statistics literature. How is it related to the influence function used for semiparametric inference?\n(2) page 2, line 59-60: in the direction of H or for all H?\n\nOn plugin estimation through density estimation\n\n(1) Given the curse of dimensionality, it is unclear to me why the approximation must be based on a density estimate. I do not parse the argument provided in line 117-121: can the authors elaborate on this? More specifically, for the running example, it seems that one can easily simulate data from the perturbed distribution. Can the approximation be based on an estimator using the simulated perturbed data (e.g., empirical average of an estimated conditional mean, where the distribution is that of the simulated data)?\n(2) Suppose density estimation is necessary. Then it is worth discussing when the kernel-based estimators can fulfill the conditions required, e.g., (iv) in Assumption 1. \n(3) To really \"bolster confidence in the numerical procedure\", the case study of the running example should be expanded accordingly to show that the proposed method works in a range of settings (e.g., at least when dimension is not high). \n\nI have a hard time trying to follow the extension to dynamic settings in \u00a7\u00a74. Can the authors summarize the take-away message there?\n\nA few points worth clarification.\n\n\n(1) How is P~ used in Algorithm 1?\n(2) line 71: it is unclear what \"\u03a8(P\u03f5,\u03bb\u2217) is the projection of \u03a8(P\u03f5,\u03bb) ...\" means. \n\nOn the relation to previous works in \u201cautomatic\u201d or \u201ccomputerized\u201d semiparametric inference\n\nThe paper features a long list of references. Since the focus here is the influence function, I would suggest adding a paragraph after \u00a7\u00a72, which clarifies the relation to previous papers on \"computerizing\" influence-function based estimations, e.g., [9] and [17] in the bibliography.\nLimitations: I do not foresee a potential negative societal impact of the proposed work.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 2 fair\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper discusses the Gateaux derivative for a parameter functional of a probability distribution. The authors propose a method for approximating the Gateaux derivative empirically, with applications to causal inference. The authors also suggest dynamic treatment regimes as an interesting application.",
                "Strengths And Weaknesses": "First, I could not fully understand this study. In particular, I would like the authors to elaborate on the motivation more. Therefore, I would like to make a final evaluation after a discussion with the authors.\nI think that the authors' proposed method for approximating the Gateaux derivative is interesting. As the authors mention, the Gateaux derivative and the influence function play an important role in statistical inference. For example, in (semiparametric) counterfactual mean estimation, we usually analytically derive the (semiparametric) influence function and use it as a lower bound of the asymptotic variance; then, we propose an estimator that achieves the lower bound. However, I could not understand what it means to approximate the Gateaux derivative empirically, and I would appreciate a careful explanation.\nThe influence function is helpful in constructing the estimator, but I do not think it is necessary to be concerned with its estimation as long as it can be analytically derived. For example, Hirano, Imbens, and Ridder (2003) propose an IPW-based estimator that achieves the lower bound derived from Hahn (1998)'s (AIPW-style) influence function. Of course, defining the influence function for a broad class of estimators is an important issue, and several previous studies have attempted it. However, once the Gateaux derivative is defined, it is not clear to what extent its empirical approximation needs to be discussed. At least, it does not seem to be necessary for counterfactual mean estimation and many OPE tasks.\nIn summary, while I acknowledge the contribution of the method, I would like to know more about the motivation.",
                "Questions": "Following on from the above question, I have the following minor question.\n\nIs it possible to apply the proposed method to robust statistics, such as Koh and Liang (2017)?\nI think one of the parentheses in Lemma 1 is not closed.\nWhat estimator (method) is used to estimate the nuisance parameter in the counterfactual mean estimation in Section 4.1?",
                "Limitations": "See the above comments.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "1: Your assessment is an educated guess. The submission is not in your area or the submission was difficult to understand. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "Gateaux derivatives arise in a number of statistical estimation problems, and are used to improve asymptotic efficiency in estimation (e.g., in one-step estimators).  For a given problem, the form of the Gateaux derivative is typically derived analytically, and the relevant components then estimated from data (e.g., certain conditional expectations).  Here, the form of the derivative is known, and typical analysis focuses on how different rates of estimation (in the relevant nuisance parameters) lead to appropriate rates of convergence in the original problem.\nThis paper considers \"empirical\" Gateaux derivatives, which do not involve such analytic derivations, but instead directly seek to estimate the derivative via finite-differencing.  This introduces an additional source of error in computing the Gateaux derivatives (numerical approximation error), but has the potential to broader the utility of one-step estimators, by not requiring explicit derivations in the case of new statistical functionals.\nWhile other work has considered the problem of numerical approximation error, this work analyzes how both numerical and statistical errors interact in the context of several examples: One of the main results, for instance, gives rates on numerical approximation hyperparameters that preserve parametric rates in the one-step estimator for a standard causal inference problem (counterfactual mean estimation).  Two other illustrative estimation problems are considered as well.",
                "Strengths And Weaknesses": "[REBUTTAL UPDATE: See discussion below.  My main concerns were addressed during the response, and I am convinced that the relevant clarifications are straightforward to incorporate into a camera-ready, if accepted.  My score has been updated as follows:\n\nPresentation: 2 -> 3\nOverall Score: 5 (borderline accept) -> 7 (accept)\n]\n\nStrengths\nThis paper tackles an interesting and highly relevant problem, and provides novel technical results. Theorem 1 in particular is a clean and informative result, characterizing rates of perturbation and smoothing that preserve n-consistency of counterfactual mean estimation with empirical Gateaux derivatives.  Overall, one of the main take-away messages is that the structure of the statistical problem can lead to weaker approximation requirements (e.g., rates on (\u03f5,\u03bb)) in some cases, but not in others, which I thought was an interesting point.\nWeaknesses\nThe clarity and quality of presentation could be improved, which is a weakness that is hopefully straightforward to fix.  Below, I will detail some points that were particularly unclear to me, in the hope that it is useful for the authors as they craft a response. I put explicit questions in \"bullet points\", with the remaining text as context.  I am willing to increase my score if these points can be sufficiently clarified.\n(1) Unclear significance of analysis of required rates for (\u03f5,\u03bb)\nAs I understand it, the main goal of the analysis is to understand the extra error incurred by using a finite-differencing approach, above and beyond using analytic derivatives:  As in Theorem 1, if this error decays fast enough, then one can use empirical derivatives while preserving Op(n\u22121/2) rates of estimation.  This seems like a very clear type of result, but for an application where the analytic derivative is already well known.  Meanwhile, the results in the remaining sections do not go \"all the way\" to a result like Theorem 1, but instead stop at giving some side-by-side comparison of the analytic and empirical derivatives.\nIt seems that there are two conclusions the reader is supposed to draw from this analysis, in the context of the remainder of the work:  First, that (\u03f5,\u03bb) can decay slower than we might generically \"expect\", for problems with special structure. Second, that this special structure is present in the dynamic treatment regime (DTR) functional, but not in the policy optimization functional.  This second point is implied to be surprising, because all three problems exhibit some double-robustness structure (see lines 279-280).\nI had trouble drawing such conclusions, though I suspect this is mostly an issue of presentation / clarity.\n(1a) First, it seems in several places that the reader should have a \"baseline\" result in mind, to contrast with the results presented here, but this baseline was not entirely clear.  A few examples:\n\nLine 188: \"can be a slower rate than implied by the generic analysis of finite differences\".  What kind of rate would that be, and is there a reference for such results?\nLines 190-191: \"potential improvement...could be on the order of generic rate improvements implied by a central difference scheme\".  What is this referring to?\nLines 278-280: \"does not appear that rate-double robustness would admit weaker numerical requirements on \u03f5\".  Weaker requirements than what?  The \"generic analysis\" referenced above?\nAre there \"conservative\" rates on (\u03f5,\u03bb) that will always preserve OP(n\u22121/2) rates of estimation, obtainable via some generic analysis?\n\nThe first three questions are about contextualizing the results, but the last one this is important for clarifying whether (a) there is always a generic approach to derive rates on (\u03f5,\u03bb) that preserve OP(n\u22121/2) convergence, and this is just an improved analysis for specific estimands that shows slower rates are possible, or (b) it is generally necessary to do a \"Theorem 1-style\" analysis to verify OP(n\u22121/2) convergence.  The latter conclusion seems much more restrictive than the former.\n(1b) Second, conclusions are often made by comparing the form of the empirical and analytical derivatives directly, but these were somewhat difficult to follow:\n\nProposition 2 (DTR) \"verifies that the requirements...are similar in \u03f5 as in the case of a single-timestep\", but there is no O(\u03f52) term in either Proposition 1 or Corollary 1.  Could you clarify what is meant here?\nPropositions 3 & 4 differ not only in an additive term, but also in the usage of perturbed nuisances, which makes them difficult to compare directly (this also applies to Corollary 1, as noted on line 170).  Is there a reason why a direct comparison (e.g., isolating only an additive difference) is unnecessary here?\n\n(2) Unclear significance of limitations of Empirical Gateaux derivatives: \nAs outlined in the introduction, constructive / algorithmic approaches to bias adjustment are very appealing, particularly for problems where small changes require re-derivation of the analytic derivative. This paper strikes an appropriate note of humility in the conclusion, giving limitations of Empirical Gateaux derivatives as a \"completely general approach\" (lines 329-335), namely the fact that (a) pathwise differentiability and (b) the second-order nature of the remainder must be verified analytically. However, these limitations do seem to undercut the general value of the approach. With that in mind, a few relevant questions\n\nAre there existing scenarios where the analytic form of the gateaux derivative is non-obvious, but where these conditions (pathwise differentiability, second-order remainder) can nonetheless be verified to hold? Or does verifying these conditions always require derivation of the analytic form?\nMore broadly, are there scenarios where we can apply this approach (with appropriately conservative rates on (\u03f5,\u03bb)) and have confidence in achieving OP(n\u22121/2) rates, without deriving the analytic derivative?  E.g., would the constrained MDP with arbitrary linear constraints be such an example?\n\nIf there exist some space of problems where the answer to these questions is \"yes\", then it would go a long way towards mitigating the impact of these limitations.\nComments on soundness: Regarding technical soundness, I have a (hopefully minor) question or two on Lemma 1\n\nIn the display following line 563, it is claimed that the following holds due to Cauchy-Schwarz.  I'm not sure I see the application of CS here: Is there another reason why we would expect the cross term 2E[(\u03bc~\u03f5(X)\u2212\u03bc~(X))(\u03bc~(X)\u2212\u03bc(X))] to be non-positive?\n\nE(\u03bc~\u03f5(X)\u2212\u03bc(X))2\u2264E(\u03bc~\u03f5(X)\u2212\u03bc~(X))2+E(\u03bc~(X)\u2212\u03bc(X))2\n\nIn the display following line 562, the last inequality seems like a non-trivial jump, would you mind walking through the logic explicitly?\n\nOtherwise, the proofs seem correct to me.  Note that I only read through the proofs for Section 3 in depth, and only skimmed the proofs of other relevant results (e.g., Propositions 3 and 4).  While I am well-versed in the causal inference literature, I am not otherwise an expert on non-parametric / semi-parametric statistics, so I may have missed something. \nAs an aside, it may be helpful to include a citation in the proof for some of the assumed results regarding kernels. [58] is referenced in the main text, referring to kernel smoothing more broadly, but it seems some of the prerequisite results could be cited more precisely (e.g., Lemma 25.1 of [58] appears to be a relevant result)\nOther Minor Feedback\nI consider the following points to be minor feedback re: presentation / notation / possible typos, and they did not meaningfully influence my score, and they do not require an explicit response from the authors (some are stated as questions only because I am unsure if they are typos).\nSuggestions on clarity:\n\n(Lines 15-19) This and some other sentences are a bit long and difficult to parse, and could perhaps be split into multiple sentences.\n(Line 71) Is the introduction of projections onto the semi-parametric model necessary, given Remark 1's statement that this work focuses on nonparametric models?  CLvdL (Equation 2.2) seems to refers to Luedtke, Carone, and van der Laan (2015) as a reference for the equation on between lines 71-72 holding generally in a non-parametric model.\n\nOther typos / inconsistencies\n\nExample 1 uses EP for the outer expectation, but not for the inner expectation.\nProposition 1 uses E~P~\u03f5 in one place, perhaps the tilde on E was not intended?\nLine 65, what is the observation o~?  This is not referenced anywhere, I assume this is meant to be o\u2032.\nFootnote 1, should the kernel be \u03bb\u2212dK(u/\u03bb) instead of h\u2212dK(u/\u03bb)?  There is also a reference to an O(hJ) error term on line 568 that should perhaps be O(\u03bb\u03b2)?\nAlgorithm 1: Should it be P~ on lines 3-4?  Should it likewise be P\u03f5,\u03bbi instead of P\u03f5i?\nLemma 1: Should e~\u03f5(X)=p~\u03f5(A=1,X)/p~(X) instead of the current formulation, which uses p~\u03f5(A=1\u2223X) in the numerator?  This would also make it consistent with usage in the proof (see e.g., line 561)\nLine 154, there seems to be a missing parenthesis\nLine 149 \"analyses of from kernel density estimation\"\nAssumption 1 (iv), should the equation refer to \u03bc~\u03f5 or just \u03bc~?  Additionally, should the product-rate condition be op(n\u22121) as written or op(n\u22121/2)?\nLine 561, says to bound perturbed e one should \"argue similarly\", seemingly in reference to the (later) bound on the perturbed \u03bc, perhaps the order was swapped.\nLine 562, following equation, third equality, missing a square on the final p~(A=1,x) term.\nLine 572, E[\u0393(O;e\u03f5,\u03bc)] should be E[\u0393(O;e~\u03f5,\u03bc~)] \nLine 637, indicator is missing an \u03f5 on the left-hand side\nSupplement, Section D.2, the reference is to citation [20], but I believe this should be citation [18]\n\nUndefined notation:\n\nLine 66, I did not see a definition of the function g(u).\nI'm unsure if the dimension d was precisely defined prior to usage in Lemma 1, though it is fairly obvious from context.\nEq. 7: I'm not sure if \u03bca is defined anywhere, aside from being the optimization variable, and similar for \u03bc\u2217(s,a) in Equation 8.\n\u03bd is used a few times in the proofs without being defined (end of equation starting on 576, end of equation starting on 562), presumably referring to a strong-overlap constant.",
                "Questions": "My questions can be found in the \"Strengths and Weaknesses\" section, where every bullet point corresponds to a question.  I collect them (verbatim) below.\n\nLine 188: \"can be a slower rate than implied by the generic analysis of finite differences\".  What kind of rate would that be, and is there a reference for such results?\nLines 190-191: \"potential improvement...could be on the order of generic rate improvements implied by a central difference scheme\".  What is this referring to?\nLines 278-280: \"does not appear that rate-double robustness would admit weaker numerical requirements on \u03f5\".  Weaker requirements than what?  The \"generic analysis\" referenced above?\nAre there \"conservative\" rates on (\u03f5,\u03bb) that will always preserve OP(n\u22121/2) rates of estimation, obtainable via some generic analysis?\nProposition 2 (DTR) \"verifies that the requirements...are similar in \u03f5 as in the case of a single-timestep\", but there is no O(\u03f52) term in either Proposition 1 or Corollary 1.  Could you clarify what is meant here?\nPropositions 3 & 4 differ not only in an additive term, but also in the usage of perturbed nuisances, which makes them difficult to compare directly (this also applies to Corollary 1, as noted on line 170).  Is there a reason why a direct comparison (e.g., isolating only an additive difference) is unnecessary here?\nAre there existing scenarios where the analytic form of the gateaux derivative is non-obvious, but where these conditions (pathwise differentiability, second-order remainder) can nonetheless be verified to hold? Or does verifying these conditions always require derivation of the analytic form?\nMore broadly, are there scenarios where we can apply this approach (with appropriately conservative rates on (\u03f5,\u03bb)) and have confidence in achieving OP(n\u22121/2) rates, without deriving the analytic derivative?  E.g., would the constrained MDP with arbitrary linear constraints be such an example?\nIn the display following line 563, it is claimed that the following holds due to Cauchy-Schwarz.  I'm not sure I see the application of CS here: Is there another reason why we would expect the cross term 2E[(\u03bc~\u03f5(X)\u2212\u03bc~(X))(\u03bc~(X)\u2212\u03bc(X))] to be non-positive?\n\nE(\u03bc~\u03f5(X)\u2212\u03bc(X))2\u2264E(\u03bc~\u03f5(X)\u2212\u03bc~(X))2+E(\u03bc~(X)\u2212\u03bc(X))2\n\nIn the display following line 562, the last inequality seems like a non-trivial jump, would you mind walking through the logic explicitly?",
                "Limitations": "I think the authors do a fine job of explaining limitations of the approach.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "Efficient / doubly-robust estimation in causal inference typically requires constructing estimators based on the (efficient) influence function, which is derived case by case. The paper considers numerical approximation to the influence function with empirical Gateaux derivatives, which are obtained through finite differencing and smoothed perturbation. The approximation uses plugin estimate of the probability density. The paper studies conditions on the smoothing and perturbation parameter such that the resulting one-step estimator retains desired statistical properties. The paper first examines the case of estimating the counterfactual mean and then extends to more complex dynamic settings.",
                "Strengths And Weaknesses": "Strengths\n\nThe paper is built upon recent efforts in \"automating / computerizing\" influence-function-based estimation and studies an important question. \nThe paper provides a clean analysis for the basic case of estimating the counterfactual mean.\n\nWeaknesses\n\nThe approximation is based on a density estimator of the underlying data distribution, which seems to bear serious practical limitations. It is unclear if this choice is necessary, and if so, how to overcome the limitations. \nThe conditions impose a product-form rate condition on the smoothed estimates; see (iv) of Assumption 1. It is unclear when these conditions can be met in practice. \nOther than a simple simulation, the paper does not seem to provide concrete practical recipes for the running example that can flexibly incorporate different underlying distributions, dimensions, smoothness, etc. This weakens the relevance for the results developed for the more complex, dynamic settings. \nThe clarity of certain sections can be improved.",
                "Questions": "Gateaux differentiable vs influence function\n\n(1) The definition of the influence function (\u00a7\u00a72) in terms of Gateaux derivative comes from the robust statistics literature. How is it related to the influence function used for semiparametric inference?\n(2) page 2, line 59-60: in the direction of H or for all H?\n\nOn plugin estimation through density estimation\n\n(1) Given the curse of dimensionality, it is unclear to me why the approximation must be based on a density estimate. I do not parse the argument provided in line 117-121: can the authors elaborate on this? More specifically, for the running example, it seems that one can easily simulate data from the perturbed distribution. Can the approximation be based on an estimator using the simulated perturbed data (e.g., empirical average of an estimated conditional mean, where the distribution is that of the simulated data)?\n(2) Suppose density estimation is necessary. Then it is worth discussing when the kernel-based estimators can fulfill the conditions required, e.g., (iv) in Assumption 1. \n(3) To really \"bolster confidence in the numerical procedure\", the case study of the running example should be expanded accordingly to show that the proposed method works in a range of settings (e.g., at least when dimension is not high). \n\nI have a hard time trying to follow the extension to dynamic settings in \u00a7\u00a74. Can the authors summarize the take-away message there?\n\nA few points worth clarification.\n\n\n(1) How is P~ used in Algorithm 1?\n(2) line 71: it is unclear what \"\u03a8(P\u03f5,\u03bb\u2217) is the projection of \u03a8(P\u03f5,\u03bb) ...\" means. \n\nOn the relation to previous works in \u201cautomatic\u201d or \u201ccomputerized\u201d semiparametric inference\n\nThe paper features a long list of references. Since the focus here is the influence function, I would suggest adding a paragraph after \u00a7\u00a72, which clarifies the relation to previous papers on \"computerizing\" influence-function based estimations, e.g., [9] and [17] in the bibliography.",
                "Limitations": "I do not foresee a potential negative societal impact of the proposed work.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.667,
        "confidence_avg": 2.667,
        "soundness_avg": 2.667,
        "presentation_avg": 2.333,
        "contribution_avg": 2.333,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is clear that this paper tackles an interesting and highly relevant problem in the field of causal inference. The authors propose a method for approximating the Gateaux derivative empirically, which has the potential to broaden the utility of one-step estimators. The technical results presented in the paper, particularly Theorem 1, are clean and informative, providing insights into the rates of perturbation and smoothing that preserve n-consistency of counterfactual mean estimation with empirical Gateaux derivatives. \n\nWhile there are some concerns raised by the reviewers regarding the clarity and quality of presentation, these issues can be addressed through revisions. Additionally, there are some questions raised about the significance of certain analyses and the limitations of the empirical Gateaux derivatives approach. However, these concerns do not outweigh the strengths of the paper and the contributions it makes to the field.\n\nOverall, this paper is technically solid and has moderate-to-high impact. It provides valuable insights and results that can advance the field of causal inference. Therefore, I recommend accepting this paper for publication."
    },
    "Adaptive_Interest_for_Emphatic_Reinforcement_Learning": {
        "link": "https://openreview.net//forum?id=QTjJMy-UNO",
        "pub_url": "https://openreview.net/forum?id=QTjJMy-UNO",
        "pdf_link": "https://openreview.net//pdf?id=QTjJMy-UNO",
        "paper_id": "QTjJMy-UNO",
        "title": "Adaptive_Interest_for_Emphatic_Reinforcement_Learning",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nWell-written and interesting paper that meta-learns the interest function in emphatic RL, rather than using a fixed interest function. The idea is well-motivated and a comprehensive empirical study is performed. There was an an active discussion among the reviewers and authors, in which the authors addressed the various reviewer questions effectively and which resulted in an updated presentation and an increase in scores. Overall, a clear accept.",
        "reviews": [
            "Reviewer 1: \nSummary: The paper proposes a method to learn interest state function via meta-gradients in order to do emphatic RL. This interest function essentially simplifies the credit assignment problem and highlights 'more important / interesting' states.\nThe authors study their method in multiple settings: toy domain, continuous control and discrete domains as well as in the transfer learning setting. The signal is quite clear, the method which authors propose seems to always provide the benefit compared to standard RL approaches.\nThe authors study different ways of constructing interest function and provide informative ablations over these, with somewhat limited explanations.\nOverall, the paper is clearly written, the ideas are easy to understand and the results look good.\nStrengths And Weaknesses: Strengths:\n\nClearly written paper\nThe authors studied a novel approach for RL and credit assignment via meta-learning of the interest function and provided solid experimental evidence that the approach can improve RL\nThe experiments are quite broad, demonstrating the applicability of the method in different scenarios: discrete control, continuous control, transfer learning.\n\nWeaknesses:\n\nIt is not clear why the authors didn't provide TD error interest for MinAtar. Given the results on the toy domain, this approach may actually perform better than meta-gradients.\nMinor writing / visualization details. The legend colours on the Figure 2 are very hard to read.\nQuestions: \nHow does the TD error interest method perform on MinAtar?\nWhy do the authors claim that meta-gradient performs better on Figure 2, where it is clear that TD error interest converges faster and to a better value?\nLimitations: Limitations are clear from the paper\nEthics Flag: No\nEthics Review Area: I don\u2019t know\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper studies the problem of learning the interest function, which emphasizes the importance of different states differently in RL objectives. The interests of different states are typically set to be all 1 in existing approaches. And this paper seems to pioneer the study of the adaptive interest function (the paper didn't claim it but from its discussion of existing works it appears to me that the authors believe that no other works have studied this problem before).\nThe paper proposed a meta-learning approach to the problem. Specifically, the interest function is learned to maximize an objective, which is an off-policy control objective. The paper proposed an off-policy prediction algorithm and an on-policy control algorithm. Empirically, the off-policy prediction algorithm almost matches the performance of an ETD algorithm with TD error as the interest. The on-policy control algorithm is significantly better than the PPO algorithm and the other Meta-learning algorithm.\nStrengths And Weaknesses: Strengths:\nIn general, the paper is easy to follow.\nAdapting the interest function seems to be interesting and important, and is not well understood in the literature.\nThe proposed algorithm uses an elegant idea.\nEmpirical results show some interesting patterns, which would be helpful for understanding the proposed algorithm.\nWeakness:\nThe motivation of the idea, the description of the algorithm, and the explanation of the empirical results are not clear enough. Some important questions need to be addressed to evaluate the paper's contribution. See the Questions section for details.\n\nI have read the authors' responses and feel that most of my questions were answered, including the key question about explaining how interest function influences the learning process. Therefore I decided to increase my score to 6.\nQuestions: Overall, could you explain how different interests influence the learning process in prediction and control settings respectively?\nline 21 A possible solution could be to selectively emphasize certain updates, for example through a state-dependent interest function.\nWhy is this a possible solution?\nAre there any existing methods that adaptively choose the interest? Is your work the first one studying the adaptive interest function?\nIt is not clear from the introduction section the prediction or the control setting or both is considered in the paper.\nWhen designing a fixed interest function for SARSA with emphatic weighting, it would be advantageous to emphasize the states on the left and de-emphasize the states on the right, as a way to try and avoid the sub-optimal solution.\nWhy?\nCan interests go arbitrarily large?\nIn figure 1, no algorithm eventually converges to the optimal policy (left), right? Why is that?\nIn figure 2, how did you compute the MSVE?\nIsn't figure 2 showing that the proposed method is slightly worse than the ETDLB method with the TD error as the interest in the tested problem (c.f. subfigure c)? \nI didn't find in the paper a description of the off-policy policy evaluation algorithm (the one you used to produce figure 2).\nIt seems that the interest function is shared across all sub-tasks? If so, why is it reasonably to share it? Why do you consider the multi-task setting instead of the single one?\nIs your off-policy policy evaluation algorithm a batch algorithm? Are TDRC, Vtrace, and ETDLB online algorithms or batch algorithms?\nIn figure 3, I see that during the entire training period, cells near the hallway cells have high interests. I can also see that, at the end of training, the further a state is from from the hallway state, the lower interest the state is assigned. The paper explains that \"as the target policy does not visit them often and not many states bootstrap from them, it is less important for them to be accurate\". This is a reasonable explanation. But given that the pattern looks pretty close to the value function, it can also be hypothesized that higher state value results in higher interest. If a state has a high value but is not frequently visited by the target policy, would the interest be high?\nWhat is the on-policy control algorithm? \nWhen comparing with PPO and the Meta Learned Target algorithm, do you use the same amount of buffer to store past experience and the same amount of computation?\nLimitations: Overall I would need the questions listed above to be addressed to tell the paper's limitations. The paper does not have a potential negative societal impact.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper extends work focusing on emphatic TD learning. While the original formulation of emphatic TD learning included an interest function that prioritises updates to certain states, in practice this was always made uniform or required expert knowledge to set. The idea here is to (meta) learn the interest function as training progresses - an inner loop follows regular emphatic TD learning with the learned interest function, while an outer loop next runs to update the interest function's parameters. Empirical results are provided in several domains, including pixel-based ones, continuous control tasks and linear function approximation settings. Results indicate that an adaptive interest function learned over time seems key to applying these approaches to on-policy learning, while the method also outperforms a fixed interest function, as well as other meta-parameter learning approaches.\nStrengths And Weaknesses: + I found the paper to be extremely well-written and well-motivated. Every time a sentence raised a question in my mind, the very next sentence explained or justified it to me! \n+ The main idea is conceptually simple (in a good way) and the paper does a good job of evaluating it in several different kinds of domains. \n- I realise that space is a large issue here, but I found that I had to jump back and forth between the appendix and the main paper quite often. While much of this is extra discussion, a few times it was for key information, such as the details of the domain. In particular, I'm still not 100% certain if the reward function for the four rooms domain is a sparse one (and what the exact values are), even having consulted the appendix.\nQuestions: \nIn the MinAtar experiments, I was expecting to see the TD-error heuristic which was used in the chain walk (and popped up again in MuJoCo). Is there a reason that it wasn't included in this set of experiments?\n\nOn Line 292 it states: \"We explain in detail this baseline in the App. F and theoretically show that learning the interest function is not simply (sic) special case of their approach\". However, I cannot find a discussion of this anywhere. \n\nIn the motivating example, I'm not entirely clear on why the choice of base learning algorithm was SARSA. Is this because the focus, later on, is on-policy learning? Otherwise, it seems strange to apply the various interest strategies on top of a learning algorithm that doesn't quite fit. \n\nIs there any intuition for why the MSVE should diverge for larger learning rates with the TD error interest on H4R8T, but not 4R8T?\n\n\nAs an aside (certainly not necessary to include here), the focus on the robustness of hyperparameters like learning rate could potentially benefit from applying the methodology of [1].\nMinor comments:\n\nIt would be helpful to move Figure 4 to the top of the next page. Currently, it appears before Fig 3 and you have to jump between pages to read the associated text. \n\nWithout knowledge of the exact reward function, Figure 3 takes some puzzling out. My guess is that it is sparse (1 at the goal, 0 elsewhere) but that is simply a guess because I do not see it listed anywhere\n\nMany of the references list the arxiv or preprint versions of papers. Please check these all, since many have been published. For one example: [59] appeared at NeurIPS 2019.\n\n\nMinor typos:\nL184: \"as THE inner objective\"\nL239: algorithm -> algorithms\n[1] Jordan, Scott, et al. \"Evaluating the performance of reinforcement learning algorithms.\" International Conference on Machine Learning. PMLR, 2020.\nLimitations: N/A\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper proposes to use meta-gradient to adapt the interest function in emphatic RL algorithms. Empirical study covering off-policy policy evaluation with linear function approximation, on-policy control with nonlinear function approximation, as well as transfer learning confirm the efficacy of the proposed method.\nStrengths And Weaknesses: Strength:\n\nThis paper is well motivated and targets an important problem in RL. The use of meta-gradient is straightforward but appears novel to me.\nThe paper is well organized and easy to follow. Empirical study covers a wide rage of settings.\n\nWeaknesses:\n\nThe jump from off-policy prediction to on-policy control seems a bit abrupt to me. Emphatic methods are originally designed for off-policy prediction so starting with Section 4.1 seems natural to me. But is there any particular reason that the control experiments are in the on-policy setting, especially given the success of [22, 23], the motivating example in Section 3.1, and the derivation in Section 3.2. I feel adding more off-policy control experiments would significantly strengthen this work.\nThe meta-objective in Equation (8) seems not well motivated. Why not simply use the episodic return \\sum_s p_0(s) v_\\pi(s) where p_0 denotes the initial distribution? After all all the domains used for control is episodic instead of continuing and the agents are evaluated against episodic return. Is the ease of optimization the main consideration for the use of the excursion objective? I feel more discussion about this would also strengthen this work.\nQuestions: See \"Weaknesses\"\nLimitations: n/a\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The paper proposes a method to learn interest state function via meta-gradients in order to do emphatic RL. This interest function essentially simplifies the credit assignment problem and highlights 'more important / interesting' states.\nThe authors study their method in multiple settings: toy domain, continuous control and discrete domains as well as in the transfer learning setting. The signal is quite clear, the method which authors propose seems to always provide the benefit compared to standard RL approaches.\nThe authors study different ways of constructing interest function and provide informative ablations over these, with somewhat limited explanations.\nOverall, the paper is clearly written, the ideas are easy to understand and the results look good.",
                "Strengths And Weaknesses": "Strengths:\n\nClearly written paper\nThe authors studied a novel approach for RL and credit assignment via meta-learning of the interest function and provided solid experimental evidence that the approach can improve RL\nThe experiments are quite broad, demonstrating the applicability of the method in different scenarios: discrete control, continuous control, transfer learning.\n\nWeaknesses:\n\nIt is not clear why the authors didn't provide TD error interest for MinAtar. Given the results on the toy domain, this approach may actually perform better than meta-gradients.\nMinor writing / visualization details. The legend colours on the Figure 2 are very hard to read.",
                "Questions": "How does the TD error interest method perform on MinAtar?\nWhy do the authors claim that meta-gradient performs better on Figure 2, where it is clear that TD error interest converges faster and to a better value?",
                "Limitations": "Limitations are clear from the paper",
                "Ethics Flag": "No",
                "Ethics Review Area": "I don\u2019t know",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper studies the problem of learning the interest function, which emphasizes the importance of different states differently in RL objectives. The interests of different states are typically set to be all 1 in existing approaches. And this paper seems to pioneer the study of the adaptive interest function (the paper didn't claim it but from its discussion of existing works it appears to me that the authors believe that no other works have studied this problem before).\nThe paper proposed a meta-learning approach to the problem. Specifically, the interest function is learned to maximize an objective, which is an off-policy control objective. The paper proposed an off-policy prediction algorithm and an on-policy control algorithm. Empirically, the off-policy prediction algorithm almost matches the performance of an ETD algorithm with TD error as the interest. The on-policy control algorithm is significantly better than the PPO algorithm and the other Meta-learning algorithm.",
                "Strengths And Weaknesses": "Strengths:\nIn general, the paper is easy to follow.\nAdapting the interest function seems to be interesting and important, and is not well understood in the literature.\nThe proposed algorithm uses an elegant idea.\nEmpirical results show some interesting patterns, which would be helpful for understanding the proposed algorithm.\nWeakness:\nThe motivation of the idea, the description of the algorithm, and the explanation of the empirical results are not clear enough. Some important questions need to be addressed to evaluate the paper's contribution. See the Questions section for details.\n\nI have read the authors' responses and feel that most of my questions were answered, including the key question about explaining how interest function influences the learning process. Therefore I decided to increase my score to 6.",
                "Questions": "Overall, could you explain how different interests influence the learning process in prediction and control settings respectively?\nline 21 A possible solution could be to selectively emphasize certain updates, for example through a state-dependent interest function.\nWhy is this a possible solution?\nAre there any existing methods that adaptively choose the interest? Is your work the first one studying the adaptive interest function?\nIt is not clear from the introduction section the prediction or the control setting or both is considered in the paper.\nWhen designing a fixed interest function for SARSA with emphatic weighting, it would be advantageous to emphasize the states on the left and de-emphasize the states on the right, as a way to try and avoid the sub-optimal solution.\nWhy?\nCan interests go arbitrarily large?\nIn figure 1, no algorithm eventually converges to the optimal policy (left), right? Why is that?\nIn figure 2, how did you compute the MSVE?\nIsn't figure 2 showing that the proposed method is slightly worse than the ETDLB method with the TD error as the interest in the tested problem (c.f. subfigure c)? \nI didn't find in the paper a description of the off-policy policy evaluation algorithm (the one you used to produce figure 2).\nIt seems that the interest function is shared across all sub-tasks? If so, why is it reasonably to share it? Why do you consider the multi-task setting instead of the single one?\nIs your off-policy policy evaluation algorithm a batch algorithm? Are TDRC, Vtrace, and ETDLB online algorithms or batch algorithms?\nIn figure 3, I see that during the entire training period, cells near the hallway cells have high interests. I can also see that, at the end of training, the further a state is from from the hallway state, the lower interest the state is assigned. The paper explains that \"as the target policy does not visit them often and not many states bootstrap from them, it is less important for them to be accurate\". This is a reasonable explanation. But given that the pattern looks pretty close to the value function, it can also be hypothesized that higher state value results in higher interest. If a state has a high value but is not frequently visited by the target policy, would the interest be high?\nWhat is the on-policy control algorithm? \nWhen comparing with PPO and the Meta Learned Target algorithm, do you use the same amount of buffer to store past experience and the same amount of computation?",
                "Limitations": "Overall I would need the questions listed above to be addressed to tell the paper's limitations. The paper does not have a potential negative societal impact.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper extends work focusing on emphatic TD learning. While the original formulation of emphatic TD learning included an interest function that prioritises updates to certain states, in practice this was always made uniform or required expert knowledge to set. The idea here is to (meta) learn the interest function as training progresses - an inner loop follows regular emphatic TD learning with the learned interest function, while an outer loop next runs to update the interest function's parameters. Empirical results are provided in several domains, including pixel-based ones, continuous control tasks and linear function approximation settings. Results indicate that an adaptive interest function learned over time seems key to applying these approaches to on-policy learning, while the method also outperforms a fixed interest function, as well as other meta-parameter learning approaches.",
                "Strengths And Weaknesses": "+ I found the paper to be extremely well-written and well-motivated. Every time a sentence raised a question in my mind, the very next sentence explained or justified it to me! \n+ The main idea is conceptually simple (in a good way) and the paper does a good job of evaluating it in several different kinds of domains. \n- I realise that space is a large issue here, but I found that I had to jump back and forth between the appendix and the main paper quite often. While much of this is extra discussion, a few times it was for key information, such as the details of the domain. In particular, I'm still not 100% certain if the reward function for the four rooms domain is a sparse one (and what the exact values are), even having consulted the appendix.",
                "Questions": "In the MinAtar experiments, I was expecting to see the TD-error heuristic which was used in the chain walk (and popped up again in MuJoCo). Is there a reason that it wasn't included in this set of experiments?\n\nOn Line 292 it states: \"We explain in detail this baseline in the App. F and theoretically show that learning the interest function is not simply (sic) special case of their approach\". However, I cannot find a discussion of this anywhere. \n\nIn the motivating example, I'm not entirely clear on why the choice of base learning algorithm was SARSA. Is this because the focus, later on, is on-policy learning? Otherwise, it seems strange to apply the various interest strategies on top of a learning algorithm that doesn't quite fit. \n\nIs there any intuition for why the MSVE should diverge for larger learning rates with the TD error interest on H4R8T, but not 4R8T?\n\n\nAs an aside (certainly not necessary to include here), the focus on the robustness of hyperparameters like learning rate could potentially benefit from applying the methodology of [1].\nMinor comments:\n\nIt would be helpful to move Figure 4 to the top of the next page. Currently, it appears before Fig 3 and you have to jump between pages to read the associated text. \n\nWithout knowledge of the exact reward function, Figure 3 takes some puzzling out. My guess is that it is sparse (1 at the goal, 0 elsewhere) but that is simply a guess because I do not see it listed anywhere\n\nMany of the references list the arxiv or preprint versions of papers. Please check these all, since many have been published. For one example: [59] appeared at NeurIPS 2019.\n\n\nMinor typos:\nL184: \"as THE inner objective\"\nL239: algorithm -> algorithms\n[1] Jordan, Scott, et al. \"Evaluating the performance of reinforcement learning algorithms.\" International Conference on Machine Learning. PMLR, 2020.",
                "Limitations": "N/A",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposes to use meta-gradient to adapt the interest function in emphatic RL algorithms. Empirical study covering off-policy policy evaluation with linear function approximation, on-policy control with nonlinear function approximation, as well as transfer learning confirm the efficacy of the proposed method.",
                "Strengths And Weaknesses": "Strength:\n\nThis paper is well motivated and targets an important problem in RL. The use of meta-gradient is straightforward but appears novel to me.\nThe paper is well organized and easy to follow. Empirical study covers a wide rage of settings.\n\nWeaknesses:\n\nThe jump from off-policy prediction to on-policy control seems a bit abrupt to me. Emphatic methods are originally designed for off-policy prediction so starting with Section 4.1 seems natural to me. But is there any particular reason that the control experiments are in the on-policy setting, especially given the success of [22, 23], the motivating example in Section 3.1, and the derivation in Section 3.2. I feel adding more off-policy control experiments would significantly strengthen this work.\nThe meta-objective in Equation (8) seems not well motivated. Why not simply use the episodic return \\sum_s p_0(s) v_\\pi(s) where p_0 denotes the initial distribution? After all all the domains used for control is episodic instead of continuing and the agents are evaluated against episodic return. Is the ease of optimization the main consideration for the use of the excursion objective? I feel more discussion about this would also strengthen this work.",
                "Questions": "See \"Weaknesses\"",
                "Limitations": "n/a",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "soundness_avg": 3.25,
        "presentation_avg": 3.5,
        "contribution_avg": 3.0,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is clear that the paper proposes a novel approach for reinforcement learning (RL) by learning the interest function via meta-gradients. The authors provide solid experimental evidence that their approach improves RL in various settings, including discrete control, continuous control, and transfer learning. The paper is well-written and easy to understand, and the results are promising.\n\nReviewer 1 highlights the strengths of the paper, including its clarity, the novelty of the approach, and the broad applicability of the method. They also raise a minor concern about the absence of TD error interest for MinAtar and suggest that it may perform better than meta-gradients in that case.\n\nReviewer 2 also acknowledges the strengths of the paper, such as its easy-to-follow presentation and the interesting and important problem it addresses. They raise some questions regarding the influence of different interests on the learning process and the comparison with other existing methods. However, they mention that most of their questions were answered in the authors' responses.\n\nReviewer 3 praises the paper for its well-written and well-motivated content. They appreciate the conceptual simplicity of the main idea and the evaluation in different domains. They suggest some minor improvements, such as moving a figure and providing more details about the reward function in one of the domains.\n\nReviewer 4 recognizes the importance of the problem addressed in the paper and the novelty of using meta-gradients to adapt the interest function. They suggest adding more off-policy control experiments and providing further motivation for the choice of the meta-objective.\n\nOverall, the reviewers find the paper technically solid and with moderate-to-high impact. They have some minor concerns and questions, but these do not outweigh the strengths and contributions of the paper.\n\nBased on the reviews, I recommend accepting the paper. The reviewers' feedback has been addressed adequately, and the paper has the potential to make a significant impact in the field of RL."
    },
    "Human-Robotic_Prosthesis_as_Collaborating_Agents_for_Symmetrical_Walking": {
        "link": "https://openreview.net//forum?id=HBGvWy9Vxq",
        "pub_url": "https://openreview.net/forum?id=HBGvWy9Vxq",
        "pdf_link": "https://openreview.net//pdf?id=HBGvWy9Vxq",
        "paper_id": "HBGvWy9Vxq",
        "title": "Human-Robotic_Prosthesis_as_Collaborating_Agents_for_Symmetrical_Walking",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Less certain\nThis paper present an approach for control of prosthesis under a novel collaborative multi-agent formulation. The approach is demonstrated in simulation. \nAll the reviewers agree that the paper contribution is novel and interesting.\nThe reviewers also provided several suggestions on how to improve the manuscript and pointed out the limitations intrinsic with evaluating the approach only in simulation.\nEvaluating the approach in the real-world seems a natural and desirable next step.\nI invite the authors to carefully integrate all the feedback received and, in particular, better highlight limitations and societal impact.\nPersonal comment: The references would benefit from some work: some of the references are poorly formatted; [30] and [31] cite the same paper; and finally you are not really citing 110 papers in the main text, so I think you might have forgot a \\nocite in the code.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper presents an approach to adapting control parameters in a prosthetic limb using a multi-agent Reinforcement Learning design that considers the human and the prosthetic as collaborating agents with the goal of achieving a symmetric gait pattern. \nThe design is evaluated and compared in a number of simulation experiments.\nStrengths And Weaknesses: The control of prosthetics in a way that is natural and does not put increased burden on the human is can have significant impact on the\nlife is amputees. Moreover, learning collaborative control tasks with humans in general is an important field. The paper is generally well written and lays out the rationale for the approach well.\nThe main weakness of the paper is in the experimental evaluation which, as it is done in simulation with a ver simple (and beneficial to the approach) human model. In particular it assumes that the human learns and adapts in the same way as the prosthetic (using the partial gradient of the prescribed control model with respect to the joined utility). This seems to remove some of the rationale of the interactive multi-agent approach that is to react to and address the human\u2019s reactions to the behavior of the prosthetic, which, in turn, is likely based in past experiences and existing control schemes in the human. A discussion as to the assumptions in the simulation (especially with respect to the human model) both in terms of the utility used - don\u2019t humans likely have more complex utilities?- and the policy- a human would start with a strongly pre-trained system with expectations about the other limb - or , better, inclusion of experiments with pre-trained human models that reflect likely human reactions to \u201cun-natural\u201d controls especially early on (and an evaluation of the difference this makes on learning speed and performance) would be very useful.\nAlso, it would be useful if the authors would include a comparison of the learned impedance parameter functions for the 3 scenarios and the base performance of the flat ground parameters in the robustness scenarios to give the reader an idea whether the approach would have to be trained for all terrain types separately (and maybe ultimately require a \u201cterrain classifier\u201d) or whether general parameters for variable terrains can be learned.\nAlso, to better understand the generality of the approach across walking scenarios, a discussion of whether and how it could be adapted to settings (like turning) where symmetry is not the main criterion would be useful.\nQuestions: Some questions arise regarding the degree to which the evaluations are realistic:\nTo what degree is the simulation model for the human realistic ?\nTo what degree do the learned impedance parameters generalize to slight variations of the terrain ?\nIs it realistic to assume that the human has the same objective to achieve symmetric patterns ?\nTo what degree can the approach be generalized to other non-straight walking tasks?\nLimitations: The paper addresses social impacts and considerations and discusses limitations in the conclusions. However, it would have been nice to see more discussion regarding the limitations (and potential ways to address them) earlier in the paper, especially in the experiments section to allow the reader a clearer picture regarding what the results show (and what they don\u2019t capture).\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper studies the problem of controlling robotic lower limb prosthesis for achieving better human walking assistance. The main idea is a formulation of multi-agent RL, where one agent represents the human controller and the other represents the robotic prosthesis. The robotic controller has access to some information about the human state and controller, which helps it better assist the human walking. To optimize the controllers, a Q-learning-based algorithm is deployed. The proposed method is evaluated in the OpenSim simulation environment and compared to alternative multi-agent RL algorithms. An ablation study is also carried out to investigate the impact of including human controller action as observation for the robotic controller.\nStrengths And Weaknesses: Strengths:\n\nThe paper studies an important and practical problem of controller robotic prosthesis for human motion assistance.\nThe idea of multi-agent RL training for the robotic controller seems reasonable.\nThe proposed formulation obtained promising learning performance in a simulated task.\n\nWeaknesses:\n\nThe technical contribution of the paper is not very clear. The main innovation seems to be the formulation of the observation and action spaces for the human and robotic agents and how the robot agent can observe certain information about the human. However, without evaluation on real humans, it\u2019s hard to tell how realistic these assumptions are.\nThe proposed formulation seems specific to the setup: if the task becomes walking up/down stairs, or traversing stepping stones, having desired and commanded velocity from the human controller might be insufficient.\nQuestions: \nDuring the walking, who decides the desired walking speed? If human determines that, how does the robot have access to it?\nHow well does the method generalize to unseen human behavior? For example, if the thresholds in the human controller state machine is varied during testing.\nIn the ablation it appears that without human controller input the model learns slower, but converges to a similar level of performance. Some discussion on this would be useful to better understand the impact of including the additional information.\nHuman users can adapt their behavior to the prosthesis device. To account for this, one need to either model the adaptation process, or obtain a model that is robust to this. How would the proposed method handle that?\nHow does the proposed method compare to a biomechanical engineering-based approach in terms of performance?\nLimitations: The current discussion on limitations of the method is good in general.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The paper presents an application for human-robot collaboration and shared autonomy \u2014 the task of robotic prosthesis for symmetrical walking \u2014 which has not been studied extensively using RL. The authors propose a collaborative MARL framework to study the problem by defining a state-space problem and joint cost function, and show that an actor-critic policy can jointly optimize this problem. Compared to some relevant baselines like COMA and MADDPG, the proposed agent performs better in terms of learning a stable gait. Useful ablation analysis justifies some of the design decisions made.\nStrengths And Weaknesses: Heads up: I am not familiar with the space of human-robot prosthesis, and my review is from the perspective of a general robotics/HRI/ML researcher. A quick skim of the space suggests some prior work in using RL for limb/knee prosthesis, but the proposed collaborative formulation seems novel to me.\nStrengths\n\nThe paper does a great job of describing the problem of human-robot prosthesis to an outsider (me), and it was possible to follow along the terminology and problem formulation with some effort. It\u2019s always hard to write an accessible paper bridging communities and this paper does a good job of that.\nThe experiments seem very well designed and answer specific questions I have as a reader. The ablation and reliability studies were particularly useful in convincing me that (i) the cost function is doing what it should, (ii) the human input is actually being used in a non-trivial manner, and (iii) the method can adapt to more general target signals (velocity, slope etc.). Learning curves alone do not capture this story, and the analysis included by the authors seems really comprehensive and useful.\n\n\nWeaknesses\n\n[Interpreting Results] From the quantitative results in the paper, it is very hard to interpret what is a \u201cgood enough\u201d error/symmetry. Is the lowest always better, or is there a point below which it does not matter and should be treated as the \u201ctarget\u201d. It would really help to include some qualitative result denoting what it means to \u201cdo better\u201d in the task, e.g. stability of learned gaits, or energy consumption estimate etc. Also, the learning curves seem to only denote the training curves and not the validation curves \u2014 can the authors provide validation curves instead/alongside to convey the full picture? Training loss going down does not capture the entire process.\n[Implementation Details] I found the paper severely lacking in implementation details, and in its current shape, the paper is not reproducible. Beyond providing the form of the agent and objective, the paper has no information on the agent architectures used, training algorithm, optimizer, amount of training time etc.\n[Related Work: Shared Autonomy] The discussion on related work seems to miss a very important body of research in shared autonomy [1, 2, 3, to name a few\u2026]. The task of shared autonomy very closely resembles the problem setup in the paper \u2014 human input combined with a (semi-)autonomous agent to achieve a common goal \u2014 and should be discussed when positioning the paper. While the proposed approach is shown to be better than other MARL baselines, it would also benefit from a comparison with a more shared autonomy-esque viewpoint to the problem \u2014 seeing an empirical evaluation against this, or a discussion of why this is not feasible, would really strengthen the paper.\n\n\nReferences\n[1] Nikolaidis and Shah, \u201cHuman-Robot Cross-Training: Computational Formulation, Modeling and Evaluation of a Human Team Training Strategy\u201d (2013) \n[2] Javdani, Srinivasa, and Bagnell, \u201cShared Autonomy via Hindsight Optimization\u201d (2015) \n[3] Reddy, Dragan, and Levine, \u201cShared Autonomy via Deep Reinforcement Learning\u201d (2018)\nQuestions: Drawing from the discussion of weaknesses above, here are some clarifications/suggestions that would help me re-evaluate the paper after authors\u2019 response. I am more than willing to engage with the authors and modify my review score contingent on the author discussion phase.\n\nImproving interpretability of results, with a better metric or a qualitative visualization/analysis.\nAdding implementation details, or ideally, releasing the code with the paper.\nA discussion on positioning wrt shared autonomy; ideally, added comparison against some existing approach(es).\n[Line 355] What are some other, more natural, objectives that may be used for providing shared goals in the proposed cMARL framework for robot prosthesis? Beyond the task of prosthesis, what broader set of collaborative objectives in HRI can the proposed method be applied for? A discussion on this would greatly improve how the broader community receives and builds on this work.\n\n\nAfter a productive round of responses from the authors, I have updated my score to recommend acceptance.\nLimitations: \nIt does not seem that the implementation/code is shared in the supplemental material. The data being proprietary is understandable, but that is not a sufficient reason to not release the code. The paper is also sparse in implementation details of cMARL, as well as the baselines, and it may be really difficult for people in sibling disciplines of HRI to draw useful insights and quickly try out the proposed algorithm.\nI could not find an explicit discussions on societal impacts of the work. While the immediate impacts of the work are not particularly troubling, I believe any paper on HRI, esp. involving prosthesis, should include a discussion on the potential negative implications and a discussion of how the proposed algorithms may be susceptible to malicious attacks. While this is not a criticism/limitation of the research proposed (and does not factor into my review), it helps people outside the community contextualize the research and its potential limitations.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper presents an approach to adapting control parameters in a prosthetic limb using a multi-agent Reinforcement Learning design that considers the human and the prosthetic as collaborating agents with the goal of achieving a symmetric gait pattern. \nThe design is evaluated and compared in a number of simulation experiments.",
                "Strengths And Weaknesses": "The control of prosthetics in a way that is natural and does not put increased burden on the human is can have significant impact on the\nlife is amputees. Moreover, learning collaborative control tasks with humans in general is an important field. The paper is generally well written and lays out the rationale for the approach well.\nThe main weakness of the paper is in the experimental evaluation which, as it is done in simulation with a ver simple (and beneficial to the approach) human model. In particular it assumes that the human learns and adapts in the same way as the prosthetic (using the partial gradient of the prescribed control model with respect to the joined utility). This seems to remove some of the rationale of the interactive multi-agent approach that is to react to and address the human\u2019s reactions to the behavior of the prosthetic, which, in turn, is likely based in past experiences and existing control schemes in the human. A discussion as to the assumptions in the simulation (especially with respect to the human model) both in terms of the utility used - don\u2019t humans likely have more complex utilities?- and the policy- a human would start with a strongly pre-trained system with expectations about the other limb - or , better, inclusion of experiments with pre-trained human models that reflect likely human reactions to \u201cun-natural\u201d controls especially early on (and an evaluation of the difference this makes on learning speed and performance) would be very useful.\nAlso, it would be useful if the authors would include a comparison of the learned impedance parameter functions for the 3 scenarios and the base performance of the flat ground parameters in the robustness scenarios to give the reader an idea whether the approach would have to be trained for all terrain types separately (and maybe ultimately require a \u201cterrain classifier\u201d) or whether general parameters for variable terrains can be learned.\nAlso, to better understand the generality of the approach across walking scenarios, a discussion of whether and how it could be adapted to settings (like turning) where symmetry is not the main criterion would be useful.",
                "Questions": "Some questions arise regarding the degree to which the evaluations are realistic:\nTo what degree is the simulation model for the human realistic ?\nTo what degree do the learned impedance parameters generalize to slight variations of the terrain ?\nIs it realistic to assume that the human has the same objective to achieve symmetric patterns ?\nTo what degree can the approach be generalized to other non-straight walking tasks?",
                "Limitations": "The paper addresses social impacts and considerations and discusses limitations in the conclusions. However, it would have been nice to see more discussion regarding the limitations (and potential ways to address them) earlier in the paper, especially in the experiments section to allow the reader a clearer picture regarding what the results show (and what they don\u2019t capture).",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper studies the problem of controlling robotic lower limb prosthesis for achieving better human walking assistance. The main idea is a formulation of multi-agent RL, where one agent represents the human controller and the other represents the robotic prosthesis. The robotic controller has access to some information about the human state and controller, which helps it better assist the human walking. To optimize the controllers, a Q-learning-based algorithm is deployed. The proposed method is evaluated in the OpenSim simulation environment and compared to alternative multi-agent RL algorithms. An ablation study is also carried out to investigate the impact of including human controller action as observation for the robotic controller.",
                "Strengths And Weaknesses": "Strengths:\n\nThe paper studies an important and practical problem of controller robotic prosthesis for human motion assistance.\nThe idea of multi-agent RL training for the robotic controller seems reasonable.\nThe proposed formulation obtained promising learning performance in a simulated task.\n\nWeaknesses:\n\nThe technical contribution of the paper is not very clear. The main innovation seems to be the formulation of the observation and action spaces for the human and robotic agents and how the robot agent can observe certain information about the human. However, without evaluation on real humans, it\u2019s hard to tell how realistic these assumptions are.\nThe proposed formulation seems specific to the setup: if the task becomes walking up/down stairs, or traversing stepping stones, having desired and commanded velocity from the human controller might be insufficient.",
                "Questions": "During the walking, who decides the desired walking speed? If human determines that, how does the robot have access to it?\nHow well does the method generalize to unseen human behavior? For example, if the thresholds in the human controller state machine is varied during testing.\nIn the ablation it appears that without human controller input the model learns slower, but converges to a similar level of performance. Some discussion on this would be useful to better understand the impact of including the additional information.\nHuman users can adapt their behavior to the prosthesis device. To account for this, one need to either model the adaptation process, or obtain a model that is robust to this. How would the proposed method handle that?\nHow does the proposed method compare to a biomechanical engineering-based approach in terms of performance?",
                "Limitations": "The current discussion on limitations of the method is good in general.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper presents an application for human-robot collaboration and shared autonomy \u2014 the task of robotic prosthesis for symmetrical walking \u2014 which has not been studied extensively using RL. The authors propose a collaborative MARL framework to study the problem by defining a state-space problem and joint cost function, and show that an actor-critic policy can jointly optimize this problem. Compared to some relevant baselines like COMA and MADDPG, the proposed agent performs better in terms of learning a stable gait. Useful ablation analysis justifies some of the design decisions made.",
                "Strengths And Weaknesses": "Heads up: I am not familiar with the space of human-robot prosthesis, and my review is from the perspective of a general robotics/HRI/ML researcher. A quick skim of the space suggests some prior work in using RL for limb/knee prosthesis, but the proposed collaborative formulation seems novel to me.\nStrengths\n\nThe paper does a great job of describing the problem of human-robot prosthesis to an outsider (me), and it was possible to follow along the terminology and problem formulation with some effort. It\u2019s always hard to write an accessible paper bridging communities and this paper does a good job of that.\nThe experiments seem very well designed and answer specific questions I have as a reader. The ablation and reliability studies were particularly useful in convincing me that (i) the cost function is doing what it should, (ii) the human input is actually being used in a non-trivial manner, and (iii) the method can adapt to more general target signals (velocity, slope etc.). Learning curves alone do not capture this story, and the analysis included by the authors seems really comprehensive and useful.\n\n\nWeaknesses\n\n[Interpreting Results] From the quantitative results in the paper, it is very hard to interpret what is a \u201cgood enough\u201d error/symmetry. Is the lowest always better, or is there a point below which it does not matter and should be treated as the \u201ctarget\u201d. It would really help to include some qualitative result denoting what it means to \u201cdo better\u201d in the task, e.g. stability of learned gaits, or energy consumption estimate etc. Also, the learning curves seem to only denote the training curves and not the validation curves \u2014 can the authors provide validation curves instead/alongside to convey the full picture? Training loss going down does not capture the entire process.\n[Implementation Details] I found the paper severely lacking in implementation details, and in its current shape, the paper is not reproducible. Beyond providing the form of the agent and objective, the paper has no information on the agent architectures used, training algorithm, optimizer, amount of training time etc.\n[Related Work: Shared Autonomy] The discussion on related work seems to miss a very important body of research in shared autonomy [1, 2, 3, to name a few\u2026]. The task of shared autonomy very closely resembles the problem setup in the paper \u2014 human input combined with a (semi-)autonomous agent to achieve a common goal \u2014 and should be discussed when positioning the paper. While the proposed approach is shown to be better than other MARL baselines, it would also benefit from a comparison with a more shared autonomy-esque viewpoint to the problem \u2014 seeing an empirical evaluation against this, or a discussion of why this is not feasible, would really strengthen the paper.\n\n\nReferences\n[1] Nikolaidis and Shah, \u201cHuman-Robot Cross-Training: Computational Formulation, Modeling and Evaluation of a Human Team Training Strategy\u201d (2013) \n[2] Javdani, Srinivasa, and Bagnell, \u201cShared Autonomy via Hindsight Optimization\u201d (2015) \n[3] Reddy, Dragan, and Levine, \u201cShared Autonomy via Deep Reinforcement Learning\u201d (2018)",
                "Questions": "Drawing from the discussion of weaknesses above, here are some clarifications/suggestions that would help me re-evaluate the paper after authors\u2019 response. I am more than willing to engage with the authors and modify my review score contingent on the author discussion phase.\n\nImproving interpretability of results, with a better metric or a qualitative visualization/analysis.\nAdding implementation details, or ideally, releasing the code with the paper.\nA discussion on positioning wrt shared autonomy; ideally, added comparison against some existing approach(es).\n[Line 355] What are some other, more natural, objectives that may be used for providing shared goals in the proposed cMARL framework for robot prosthesis? Beyond the task of prosthesis, what broader set of collaborative objectives in HRI can the proposed method be applied for? A discussion on this would greatly improve how the broader community receives and builds on this work.\n\n\nAfter a productive round of responses from the authors, I have updated my score to recommend acceptance.",
                "Limitations": "It does not seem that the implementation/code is shared in the supplemental material. The data being proprietary is understandable, but that is not a sufficient reason to not release the code. The paper is also sparse in implementation details of cMARL, as well as the baselines, and it may be really difficult for people in sibling disciplines of HRI to draw useful insights and quickly try out the proposed algorithm.\nI could not find an explicit discussions on societal impacts of the work. While the immediate impacts of the work are not particularly troubling, I believe any paper on HRI, esp. involving prosthesis, should include a discussion on the potential negative implications and a discussion of how the proposed algorithms may be susceptible to malicious attacks. While this is not a criticism/limitation of the research proposed (and does not factor into my review), it helps people outside the community contextualize the research and its potential limitations.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "soundness_avg": 2.667,
        "presentation_avg": 3.0,
        "contribution_avg": 2.667,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that this paper presents a technically solid contribution with high impact in the field of human-robot collaboration and shared autonomy for robotic prosthesis. The paper addresses an important problem and proposes a collaborative multi-agent reinforcement learning framework that shows promising results in achieving a symmetric gait pattern.\n\nReviewer 1 raises valid concerns about the experimental evaluation, particularly regarding the assumptions made in the simulation and the generalizability of the approach to different walking scenarios. It would be beneficial for the authors to address these concerns by discussing the limitations and potential ways to address them earlier in the paper, as well as including experiments with pre-trained human models to reflect likely human reactions to \"un-natural\" controls.\n\nReviewer 2 also highlights some weaknesses, including the lack of clarity in the technical contribution and the need for evaluation on real humans to validate the assumptions made in the formulation. The reviewer also raises important questions regarding the generalizability of the method to unseen human behavior and the handling of human adaptation to the prosthesis device.\n\nReviewer 3 provides a positive review, commending the paper for its accessibility and comprehensive experiments. However, the reviewer also points out the need for better interpretation of results, more implementation details, and a discussion on the positioning of the proposed method in relation to shared autonomy.\n\nOverall, the strengths of the paper, including its clear problem formulation, well-designed experiments, and promising learning performance, outweigh the weaknesses and limitations identified by the reviewers. The paper makes a significant contribution to the field and has the potential for high impact. Therefore, I recommend accepting the paper."
    },
    "Uni[MASK]:_Unified_Inference_in_Sequential_Decision_Problems": {
        "link": "https://openreview.net//forum?id=GisHNaleWiA",
        "pub_url": "https://openreview.net/forum?id=GisHNaleWiA",
        "pdf_link": "https://openreview.net//pdf?id=GisHNaleWiA",
        "paper_id": "GisHNaleWiA",
        "title": "Uni[MASK]:_Unified_Inference_in_Sequential_Decision_Problems",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nThis paper extends masked language modeling to other sequential decision making problems. The idea is simple (which is a plus), the experiments are thorough, and the results are convincing. All reviewers agreed this is a good paper. I recommend acceptance.",
        "reviews": [
            "Reviewer 1: \nSummary: Proposes an approach to using a single bidirectional transformer to accomplish many different reinforcement learning tasks, including behavior cloning, (sub)goal conditioning, and conditioning on properties more generally. It accomplishes this by creating a sequence of out of the (state, action, properties) for all timesteps, then either (1) training on a single type of mask, (2) training across many masking styles drawn from fixed set, and (3) randomly masking positions in the sequence. (2) and (3) can be finetuned in single task fashion. They evaluate on a toy gridworld and the mujoco 2d maze tasks. They find that Uni[MASK] performs better across both given a short truncated sequence, but it underperforms a GPT model for longer sequences. They attribute this to difficulties in training BERT models.\nStrengths And Weaknesses: - originality\n    - Concurrent work suggests that the core ideas of this paper are in the air (see: foundation posterior, multigame decision transformer, The UL2 paper on unifying masking schemes).\n- quality\n    - The paper is well executed. It has simple experiments which verify the core claims.\n    - My main concern is that the length 10 context experiments underperforming. Would like to see more study of this instead of alluding to claims that BERT has this known failure mode.\n- clarity\n    - The paper is well written and a pleasant read. It adequately cites prior work, and it does a great job of explaining and illustrating the core ideas.\n- significance\n    - The paper is a solid contribution to the literature. Overall, its core findings and technique align with concurrent and prior work.\nQuestions: 1. Clarify which task is shown in table 1. The grid world or maze?\n2. Consider expanding on what position vs. timestep encoding is in the body of the paper (line 231)?\n3. The \"bert has no mouth and must speak\" paper was withdrawn\n4. Take a look at XLNet and NADE style masking, which would allow combining benefits of GPT and BERT\n5. One possibile reason the longer sequence is failing is because it is never exposed to many masked positions in a row at the end of the sequence. Randomized decoding as in xlnet might help here, or applying more structured masking (such as blocking out spans instead of ). See the uni\n    1. Perhaps training on both multitask and \n6. What happens if you train on both multitask and random masking? \n7. Potential improvements\n    1. Vary the sequence lengths instead of holding fixed\n        1. This is more natural for GPT style models, but can be done with XLNet/NADE approaches as well\n        2. How might Uni[MASK] handle the full length 200 timestep sequences instead of truncating to last 5/10?\n    2. Ideally would have more complicated tasks than the two presented\n    3. Consider studying how \n8. Relevant concurrent work: foundation posterior, which applies a similar approach to inference in probabilistic programs (i.e. generalized bayesian networks) in Stan.\n9. nits\n    1. works -> work in line 300\nLimitations: There are no major concerns with this paper\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 3 good\nRating: 8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper presents the Uni[MASK] framework, which generalizes masked language modeling (in natural language processing) to more general sequence decision problems. Given actions, states and optional property tokens (such as the return-to-go), multiple tasks such as behavioral cloning, reward-conditional offline RL, forward dynamics, etc., may be represented by specific masking schemes. The authors propose to train a model by using a randomized masking scheme (instead of single-task only or with a fixed set of tasks). Such a Uni[Mask] model may also be fine-tuned on a given task afterwards. A pre-trained Uni[MASK] model often performs comparably to single-task training, and fine-tuning further improves results.\n[Post author response] I updated the rating I assigned to this paper, in particular because of the correction to the originally misleading discussion.\nStrengths And Weaknesses: Strengths\nThe proposed approach neatly formalizes multiple tasks under a general masking framework.\nTraining a Uni[MASK] model, then finetuning it on a given task, generally leads to better results than single-task training only.\nThe approach is tested in both discrete (MiniGrid) and continuous (Maze2D) environments.\nWeaknesses\nThe discussion around line 200 is misleading. In figure 7, multi-task performs worse than single-task (although sometimes negligibly), which doesn't support H1.\nThe distinction between BERT-like and GPT-like models should be described more clearly (see question below).\nThe MiniGrid environment appears to be very simple. I would be interested in seeing how well the approach scales with larger grids.\nQuestions: Questions\nMost important question: Could you please clarify exactly what you mean by \"BERT\" architecture vs \"GPT\" architecture, and how they interact with the masking schemes you propose? In NLP, BERT uses a transformer encoder (self-attention) with some masked inputs whereas GPT uses a transformer decoder (causal self-attention, i.e. not looking at the future).\nL160+: Should there be a reward for shorter paths? Otherwise, there could be useless \nL190: Why no test data?\nL212: Do you mean figure 15 in the appendix? In general, figures referred in the main text should also be within the paper itself.\nSuggestion\nPlease move the description of random masking (end of appendix 1) and appendix 2 to the main text. This is too important to leave out.\nOther\nL235: This points to the wrong appendix.\nLimitations: Some limitations are discussed.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This submission proposed a new framework, Uni[MASK], which performs unified inference in sequential decision problems, using different masking schemes. \nThe authors demonstrated that randomly sampling masking schemes help the bidirectional transformer model being able to do behavior cloning, rewarding conditioning, dynamics modeling and more.\nThe experiments are first on grid-world and then extended to Mujoco-physics Maze2D environment. The comparison between single-task, multi-task, random-task, with finetune are through and solid, integrating the theory with practice, and quite convincing. The experiments in Mujoco-physics Maze2D environment shows that Uni[MASK] framework outperforms baselines, such as Feedforward Neural Network and Decision Transformer.\nI fully endorse that this submission is a wonderful work: well designed experiments, diplomatic and sound illustration and the novelty of unifying decision making through Uni[MASK] and bidirectional models.\nStrengths And Weaknesses: Strengths:\n\nUni[MASK] unifies inference task in sequential decision problems.\nThe illustration of motivation, theory and experiments design is convincing and sound, written and presented very well.\nThe authors demonstrate how randomly sampling masking schemes at training time produces a single multi-inference-task model that can do behavior cloning, reward-conditioning, dynamics modeling and more.\nThe authors test how training on many tasks affects single-task performance.\nThe authors show how fine-tuning models trained with random masking consistently outperforms single-task models.\nThe proposed Hypothesis H1 ( {multi-task, random-mask, finetune} > single-task) and H2 ( {random-mask > multi-task} ) make sense intuitively, as \"H1 test whether models indeed learn richer representations by training on multiple inference tasks\" and H2 test \"whether training on all possible tasks by randomly sampling maskings at training time is better than selecting a set of specific maskings\"\nThe results from well designed experiments strongly support hypothesis H1 and H2.\nThe authors extensively analyze how different training regimes (combination of single-task, multi-task, random mask, fintune) affect performance. The analysis is very convincing to me.\nThe authors also make experiments comparison with GPT-like architectures, and the analysis is also very convincing: \"We find that while using GPT seems to yield similar performance to BERT for context length five, using GPT seems to give an advantage for longer sequence lengths,\" and \"This suggests that if one were able to use a GPT architecture and train it with random masking and fine-tuning, it might be possible to get the best of both worlds.\"\n\nWeakness:\n\nRelative short context lengths, and the experiments is mainly on the grid world (4 * 4), if the grid size increases, it might further improve this work.\nQuestions: From line 285 to line 2899, \"A clear avenue of future work would therefore be to get the \u201cbest of both worlds\u201d: long sequences and benefits of random-mask pre-training by using a GPT-like architectures, with our random-mask and finetune training regimes. This which would require finding ways to make GPT act like a bidirectional model \u2013 for which recent methods in NLP might offer a useful starting point\". In the rebuttal period, may I know the opinion from the authors, why making GPT act like a bidirectional model is important in the decision making scenario? The answers to this question would make me (maybe other readers) understand this paper better.\nLimitations: \nRelative short context lengths. Experiments with longer context lengths would make this submission more convincing.\nThe experiments are mainly on the grid world (grid size is 4* 4). If the grid sizes increase more, this work would become more persuasive.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 4 excellent\nRating: 9: Very Strong Accept: Technically flawless paper with groundbreaking impact on at least one area of AI/ML and excellent impact on multiple areas of AI/ML, with flawless evaluation, resources, and reproducibility, and no unaddressed ethical considerations.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "Proposes an approach to using a single bidirectional transformer to accomplish many different reinforcement learning tasks, including behavior cloning, (sub)goal conditioning, and conditioning on properties more generally. It accomplishes this by creating a sequence of out of the (state, action, properties) for all timesteps, then either (1) training on a single type of mask, (2) training across many masking styles drawn from fixed set, and (3) randomly masking positions in the sequence. (2) and (3) can be finetuned in single task fashion. They evaluate on a toy gridworld and the mujoco 2d maze tasks. They find that Uni[MASK] performs better across both given a short truncated sequence, but it underperforms a GPT model for longer sequences. They attribute this to difficulties in training BERT models.",
                "Strengths And Weaknesses": "- originality\n    - Concurrent work suggests that the core ideas of this paper are in the air (see: foundation posterior, multigame decision transformer, The UL2 paper on unifying masking schemes).\n- quality\n    - The paper is well executed. It has simple experiments which verify the core claims.\n    - My main concern is that the length 10 context experiments underperforming. Would like to see more study of this instead of alluding to claims that BERT has this known failure mode.\n- clarity\n    - The paper is well written and a pleasant read. It adequately cites prior work, and it does a great job of explaining and illustrating the core ideas.\n- significance\n    - The paper is a solid contribution to the literature. Overall, its core findings and technique align with concurrent and prior work.",
                "Questions": "1. Clarify which task is shown in table 1. The grid world or maze?\n2. Consider expanding on what position vs. timestep encoding is in the body of the paper (line 231)?\n3. The \"bert has no mouth and must speak\" paper was withdrawn\n4. Take a look at XLNet and NADE style masking, which would allow combining benefits of GPT and BERT\n5. One possibile reason the longer sequence is failing is because it is never exposed to many masked positions in a row at the end of the sequence. Randomized decoding as in xlnet might help here, or applying more structured masking (such as blocking out spans instead of ). See the uni\n    1. Perhaps training on both multitask and \n6. What happens if you train on both multitask and random masking? \n7. Potential improvements\n    1. Vary the sequence lengths instead of holding fixed\n        1. This is more natural for GPT style models, but can be done with XLNet/NADE approaches as well\n        2. How might Uni[MASK] handle the full length 200 timestep sequences instead of truncating to last 5/10?\n    2. Ideally would have more complicated tasks than the two presented\n    3. Consider studying how \n8. Relevant concurrent work: foundation posterior, which applies a similar approach to inference in probabilistic programs (i.e. generalized bayesian networks) in Stan.\n9. nits\n    1. works -> work in line 300",
                "Limitations": "There are no major concerns with this paper",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper presents the Uni[MASK] framework, which generalizes masked language modeling (in natural language processing) to more general sequence decision problems. Given actions, states and optional property tokens (such as the return-to-go), multiple tasks such as behavioral cloning, reward-conditional offline RL, forward dynamics, etc., may be represented by specific masking schemes. The authors propose to train a model by using a randomized masking scheme (instead of single-task only or with a fixed set of tasks). Such a Uni[Mask] model may also be fine-tuned on a given task afterwards. A pre-trained Uni[MASK] model often performs comparably to single-task training, and fine-tuning further improves results.\n[Post author response] I updated the rating I assigned to this paper, in particular because of the correction to the originally misleading discussion.",
                "Strengths And Weaknesses": "Strengths\nThe proposed approach neatly formalizes multiple tasks under a general masking framework.\nTraining a Uni[MASK] model, then finetuning it on a given task, generally leads to better results than single-task training only.\nThe approach is tested in both discrete (MiniGrid) and continuous (Maze2D) environments.\nWeaknesses\nThe discussion around line 200 is misleading. In figure 7, multi-task performs worse than single-task (although sometimes negligibly), which doesn't support H1.\nThe distinction between BERT-like and GPT-like models should be described more clearly (see question below).\nThe MiniGrid environment appears to be very simple. I would be interested in seeing how well the approach scales with larger grids.",
                "Questions": "Questions\nMost important question: Could you please clarify exactly what you mean by \"BERT\" architecture vs \"GPT\" architecture, and how they interact with the masking schemes you propose? In NLP, BERT uses a transformer encoder (self-attention) with some masked inputs whereas GPT uses a transformer decoder (causal self-attention, i.e. not looking at the future).\nL160+: Should there be a reward for shorter paths? Otherwise, there could be useless \nL190: Why no test data?\nL212: Do you mean figure 15 in the appendix? In general, figures referred in the main text should also be within the paper itself.\nSuggestion\nPlease move the description of random masking (end of appendix 1) and appendix 2 to the main text. This is too important to leave out.\nOther\nL235: This points to the wrong appendix.",
                "Limitations": "Some limitations are discussed.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This submission proposed a new framework, Uni[MASK], which performs unified inference in sequential decision problems, using different masking schemes. \nThe authors demonstrated that randomly sampling masking schemes help the bidirectional transformer model being able to do behavior cloning, rewarding conditioning, dynamics modeling and more.\nThe experiments are first on grid-world and then extended to Mujoco-physics Maze2D environment. The comparison between single-task, multi-task, random-task, with finetune are through and solid, integrating the theory with practice, and quite convincing. The experiments in Mujoco-physics Maze2D environment shows that Uni[MASK] framework outperforms baselines, such as Feedforward Neural Network and Decision Transformer.\nI fully endorse that this submission is a wonderful work: well designed experiments, diplomatic and sound illustration and the novelty of unifying decision making through Uni[MASK] and bidirectional models.",
                "Strengths And Weaknesses": "Strengths:\n\nUni[MASK] unifies inference task in sequential decision problems.\nThe illustration of motivation, theory and experiments design is convincing and sound, written and presented very well.\nThe authors demonstrate how randomly sampling masking schemes at training time produces a single multi-inference-task model that can do behavior cloning, reward-conditioning, dynamics modeling and more.\nThe authors test how training on many tasks affects single-task performance.\nThe authors show how fine-tuning models trained with random masking consistently outperforms single-task models.\nThe proposed Hypothesis H1 ( {multi-task, random-mask, finetune} > single-task) and H2 ( {random-mask > multi-task} ) make sense intuitively, as \"H1 test whether models indeed learn richer representations by training on multiple inference tasks\" and H2 test \"whether training on all possible tasks by randomly sampling maskings at training time is better than selecting a set of specific maskings\"\nThe results from well designed experiments strongly support hypothesis H1 and H2.\nThe authors extensively analyze how different training regimes (combination of single-task, multi-task, random mask, fintune) affect performance. The analysis is very convincing to me.\nThe authors also make experiments comparison with GPT-like architectures, and the analysis is also very convincing: \"We find that while using GPT seems to yield similar performance to BERT for context length five, using GPT seems to give an advantage for longer sequence lengths,\" and \"This suggests that if one were able to use a GPT architecture and train it with random masking and fine-tuning, it might be possible to get the best of both worlds.\"\n\nWeakness:\n\nRelative short context lengths, and the experiments is mainly on the grid world (4 * 4), if the grid size increases, it might further improve this work.",
                "Questions": "From line 285 to line 2899, \"A clear avenue of future work would therefore be to get the \u201cbest of both worlds\u201d: long sequences and benefits of random-mask pre-training by using a GPT-like architectures, with our random-mask and finetune training regimes. This which would require finding ways to make GPT act like a bidirectional model \u2013 for which recent methods in NLP might offer a useful starting point\". In the rebuttal period, may I know the opinion from the authors, why making GPT act like a bidirectional model is important in the decision making scenario? The answers to this question would make me (maybe other readers) understand this paper better.",
                "Limitations": "Relative short context lengths. Experiments with longer context lengths would make this submission more convincing.\nThe experiments are mainly on the grid world (grid size is 4* 4). If the grid sizes increase more, this work would become more persuasive.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "4 excellent",
                "Rating": "9: Very Strong Accept: Technically flawless paper with groundbreaking impact on at least one area of AI/ML and excellent impact on multiple areas of AI/ML, with flawless evaluation, resources, and reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 8.0,
        "confidence_avg": 4.0,
        "soundness_avg": 3.333,
        "presentation_avg": 3.667,
        "contribution_avg": 3.333,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the paper presents a novel and well-executed approach to using a single bidirectional transformer for various reinforcement learning tasks. The proposed Uni[MASK] framework shows promising results in both discrete and continuous environments, and the experiments support the hypotheses put forward by the authors. The paper is well-written and provides a clear motivation, theory, and experimental design.\n\nWhile there are some minor concerns raised by the reviewers, such as the performance of longer sequences and the distinction between BERT-like and GPT-like models, these do not significantly impact the overall positive evaluation of the paper. The limitations mentioned, such as the relatively short context lengths and the use of a small grid size, can be addressed in future work.\n\nOverall, this paper makes a strong contribution to the literature and has the potential for high impact in the field of AI/ML. Therefore, I recommend accepting it for publication."
    },
    "Leveraging_the_Hints:_Adaptive_Bidding_in_Repeated_First-Price_Auctions": {
        "link": "https://openreview.net//forum?id=hjqTeP05OMB",
        "pub_url": "https://openreview.net/forum?id=hjqTeP05OMB",
        "pdf_link": "https://openreview.net//pdf?id=hjqTeP05OMB",
        "paper_id": "hjqTeP05OMB",
        "title": "Leveraging_the_Hints:_Adaptive_Bidding_in_Repeated_First-Price_Auctions",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nThe paper studies a regret minimization model of bidding in repeated first price auctions, when a noisy \"hint\" about the highest competing bid is available. The question is whether the availability of such a hint can significantly reduce the best achievable regret. The authors give almost matching lower and upper bounds on the regret in several cases (e.g., hint is provided as a point/interval estimate, or if the distribution of the highest competing bid has a small finite support). They also present experimental evaluation of the algorithms.\nThe reviewers agree that this is a practically relevant and theoretically interesting model, and the results are non-trivial and interesting. The proofs are technically involved, although they do not introduce particularly new techniques. While the main contribution of the paper is theoretical, the experimental results nicely complement the theory. Overall, this is a nice paper and can be accepted to NeurIPS.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper studies the problem of online learning to bid in first-price auctions. In this problem, each round a bidder with some value for the item (either fixed over the duration of the bidding, or independently sampled from a known distribution) must submit a bid; simultaneously, a minimum-bid-to-win MBTW is generated (either adversarially or stochastically from the distribution). If the bidder bids above the MBTW, they win the item (and receive value - bid in utility); otherwise, they lose (and receive nothing). \nThis has been a popular question in recent years (largely motivated by the migration of several large advertising auctions from second-price to first-price); this work contributes to the literature by exploring what happens when the bidder is provided some side information regarding the true MBTW. This information takes the form of a \u201chint\u201d; a value who is guaranteed to be somewhat close (on average) to the true MBTW. The authors differentiate between the cases where the learner receives just the hint each round (\u201csingle hint\u201d), or the case where they receive the hint and how noisy it is (\u201chint interval\u201d) each round. The ultimate regret bounds are in terms of the total error L of the hints (in a similar manner as data-dependent regret guarantees). \nThe authors show the following results:\n\nThe authors characterize (up to logarithmic factors) the optimal regret guarantees for the single hint and hint interval setting, in the case where value is fixed. To do this, they present an adaptation of multiplicative weights that incorporates hint information. Interestingly, they show there exists a gap in regret guarantees between these two settings.\nThey also characterize the optimal regret guarantees in the setting of varying private prices. They show in this case it is hard to take advantage of hint information to get asymptotically better regret guarantees.\nTo address this, they investigate whether it is possible to get better regret guarantees if the MBTW is \u201csparse\u201d and can take on at most K different values. Again they provide asymptotically tight regret guarantees in this setting.\nFinally, they perform empirical simulations of these learning algorithms on data taken from real auctions (and demonstrate they are effective at incorporating this side-information).\nStrengths And Weaknesses: Understanding how to bid in first-price auctions is an immensely important problem in practice. Although this paper is not the first paper to study this, I think it makes some fairly interesting and significant contributions both theoretically (it is nice they have fairly tight characterizations of regret guarantees everywhere, and I think the existence of a gap between single hints and hint intervals is an interesting message) and experimentally (they present fairly simple / implementable methods for taking advantage of hint information, something which does exist in real life). \nI am not super familiar with all the related literature, so it is hard for me to evaluate how novel these techniques are over e.g. the techniques in the related first-price bidding paper [HZF+ 20] or more general data-dependent learning papers like [WLA20]. My reading is that the proofs are technically involved but this paper doesn\u2019t contribute any especially novel techniques (but I think this is OK in light of its other contributions). \nOverall the paper was well-written and easy to read. I would recommend acceptance.\nQuestions: In Algorithm 1, is it necessary to know all the accuracies sigma_t ahead of time? If not, how do you set the learning rate eta (it seem s like it depends on all sigma_t).\nLimitations: They have adequately addressed this.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: In the past four years, an important development in the digital advertising industry is the shift from second-price auctions to first-price auctions. They consider a differentiated setup: assume that we have access to a hint that serves as a prediction of other bidders\u2019 maximum bid, where the prediction is learned through some blackbox machine learning model. They consider two types of hints: one where a single point-prediction is available, and the other where a  hint interval (representing a type of confidence region into which others\u2019 maximum bid falls) is available. They establish minimax optimal regret bounds for both cases and highlight the quantitatively different behavior between the two settings, and provide improved regret bounds when the others\u2019 maximum bid exhibits the further structure of sparsity. They also complement the theoretical results with demonstrations using real bidding data.\nStrengths And Weaknesses: This paper studies first price auction with hint. Nowadays, first price auction obtains more research interest. The topic is important and the result is good. The writing is clear.\nQuestions: Line 259, what is CheW?\nLimitations:  I didn\u2019t think it has negative societal impact.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper studies bidding in repeated first-price actions with hints, which could be a point estimate or an interval. The authors first establish optimal regret bounds for both cases when the bidder's value is the same across auctions. The authors further show that when the private values could vary, the hints do not help much. The authors then examine the cases when the others' bids are sparse and demonstrate a better bound. The empirical results support and validate the theoretical findings.\nStrengths And Weaknesses: Strength:\n\nThe problem studied in this paper is timely, interesting and important.\n\nThe paper is generally well-written, clear, and easy to follow.\n\nThe results are novel and technically strong; and the empirical results nicely support and validate the effectiveness of the proposed methods.\n\n\nWeakness\n\nThe sparsity assumption requires more motivations and support from practice.\nQuestions: \nIt seems that for the sparsity assumption, even if it holds in practice now, it is vulnerable to future changes or adversarial attacks. In particular, the authors mention that \"Part of the reason for the sparsity is due to the scenario where the maximum competing bid is the reserve price set by the seller.\" If the seller adopts the strategy to set randomized reserve, will the assumption break? Similarly, the competing bidders could adopt randomized bidding strategy as well.\nLimitations: The authors adequately addressed the limitations and potential negative societal impact is not applicable.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper focus on the problem of deriving a best-response bidding strategy in a first-price auction in a bandit setting where a so-called \"hint\" ht on the highest bid from the competition (the other bidders) is provided. The paper refines existing upper and lower bound on the regret by parametrizing them with the total error made by the hints, inspired by recent path-length parametrizations of regret in bandit. \nThe main difference is that, usually, in the literature, a hint tildert(b) is provided as an indication of the reward function r(b,mt) itself. Here the hint ht informs about the parameter mt of the reward function.\nThe paper provides an algorithm with matching upper and lower bounds in 3 settings about 2 types of hints.\nTypes of hints: just a prediction of mt or an interval that contains mt with high proba.\nTypes settings: \n\nConstant value vt:=1 and mt\u2208[0,1] \nVarying values vt\u2208[0,1] and mt\u2208[0,1] \nVarying values vt\u2208[0,1] and mt belonging to a finite subset of [0,1]\nStrengths And Weaknesses: (+) To my knowledge, the paper does not consists in a simple application of previous technique to the problem of bidding in first-price auction. Indeed, usually, the hint concerns the reward function it self and not a parameter of the reward function. Here, the parametrization of the regret is based on the cumulative prediction error of the parameter and not on the cumulative error of the induced reward function.\n(+) I find the result of Th. 3 and 4 unexpected, especially the lower-bound part, even though they feel a bit frustrating. \n(-) I would have expected this somehow negative result (of Th. 3 and 4) to be more commented and some intuition as for the why detailed. Especially, this degradation of the regret is introduced as a result of considering varying (rather than constant) values vt, but is solved by considering mt to have finite support. I completely fail to follow the logic and the intuition.\nMinor detail:\n\nline 48 it is not optimal for an exchange bidding in a header bidder to bid the second highest internal value see [1] for instance\nI think the paper could shorten a lot the introduction. The study of first-price auctions is widespread enough not to need such a long motivation in introduction.\n\n[1] Bidder collusion. Marshall (2007)\nQuestions: \nWith the same definition for the hint ht, would it be possible / relevant to provide regret bounds parametrized in terms of cumulative reward prediction error \ud835\udfd9\ud835\udfd9L~=\u2211t=1T\u222b|(vt\u2212b)(1[b\u2265mt]\u22121[b\u2265ht])|db rather than cumulative competition prediction error L=\u2211t=1T\u03c3t ? \n\nFollowing the previous question, may it provide finer parametrized bound for the case when vt varies (Th. 3 and 4)? Even though in my understanding of the proof, it won't improve the lower-bound I think.\n\nWould the results of the paper extend to best-response to any (nice enough) auction? Like for instance for C-Lipschitz auctions which have a regret without hint of order CT2/3 (see [2, Prop. 4.2]).\n\n\n[2] Learning in repeated auctions, Nedelec et al. (2022)\nLimitations: I would have liked to have a bit more motivation on the practical use of hints in auctions. Where does it come from ? Who is providing it ? What data is it based on ?\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper studies the problem of online learning to bid in first-price auctions. In this problem, each round a bidder with some value for the item (either fixed over the duration of the bidding, or independently sampled from a known distribution) must submit a bid; simultaneously, a minimum-bid-to-win MBTW is generated (either adversarially or stochastically from the distribution). If the bidder bids above the MBTW, they win the item (and receive value - bid in utility); otherwise, they lose (and receive nothing). \nThis has been a popular question in recent years (largely motivated by the migration of several large advertising auctions from second-price to first-price); this work contributes to the literature by exploring what happens when the bidder is provided some side information regarding the true MBTW. This information takes the form of a \u201chint\u201d; a value who is guaranteed to be somewhat close (on average) to the true MBTW. The authors differentiate between the cases where the learner receives just the hint each round (\u201csingle hint\u201d), or the case where they receive the hint and how noisy it is (\u201chint interval\u201d) each round. The ultimate regret bounds are in terms of the total error L of the hints (in a similar manner as data-dependent regret guarantees). \nThe authors show the following results:\n\nThe authors characterize (up to logarithmic factors) the optimal regret guarantees for the single hint and hint interval setting, in the case where value is fixed. To do this, they present an adaptation of multiplicative weights that incorporates hint information. Interestingly, they show there exists a gap in regret guarantees between these two settings.\nThey also characterize the optimal regret guarantees in the setting of varying private prices. They show in this case it is hard to take advantage of hint information to get asymptotically better regret guarantees.\nTo address this, they investigate whether it is possible to get better regret guarantees if the MBTW is \u201csparse\u201d and can take on at most K different values. Again they provide asymptotically tight regret guarantees in this setting.\nFinally, they perform empirical simulations of these learning algorithms on data taken from real auctions (and demonstrate they are effective at incorporating this side-information).",
                "Strengths And Weaknesses": "Understanding how to bid in first-price auctions is an immensely important problem in practice. Although this paper is not the first paper to study this, I think it makes some fairly interesting and significant contributions both theoretically (it is nice they have fairly tight characterizations of regret guarantees everywhere, and I think the existence of a gap between single hints and hint intervals is an interesting message) and experimentally (they present fairly simple / implementable methods for taking advantage of hint information, something which does exist in real life). \nI am not super familiar with all the related literature, so it is hard for me to evaluate how novel these techniques are over e.g. the techniques in the related first-price bidding paper [HZF+ 20] or more general data-dependent learning papers like [WLA20]. My reading is that the proofs are technically involved but this paper doesn\u2019t contribute any especially novel techniques (but I think this is OK in light of its other contributions). \nOverall the paper was well-written and easy to read. I would recommend acceptance.",
                "Questions": "In Algorithm 1, is it necessary to know all the accuracies sigma_t ahead of time? If not, how do you set the learning rate eta (it seem s like it depends on all sigma_t).",
                "Limitations": "They have adequately addressed this.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "In the past four years, an important development in the digital advertising industry is the shift from second-price auctions to first-price auctions. They consider a differentiated setup: assume that we have access to a hint that serves as a prediction of other bidders\u2019 maximum bid, where the prediction is learned through some blackbox machine learning model. They consider two types of hints: one where a single point-prediction is available, and the other where a  hint interval (representing a type of confidence region into which others\u2019 maximum bid falls) is available. They establish minimax optimal regret bounds for both cases and highlight the quantitatively different behavior between the two settings, and provide improved regret bounds when the others\u2019 maximum bid exhibits the further structure of sparsity. They also complement the theoretical results with demonstrations using real bidding data.",
                "Strengths And Weaknesses": "This paper studies first price auction with hint. Nowadays, first price auction obtains more research interest. The topic is important and the result is good. The writing is clear.",
                "Questions": "Line 259, what is CheW?",
                "Limitations": "I didn\u2019t think it has negative societal impact.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper studies bidding in repeated first-price actions with hints, which could be a point estimate or an interval. The authors first establish optimal regret bounds for both cases when the bidder's value is the same across auctions. The authors further show that when the private values could vary, the hints do not help much. The authors then examine the cases when the others' bids are sparse and demonstrate a better bound. The empirical results support and validate the theoretical findings.",
                "Strengths And Weaknesses": "Strength:\n\nThe problem studied in this paper is timely, interesting and important.\n\nThe paper is generally well-written, clear, and easy to follow.\n\nThe results are novel and technically strong; and the empirical results nicely support and validate the effectiveness of the proposed methods.\n\n\nWeakness\n\nThe sparsity assumption requires more motivations and support from practice.",
                "Questions": "It seems that for the sparsity assumption, even if it holds in practice now, it is vulnerable to future changes or adversarial attacks. In particular, the authors mention that \"Part of the reason for the sparsity is due to the scenario where the maximum competing bid is the reserve price set by the seller.\" If the seller adopts the strategy to set randomized reserve, will the assumption break? Similarly, the competing bidders could adopt randomized bidding strategy as well.",
                "Limitations": "The authors adequately addressed the limitations and potential negative societal impact is not applicable.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper focus on the problem of deriving a best-response bidding strategy in a first-price auction in a bandit setting where a so-called \"hint\" ht on the highest bid from the competition (the other bidders) is provided. The paper refines existing upper and lower bound on the regret by parametrizing them with the total error made by the hints, inspired by recent path-length parametrizations of regret in bandit. \nThe main difference is that, usually, in the literature, a hint tildert(b) is provided as an indication of the reward function r(b,mt) itself. Here the hint ht informs about the parameter mt of the reward function.\nThe paper provides an algorithm with matching upper and lower bounds in 3 settings about 2 types of hints.\nTypes of hints: just a prediction of mt or an interval that contains mt with high proba.\nTypes settings: \n\nConstant value vt:=1 and mt\u2208[0,1] \nVarying values vt\u2208[0,1] and mt\u2208[0,1] \nVarying values vt\u2208[0,1] and mt belonging to a finite subset of [0,1]",
                "Strengths And Weaknesses": "(+) To my knowledge, the paper does not consists in a simple application of previous technique to the problem of bidding in first-price auction. Indeed, usually, the hint concerns the reward function it self and not a parameter of the reward function. Here, the parametrization of the regret is based on the cumulative prediction error of the parameter and not on the cumulative error of the induced reward function.\n(+) I find the result of Th. 3 and 4 unexpected, especially the lower-bound part, even though they feel a bit frustrating. \n(-) I would have expected this somehow negative result (of Th. 3 and 4) to be more commented and some intuition as for the why detailed. Especially, this degradation of the regret is introduced as a result of considering varying (rather than constant) values vt, but is solved by considering mt to have finite support. I completely fail to follow the logic and the intuition.\nMinor detail:\n\nline 48 it is not optimal for an exchange bidding in a header bidder to bid the second highest internal value see [1] for instance\nI think the paper could shorten a lot the introduction. The study of first-price auctions is widespread enough not to need such a long motivation in introduction.\n\n[1] Bidder collusion. Marshall (2007)",
                "Questions": "With the same definition for the hint ht, would it be possible / relevant to provide regret bounds parametrized in terms of cumulative reward prediction error \ud835\udfd9\ud835\udfd9L~=\u2211t=1T\u222b|(vt\u2212b)(1[b\u2265mt]\u22121[b\u2265ht])|db rather than cumulative competition prediction error L=\u2211t=1T\u03c3t ? \n\nFollowing the previous question, may it provide finer parametrized bound for the case when vt varies (Th. 3 and 4)? Even though in my understanding of the proof, it won't improve the lower-bound I think.\n\nWould the results of the paper extend to best-response to any (nice enough) auction? Like for instance for C-Lipschitz auctions which have a regret without hint of order CT2/3 (see [2, Prop. 4.2]).\n\n\n[2] Learning in repeated auctions, Nedelec et al. (2022)",
                "Limitations": "I would have liked to have a bit more motivation on the practical use of hints in auctions. Where does it come from ? Who is providing it ? What data is it based on ?",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.75,
        "confidence_avg": 3.25,
        "soundness_avg": 3.5,
        "presentation_avg": 3.0,
        "contribution_avg": 3.0,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is evident that this paper makes significant contributions to the field of online learning to bid in first-price auctions. The authors explore the use of hints in improving bidding strategies and provide optimal regret guarantees for different scenarios. The theoretical results are supported by empirical simulations using real auction data.\n\nThe strengths of this paper lie in its timeliness, importance, and technical soundness. The problem studied is relevant in the digital advertising industry, and the results are novel and well-supported. The paper is well-written and easy to follow, making it accessible to a wide audience.\n\nWhile some reviewers have raised questions and limitations regarding the sparsity assumption and the practical use of hints in auctions, these concerns have been adequately addressed by the authors. There are no major concerns with respect to evaluation, resources, reproducibility, or ethical considerations.\n\nOverall, this paper is technically solid and has a moderate-to-high impact on the field. It contributes valuable insights and provides practical methods for incorporating hint information in bidding strategies. Therefore, I recommend accepting this paper for publication."
    },
    "ReCo:_Retrieve_and_Co-segment_for_Zero-shot_Transfer": {
        "link": "https://openreview.net//forum?id=8ViFz-5Mnnv",
        "pub_url": "https://openreview.net/forum?id=8ViFz-5Mnnv",
        "pdf_link": "https://openreview.net//pdf?id=8ViFz-5Mnnv",
        "paper_id": "8ViFz-5Mnnv",
        "title": "ReCo:_Retrieve_and_Co-segment_for_Zero-shot_Transfer",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nAfter author response and the discussion the paper received 1x borderline reject, 1x borderline accept, 3x weak accept [note that one reviewer mentioned the score increase only in the discussion].\nThe main strength are:\n\nOverall novel framework for zero-shot segmentation\nStrong performance\nThe authors revised the paper and addressed many/most of the reviewer's concerns/suggestions in the author response.\n\nI recommend acceptance, with the expectation\n\nthe authors provide the additional revisions as promised\nIf possible address the comment of reviewer 1QtT \"what if remove Eq. (3)? It seems P^c_{new} is already good enough from Figure 2.\"",
        "reviews": [
            "Reviewer 1: \nSummary: This paper leverages CLIP for Zero-shot segmentation, which is a very hot topic currently. The authors proposed a CLIP-retrieval-based way to build gallery candidates for the semantics segmentation class, and then use dense-clip to generate reference image embedding. Then they proposed  several way to boost the performances, including language-guided co-segment and context elimination to remove the bias of background. Experiments show the proposed method achieves state-of-the-art performance.\nStrengths And Weaknesses: Strength:\n\nOutperforming State-of-the-art performance.\n\nWeaknesses:\n\n\nThe paper is not well written. The authors make it hard to understand even for some very clear concepts.\n\n\n\nNovelty is somehow limited. Technical contribution is not enough. It is just like to find a prototype for a class and then use it for normal clip inference. Although there are some modifications, such as context elimination, however, these are more like tricks which does not have technical depth.\n\n\n\nWhy the used numbers in Table 2 are different for DenseCLIP [92] (Table 1 and Table 3 in original DenseCLIP [92])?\nQuestions: See weakness\nLimitations: Yes\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper proposes a retrieve and co-segment approach that leverages a pretrained image-text model (e.g. CLIP) for unsupervised semantic segmentation. The results on existing benchmarks are good compared to other unsupervised segmentation approaches.\nStrengths And Weaknesses: Strength\n\nRetrieve and co-segment is an intuitive and reasonable approach for unsupervised segmentation.\nUsing image-text models e.g. CLIP for retrieval makes sense and is effective.\nAdaptation to target distribution by training on pseudo labels is reasonable and effective.\nPerformance of ReCo+ seems better than existing unsupervised segmentation approaches at system level.\n\nWeakness\n\nCompared with the unsupervised segmentation approaches, I think ReCo has a clear advantage by using CLIP which makes the approaches not directly comparable. CLIP has seen lots of image-text pairs and acquired reasonable pixel localization ability, while existing approaches such as PiCIE have no access to this kind of knowledge. In addition, if I understand correctly, ReCo has access to the category names of the target dataset while existing approaches do not.\nReCo uses ViT-L/14 for retrieval, which is larger and stronger than the models used by existing works (e.g. ResNet18 of PiCIE). How does the performance of ReCo compare to existing unsupervised segmentation methods if we use smaller CLIP models (e.g. R50 or ViT-B/32) for retrieval and inference?\nHow does the performance change if you pick more than one seed pixel per image?\nThe steps to identify seed pixels (L158-168) seem highly heuristics-based. Alternatively, would clustering approaches work there?\nQuestions: See weakness.\nLimitations: Yes.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 2 fair\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper addresses the task of zero-shot segmentation in images by leveraging powerful large-scale pretrained vision-and-language models such as CLIP. Interestingly, the proposed approach does not require costly and time-consuming pixel-wise annotations for training. Instead, it uses CLIP to select groups of relevant images that correspond to the natural language queries, based on nearest neighbors. Next, it uses pretrained visual encoders to identify seed pixels in the images that have strong support across the entire group of relevant images. These seed pixels are used to compute a reference feature for each language query to produce a segmentation attention map for each new query image, which is further refined by another segmentation mask that is computed by CLIP.\nStrengths And Weaknesses: Strengths: \n\nThe paper is largely well-written and easy to follow. In particular, the mathematical definitions that are provided are very helpful for understanding the proposed approach.\n\nThe proposed approach is theoretically sound and intuitive. While it is not entirely original due to the existence of approaches including DenseCLIP, the idea of discovering common spatial regions that occur in images containing the same concept is very interesting. More importantly, it leverages the large-scale pretrained CLIP model to retrieve related images for a language query. This allows the proposed approach to be trained on any unlabeled image sets.\n\nThe task of image segmentation often requires fine-grained pixel-wise annotations which is an especially costly process. Being able to leverage powerful and large-scale pretrained models to circumvent this process is especially significant. Coupled with the empirical evidence that it outperforms state-of-the-art approaches, this can be an important area of research, given the availability of increasingly larger multimodal datasets such as LAION-5B.\n\n\nWeaknesses:\nIt would be helpful to see some qualitative visualizations of co-segmentation with seed pixels. Given that these seed pixels are used to compute a reference embedding for new query images and concepts during inference time, it seems to be a very important component of the proposed approach. It may help a reader to determine if the regions selected by the seed pixels are consistent across most images that contain a concept.\nQuestions: \nDuring inference time, are you always computing the reference feature for a given image and query concept on the fly, or do you store a dictionary of precomputed reference features for a selected list of concepts?\nLimitations: Yes, the authors have addressed the limitations.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper proposed a method for zero-shot transfer in semantic segmentation. To solve this problem, it first performs a image-text retrieval by CLIP to get image archive. Then it use a pre-trained encoder to perform co-segmentation. During inference, it combines the results from reference image embedding and Dense CLIP to get the final segmentation results.\nStrengths And Weaknesses: Strengths:\n\nThe proposed pipeline which combines retrieval and co-segmentation is novel.\nIt outperforms the compared methods significantly.\n\nWeakness:\n\nThe method is complicated and requires two encoders during inference, which slow down the speed. I want to know the comparisons in FPS when compared to other methods.\nMissing important citations: there are some concurrent works for open vocabulary semantic segmentation[1, 2], which are not cited. It would be better if related discussions are included.\n\n[1] A simple baseline for zero-shot semantic segmentation with pre-trained vision-language model. Arxiv.\n[2] Decoupling Zero-Shot Semantic Segmentation. CVPR 2022.\nQuestions: see weakness\nLimitations: Yes.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 5: \nSummary: This paper utilizes the CLIP model for zero-shot transfer. At first, they leverage the CLIP to dynamically curate training sets from unlabelled images for arbitrary collections of concept names and leverage the robust correspondences offered by modern image representations to co-segment entities among the resulting collections. The synthetic segment collections are then employed to construct a segmentation model whose knowledge of concepts is inherited from the scalable pre-training process of CLIP. In this way, the proposed method could perform unsupervised segmentation approaches while inheriting the convenience of nameable predictions and zero-shot transfer.\nStrengths And Weaknesses: strengths:\n1, The paper is well written and easy to understand.\n2, Leveraging the CLIP for unsupervised segmentation is interesting. \n3, The proposed training pipeline is reasonable.\n3, The experiments are sufficient to show the effectiveness of the proposed method.\nweaknesses:\n1, The whole training pipeline seems a little complex. For example, the proposed method should utilize CLIP to filter some candidate images from numerous unlabeled data. And the identification of seed pixels includes four steps \n2, Also, the adjacency matrix A is the computation cost and is sensitive to k in the first step of the identification of seed pixels.\nQuestions: I only have one question about the fourth step in identifying seed pixels. Could the author clarify them?\nLimitations: I am very curious about the potential of employing the proposed method in instance segmentation. And the whole training pipeline is a little complicated.\nEthics Flag: No\nEthics Review Area: Responsible Research Practice (e.g., IRB, documentation, research ethics)\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper leverages CLIP for Zero-shot segmentation, which is a very hot topic currently. The authors proposed a CLIP-retrieval-based way to build gallery candidates for the semantics segmentation class, and then use dense-clip to generate reference image embedding. Then they proposed  several way to boost the performances, including language-guided co-segment and context elimination to remove the bias of background. Experiments show the proposed method achieves state-of-the-art performance.",
                "Strengths And Weaknesses": "Strength:\n\nOutperforming State-of-the-art performance.\n\nWeaknesses:\n\n\nThe paper is not well written. The authors make it hard to understand even for some very clear concepts.\n\n\n\nNovelty is somehow limited. Technical contribution is not enough. It is just like to find a prototype for a class and then use it for normal clip inference. Although there are some modifications, such as context elimination, however, these are more like tricks which does not have technical depth.\n\n\n\nWhy the used numbers in Table 2 are different for DenseCLIP [92] (Table 1 and Table 3 in original DenseCLIP [92])?",
                "Questions": "See weakness",
                "Limitations": "Yes",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposes a retrieve and co-segment approach that leverages a pretrained image-text model (e.g. CLIP) for unsupervised semantic segmentation. The results on existing benchmarks are good compared to other unsupervised segmentation approaches.",
                "Strengths And Weaknesses": "Strength\n\nRetrieve and co-segment is an intuitive and reasonable approach for unsupervised segmentation.\nUsing image-text models e.g. CLIP for retrieval makes sense and is effective.\nAdaptation to target distribution by training on pseudo labels is reasonable and effective.\nPerformance of ReCo+ seems better than existing unsupervised segmentation approaches at system level.\n\nWeakness\n\nCompared with the unsupervised segmentation approaches, I think ReCo has a clear advantage by using CLIP which makes the approaches not directly comparable. CLIP has seen lots of image-text pairs and acquired reasonable pixel localization ability, while existing approaches such as PiCIE have no access to this kind of knowledge. In addition, if I understand correctly, ReCo has access to the category names of the target dataset while existing approaches do not.\nReCo uses ViT-L/14 for retrieval, which is larger and stronger than the models used by existing works (e.g. ResNet18 of PiCIE). How does the performance of ReCo compare to existing unsupervised segmentation methods if we use smaller CLIP models (e.g. R50 or ViT-B/32) for retrieval and inference?\nHow does the performance change if you pick more than one seed pixel per image?\nThe steps to identify seed pixels (L158-168) seem highly heuristics-based. Alternatively, would clustering approaches work there?",
                "Questions": "See weakness.",
                "Limitations": "Yes.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper addresses the task of zero-shot segmentation in images by leveraging powerful large-scale pretrained vision-and-language models such as CLIP. Interestingly, the proposed approach does not require costly and time-consuming pixel-wise annotations for training. Instead, it uses CLIP to select groups of relevant images that correspond to the natural language queries, based on nearest neighbors. Next, it uses pretrained visual encoders to identify seed pixels in the images that have strong support across the entire group of relevant images. These seed pixels are used to compute a reference feature for each language query to produce a segmentation attention map for each new query image, which is further refined by another segmentation mask that is computed by CLIP.",
                "Strengths And Weaknesses": "Strengths: \n\nThe paper is largely well-written and easy to follow. In particular, the mathematical definitions that are provided are very helpful for understanding the proposed approach.\n\nThe proposed approach is theoretically sound and intuitive. While it is not entirely original due to the existence of approaches including DenseCLIP, the idea of discovering common spatial regions that occur in images containing the same concept is very interesting. More importantly, it leverages the large-scale pretrained CLIP model to retrieve related images for a language query. This allows the proposed approach to be trained on any unlabeled image sets.\n\nThe task of image segmentation often requires fine-grained pixel-wise annotations which is an especially costly process. Being able to leverage powerful and large-scale pretrained models to circumvent this process is especially significant. Coupled with the empirical evidence that it outperforms state-of-the-art approaches, this can be an important area of research, given the availability of increasingly larger multimodal datasets such as LAION-5B.\n\n\nWeaknesses:\nIt would be helpful to see some qualitative visualizations of co-segmentation with seed pixels. Given that these seed pixels are used to compute a reference embedding for new query images and concepts during inference time, it seems to be a very important component of the proposed approach. It may help a reader to determine if the regions selected by the seed pixels are consistent across most images that contain a concept.",
                "Questions": "During inference time, are you always computing the reference feature for a given image and query concept on the fly, or do you store a dictionary of precomputed reference features for a selected list of concepts?",
                "Limitations": "Yes, the authors have addressed the limitations.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposed a method for zero-shot transfer in semantic segmentation. To solve this problem, it first performs a image-text retrieval by CLIP to get image archive. Then it use a pre-trained encoder to perform co-segmentation. During inference, it combines the results from reference image embedding and Dense CLIP to get the final segmentation results.",
                "Strengths And Weaknesses": "Strengths:\n\nThe proposed pipeline which combines retrieval and co-segmentation is novel.\nIt outperforms the compared methods significantly.\n\nWeakness:\n\nThe method is complicated and requires two encoders during inference, which slow down the speed. I want to know the comparisons in FPS when compared to other methods.\nMissing important citations: there are some concurrent works for open vocabulary semantic segmentation[1, 2], which are not cited. It would be better if related discussions are included.\n\n[1] A simple baseline for zero-shot semantic segmentation with pre-trained vision-language model. Arxiv.\n[2] Decoupling Zero-Shot Semantic Segmentation. CVPR 2022.",
                "Questions": "see weakness",
                "Limitations": "Yes.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper utilizes the CLIP model for zero-shot transfer. At first, they leverage the CLIP to dynamically curate training sets from unlabelled images for arbitrary collections of concept names and leverage the robust correspondences offered by modern image representations to co-segment entities among the resulting collections. The synthetic segment collections are then employed to construct a segmentation model whose knowledge of concepts is inherited from the scalable pre-training process of CLIP. In this way, the proposed method could perform unsupervised segmentation approaches while inheriting the convenience of nameable predictions and zero-shot transfer.",
                "Strengths And Weaknesses": "strengths:\n1, The paper is well written and easy to understand.\n2, Leveraging the CLIP for unsupervised segmentation is interesting. \n3, The proposed training pipeline is reasonable.\n3, The experiments are sufficient to show the effectiveness of the proposed method.\nweaknesses:\n1, The whole training pipeline seems a little complex. For example, the proposed method should utilize CLIP to filter some candidate images from numerous unlabeled data. And the identification of seed pixels includes four steps \n2, Also, the adjacency matrix A is the computation cost and is sensitive to k in the first step of the identification of seed pixels.",
                "Questions": "I only have one question about the fourth step in identifying seed pixels. Could the author clarify them?",
                "Limitations": "I am very curious about the potential of employing the proposed method in instance segmentation. And the whole training pipeline is a little complicated.",
                "Ethics Flag": "No",
                "Ethics Review Area": "Responsible Research Practice (e.g., IRB, documentation, research ethics)",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.0,
        "confidence_avg": 3.8,
        "soundness_avg": 3.0,
        "presentation_avg": 2.6,
        "contribution_avg": 2.6,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the proposed method for zero-shot segmentation using CLIP has several strengths. The paper presents a novel approach that combines retrieval and co-segmentation, leveraging the power of CLIP for unsupervised semantic segmentation. The proposed method outperforms existing approaches and is theoretically sound and intuitive. It also addresses the limitations and provides a reasonable training pipeline.\n\nWhile there are some weaknesses mentioned by the reviewers, such as the complexity of the method and the need for two encoders during inference, these do not outweigh the strengths and contributions of the paper. The reviewers also have some questions and limitations, but these can be addressed in future work.\n\nOverall, the paper is technically solid and has moderate-to-high impact. The evaluations are sufficient, and there are no major concerns with respect to evaluation, resources, reproducibility, or ethical considerations. Therefore, I recommend accepting the paper."
    },
    "Boosting_the_Performance_of_Generic_Deep_Neural_Network_Frameworks_with_Log-supermodular_CRFs": {
        "link": "https://openreview.net//forum?id=M_et7iOQC_s",
        "pub_url": "https://openreview.net/forum?id=M_et7iOQC_s",
        "pdf_link": "https://openreview.net//pdf?id=M_et7iOQC_s",
        "paper_id": "M_et7iOQC_s",
        "title": "Boosting_the_Performance_of_Generic_Deep_Neural_Network_Frameworks_with_Log-supermodular_CRFs",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Less certain\nThe paper proposes to use   Log-supermodular CRFs  to smooth the DNN models. The paper is well motivated and conduct extensive experiments to  verify the effective of the attractive smoothing algorithm.It could be better if the paper conduct more experiments based on different networks such as RNN and Transformer.  Besides, this paper only explores the proposed attractive smoothing. It should make a comparision with other smoothing methods.",
        "reviews": [
            "Reviewer 1: \nSummary: Paper proposes an attractive smoothing algorithm via log-supermodular CRFs, which takes the CRF as a regularizer for the DNNs. . Extensive experiments on a range of applications demonstrate that even conventional models outperform more recent ones with the addition of an attractive CRF.\nThe paper is written clearly, both the quantitative and qualitative analysis experiments are well done, which can fully verify the effective of the attractive smoothing algorithm. However, I'm not an expert in this field, so I'm not able to appraise it from the aspects of innovation, algorithm design, and whether it has a positive role in promoting the research field.\nStrengths And Weaknesses: N/A\nQuestions: N/A\nLimitations: N/A\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper proposes the use of super-modular CRF to regularize a DNN model for applications where smoothing is important. The intuition is that while DNNs are easier to scale, they do not take into account the natural constraints in the task e.g. two neighboring image pixels need to have similar colors. In this DNN-CRF hybrid model, there are two DNNs for generating the feature vectors and the CRF parameters respectively, and a CRF-based inference layer. Results are reports on three tasks: stereo matching, image colorization and semantic segmentation. On stereo matching, adding the CRF regularizer improves the performance of three DNN baselines. On semantic segmentation, CRF gives a small boost to the DNN. On image colorization, adding the CRF improves the peak signal to noise ratio.\nStrengths And Weaknesses: Strengths:\n\nNovel use of supermodular CRFs to improve DNN performance across tasks where smoothing is important\nPerformance improvements on three tasks\n\nWeaknesses:\n\nIt would be useful to compare performance against alternative neural approaches e.g. RNN or transformer, that can take into account correlations across time steps.\nThe paper does not report the impact on training time due to the CRF regularizer. \nThe paper states that \"Our approach applies in both discrete and continuous settings\" but the approach is evaluated only for scenarios with continuous inputs.\nIt would be useful to provide more details on the hybrid model training e.g. are there practical tips to ensure convergence? Does the DNN/CRF training need to be done in some alternating fashion etc? \nThe appendix is not included in the paper.\nQuestions: \nIt would be useful to provide more details on the DNN-CRF hybrid training including the algorithm, the variational method, update steps, any practical tricks to ensure convergence, etc. \nWhat is the impact on training time due to the CRF regularizer?\nWould it be possible to report a metric that indicates whether the proposed method has improved the smoothness objective on each of the tasks?\nLimitations: There is no explicit discussion of limitations in the paper. Hence, it would be useful to add a paragraph on limitations to the conclusions section. The authors should also add a sentence about the potential negative societal impact in the conclusions.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 1: Your assessment is an educated guess. The submission is not in your area or the submission was difficult to understand. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The authors present log-supermodular CRF as a smoothing layer for a wide class of applications, including optical flow estimation, activity recognition, colorization, and segmentation. They show in experiments that the proposed module can improve the performance of the model over all the mentioned tasks.\nStrengths And Weaknesses: Strengths:\n\neasy to read through and solid experiments.\n\nWeakness:\n\nthe authors only compare the deep models with and without attractive smoothing. I would encourage them to consider some other adaptive, ad-hoc smoothing methods as baselines.\nIt's hard to tell the improvement through the figures for tasks like colorization and segmentation. Also, it is questionable whether segmentation needs smoothing.\nQuestions: \nAre the potential functions you presented in Equations 1-4 log-supermodular? Why are they would be helpful for smoothing?\nCould you briefly explain what \"attractive\" means in this context?\nIn Figure 1, what is \u03bc,\u03c3,\u03bb and  \u0394\u03bc,\u0394\u03c3,\u0394\u03bb? you may need to give an explicit form of BFE in your methodology.\nWhy not compare with some deep network with ad-hoc smoothing techniques?\nIn Figure 2, I can only tell the first and second rows have distance differences, while the rest rows do not show much difference.\nIn Figure 3, I cannot tell which colorization is better. Are there any other examples that can show the impact of the proposed method?\nIn Figure 4, smooth for segmentation may remove all the detailed small blocks. It may be helpful but not necessary.\nLimitations: The author may mention if their attractive smoothing idea can be (not-)helpful for other CRF applications in text, like part-of-speech tagging and dependency parsing.\nEthics Flag: No\nEthics Review Area: I don\u2019t know\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "Paper proposes an attractive smoothing algorithm via log-supermodular CRFs, which takes the CRF as a regularizer for the DNNs. . Extensive experiments on a range of applications demonstrate that even conventional models outperform more recent ones with the addition of an attractive CRF.\nThe paper is written clearly, both the quantitative and qualitative analysis experiments are well done, which can fully verify the effective of the attractive smoothing algorithm. However, I'm not an expert in this field, so I'm not able to appraise it from the aspects of innovation, algorithm design, and whether it has a positive role in promoting the research field.",
                "Strengths And Weaknesses": "N/A",
                "Questions": "N/A",
                "Limitations": "N/A",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper proposes the use of super-modular CRF to regularize a DNN model for applications where smoothing is important. The intuition is that while DNNs are easier to scale, they do not take into account the natural constraints in the task e.g. two neighboring image pixels need to have similar colors. In this DNN-CRF hybrid model, there are two DNNs for generating the feature vectors and the CRF parameters respectively, and a CRF-based inference layer. Results are reports on three tasks: stereo matching, image colorization and semantic segmentation. On stereo matching, adding the CRF regularizer improves the performance of three DNN baselines. On semantic segmentation, CRF gives a small boost to the DNN. On image colorization, adding the CRF improves the peak signal to noise ratio.",
                "Strengths And Weaknesses": "Strengths:\n\nNovel use of supermodular CRFs to improve DNN performance across tasks where smoothing is important\nPerformance improvements on three tasks\n\nWeaknesses:\n\nIt would be useful to compare performance against alternative neural approaches e.g. RNN or transformer, that can take into account correlations across time steps.\nThe paper does not report the impact on training time due to the CRF regularizer. \nThe paper states that \"Our approach applies in both discrete and continuous settings\" but the approach is evaluated only for scenarios with continuous inputs.\nIt would be useful to provide more details on the hybrid model training e.g. are there practical tips to ensure convergence? Does the DNN/CRF training need to be done in some alternating fashion etc? \nThe appendix is not included in the paper.",
                "Questions": "It would be useful to provide more details on the DNN-CRF hybrid training including the algorithm, the variational method, update steps, any practical tricks to ensure convergence, etc. \nWhat is the impact on training time due to the CRF regularizer?\nWould it be possible to report a metric that indicates whether the proposed method has improved the smoothness objective on each of the tasks?",
                "Limitations": "There is no explicit discussion of limitations in the paper. Hence, it would be useful to add a paragraph on limitations to the conclusions section. The authors should also add a sentence about the potential negative societal impact in the conclusions.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "1: Your assessment is an educated guess. The submission is not in your area or the submission was difficult to understand. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors present log-supermodular CRF as a smoothing layer for a wide class of applications, including optical flow estimation, activity recognition, colorization, and segmentation. They show in experiments that the proposed module can improve the performance of the model over all the mentioned tasks.",
                "Strengths And Weaknesses": "Strengths:\n\neasy to read through and solid experiments.\n\nWeakness:\n\nthe authors only compare the deep models with and without attractive smoothing. I would encourage them to consider some other adaptive, ad-hoc smoothing methods as baselines.\nIt's hard to tell the improvement through the figures for tasks like colorization and segmentation. Also, it is questionable whether segmentation needs smoothing.",
                "Questions": "Are the potential functions you presented in Equations 1-4 log-supermodular? Why are they would be helpful for smoothing?\nCould you briefly explain what \"attractive\" means in this context?\nIn Figure 1, what is \u03bc,\u03c3,\u03bb and  \u0394\u03bc,\u0394\u03c3,\u0394\u03bb? you may need to give an explicit form of BFE in your methodology.\nWhy not compare with some deep network with ad-hoc smoothing techniques?\nIn Figure 2, I can only tell the first and second rows have distance differences, while the rest rows do not show much difference.\nIn Figure 3, I cannot tell which colorization is better. Are there any other examples that can show the impact of the proposed method?\nIn Figure 4, smooth for segmentation may remove all the detailed small blocks. It may be helpful but not necessary.",
                "Limitations": "The author may mention if their attractive smoothing idea can be (not-)helpful for other CRF applications in text, like part-of-speech tagging and dependency parsing.",
                "Ethics Flag": "No",
                "Ethics Review Area": "I don\u2019t know",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.667,
        "confidence_avg": 1.667,
        "soundness_avg": 3.0,
        "presentation_avg": 2.667,
        "contribution_avg": 2.667,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is evident that the paper proposes an attractive smoothing algorithm using log-supermodular CRFs, which shows promising results in various applications. The experiments conducted in the paper demonstrate the effectiveness of the proposed algorithm. While there are some suggestions for improvement, such as comparing with alternative neural approaches and providing more details on the training process, these do not outweigh the positive aspects of the paper. Overall, the paper is technically solid and has the potential for moderate-to-high impact in the field. Therefore, I recommend accepting the paper."
    },
    "End-to-end_Stochastic_Optimization_with_Energy-based_Model": {
        "link": "https://openreview.net//forum?id=_sYOodxTMcF",
        "pub_url": "https://openreview.net/forum?id=_sYOodxTMcF",
        "pdf_link": "https://openreview.net//pdf?id=_sYOodxTMcF",
        "paper_id": "_sYOodxTMcF",
        "title": "End-to-end_Stochastic_Optimization_with_Energy-based_Model",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nIn agreement with all the reviewers, I recommend acceptance. In the final version, the authors should take into account the reviewers\u2019 recommendations and update the paper accordingly. Also, regarding the suggestion of Reviewer kQia, I recommend that the author include a high-dimensional synthetic experiment to analyze how their method behaves in that scenario.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper proposes a method to mitigate some of the computational challenges associated with the decision-focused learning paradigm under stochastic optimization-based decisions with unknown parameters. In particular, the authors construct (a) an energy-based surrogate function for the stochastic optimization-based decisions, (b) a loss function encouraging both good predictive accuracy and good global behavior of the energy-based surrogate, and (c) an efficient training procedure based on a mixture-of-Gaussians proposal. This enables them to avoid expensive implicit KKT differentiation steps that are needed when representing the decision procedure exactly as an optimization problem, as well as better enabling the representation of non-convex decision-making processes. The authors provide extensive experiments on several settings, and show empirically that their method achieves comparable or improved performance over baseline methods while drastically improving on computation time.\nStrengths And Weaknesses: Strengths: \n\nThe proposed method is well-motivated, nicely integrates concepts from energy-based learning into the decision-focused learning literature, and mitigates a number of existing challenges with decision-focused learning paradigms.\nThe experimental evaluation is thorough and well-done, demonstrating performance on different kinds of settings with respect to the form of the task loss, and showing insightful ablations. The method strongly outperforms other baselines (and the authors both include error bars and transparently leave in one setting where a baseline outperforms their method, both of which I appreciate).\nEverything is very well-explained, making the paper an absolute pleasure to read.\n\nWeaknesses: \n\nIn the checklist, the authors mention that they describe limitations and potential negative societal impacts of their work, but I cannot find this discussion.\n\nQuestions:\n\nSection 4.1: Why does SO-EBM improve over DFL-QPTH? It would be useful to give some intuition for this, as at first glance it seems strange that a method using a surrogate loss would outperform a method using a more \u201cexact\u201d version of the loss.\n\nMinor points:\n\nSection 2, Problem Formulation paragraph: The terms M and a\u2217(x;\u03b8) should be more formally defined in the text (not just in Figure 1), as the rest of the problem formulation and method hinge on this. In particular, the current statement about learning a model that \u201ctakes the features x as input and outputs the optimal decisions a\u2217(x;\u03b8)\u201d could be misunderstood as a model that maps directly from data to decisions, without the intermediate prediction of the distribution.\nSection 2, Problem Formulation paragraph: As previously defined, D is the dataset. However, the optimization loss is introduced as \u201cthe expected decision cost under the joint distribution.\u201d The wording here should be clarified. The goal is to learn the expected decision cost under the joint test-time distribution, as approximated by the dataset at training time, which is what the loss shows.\nLine 92: The left side should be the total derivative, rather than the partial derivative. Similarly, \u2202y/\u2202\u03b8 should be dy/d\u03b8. Similarly, in Equation (6), some of the partial derivatives should be total derivatives.\n\nTypos:\n\nLine 84: \u201cDFL method\u201d -> \u201cDFL methods\u201d\nProblem Formulation paragraph in Section 2: \u201coptimal decisions minimizes\u201d -> \u201coptimal decisions minimize\u201d\nLine 99: \u201cCVXlayers\u201d -> \u201ccvxpylayers\u201d\nLine 100: \u201cgrammer\u201d -> \u201cgrammar\u201d\nLine 132: The optimization problem is missing xi \nLine 305: \u201ctarget node\u201d -> \u201ctarget nodes\u201d\nQuestions: \nSection 4.1: Why does SO-EBM improve over DFL-QPTH? It would be useful to give some intuition for this, as at first glance it seems strange that a method using a surrogate loss would outperform a method using a more \u201cexact\u201d version of the loss.\nWhat are some of the limitations and potential negative impacts of the method?\nLimitations: In the checklist, the authors mention that they describe limitations and potential negative societal impacts of their work, but I cannot find this discussion. This discussion should be made more explicit, and should acknowledge that while the applications presented in the paper are social good applications (which I appreciate), the method is general enough that it may also have negative uses.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 4 excellent\nRating: 8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper tackles stochastic optimization problems of the form maxa\u2208Cf(y,a), where y is a stochastic variable and a is an action taken by the learner given an observation x. \nRecent work have introduced solutions that involve Deep Neural Networks. One body of work uses DNNs to make a prediction y^ given x, and then running an off-the-shelf optimizer for the inferred problem f(y^,\u22c5). This can lead to suboptimal solutions if y^ is not accurate. Another body of work can overcome this in certain scenarios by optimizing (y^,a) jointly. They do so via end-to-end architectures that use so-called optimization-layers. These layers run a differentiable convex optimizer, and hence the incurred cost f(y^,a^) can be optimized by jointly through backpropagation. A limitation of this approach is that the optimization layers must backpropagate through a convex optimiser; hence if it does not have a closed form solution, the computational cost can be steep.\nThe authors propose a novel architecture for joint optimization of (y^,a^) that avoids introducing optimization layers by taking an EBM approach. They construct an EBM that takes the expected cost f(y^,a^) under the model as the energy. To optimize the energy function, the authors operate a two-stage process. First, given a dataset D={(xi,yi)}i=1K, they compute expert actions ai for each yi to construct an auxiliary dataset D\u2032={(xi,ai)}i=1K. They then use MLE to optimise the energy model under D\u2032. \nHowever, a main complication of this approach is that it requires stochastic outputs from the DNN. To this end, the authors rely on a Gaussian parameterization and self-normalized importance sampling. This means that the main computational difference between optimization-layer approaches and the author's approach is that they rely on stochastic relaxation instead of exact optimization. \nThe authors provide three synthetic experiments to evaluate their architecture: load balancing in power systems, healthcare resource allocation, and network security. In all cases, they show that their proposed method is competitive in terms of final performance while being computationally more efficient than optimization-layer based approaches.\nStrengths And Weaknesses: Strengths\n\nThe paper is generally well written. The main idea, its motivation, mechanics, and intuition for design choices are all clearly spelled out. The experiments are well described with uncertainty estimates.\nThe proposed architecture is quite clean and follows naturally from the EBM perspective. \nThe experiments are well executed; clearly described, with thorough analysis of results.\n\nWeaknesses\n\nThe main contribution stated on page 2 does not seem to be well supported. First, the authors claim that the method is end-to-end, but this is not true since to construct the dataset, an off-the-shelf solver is needed to generate expert actions. Second, it does require solving the optimization problem (though not backpropagating through the solver), and while the EBM objective does not require convexity, imputing expert actions does. Overall, I think the paper can be strengthen significantly by a more nuanced discussion of the relative merits of the proposed method.\nThe experiments are somewhat underwhelming in that they are all synthetic. It would have been significantly more interesting to test the proposed architecture on a real world problem with well-developed benchmarks. Moreover, the results themselves suggest that the gains are marginal; in most cases, the two-stage approach of pretraining a predictor y^ is faster and the loss in performance is not statistically significant.\nQuestions: \nThe ability to generate expert actions is critical for this method to work. The authors suggest that previous method are limited in that they rely on convex solver - but it seems the proposed method suffer from the same limitation in that the solver is required to obtain expert actions?\n\nThe authors opted for an EBM approach. Another equally valid method would have been expert distillation, which would have the benefit of not requiring estimating the energy function. Could the authors comment on why they opted against this simpler approach?\nLimitations: The authors discuss some limitations of the EBM approach, mainly the risk of overfitting. They provide an ablation to study the severity of the problem. The authors do not discuss other limitations, sensitivity to the choice of sampler and sensitivity to the choice of solver for expert actions.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The authors propose an approach for \"decision-focused learning\" (DFL).  This is where there is a prediction stage to predict stochastic parameters from some input features, that are then used to solve an optimization problem to determine an optimal action.  For example, an optimization of electricity generator scheduling based on forecasted electricity load / demand.  The old two-stage approach would be to separately fit a forecast model, and then use its predictions in an optimization problem solved by optimization solvers.  The DFL approach is to fit the forecast model in conjunction with the optimization problem, so the forecasts are optimal for the down-stream optimization problems themselves.\nTo do this for modern models using neural networks for the forecasters would generally require computing and back-propagating the gradient through the optimization loss and problem to the model parameters.  However, the gradient of the optimal action with respect to the forecast / prediction values is not always differentiable and the optimal action is the solution to an optimization problem, so computing gradient updates can be challenging and time consuming.\nMost past work tended to either make restrictive assumptions or approximations, or used computational complex and inefficient implicitly differentiable layers.   This work proposes a workaround by modeling the optimal actions / optimization problem solution as a function of the features directly, but ties it to the forecast model as the energy term of the energy model is given by the expected optimization loss of under the forecast model (the forecast gives the distribution over the predicted parameters for the optimization problem).  In this way the energy model can be trained directly on historical examples with optimal solutions previously derived, by minimizing the negative log likelihood (which in turn optimizes the forecast model for the optimization problem) along with a KL-divergence regularizer added to the objective as well.  \nThe authors compare their proposed approach to past methods on 3 datasets / tasks from different domains, and show it consistently has as good or better performance to other past DFL approaches, while also having as good or better run time.\nStrengths And Weaknesses: Strengths:\n-The authors point out key limitations of past work and aim to tackle a significant and important problem.  I.e., most practical applications of ML involve combining predictions and optimization and the DFL approach is arguably the way things should be done for all these applications / ML in general.\n-The authors propose a novel solution that is interesting and shows promising results.\n-The authors provide experimental results on a variety of different tasks and compare to multiple past DFL methods.  \n-The authors pledge to make the code publicly available, which will help a lot with reproducibility and understanding the approach.\nWeaknesses:\n-One piece of the problem, in particular the optimization part, that seems overlooked and not mentioned is the constraints.  Constraints are not included at all in the model of the end-to-end problem (mapping the features to the action) - they could only be included implicitly since the optimal actions, a, the model is trained on must satisfy the constraints.  It would help to have discussion about why it's not necessary to consider the constraints and what kind of impact it would have.  My speculation is that this can actually have a negative impact, because it puts more burden on the forecast neural network part of the model to account for the constraints (this model then needs to be more complex) - as what naturally fits the data better would have to be abandoned to predict a solution that leads to the best action when dropping the constraints.  I feel the problems chosen had very few and basic constraints which may be why the approach still worked in the experiments, but I would be curious to see how more constraints, and more complex constraints, might impact the performance.  It would also be useful to see how the learned forecast model compares to the separately trained model, and what cases it's making predictions farther off from the true values.\n-There is one closely-related work overlooked here that appeared in the AAAI-22 Workshop on AI for Decision Optimization - this pointed out the same limitations and similarly targeted a somewhat similar approach.  However, that approach was different in that it approximated the optimization algorithm itself with a neural net, so the solution could be easily computed and differentiated, as opposed to effectively approximating the entire end-to-end problem as was done here (though here essentially only using the neural net to approximate the forecast piece of the model).  It would be good to mention this alternative approach, and it would be great if the two could be compared, as I'm very curious to see how they compare.  Paper:\n\"End-to-End Learning via Constraint-Enforcing Approximators for Linear Programs with Applications to Supply Chains\"\nhttps://research.ibm.com/haifa/Workshops/AAAI-22-AI4DO/PDF/End-to-End%20Learning%20via%20Constraint-Enforcing%20Approximators%20for%20LinearPrograms%20with%20Applications%20to%20Supply%20Chains.pdf\n-The clarity of the presentation and description could be improved.  It's hard to follow the details of the method and the experiments.  For instance, the method description is not easy to follow, especially the KL-divergence regularization and the rationale behind it.  Another example, the experiment procedure is not clearly explained - i.e., for all methods, is the model fit and then just the forecast part used in conjunction with an optimization solver to get the final action / decision?  If so, what solver is used?  How are various hyper parameters set for different methods?  \n-Further experimental study would be useful.  In particular it would be good to see the impact on training data size on the performance of the different approaches.  In particular, with enough training data one would not expect the DFL approach to out-perform the two-stage one.  I also wonder if this approach may need more training data points to work well as it directly models the action given the inputs. \n Additionally run times will also be affected by amount of training data.  It would be good to understand these trade-offs.  Additionally it would be best to see the impact of varying lambda.   Additionally, what is the impact of using different network architectures / sizes?\nQuestions: Please see questions and suggestions raised under weaknesses.  \nIt would be good to mention and contrast with the other related work mentioned above.\nHow does the proposed approach handle constraints?  What is the impact of not including constraints?  What is the impact on large numbers of constraints / more complex optimization problems?\nHow much data does the proposed approach require?  How does the amount of data affect performance?\n-Figures 4, 5, and 6 - labels are not lined up with the bars so it's hard to match the methods to the bars\nLimitations: There doesn't seem to be discussion of what are the limitations of this approach - it could benefit from some thought and discussion around what the limitations are.  Perhaps this would include dealing with constraints, or it could be the case where a large number of solved problems are needed for it to work well, as this should also be investigated ideally.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper proposes to address the problem of end-to-end stochastic optimization. That is; finding argmin_a f(y, a) for some cost function f, input variables y, and actions a. The key caveat here is that y is not observed and instead, we observe x, a variable correlated with y (but the relationship between x, y is not provided). \nStandard approaches to this problem learn a model of p(y|x), then use an off-the-shelf stochastic optimizer to find argmin_a E_{p(y|x)}[f(y, a)]. This approach of course can accrue errors due to the p(y|x) model not being perfect leading to subpar results. \nThis work proposes to learn the p(y|x) model, not to predict y, but such that the induced optimal action a performs best. To do this, they parametrize an energy-based model by taking the expected value of the cost function over the p(y|x) model, i.e. E(a; x) = E_{p(y|x)}[f(y, a)] and train this EBM to maximize likelihood of obtaining the ground truth optimal actions a, given the input x. \nThe model is trained using contrastive divergence but an importance sampling estimator is used to deal with the partition function. \nGiven that we also have knowledge of the true y for each x in the dataset, we also have access to a noiseless version of the loss function, not available at test time. This information is utilized by adding a regularizer to encourage low KL divergence. Between the noisy model and the noise-free model. \nThe authors present results on 3 stochastic optimization problems and show that on average their approach either outperforms the baselines or performs comparable to the strongest baselines while having a considerably lower training cost.\nStrengths And Weaknesses: Strengths:\nThis is an interesting application of the theory of energy-based models. It is always nice to see work embracing the methods that have been developed to work with and train unnormalized models, rather than replacing them with normalized surrogates. The proposed method is simple and enables end-to-end optimization of the target lost function rather than a multi-stage approach. Unfortunately, I am not very familiar with this problem-space and the baselines, so I cannot speak much to the quality of the experimental evaluation. \nWeaknesses:\nI am somewhat concerned by the procedure used to train the models and I feel like the authors could provide more evidence to verify that the method is working as expected. Partition function estimation and training in energy-based models is notoriously difficult and, in my experience, importance sampling estimators only tend to work in very small scale settings. In larger scale settings, MCMC-based training such as PCD or CD tend to scale much better. I would expect to see at least 1 MCMC-based training procedure as a baseline. But, given that all of the experiments are in relatively low-dimensional problems, we are in a regime where alternative EBM training procedures may also such such as score-matching, noise contrastive estimation, or conditional noise contrastive estimation. I believe the work would be improved if some investigation was done into the method chosen to train the model.\nHaving said that, I would love to see a larger-scale application -- something maybe with a few hundred or thousand variables. EBM training has been successfully scaled to very high-dimensional data so I expect the method should work. Again, I am not very familiar with this space so I am not sure if any such benchmark problems exist, but if they do, that would be nice to include. \nBesides this, I found the experimental details to be very lacking. There is no mention of the number of importance samples used in training and the scales of the importance weighting distribution. The neural networks used in the model are not described very well and I had to re-read a few times to understand that p(y|x) = N(y; neural_net1(x), neural_net2(x)). Is that right? The types of neural networks should be explained.\nThere is also no discussion of how long the models are trained, how they are optimized, and how model selection is performed. This is very difficult for EBMs, and therefore people typically use proxies for model fit instead of test-set likelihood. For that reason, I feel like it would be important for the authors to comment on this in the paper.\nQuestions: After reading this paper, I am left with a few questions. First, did you explore alternative methods for EBM training such as contrastive divergence, PCD, noise contrastive estimation, or score matching? As I mentioned above, at the scale of the presented experiments, I think it is likely that a number of these techniques could be successful. \nNext, given that your training procedure relies on self-normalized importance sampling, did you perform any verification that the SNIS estimator is accurate? One way to do this would be to show the effective sample size of the importance samples. This can also be used to help tune many parts of the sampler such as the proposal distribution.\nLimitations: The work discusses some of the limitations of EBM training and evaluation but does not spend much time talking about the specific drawbacks of the proposed method. I think the work would benefit from a limitations section.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper proposes a method to mitigate some of the computational challenges associated with the decision-focused learning paradigm under stochastic optimization-based decisions with unknown parameters. In particular, the authors construct (a) an energy-based surrogate function for the stochastic optimization-based decisions, (b) a loss function encouraging both good predictive accuracy and good global behavior of the energy-based surrogate, and (c) an efficient training procedure based on a mixture-of-Gaussians proposal. This enables them to avoid expensive implicit KKT differentiation steps that are needed when representing the decision procedure exactly as an optimization problem, as well as better enabling the representation of non-convex decision-making processes. The authors provide extensive experiments on several settings, and show empirically that their method achieves comparable or improved performance over baseline methods while drastically improving on computation time.",
                "Strengths And Weaknesses": "Strengths: \n\nThe proposed method is well-motivated, nicely integrates concepts from energy-based learning into the decision-focused learning literature, and mitigates a number of existing challenges with decision-focused learning paradigms.\nThe experimental evaluation is thorough and well-done, demonstrating performance on different kinds of settings with respect to the form of the task loss, and showing insightful ablations. The method strongly outperforms other baselines (and the authors both include error bars and transparently leave in one setting where a baseline outperforms their method, both of which I appreciate).\nEverything is very well-explained, making the paper an absolute pleasure to read.\n\nWeaknesses: \n\nIn the checklist, the authors mention that they describe limitations and potential negative societal impacts of their work, but I cannot find this discussion.\n\nQuestions:\n\nSection 4.1: Why does SO-EBM improve over DFL-QPTH? It would be useful to give some intuition for this, as at first glance it seems strange that a method using a surrogate loss would outperform a method using a more \u201cexact\u201d version of the loss.\n\nMinor points:\n\nSection 2, Problem Formulation paragraph: The terms M and a\u2217(x;\u03b8) should be more formally defined in the text (not just in Figure 1), as the rest of the problem formulation and method hinge on this. In particular, the current statement about learning a model that \u201ctakes the features x as input and outputs the optimal decisions a\u2217(x;\u03b8)\u201d could be misunderstood as a model that maps directly from data to decisions, without the intermediate prediction of the distribution.\nSection 2, Problem Formulation paragraph: As previously defined, D is the dataset. However, the optimization loss is introduced as \u201cthe expected decision cost under the joint distribution.\u201d The wording here should be clarified. The goal is to learn the expected decision cost under the joint test-time distribution, as approximated by the dataset at training time, which is what the loss shows.\nLine 92: The left side should be the total derivative, rather than the partial derivative. Similarly, \u2202y/\u2202\u03b8 should be dy/d\u03b8. Similarly, in Equation (6), some of the partial derivatives should be total derivatives.\n\nTypos:\n\nLine 84: \u201cDFL method\u201d -> \u201cDFL methods\u201d\nProblem Formulation paragraph in Section 2: \u201coptimal decisions minimizes\u201d -> \u201coptimal decisions minimize\u201d\nLine 99: \u201cCVXlayers\u201d -> \u201ccvxpylayers\u201d\nLine 100: \u201cgrammer\u201d -> \u201cgrammar\u201d\nLine 132: The optimization problem is missing xi \nLine 305: \u201ctarget node\u201d -> \u201ctarget nodes\u201d",
                "Questions": "Section 4.1: Why does SO-EBM improve over DFL-QPTH? It would be useful to give some intuition for this, as at first glance it seems strange that a method using a surrogate loss would outperform a method using a more \u201cexact\u201d version of the loss.\nWhat are some of the limitations and potential negative impacts of the method?",
                "Limitations": "In the checklist, the authors mention that they describe limitations and potential negative societal impacts of their work, but I cannot find this discussion. This discussion should be made more explicit, and should acknowledge that while the applications presented in the paper are social good applications (which I appreciate), the method is general enough that it may also have negative uses.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "4 excellent",
                "Rating": "8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper tackles stochastic optimization problems of the form maxa\u2208Cf(y,a), where y is a stochastic variable and a is an action taken by the learner given an observation x. \nRecent work have introduced solutions that involve Deep Neural Networks. One body of work uses DNNs to make a prediction y^ given x, and then running an off-the-shelf optimizer for the inferred problem f(y^,\u22c5). This can lead to suboptimal solutions if y^ is not accurate. Another body of work can overcome this in certain scenarios by optimizing (y^,a) jointly. They do so via end-to-end architectures that use so-called optimization-layers. These layers run a differentiable convex optimizer, and hence the incurred cost f(y^,a^) can be optimized by jointly through backpropagation. A limitation of this approach is that the optimization layers must backpropagate through a convex optimiser; hence if it does not have a closed form solution, the computational cost can be steep.\nThe authors propose a novel architecture for joint optimization of (y^,a^) that avoids introducing optimization layers by taking an EBM approach. They construct an EBM that takes the expected cost f(y^,a^) under the model as the energy. To optimize the energy function, the authors operate a two-stage process. First, given a dataset D={(xi,yi)}i=1K, they compute expert actions ai for each yi to construct an auxiliary dataset D\u2032={(xi,ai)}i=1K. They then use MLE to optimise the energy model under D\u2032. \nHowever, a main complication of this approach is that it requires stochastic outputs from the DNN. To this end, the authors rely on a Gaussian parameterization and self-normalized importance sampling. This means that the main computational difference between optimization-layer approaches and the author's approach is that they rely on stochastic relaxation instead of exact optimization. \nThe authors provide three synthetic experiments to evaluate their architecture: load balancing in power systems, healthcare resource allocation, and network security. In all cases, they show that their proposed method is competitive in terms of final performance while being computationally more efficient than optimization-layer based approaches.",
                "Strengths And Weaknesses": "Strengths\n\nThe paper is generally well written. The main idea, its motivation, mechanics, and intuition for design choices are all clearly spelled out. The experiments are well described with uncertainty estimates.\nThe proposed architecture is quite clean and follows naturally from the EBM perspective. \nThe experiments are well executed; clearly described, with thorough analysis of results.\n\nWeaknesses\n\nThe main contribution stated on page 2 does not seem to be well supported. First, the authors claim that the method is end-to-end, but this is not true since to construct the dataset, an off-the-shelf solver is needed to generate expert actions. Second, it does require solving the optimization problem (though not backpropagating through the solver), and while the EBM objective does not require convexity, imputing expert actions does. Overall, I think the paper can be strengthen significantly by a more nuanced discussion of the relative merits of the proposed method.\nThe experiments are somewhat underwhelming in that they are all synthetic. It would have been significantly more interesting to test the proposed architecture on a real world problem with well-developed benchmarks. Moreover, the results themselves suggest that the gains are marginal; in most cases, the two-stage approach of pretraining a predictor y^ is faster and the loss in performance is not statistically significant.",
                "Questions": "The ability to generate expert actions is critical for this method to work. The authors suggest that previous method are limited in that they rely on convex solver - but it seems the proposed method suffer from the same limitation in that the solver is required to obtain expert actions?\n\nThe authors opted for an EBM approach. Another equally valid method would have been expert distillation, which would have the benefit of not requiring estimating the energy function. Could the authors comment on why they opted against this simpler approach?",
                "Limitations": "The authors discuss some limitations of the EBM approach, mainly the risk of overfitting. They provide an ablation to study the severity of the problem. The authors do not discuss other limitations, sensitivity to the choice of sampler and sensitivity to the choice of solver for expert actions.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors propose an approach for \"decision-focused learning\" (DFL).  This is where there is a prediction stage to predict stochastic parameters from some input features, that are then used to solve an optimization problem to determine an optimal action.  For example, an optimization of electricity generator scheduling based on forecasted electricity load / demand.  The old two-stage approach would be to separately fit a forecast model, and then use its predictions in an optimization problem solved by optimization solvers.  The DFL approach is to fit the forecast model in conjunction with the optimization problem, so the forecasts are optimal for the down-stream optimization problems themselves.\nTo do this for modern models using neural networks for the forecasters would generally require computing and back-propagating the gradient through the optimization loss and problem to the model parameters.  However, the gradient of the optimal action with respect to the forecast / prediction values is not always differentiable and the optimal action is the solution to an optimization problem, so computing gradient updates can be challenging and time consuming.\nMost past work tended to either make restrictive assumptions or approximations, or used computational complex and inefficient implicitly differentiable layers.   This work proposes a workaround by modeling the optimal actions / optimization problem solution as a function of the features directly, but ties it to the forecast model as the energy term of the energy model is given by the expected optimization loss of under the forecast model (the forecast gives the distribution over the predicted parameters for the optimization problem).  In this way the energy model can be trained directly on historical examples with optimal solutions previously derived, by minimizing the negative log likelihood (which in turn optimizes the forecast model for the optimization problem) along with a KL-divergence regularizer added to the objective as well.  \nThe authors compare their proposed approach to past methods on 3 datasets / tasks from different domains, and show it consistently has as good or better performance to other past DFL approaches, while also having as good or better run time.",
                "Strengths And Weaknesses": "Strengths:\n-The authors point out key limitations of past work and aim to tackle a significant and important problem.  I.e., most practical applications of ML involve combining predictions and optimization and the DFL approach is arguably the way things should be done for all these applications / ML in general.\n-The authors propose a novel solution that is interesting and shows promising results.\n-The authors provide experimental results on a variety of different tasks and compare to multiple past DFL methods.  \n-The authors pledge to make the code publicly available, which will help a lot with reproducibility and understanding the approach.\nWeaknesses:\n-One piece of the problem, in particular the optimization part, that seems overlooked and not mentioned is the constraints.  Constraints are not included at all in the model of the end-to-end problem (mapping the features to the action) - they could only be included implicitly since the optimal actions, a, the model is trained on must satisfy the constraints.  It would help to have discussion about why it's not necessary to consider the constraints and what kind of impact it would have.  My speculation is that this can actually have a negative impact, because it puts more burden on the forecast neural network part of the model to account for the constraints (this model then needs to be more complex) - as what naturally fits the data better would have to be abandoned to predict a solution that leads to the best action when dropping the constraints.  I feel the problems chosen had very few and basic constraints which may be why the approach still worked in the experiments, but I would be curious to see how more constraints, and more complex constraints, might impact the performance.  It would also be useful to see how the learned forecast model compares to the separately trained model, and what cases it's making predictions farther off from the true values.\n-There is one closely-related work overlooked here that appeared in the AAAI-22 Workshop on AI for Decision Optimization - this pointed out the same limitations and similarly targeted a somewhat similar approach.  However, that approach was different in that it approximated the optimization algorithm itself with a neural net, so the solution could be easily computed and differentiated, as opposed to effectively approximating the entire end-to-end problem as was done here (though here essentially only using the neural net to approximate the forecast piece of the model).  It would be good to mention this alternative approach, and it would be great if the two could be compared, as I'm very curious to see how they compare.  Paper:\n\"End-to-End Learning via Constraint-Enforcing Approximators for Linear Programs with Applications to Supply Chains\"\nhttps://research.ibm.com/haifa/Workshops/AAAI-22-AI4DO/PDF/End-to-End%20Learning%20via%20Constraint-Enforcing%20Approximators%20for%20LinearPrograms%20with%20Applications%20to%20Supply%20Chains.pdf\n-The clarity of the presentation and description could be improved.  It's hard to follow the details of the method and the experiments.  For instance, the method description is not easy to follow, especially the KL-divergence regularization and the rationale behind it.  Another example, the experiment procedure is not clearly explained - i.e., for all methods, is the model fit and then just the forecast part used in conjunction with an optimization solver to get the final action / decision?  If so, what solver is used?  How are various hyper parameters set for different methods?  \n-Further experimental study would be useful.  In particular it would be good to see the impact on training data size on the performance of the different approaches.  In particular, with enough training data one would not expect the DFL approach to out-perform the two-stage one.  I also wonder if this approach may need more training data points to work well as it directly models the action given the inputs. \n Additionally run times will also be affected by amount of training data.  It would be good to understand these trade-offs.  Additionally it would be best to see the impact of varying lambda.   Additionally, what is the impact of using different network architectures / sizes?",
                "Questions": "Please see questions and suggestions raised under weaknesses.  \nIt would be good to mention and contrast with the other related work mentioned above.\nHow does the proposed approach handle constraints?  What is the impact of not including constraints?  What is the impact on large numbers of constraints / more complex optimization problems?\nHow much data does the proposed approach require?  How does the amount of data affect performance?\n-Figures 4, 5, and 6 - labels are not lined up with the bars so it's hard to match the methods to the bars",
                "Limitations": "There doesn't seem to be discussion of what are the limitations of this approach - it could benefit from some thought and discussion around what the limitations are.  Perhaps this would include dealing with constraints, or it could be the case where a large number of solved problems are needed for it to work well, as this should also be investigated ideally.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposes to address the problem of end-to-end stochastic optimization. That is; finding argmin_a f(y, a) for some cost function f, input variables y, and actions a. The key caveat here is that y is not observed and instead, we observe x, a variable correlated with y (but the relationship between x, y is not provided). \nStandard approaches to this problem learn a model of p(y|x), then use an off-the-shelf stochastic optimizer to find argmin_a E_{p(y|x)}[f(y, a)]. This approach of course can accrue errors due to the p(y|x) model not being perfect leading to subpar results. \nThis work proposes to learn the p(y|x) model, not to predict y, but such that the induced optimal action a performs best. To do this, they parametrize an energy-based model by taking the expected value of the cost function over the p(y|x) model, i.e. E(a; x) = E_{p(y|x)}[f(y, a)] and train this EBM to maximize likelihood of obtaining the ground truth optimal actions a, given the input x. \nThe model is trained using contrastive divergence but an importance sampling estimator is used to deal with the partition function. \nGiven that we also have knowledge of the true y for each x in the dataset, we also have access to a noiseless version of the loss function, not available at test time. This information is utilized by adding a regularizer to encourage low KL divergence. Between the noisy model and the noise-free model. \nThe authors present results on 3 stochastic optimization problems and show that on average their approach either outperforms the baselines or performs comparable to the strongest baselines while having a considerably lower training cost.",
                "Strengths And Weaknesses": "Strengths:\nThis is an interesting application of the theory of energy-based models. It is always nice to see work embracing the methods that have been developed to work with and train unnormalized models, rather than replacing them with normalized surrogates. The proposed method is simple and enables end-to-end optimization of the target lost function rather than a multi-stage approach. Unfortunately, I am not very familiar with this problem-space and the baselines, so I cannot speak much to the quality of the experimental evaluation. \nWeaknesses:\nI am somewhat concerned by the procedure used to train the models and I feel like the authors could provide more evidence to verify that the method is working as expected. Partition function estimation and training in energy-based models is notoriously difficult and, in my experience, importance sampling estimators only tend to work in very small scale settings. In larger scale settings, MCMC-based training such as PCD or CD tend to scale much better. I would expect to see at least 1 MCMC-based training procedure as a baseline. But, given that all of the experiments are in relatively low-dimensional problems, we are in a regime where alternative EBM training procedures may also such such as score-matching, noise contrastive estimation, or conditional noise contrastive estimation. I believe the work would be improved if some investigation was done into the method chosen to train the model.\nHaving said that, I would love to see a larger-scale application -- something maybe with a few hundred or thousand variables. EBM training has been successfully scaled to very high-dimensional data so I expect the method should work. Again, I am not very familiar with this space so I am not sure if any such benchmark problems exist, but if they do, that would be nice to include. \nBesides this, I found the experimental details to be very lacking. There is no mention of the number of importance samples used in training and the scales of the importance weighting distribution. The neural networks used in the model are not described very well and I had to re-read a few times to understand that p(y|x) = N(y; neural_net1(x), neural_net2(x)). Is that right? The types of neural networks should be explained.\nThere is also no discussion of how long the models are trained, how they are optimized, and how model selection is performed. This is very difficult for EBMs, and therefore people typically use proxies for model fit instead of test-set likelihood. For that reason, I feel like it would be important for the authors to comment on this in the paper.",
                "Questions": "After reading this paper, I am left with a few questions. First, did you explore alternative methods for EBM training such as contrastive divergence, PCD, noise contrastive estimation, or score matching? As I mentioned above, at the scale of the presented experiments, I think it is likely that a number of these techniques could be successful. \nNext, given that your training procedure relies on self-normalized importance sampling, did you perform any verification that the SNIS estimator is accurate? One way to do this would be to show the effective sample size of the importance samples. This can also be used to help tune many parts of the sampler such as the proposal distribution.",
                "Limitations": "The work discusses some of the limitations of EBM training and evaluation but does not spend much time talking about the specific drawbacks of the proposed method. I think the work would benefit from a limitations section.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "soundness_avg": 3.25,
        "presentation_avg": 2.75,
        "contribution_avg": 3.0,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is clear that the proposed method in this paper is well-motivated and addresses an important problem in end-to-end stochastic optimization. The authors integrate concepts from energy-based learning into the decision-focused learning literature and provide a thorough experimental evaluation, demonstrating the performance of their method on different tasks. The paper is technically solid and the results show that the proposed method outperforms or performs comparably to existing baselines while being computationally more efficient.\n\nWhile there are some weaknesses pointed out by the reviewers, such as the lack of discussion on constraints and the need for more investigation into the training procedure, these limitations do not outweigh the strengths of the paper. The proposed method is novel and shows promising results.\n\nTherefore, I recommend accepting this paper."
    },
    "EAGER:_Asking_and_Answering_Questions_for_Automatic_Reward_Shaping_in_Language-guided_RL": {
        "link": "https://openreview.net//forum?id=scfOjwTtZ8S",
        "pub_url": "https://openreview.net/forum?id=scfOjwTtZ8S",
        "pdf_link": "https://openreview.net//pdf?id=scfOjwTtZ8S",
        "paper_id": "scfOjwTtZ8S",
        "title": "EAGER:_Asking_and_Answering_Questions_for_Automatic_Reward_Shaping_in_Language-guided_RL",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nThis paper presents a language-guided auxiliary reward mechanism based on generating Q&A pairs based on agent trajectories and rewarding the agent for producing trajectories that yield correct answers from an answering model. The reviewers broadly found the paper compelling and convincing, and thus I am happy to follow their general consensus in recommending acceptance.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper proposes a new reward shaping method, EAGER, in Language-guided reinforcement learning (RL).  By extracting auxiliary Question Answering (QA) tasks, the agent is given intrinsic rewards based on how the generated trajectories could help answer these questions.  The authors claim that such auxiliary tasks can be designed without engineer interventions.  Specifically, the answer to these questions is the output of the pre-trained QA transformer model after feeding the generated trajectories.  For the BabyAI experiments, this QA model is pre-trained using example trajectories provided by the bot that can already solve the environment. The method is compared against two recent baselines RIDE and ELLA.  EAGER improves sample-efficiency in some tasks from BabyAI.\nStrengths And Weaknesses: Strengths: \n-This seems like a novel method that is inspired by reference-less metrics in NLP. The idea is interesting, and the authors provided detailed explanations on how each component, QA module, QA module, is implemented. \n\nOverall, the paper is well-structured and clearly written from the method section to the experiment section.  \nI believe the future work could be influenced by the idea of reference-less metrics proposed here.\n\nWeaknesses: \n\nI think the experiment part is weak due to EAGER still using \u201cengineer intervention\u201d in BabyAI.  If I understand correctly, RIDE [1] does not use any expert information at all while EAGER currently requires a bot that can already solve some of the tasks from BabyAI.  In addition,  QG assumes the answer to the generated questions is one of the words that appear in the goal sentence.  The output of the QA model also requires prior knowledge about the potential words that can appear in the goal sentence though this might be okay if you assume these  are all nouns and you could extract them in advance.  I recommend adding a table to list all the assumptions and expert knowledge required for RIDE, EAGER, and ELLA [2] in a table.  \nAlthough EAGER outperforms RIDE, RIDE does not use the bot from BabyAI so I think it\u2019s not too surprising that EAGER can outperform RIDE all the time.  Since EAGER and ELLA both excel in certain tasks, it is difficult to judge whether the method is actually an improvement to ELLA given the reasons in the previous bullet point.\n\nMinor points:\n\nTitle 5.2 \u201cHow does EAGER performs\u201d \u2192 \u201cHow does EAGER perform\u201d \u201cSparsity increase\u201d \u2192 increases\nLine245: I think it\u2019ll be helpful to explain what these 3 input values represent in BabyAI.  How are objects represented in the gridworld.\n\n[1] Roberta Raileanu and Tim Rockt\u00e4schel. Ride: Rewarding impact-driven exploration for 418 procedurally-generated environments. In International Conference on Learning Representations 419 (ICLR), 2020\n[2] Suvir Mirchandani, Siddharth Karamcheti, and Dorsa Sadigh. Ella: Exploration through learned 406 language abstraction. In Advances in Neural Information Processing Systems (NeurIPS), 2021.\nQuestions: \nIs it possible to use behavior cloning to train an agent using those example trajectories from the bot?  This might serve a good baseline.\nLimitations: Yes, the authors have addressed the limitations\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper presents a simple but novel reward shaping method for language-conditioned RL. The paper mainly proposes the auxiliary objectives for question generation and question answering models. Then they calculate the intrinsic reward which is proportional to its confidence in its answer. In the experiments, the authors showed that the proposed algorithm learns more efficiently on various tasks than the baseline algorithms.\nStrengths And Weaknesses: Strengths\n\nThe main idea of the proposed method in the paper is simple but novel. \nThe experiments include not only the results of sample efficient learning but also various analyzes.\n\nWeaknesses\n\nA near expert dataset is needed for pre-training the QA module, which seems to be a quite strong assumption.\nQuestions: \nIn lines 280-281, it is expressed as without using expert knowledge, but is the expert dataset not used for pre-training when learning the QA module? (The paper explains as if it used less information than the ELLA, but it requires the same or similar information as the ELLA.)\nIf there is a pre-trained dataset (for the QA module), isn't it more efficient to use knowledge in the form of a prior policy learned from it? It seems that there should be an experiment about it.\nWhat if it is used simultaneously with intrinsic reward methods such as RIDE? It is also important to check whether the effect of both methods is still helpful even if they are used at the same time.\nLimitations: The authors adequately addressed the limitations and potential negative societal impact of their work.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The paper proposes an auxiliary reward scheme (EAGER) for instruction following RL (BabyAI framework) based on question generation (QG) and answering (QA). Concretely, QG is based on masked word modeling of the instruction, and QA is pre-trained with demo instructions and trajectories and fixed when training RL. The intuition is good and successful RL agent trajectories should make QA correct and easy, thus when QA is successful, an auxiliary reward proportional to correct answer confidence is given. The method is evaluated on several BabyAI tasks and shown on par with other methods (ELLA, RIDE) with more expert inductive bias for subgoal specification and judgement. Further analysis shows EAGER is fairly robust to QA performance, but some QA design choices are important.\nStrengths And Weaknesses: Strengths: \n\nThe idea is neat, novel, effective, and provides a means to auxiliary reward for instruction following only using example instructions and trajectories, and minimal linguistic assumptions (what is noun/adj). In contrast, previous methods usually require domain knowledge about subgoal formulation/proposal/completion judgement. \n\nSome design choices for QA are reasonably explained in theory (e.g. policy invariance) and practice (e.g. no_answer, using confidence instead of binary reward).\n\nThe motivation and idea are well explained, and the paper is well structured and easy to read for most parts.\n\n\nWeakness:\nAs mentioned in the last part of the paper, two main limitations (and some of my extensions) are \n\nQA needs expert trajectories with instructions to pre-train. Arguably it is a weaker assumption compared to prior work, but I feel two important ablations are missing: direct PPO without the auxiliary reward (a trivial low-bound baseline), and just using the QA training trajectories to do imitation learning and warmstarting for RL agent (a trivial way to use these pre-training trajectories). \n\nBabyAI is perhaps too simple, and experiments seem a bit limited. I can see some sample efficiency advantage on PutNext tasks, but ELLA seems better than EAGER on Unlock and Sequence. What about other tasks in BabyAI, let alone more complex tasks like Alfred (which I feel this method might not easily work, given the visual observation and language instruction are both much harder). Some more experiments or tasks would make me believe the method is more general and robust.\n\n\nAlso pointed out in the paper (line 295),'\n\nEAGER might not work well on Sequence or tasks with temporal subgoals. In general, I don't have an intuition what properties of env/task does EAGER work better on and what not. Some analysis or examples of agent behavior or even how auxiliary reward changes with time would give me more concrete ideas.\nQuestions: Some minor points:\n\nMaybe in abstract, mention the domain (babyAI)?\nIs there any ablation for the policy invariance thing?\nLimitations: They are discussed in the paper, see the weakness part.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 4 excellent\nRating: 8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: In this paper, the authors proposed a reward shaping method for language-conditioned RL. The authors proposed to generate a set of questions based on natural language instructions, and then evaluate how likely the current trajectory answers the questions. The probabilities of the questions being correctly answered are used as intrinsic rewards. In the experiment, the authors worked on Baby AI benchmark and showed that the proposed reward shaping method helped to improve sample complexity and model performance.\nStrengths And Weaknesses: Strengths:\nThe idea of using question generation and answering to do reward shaping for LC-RL is novel and interesting. It is like doing a self-check when a human follows a task instruction.\nThe paper showed that this idea works in the Baby AI benchmark.\nWeaknesses:\nWhile the idea is interesting, I think it is not sophisticated enough to generalized to more complex setting.\nFirst of all, the QG module generates a questions by masking a word (such as nouns and adjectives) in the linguistic instruction. However, for complex instructions, it is likely that the question can by answered by the masked instruction. For example, an instruction \"pick the [red ball], open the red door, ...., put the [red ball] on the chair\". If we mask the 'red ball' at the beginning of the sentence, we can still infer the answer from the 'red ball' at the end of the sentence. Therefore, even without the trajectory, the questions can be answered. I'd assume that it requires more than just masking words to generate a valid question.\nSecondly, the QA model is trained by using the full trajectory, however, when calculating intrinsic rewards, partial trajectories (trajectories up to the current timestep) are used. I would assume that when the partial trajectories are short, the QA model performance is bad. Have the authors investigated this?\nQuestions: Section 4.1 mentioned that if a question is answered, then it is removed from the set of questions. How to determine if a question is answered? Does the QA model have to predict the correct answer with high probability?\nLimitations: N/A\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper proposes a new reward shaping method, EAGER, in Language-guided reinforcement learning (RL).  By extracting auxiliary Question Answering (QA) tasks, the agent is given intrinsic rewards based on how the generated trajectories could help answer these questions.  The authors claim that such auxiliary tasks can be designed without engineer interventions.  Specifically, the answer to these questions is the output of the pre-trained QA transformer model after feeding the generated trajectories.  For the BabyAI experiments, this QA model is pre-trained using example trajectories provided by the bot that can already solve the environment. The method is compared against two recent baselines RIDE and ELLA.  EAGER improves sample-efficiency in some tasks from BabyAI.",
                "Strengths And Weaknesses": "Strengths: \n-This seems like a novel method that is inspired by reference-less metrics in NLP. The idea is interesting, and the authors provided detailed explanations on how each component, QA module, QA module, is implemented. \n\nOverall, the paper is well-structured and clearly written from the method section to the experiment section.  \nI believe the future work could be influenced by the idea of reference-less metrics proposed here.\n\nWeaknesses: \n\nI think the experiment part is weak due to EAGER still using \u201cengineer intervention\u201d in BabyAI.  If I understand correctly, RIDE [1] does not use any expert information at all while EAGER currently requires a bot that can already solve some of the tasks from BabyAI.  In addition,  QG assumes the answer to the generated questions is one of the words that appear in the goal sentence.  The output of the QA model also requires prior knowledge about the potential words that can appear in the goal sentence though this might be okay if you assume these  are all nouns and you could extract them in advance.  I recommend adding a table to list all the assumptions and expert knowledge required for RIDE, EAGER, and ELLA [2] in a table.  \nAlthough EAGER outperforms RIDE, RIDE does not use the bot from BabyAI so I think it\u2019s not too surprising that EAGER can outperform RIDE all the time.  Since EAGER and ELLA both excel in certain tasks, it is difficult to judge whether the method is actually an improvement to ELLA given the reasons in the previous bullet point.\n\nMinor points:\n\nTitle 5.2 \u201cHow does EAGER performs\u201d \u2192 \u201cHow does EAGER perform\u201d \u201cSparsity increase\u201d \u2192 increases\nLine245: I think it\u2019ll be helpful to explain what these 3 input values represent in BabyAI.  How are objects represented in the gridworld.\n\n[1] Roberta Raileanu and Tim Rockt\u00e4schel. Ride: Rewarding impact-driven exploration for 418 procedurally-generated environments. In International Conference on Learning Representations 419 (ICLR), 2020\n[2] Suvir Mirchandani, Siddharth Karamcheti, and Dorsa Sadigh. Ella: Exploration through learned 406 language abstraction. In Advances in Neural Information Processing Systems (NeurIPS), 2021.",
                "Questions": "Is it possible to use behavior cloning to train an agent using those example trajectories from the bot?  This might serve a good baseline.",
                "Limitations": "Yes, the authors have addressed the limitations",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper presents a simple but novel reward shaping method for language-conditioned RL. The paper mainly proposes the auxiliary objectives for question generation and question answering models. Then they calculate the intrinsic reward which is proportional to its confidence in its answer. In the experiments, the authors showed that the proposed algorithm learns more efficiently on various tasks than the baseline algorithms.",
                "Strengths And Weaknesses": "Strengths\n\nThe main idea of the proposed method in the paper is simple but novel. \nThe experiments include not only the results of sample efficient learning but also various analyzes.\n\nWeaknesses\n\nA near expert dataset is needed for pre-training the QA module, which seems to be a quite strong assumption.",
                "Questions": "In lines 280-281, it is expressed as without using expert knowledge, but is the expert dataset not used for pre-training when learning the QA module? (The paper explains as if it used less information than the ELLA, but it requires the same or similar information as the ELLA.)\nIf there is a pre-trained dataset (for the QA module), isn't it more efficient to use knowledge in the form of a prior policy learned from it? It seems that there should be an experiment about it.\nWhat if it is used simultaneously with intrinsic reward methods such as RIDE? It is also important to check whether the effect of both methods is still helpful even if they are used at the same time.",
                "Limitations": "The authors adequately addressed the limitations and potential negative societal impact of their work.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper proposes an auxiliary reward scheme (EAGER) for instruction following RL (BabyAI framework) based on question generation (QG) and answering (QA). Concretely, QG is based on masked word modeling of the instruction, and QA is pre-trained with demo instructions and trajectories and fixed when training RL. The intuition is good and successful RL agent trajectories should make QA correct and easy, thus when QA is successful, an auxiliary reward proportional to correct answer confidence is given. The method is evaluated on several BabyAI tasks and shown on par with other methods (ELLA, RIDE) with more expert inductive bias for subgoal specification and judgement. Further analysis shows EAGER is fairly robust to QA performance, but some QA design choices are important.",
                "Strengths And Weaknesses": "Strengths: \n\nThe idea is neat, novel, effective, and provides a means to auxiliary reward for instruction following only using example instructions and trajectories, and minimal linguistic assumptions (what is noun/adj). In contrast, previous methods usually require domain knowledge about subgoal formulation/proposal/completion judgement. \n\nSome design choices for QA are reasonably explained in theory (e.g. policy invariance) and practice (e.g. no_answer, using confidence instead of binary reward).\n\nThe motivation and idea are well explained, and the paper is well structured and easy to read for most parts.\n\n\nWeakness:\nAs mentioned in the last part of the paper, two main limitations (and some of my extensions) are \n\nQA needs expert trajectories with instructions to pre-train. Arguably it is a weaker assumption compared to prior work, but I feel two important ablations are missing: direct PPO without the auxiliary reward (a trivial low-bound baseline), and just using the QA training trajectories to do imitation learning and warmstarting for RL agent (a trivial way to use these pre-training trajectories). \n\nBabyAI is perhaps too simple, and experiments seem a bit limited. I can see some sample efficiency advantage on PutNext tasks, but ELLA seems better than EAGER on Unlock and Sequence. What about other tasks in BabyAI, let alone more complex tasks like Alfred (which I feel this method might not easily work, given the visual observation and language instruction are both much harder). Some more experiments or tasks would make me believe the method is more general and robust.\n\n\nAlso pointed out in the paper (line 295),'\n\nEAGER might not work well on Sequence or tasks with temporal subgoals. In general, I don't have an intuition what properties of env/task does EAGER work better on and what not. Some analysis or examples of agent behavior or even how auxiliary reward changes with time would give me more concrete ideas.",
                "Questions": "Some minor points:\n\nMaybe in abstract, mention the domain (babyAI)?\nIs there any ablation for the policy invariance thing?",
                "Limitations": "They are discussed in the paper, see the weakness part.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "4 excellent",
                "Rating": "8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "In this paper, the authors proposed a reward shaping method for language-conditioned RL. The authors proposed to generate a set of questions based on natural language instructions, and then evaluate how likely the current trajectory answers the questions. The probabilities of the questions being correctly answered are used as intrinsic rewards. In the experiment, the authors worked on Baby AI benchmark and showed that the proposed reward shaping method helped to improve sample complexity and model performance.",
                "Strengths And Weaknesses": "Strengths:\nThe idea of using question generation and answering to do reward shaping for LC-RL is novel and interesting. It is like doing a self-check when a human follows a task instruction.\nThe paper showed that this idea works in the Baby AI benchmark.\nWeaknesses:\nWhile the idea is interesting, I think it is not sophisticated enough to generalized to more complex setting.\nFirst of all, the QG module generates a questions by masking a word (such as nouns and adjectives) in the linguistic instruction. However, for complex instructions, it is likely that the question can by answered by the masked instruction. For example, an instruction \"pick the [red ball], open the red door, ...., put the [red ball] on the chair\". If we mask the 'red ball' at the beginning of the sentence, we can still infer the answer from the 'red ball' at the end of the sentence. Therefore, even without the trajectory, the questions can be answered. I'd assume that it requires more than just masking words to generate a valid question.\nSecondly, the QA model is trained by using the full trajectory, however, when calculating intrinsic rewards, partial trajectories (trajectories up to the current timestep) are used. I would assume that when the partial trajectories are short, the QA model performance is bad. Have the authors investigated this?",
                "Questions": "Section 4.1 mentioned that if a question is answered, then it is removed from the set of questions. How to determine if a question is answered? Does the QA model have to predict the correct answer with high probability?",
                "Limitations": "N/A",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "soundness_avg": 3.25,
        "presentation_avg": 3.25,
        "contribution_avg": 3.25,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the proposed method, EAGER, is novel and interesting. The idea of using question generation and answering as an auxiliary reward for language-guided reinforcement learning is well-received. The paper is well-structured and clearly written, providing detailed explanations of the method and experiments.\n\nWhile there are some weaknesses pointed out by the reviewers, such as the need for expert trajectories for pre-training the QA module and the limitations of the experiments on the BabyAI benchmark, these limitations have been adequately addressed by the authors. The reviewers also suggest some additional experiments and analyses that could further strengthen the paper.\n\nOverall, the paper is technically solid and has the potential for moderate-to-high impact. The evaluations, resources, and reproducibility are well-addressed. There are no major concerns with respect to evaluation, resources, reproducibility, or ethical considerations.\n\nTherefore, based on the reviews and considering the strictness of the conference, I recommend accepting the paper."
    },
    "A_Causal_Analysis_of_Harm": {
        "link": "https://openreview.net//forum?id=q9XPBhFgL6z",
        "pub_url": "https://openreview.net/forum?id=q9XPBhFgL6z",
        "pdf_link": "https://openreview.net//pdf?id=q9XPBhFgL6z",
        "paper_id": "q9XPBhFgL6z",
        "title": "A_Causal_Analysis_of_Harm",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nThe paper aims at formally defining a qualitative notion of harm based on \"actual causality\". This is an important problem tackled, also or in even in particular for ML research. Many ethical issues raised about AI circle around a notion of harm, such as discrimination induced by classifiers, decision of autonomous agents, and even just harmful content of training sets. From this perspective, I really congratulate the authors. However, it is a downside that existing approaches to related approaches within the ML community are not discussed.  It is good tradition and practice to provide related work. Indeed, there is no actual causality model of harm yet (as far as I can say) but there are e.g. deontological approaches that could be mentioned or even briefly discussed such as \nLiwei Jiang, Jena D. Hwang, Chandra Bhagavatula, Ronan Le Bras, Maxwell Forbes, Jon Borchardt, Jenny Liang, Oren Etzioni, Maarten Sap, Yejin Choi: Delphi: Towards Machine Ethics and Norms. CoRR abs/2110.07574 (2021)\nPatrick Schramowski, Christopher Tauchmann, Kristian Kersting: Can Machines Help Us Answering Question 16 in Datasheets, and In Turn Reflecting on Inappropriate Content? In Proceedings of the ACM Conference on Fairness, Accountability, and Transparency (2022)\nPatrick Schramowski, Cigdem Turan, Nico Andersen, Constantin A. Rothkopf, Kristian Kersting. Large pre-trained language models contain human-like biases of what is right and wrong to do. Nature Machine Intelligence 4(3): 258-268 (2022)\nMoreover, the authors should discuss \"we define an event to cause harm whenever it causes the utility of the outcome to be lower than the default utility\" in more detail. Why is this a good definition? Let us for a moment equate utility with money then even too much money could be harmful due to network effects. In other words, it would be great if the authors could discuss a bit more the assumption made and their implications. This is even more important given the closeness to Bountly's notion of harm, replacing \u201cstate of affairs\u201d by \u201coutcomes\u201d, and associating with each outcome a utility. The main downside, however, is the missing illustration of how the presented formalization of harm actually will help to tackle some of the ethical issues of AI. Is this really the right way? But then, who knows, and this paper is indeed taking a very different step than the average NeurIPS paper. In my opinion, the reviewers raise some salient arguments about the suitability of this paper for NeruIPS. For instance, there are indeed positive examples presented only. However, then the negative examples in the review want to illustrate that actual causality is not the right tool either. Still, the discussion within the NeurIPS community would then help already. Moreover, not knowing to break the arm is still causing harm. Anyhow, it is exactly this type of discussion that makes the paper in my humble opinion interesting to the NeurIPS community. The discussions with the authors showed that it is a topic that will provoke a lot of discussions. And since the overall sentiment of the reviewers is positive, I recommend accepting the paper.",
        "reviews": [
            "Reviewer 1: \nSummary: The paper introduces a formal definition of harm that builds upon the modified Halpern-Pearl definition of actual causation. The main differences between the definition and previous definitions in the literature are the new concepts introduced in the causal utility model, which adds 1) a utility function u:R(O)\u2192[0,1] for some O\u2208V and 2) a \"default utility\" d\u2208[0,1] to the standard causal model. The authors introduce 7 examples of situations where an agent is or is not caused harm that are prominent in the literature. They argue that their definition of harm either correctly identifies the presence or absence of harm for each of these examples, or correctly identifies the precise source of ambiguity regarding the presence or absence of harm.\nStrengths And Weaknesses: Originality: The paper's main idea of introducing a causal definition of harm follows (Bontly, 2016). The novelty of the method lies in the fact that the definition introduced is formally stated using Halpern and Pearl's language of causal models. However, the novel components that the new definition introduces \u2013 default utility + the observation that preventing a worse outcome does not constitute harm \u2013 do not seem original, as they seem to be subsumed by the extended causal model for the purpose of determining whether or not harm was caused. (Halpern and Hitchcock, 2011 - https://arxiv.org/pdf/1309.1226.pdf). The concepts of the default world and utility function could be naturally included in the partial preorder if the previous definition of extended causal models were used. This would mean that harm may be defined as modified Halpern-Pearl causation under the extended model, using a particular partial preorder. Perhaps the authors could comment on and clarify this point, in case I am missing any subtlety here. (retracted, see \"Reply to reviewer's first response\", parts 1 and 2 below)\nQuality: The solution to the proposed research question ignores or misses prior work, as discussed above, and while While the solution to the proposed research question resolves an issue posed to a previous attempt in the literature made at defining harm using causation, the proposed definition lacks sufficient justification. Why would we need this specific definition instead of using the already existent one? Further, there There are no theoretical results introduced that demonstrate that counterexamples do not exist, and neither extensive human evaluation of the definition. Some potential counterexamples to the proposed definition are provided in the limitations section of this review.\nClarity: Overall, the paper is clearly written. The motivation of the paper is clear, as is the proposed definition, the example formulation, and the comparison of the definition's evaluations on the examples to those of the prior work mentioned in the paper.\nSignificance: Formalizations of harm become increasingly important as automated systems grow in ubiquity. Thus, the problem addressed by the paper and the idea of using actual causation to formalize the problem are important to the responsible development of large-scale AI systems. Overall, the motivation behind the paper is greatly appreciated.\nQuestions: Questions:\n\nWhy is the causal utility model defined and used, rather than Halpern's extended causal model in the definition of harm? It appears to me that harm as defined in the paper is equivalent to causation under an extended causal model with a particular partial preorder.\nIs it possible for harm to occur without causation? If not, why is this? Is it possible to introduce a result demonstrating that harm should occur due to causation?\nIt seems the notion of harm and blame should be related; do you have thoughts about this? Shouldn\u2019t the definition of harm incorporate the mental model of the agent taking an action that may have harmed the agent being harmed and that of the agent being harmed?\nThe authors emphasize that the definition of harm proposed in the paper is \"qualitative\", while RBT's definition is quantitative. I am not sure this is clear, can you explain this distinction and provide further elaborations on how to think about it?\nIf the definition of harm is qualitative, why does the causal utility model use a utility function that maps to a number in [0,1], rather than one that induces an ordering (or partial preorder) over O? As the authors note, it is unclear how to combine the numerical utilities of multiple agents. Is there a reason a mapping to [0,1] must be used rather than an ordering?\nThis definition of harm seems quite interesting, and I am a bit intrigued to know if counterexamples to the definition already exist (similar to the ones I showed in the limitations section).\nLimitations: I do not see potential for negative social impact of the work, as the work is aimed at formally defining harm - research which may help autonomous systems reason about minimizing harm in the future. Thus, I list some limitations of the work I observed below.\nInsufficient evaluation\nThe positive examples provided do not provide any guarantees that there are no counterexamples to the definition, and there are only 7 positive examples provided with no extensive human evaluation (by laypeople or by experts). I list two possible counterexamples below and would be curious to hear the authors\u2019 thoughts.\nThe relationship between harm and responsibility of agents is not considered by the work\nThis criticism is aimed at the fact that the definition proposed in the work does not consider the intention of the agents.\nConsider the following example:\n\nA driver honks her car horn at the driver in front of her, startling an apartment resident dangling his legs off of his balcony railing. The resident falls off the balcony in fright, becoming gravely injured upon hitting the ground.\n\nIt seems strange to claim that the driver harmed the resident, because 1) she could not have known that the resident was in danger of falling 2) even if she did know, the resident is partially at fault for willfully placing himself in a precarious situation. To make the example even more clear-cut:\n\nAn apartment resident decides that he will jump off his balcony upon the first car honk he hears. A driver honks her horn at the driver in front of her. Hearing this horn honk, the resident jumps off the balcony, becoming injured upon hitting the ground.\n\nNow, it seems even stranger to claim that the driver harmed the resident, because the resident took an action intended to harm himself, while the driver did not.\nThis issue could be resolved by using Halpern's concept of blame introduced in (Chockler and Halpern, 2014 - https://www.aaai.org/Papers/JAIR/Vol22/JAIR-2204.pdf). The extended causal model could also solve this problem.\nThe idea of blame is also touched upon in Example 7. If Victoria knew she was able to rescue Betty without breaking her arm (P=2) and chose to break her arm while rescuing her (P=1), she caused Betty harm, because this goes against social norms. However, if she did not know she'd be able to do so and accidentally broke her arm (P=2 was not an option), it is hard to argue that she caused Betty harm, as attempting to rescue Betty is well within social norms, and Betty's utility increased overall.\nCausing a decrease in utility in a socially unacceptable way (violating a default) is sufficient but not necessary for harm to occur\nThis criticism is aimed at the use of the \"default utility\" to represent all norms.\nThe work does not allow for situations where harm is done but reparations are made, and the agent in question is overall better off. For example: \n\nA thief assaults and robs a passerby but later, out of a guilty conscience, gives the money back, adding some additional money to more-than compensate for any physical and emotional distress caused. The passerby is happier than they would have been otherwise, because they needed the money.\n\nWhile the passerby is better off by the end of the story, the thief did cause harm to the passerby in the intermediate step of assaulting and robbing them. While this issue could be addressed by stating that the default world is the world where the thief does not assault/rob and gives the passerby money for no reason, this seems to be a difficult argument to make, as the thief is expected by social norms only to not commit any crimes. Setting to default world to the world where the thief gives money to the passerby would mean that everyone is harming the passerby by not giving money to them.\nAn even more clear-cut version of this example follows:\n\nA thief assaults and robs a passerby. After the local media reports on the crimes committed, many people donate money to the passerby in sympathy. The passerby agrees that he is better off now than he would have been had he not been robbed and assaulted.\n\nIt seems that the thief's actions, contrary to his expectations, helped the passerby overall. Is it still true that the thief did not cause harm to the passerby?\nThe issue could also be fixed by using the extended causal model to, regardless of utility, label any world where the thief commits a crime as less normal than a world where the thief does not commit a crime.\nEthics Flag: No\nSoundness: 1 poor\nPresentation: 3 good\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: [REMARK: This is an emergency review, that is, the reviewer did neither select autonomously into this paper out of interest/expertise nor was the reviewer granted with sufficient time (with respect to standard time frames) to appropriately provide a review. Please take the review with caution, the confidence level will be adjusted accordingly.]\nThe paper presents a formalization of the concept of \"harm\" (to harm someone) using structural causal models (SCM) as found in the counterfactual theory of causality vocally discussed by Judea Pearl. Specifically, the authors extend SCMs to cover a \"default utility\" (referred to as causal utility model) to then propose 3 conditions (H1 to H3) which captures (defines) whether an even x\u2192 causes harm to an agent ag. The authors provide a motivation, a comparison to other definitions (in terms of their presented formalism) and finally discuss several philosophical key examples displaying the advantages of their proposed definition.\nStrengths And Weaknesses: Strengths\nDiscussing and overall researching into harm and how to capture/measure it is certainly timely in the advent of discussions around AGI alignment etc. The same holds for the intention of deriving a causal account since causal models allow for an explicable, interpretable modelling scheme. As the authors suggest, one can only debate about assumptions if said modelling assumption are recognizable. The presented formalization copes well with the discussed examples, which cover key philosophical dilemmas. Capturing formally, with thought through notions, otherwise intangible concepts like harm is an important step towards accountable intelligent systems.\nWeaknesses\nWhile one can question on a more general note whether discussing this topic within NeurIPS (especially in the presented form) is sensible, I believe the importance on a societal scale for such a work is undeniable and NeurIPS with both its breadth and influence would fit as a great platform. To comment on the paper itself more importantly, the presentation sets its focus on the formal account of harm, and while it does motivate generally and discuss specifically, the presentation (of otherwise very visual/intuitive ideas) is arguably dry. That is, to convey the ideas or spread the formalized notion (which is likely the key interest of the authors) alternate means of presentation using illustrations with figures but also visualizations of possibly synthesized versions of the examples would help in doing so. Regarding the mathematical account, the lack of analysis for induced properties (when is the computation feasible, what models do satisfy the condition in the first place, etc.) is a weakness (albeit a likely difficult one to fix since it is difficult enough already to capture a philosophical core problem that has existed for centuries mathematically).\nQuestions: The questions are derived mostly from aspects mentioned in the \"Weaknesses\" section. I'd invite the authors to answer these questions to overcome the observed weaknesses for improving the paper to ultimately increase the chances of both contribution and visibility to the community. The list of questions is unordered and they range in quality and speed of expected answer (some are minor, quickly answerable whereas others are more fundamental, crucial, maybe difficult to answer):\n\nHow can we cope with temporal notions?\nHow can we overcome intractability of harm computation, in the face of our necessity to compute since otherwise a formalized notion would have no practical implications?\nUnder which circumstances can our causal model guarantee that our harm computation will be approximately correct?\nLimitations: No contradictions or any sort of relevant mistake have been detected in the paper. The overall clarity of the paper is a clear advantage. Existing bodies of work are being referenced accordingly throughout the paper.\nThere is nothing to be reproduced, therefore, naturally, there is also no code. Societal impact is being discussed throughout.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: In this paper, the authors proposed the first qualitative causal framework that is used to define the harm and conceptually show their framework can solve various controversial real-life examples in terms of minimizing the harm.\nStrengths And Weaknesses: Strength:\nIt is by far the first literature, as far as I know, that attempts to discuss forming the framework for evaluating harm. It also discussed how to apply this framework to several real-life problems. \nWeakness:\nThough I understand the difficulty of quantitatively defining the utility function, the lack of discussion of it could discourage its application to reality, I will discuss it in detail in the questions session.\nQuestions: The authors applied the framework of harm to several real-life scenarios. However, one thing in common is that all the scenarios consider defining harm for a single agent. However, in reality, the harm is usually multi-agents based. Without a clear quantitative suggestion for the utility function, it is hard to minimize the total harm. Even without considering the dependency among the agents, simply using the framework proposed by the author to make the decision could be challenging (Consider the Trolley problem). I suggest the authors consider how to address this issue or explicitly state this limitation.\nLimitations: The utility function u which measures the goodness of the decision is a vague term. In reality, the way of defining such a utility function could invoke controversy and fairness issues, which have also been discussed by the author.\nEthics Flag: Yes\nEthics Review Area: Discrimination / Bias / Fairness Concerns\nSoundness: 2 fair\nPresentation: 4 excellent\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper proposes a way to define harm in a causal way. The work in more on of a philosophical level, trying to criticize the fact that the definition of harm in philosophical studies is generally devoid of causality and putting forward the notion that the use of causality theory can define a more general definition of harm. Several examples are presented throughout the paper that show how the causal analysis and a new definition of harm can handle several standard examples from literature and can thus be used for effective reasoning in various domains and situations.\nStrengths And Weaknesses: Strengths:\n\nThe paper tackles a very important and sensitive problem of defining harm. Since this can have multiple interpretations and can be conceived by different people in unique ways, trying to  come up with a causal-standard definition is indeed a nice effort.\n\nThe paper is written beautifully and the examples are crystal clear. In my opinion, even a person with little knowledge of causality will be able to follow the paper and get an overall idea about the main message of this work.\n\nThe definition of harm in section 3 seems well thought out and well sketched.\n\n\nWeaknesses:\n\nThe method seems to have a very heavy dependence on the default utility. \n\nI do not agree with the Batman and Robin example, where the definition concludes that Robin was harmed. Just because Robin receives a new set of clubs at start of every season, it still does not make him entitled to receive it the next year as well. There can be the effects of some hidden confounders that are being ignored here.\n\nThe default utility of receiving or not receiving a tip in Example 4 seems incomplete. For example, what about the cases where the exact amount of tip is also important? Say the waiter is better off if he/she receives 15% of the total bill as a tip instead of 5% in the US.\n\n\nOverall, this is an interesting take combining philosophical arguments with causality in a more explicit way. I would be eager to see the author's response to the raised points.\nQuestions: In addition to some important points raised in the weaknesses section, I have a couple of specific questions:\n\nHow will the definition of harm be extended/modified if we have dependent exogeneous variables in the causal graph?\n\nHow are confounders handled in the causal definition of harm?\nLimitations: This is tricky. Although I do not see any specific negative societal impact, defining and constraining harm to a single definition might be a little bit risky. As I have mentioned in my review before, each can have his/her own interpretation with respect to the definition.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 4 excellent\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 5: \nSummary: The work proposes a qualitative definition of harm based on causal models in the context of dealing with autonomous AI systems. The authors state that the notion of harm is ill-defined and motivate their qualitative approach on the observation that much of the discussion of harm is qualitative. After reviewing causal models and describing the introduced definition of harm, the work applies and discusses it (including its limitations) on various examples.\nStrengths And Weaknesses: Strengths\n\nS1: The definition is inspired by previous work (RBT, Bontly) and extends them to a causal definition.\n\nS2: Besides some minor issues (see following weaknesses), the proposed definition is well described and understandable. \n\nS3: The extensive examples, including the discussions contained in the main text and the supplement, give a great overview and intuition of the proposed definition.\n\n\nWeaknesses\n\nW1: While building on Y. Halpern [11] and Y. Halpern and J. Pearl. [13] working with the concept of 'actual causality', the paper might be improved by briefly discussing differences to the common approach of probabilistic structural causal models [X1, X2], where variables are considered to be sampled from probability distributions with structural equations including random noise terms. Especially recursive deterministic computation of variables as described in the paper must assume that no noise terms are included in the system. The authors might consider to state this assumption explicitly.\n\nW2: Furthermore, the relations between exogenous and endogenous variables (line 112) seems to be more strict than the standard definition using 'Pearlian causality'. E.g. compare to [X2] p.23 \u201cEndogeneous variables are those that the modeler tries to understand, while exogenous ones are determined by factors outside the model, and are taken as given.\u201d While similar in the intention, Peters et al. give no definition of how to treat the relationship between endogenous and exogenous variables. Assuming endogenous variables to be fully determined by exogenous factors is a strong assumption that, again, only holds under the assumption that all exogenous variables are known and observed and no additional random noise terms are influencing the system.\n\n\n[X1] Pearl, J. (2009). Causality (Cambridge university press)\n[X2] Peters, J., Janzing, D., and Sch\u00f6lkopf, B. (2017). Elements of causal inference: foundations and learning algorithms (The MIT Press)\nMinor comments\n\nTypo line 104 \"that that\"\nTypo line 166 \"beem\"\nQuestions: See W1 and W2 above.\nLimitations: The authors adequately addressed the limitations.\nEthics Flag: No\nEthics Review Area: I don\u2019t know\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The paper introduces a formal definition of harm that builds upon the modified Halpern-Pearl definition of actual causation. The main differences between the definition and previous definitions in the literature are the new concepts introduced in the causal utility model, which adds 1) a utility function u:R(O)\u2192[0,1] for some O\u2208V and 2) a \"default utility\" d\u2208[0,1] to the standard causal model. The authors introduce 7 examples of situations where an agent is or is not caused harm that are prominent in the literature. They argue that their definition of harm either correctly identifies the presence or absence of harm for each of these examples, or correctly identifies the precise source of ambiguity regarding the presence or absence of harm.",
                "Strengths And Weaknesses": "Originality: The paper's main idea of introducing a causal definition of harm follows (Bontly, 2016). The novelty of the method lies in the fact that the definition introduced is formally stated using Halpern and Pearl's language of causal models. However, the novel components that the new definition introduces \u2013 default utility + the observation that preventing a worse outcome does not constitute harm \u2013 do not seem original, as they seem to be subsumed by the extended causal model for the purpose of determining whether or not harm was caused. (Halpern and Hitchcock, 2011 - https://arxiv.org/pdf/1309.1226.pdf). The concepts of the default world and utility function could be naturally included in the partial preorder if the previous definition of extended causal models were used. This would mean that harm may be defined as modified Halpern-Pearl causation under the extended model, using a particular partial preorder. Perhaps the authors could comment on and clarify this point, in case I am missing any subtlety here. (retracted, see \"Reply to reviewer's first response\", parts 1 and 2 below)\nQuality: The solution to the proposed research question ignores or misses prior work, as discussed above, and while While the solution to the proposed research question resolves an issue posed to a previous attempt in the literature made at defining harm using causation, the proposed definition lacks sufficient justification. Why would we need this specific definition instead of using the already existent one? Further, there There are no theoretical results introduced that demonstrate that counterexamples do not exist, and neither extensive human evaluation of the definition. Some potential counterexamples to the proposed definition are provided in the limitations section of this review.\nClarity: Overall, the paper is clearly written. The motivation of the paper is clear, as is the proposed definition, the example formulation, and the comparison of the definition's evaluations on the examples to those of the prior work mentioned in the paper.\nSignificance: Formalizations of harm become increasingly important as automated systems grow in ubiquity. Thus, the problem addressed by the paper and the idea of using actual causation to formalize the problem are important to the responsible development of large-scale AI systems. Overall, the motivation behind the paper is greatly appreciated.",
                "Questions": "Questions:\n\nWhy is the causal utility model defined and used, rather than Halpern's extended causal model in the definition of harm? It appears to me that harm as defined in the paper is equivalent to causation under an extended causal model with a particular partial preorder.\nIs it possible for harm to occur without causation? If not, why is this? Is it possible to introduce a result demonstrating that harm should occur due to causation?\nIt seems the notion of harm and blame should be related; do you have thoughts about this? Shouldn\u2019t the definition of harm incorporate the mental model of the agent taking an action that may have harmed the agent being harmed and that of the agent being harmed?\nThe authors emphasize that the definition of harm proposed in the paper is \"qualitative\", while RBT's definition is quantitative. I am not sure this is clear, can you explain this distinction and provide further elaborations on how to think about it?\nIf the definition of harm is qualitative, why does the causal utility model use a utility function that maps to a number in [0,1], rather than one that induces an ordering (or partial preorder) over O? As the authors note, it is unclear how to combine the numerical utilities of multiple agents. Is there a reason a mapping to [0,1] must be used rather than an ordering?\nThis definition of harm seems quite interesting, and I am a bit intrigued to know if counterexamples to the definition already exist (similar to the ones I showed in the limitations section).",
                "Limitations": "I do not see potential for negative social impact of the work, as the work is aimed at formally defining harm - research which may help autonomous systems reason about minimizing harm in the future. Thus, I list some limitations of the work I observed below.\nInsufficient evaluation\nThe positive examples provided do not provide any guarantees that there are no counterexamples to the definition, and there are only 7 positive examples provided with no extensive human evaluation (by laypeople or by experts). I list two possible counterexamples below and would be curious to hear the authors\u2019 thoughts.\nThe relationship between harm and responsibility of agents is not considered by the work\nThis criticism is aimed at the fact that the definition proposed in the work does not consider the intention of the agents.\nConsider the following example:\n\nA driver honks her car horn at the driver in front of her, startling an apartment resident dangling his legs off of his balcony railing. The resident falls off the balcony in fright, becoming gravely injured upon hitting the ground.\n\nIt seems strange to claim that the driver harmed the resident, because 1) she could not have known that the resident was in danger of falling 2) even if she did know, the resident is partially at fault for willfully placing himself in a precarious situation. To make the example even more clear-cut:\n\nAn apartment resident decides that he will jump off his balcony upon the first car honk he hears. A driver honks her horn at the driver in front of her. Hearing this horn honk, the resident jumps off the balcony, becoming injured upon hitting the ground.\n\nNow, it seems even stranger to claim that the driver harmed the resident, because the resident took an action intended to harm himself, while the driver did not.\nThis issue could be resolved by using Halpern's concept of blame introduced in (Chockler and Halpern, 2014 - https://www.aaai.org/Papers/JAIR/Vol22/JAIR-2204.pdf). The extended causal model could also solve this problem.\nThe idea of blame is also touched upon in Example 7. If Victoria knew she was able to rescue Betty without breaking her arm (P=2) and chose to break her arm while rescuing her (P=1), she caused Betty harm, because this goes against social norms. However, if she did not know she'd be able to do so and accidentally broke her arm (P=2 was not an option), it is hard to argue that she caused Betty harm, as attempting to rescue Betty is well within social norms, and Betty's utility increased overall.\nCausing a decrease in utility in a socially unacceptable way (violating a default) is sufficient but not necessary for harm to occur\nThis criticism is aimed at the use of the \"default utility\" to represent all norms.\nThe work does not allow for situations where harm is done but reparations are made, and the agent in question is overall better off. For example: \n\nA thief assaults and robs a passerby but later, out of a guilty conscience, gives the money back, adding some additional money to more-than compensate for any physical and emotional distress caused. The passerby is happier than they would have been otherwise, because they needed the money.\n\nWhile the passerby is better off by the end of the story, the thief did cause harm to the passerby in the intermediate step of assaulting and robbing them. While this issue could be addressed by stating that the default world is the world where the thief does not assault/rob and gives the passerby money for no reason, this seems to be a difficult argument to make, as the thief is expected by social norms only to not commit any crimes. Setting to default world to the world where the thief gives money to the passerby would mean that everyone is harming the passerby by not giving money to them.\nAn even more clear-cut version of this example follows:\n\nA thief assaults and robs a passerby. After the local media reports on the crimes committed, many people donate money to the passerby in sympathy. The passerby agrees that he is better off now than he would have been had he not been robbed and assaulted.\n\nIt seems that the thief's actions, contrary to his expectations, helped the passerby overall. Is it still true that the thief did not cause harm to the passerby?\nThe issue could also be fixed by using the extended causal model to, regardless of utility, label any world where the thief commits a crime as less normal than a world where the thief does not commit a crime.",
                "Ethics Flag": "No",
                "Soundness": "1 poor",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "[REMARK: This is an emergency review, that is, the reviewer did neither select autonomously into this paper out of interest/expertise nor was the reviewer granted with sufficient time (with respect to standard time frames) to appropriately provide a review. Please take the review with caution, the confidence level will be adjusted accordingly.]\nThe paper presents a formalization of the concept of \"harm\" (to harm someone) using structural causal models (SCM) as found in the counterfactual theory of causality vocally discussed by Judea Pearl. Specifically, the authors extend SCMs to cover a \"default utility\" (referred to as causal utility model) to then propose 3 conditions (H1 to H3) which captures (defines) whether an even x\u2192 causes harm to an agent ag. The authors provide a motivation, a comparison to other definitions (in terms of their presented formalism) and finally discuss several philosophical key examples displaying the advantages of their proposed definition.",
                "Strengths And Weaknesses": "Strengths\nDiscussing and overall researching into harm and how to capture/measure it is certainly timely in the advent of discussions around AGI alignment etc. The same holds for the intention of deriving a causal account since causal models allow for an explicable, interpretable modelling scheme. As the authors suggest, one can only debate about assumptions if said modelling assumption are recognizable. The presented formalization copes well with the discussed examples, which cover key philosophical dilemmas. Capturing formally, with thought through notions, otherwise intangible concepts like harm is an important step towards accountable intelligent systems.\nWeaknesses\nWhile one can question on a more general note whether discussing this topic within NeurIPS (especially in the presented form) is sensible, I believe the importance on a societal scale for such a work is undeniable and NeurIPS with both its breadth and influence would fit as a great platform. To comment on the paper itself more importantly, the presentation sets its focus on the formal account of harm, and while it does motivate generally and discuss specifically, the presentation (of otherwise very visual/intuitive ideas) is arguably dry. That is, to convey the ideas or spread the formalized notion (which is likely the key interest of the authors) alternate means of presentation using illustrations with figures but also visualizations of possibly synthesized versions of the examples would help in doing so. Regarding the mathematical account, the lack of analysis for induced properties (when is the computation feasible, what models do satisfy the condition in the first place, etc.) is a weakness (albeit a likely difficult one to fix since it is difficult enough already to capture a philosophical core problem that has existed for centuries mathematically).",
                "Questions": "The questions are derived mostly from aspects mentioned in the \"Weaknesses\" section. I'd invite the authors to answer these questions to overcome the observed weaknesses for improving the paper to ultimately increase the chances of both contribution and visibility to the community. The list of questions is unordered and they range in quality and speed of expected answer (some are minor, quickly answerable whereas others are more fundamental, crucial, maybe difficult to answer):\n\nHow can we cope with temporal notions?\nHow can we overcome intractability of harm computation, in the face of our necessity to compute since otherwise a formalized notion would have no practical implications?\nUnder which circumstances can our causal model guarantee that our harm computation will be approximately correct?",
                "Limitations": "No contradictions or any sort of relevant mistake have been detected in the paper. The overall clarity of the paper is a clear advantage. Existing bodies of work are being referenced accordingly throughout the paper.\nThere is nothing to be reproduced, therefore, naturally, there is also no code. Societal impact is being discussed throughout.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "In this paper, the authors proposed the first qualitative causal framework that is used to define the harm and conceptually show their framework can solve various controversial real-life examples in terms of minimizing the harm.",
                "Strengths And Weaknesses": "Strength:\nIt is by far the first literature, as far as I know, that attempts to discuss forming the framework for evaluating harm. It also discussed how to apply this framework to several real-life problems. \nWeakness:\nThough I understand the difficulty of quantitatively defining the utility function, the lack of discussion of it could discourage its application to reality, I will discuss it in detail in the questions session.",
                "Questions": "The authors applied the framework of harm to several real-life scenarios. However, one thing in common is that all the scenarios consider defining harm for a single agent. However, in reality, the harm is usually multi-agents based. Without a clear quantitative suggestion for the utility function, it is hard to minimize the total harm. Even without considering the dependency among the agents, simply using the framework proposed by the author to make the decision could be challenging (Consider the Trolley problem). I suggest the authors consider how to address this issue or explicitly state this limitation.",
                "Limitations": "The utility function u which measures the goodness of the decision is a vague term. In reality, the way of defining such a utility function could invoke controversy and fairness issues, which have also been discussed by the author.",
                "Ethics Flag": "Yes",
                "Ethics Review Area": "Discrimination / Bias / Fairness Concerns",
                "Soundness": "2 fair",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposes a way to define harm in a causal way. The work in more on of a philosophical level, trying to criticize the fact that the definition of harm in philosophical studies is generally devoid of causality and putting forward the notion that the use of causality theory can define a more general definition of harm. Several examples are presented throughout the paper that show how the causal analysis and a new definition of harm can handle several standard examples from literature and can thus be used for effective reasoning in various domains and situations.",
                "Strengths And Weaknesses": "Strengths:\n\nThe paper tackles a very important and sensitive problem of defining harm. Since this can have multiple interpretations and can be conceived by different people in unique ways, trying to  come up with a causal-standard definition is indeed a nice effort.\n\nThe paper is written beautifully and the examples are crystal clear. In my opinion, even a person with little knowledge of causality will be able to follow the paper and get an overall idea about the main message of this work.\n\nThe definition of harm in section 3 seems well thought out and well sketched.\n\n\nWeaknesses:\n\nThe method seems to have a very heavy dependence on the default utility. \n\nI do not agree with the Batman and Robin example, where the definition concludes that Robin was harmed. Just because Robin receives a new set of clubs at start of every season, it still does not make him entitled to receive it the next year as well. There can be the effects of some hidden confounders that are being ignored here.\n\nThe default utility of receiving or not receiving a tip in Example 4 seems incomplete. For example, what about the cases where the exact amount of tip is also important? Say the waiter is better off if he/she receives 15% of the total bill as a tip instead of 5% in the US.\n\n\nOverall, this is an interesting take combining philosophical arguments with causality in a more explicit way. I would be eager to see the author's response to the raised points.",
                "Questions": "In addition to some important points raised in the weaknesses section, I have a couple of specific questions:\n\nHow will the definition of harm be extended/modified if we have dependent exogeneous variables in the causal graph?\n\nHow are confounders handled in the causal definition of harm?",
                "Limitations": "This is tricky. Although I do not see any specific negative societal impact, defining and constraining harm to a single definition might be a little bit risky. As I have mentioned in my review before, each can have his/her own interpretation with respect to the definition.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The work proposes a qualitative definition of harm based on causal models in the context of dealing with autonomous AI systems. The authors state that the notion of harm is ill-defined and motivate their qualitative approach on the observation that much of the discussion of harm is qualitative. After reviewing causal models and describing the introduced definition of harm, the work applies and discusses it (including its limitations) on various examples.",
                "Strengths And Weaknesses": "Strengths\n\nS1: The definition is inspired by previous work (RBT, Bontly) and extends them to a causal definition.\n\nS2: Besides some minor issues (see following weaknesses), the proposed definition is well described and understandable. \n\nS3: The extensive examples, including the discussions contained in the main text and the supplement, give a great overview and intuition of the proposed definition.\n\n\nWeaknesses\n\nW1: While building on Y. Halpern [11] and Y. Halpern and J. Pearl. [13] working with the concept of 'actual causality', the paper might be improved by briefly discussing differences to the common approach of probabilistic structural causal models [X1, X2], where variables are considered to be sampled from probability distributions with structural equations including random noise terms. Especially recursive deterministic computation of variables as described in the paper must assume that no noise terms are included in the system. The authors might consider to state this assumption explicitly.\n\nW2: Furthermore, the relations between exogenous and endogenous variables (line 112) seems to be more strict than the standard definition using 'Pearlian causality'. E.g. compare to [X2] p.23 \u201cEndogeneous variables are those that the modeler tries to understand, while exogenous ones are determined by factors outside the model, and are taken as given.\u201d While similar in the intention, Peters et al. give no definition of how to treat the relationship between endogenous and exogenous variables. Assuming endogenous variables to be fully determined by exogenous factors is a strong assumption that, again, only holds under the assumption that all exogenous variables are known and observed and no additional random noise terms are influencing the system.\n\n\n[X1] Pearl, J. (2009). Causality (Cambridge university press)\n[X2] Peters, J., Janzing, D., and Sch\u00f6lkopf, B. (2017). Elements of causal inference: foundations and learning algorithms (The MIT Press)\nMinor comments\n\nTypo line 104 \"that that\"\nTypo line 166 \"beem\"",
                "Questions": "See W1 and W2 above.",
                "Limitations": "The authors adequately addressed the limitations.",
                "Ethics Flag": "No",
                "Ethics Review Area": "I don\u2019t know",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.2,
        "confidence_avg": 3.2,
        "soundness_avg": 2.2,
        "presentation_avg": 3.2,
        "contribution_avg": 2.6,
        "ai_sum_meta": "Recommendation: Reject\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that there are several weaknesses in the paper. Reviewer 1 points out that the proposed definition of harm lacks sufficient justification and does not consider the intention of the agents. Reviewer 2 raises concerns about the heavy dependence on the default utility and the lack of analysis for induced properties. Reviewer 3 questions the applicability of the framework to multi-agent scenarios and the lack of discussion on the utility function. Reviewer 4 disagrees with the conclusion of one of the examples and raises questions about confounders and dependent exogenous variables. Reviewer 5 suggests discussing the differences with probabilistic structural causal models and clarifying the relationship between endogenous and exogenous variables. \n\nConsidering these weaknesses and limitations, it is recommended to reject the paper."
    },
    "On-Demand_Sampling:_Learning_Optimally_from_Multiple_Distributions": {
        "link": "https://openreview.net//forum?id=FR289LMkmxZ",
        "pub_url": "https://openreview.net/forum?id=FR289LMkmxZ",
        "pdf_link": "https://openreview.net//pdf?id=FR289LMkmxZ",
        "paper_id": "FR289LMkmxZ",
        "title": "On-Demand_Sampling:_Learning_Optimally_from_Multiple_Distributions",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nThis paper studies multi-distribution learning; it formulates the problem as a zero-sum game with the stochastic payoff and then uses tools from the framework of stochastic mirror descent to obtain optimal sample complexities for various collaborative learning settings.  All reviewers are very positive about this paper: interesting problems, nice techniques, and optimal results.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper studies the problem of multi-distribution learning. Specifically, the paper proposes several sample complexity bounds for on-demand learning. The central contribution of the paper is to first frame collaborative learning as a zero-sum game with stochastic payoff and then use tools from the framework of stochastic mirror descent to obtain sharp rates for various collaborative learning settings. The authors obtain near-optimal rates for agnostic collaborative learning, group DRO, and agnostic federated learning.\nStrengths And Weaknesses: \nThe paper is well organized and very easy to understand. The main contributions are listed clearly, and the authors provide a good overview of the approach as well.\nThe approach appears to be novel and is a general technique to handle learning from multiple distributions. The authors provide near-optimal rates for a variety of problems that improve over the prior state-of-the-art by a significant amount.\nThe experimental results confirm an improvement in worst-case accuracy on 3 datasets. It would be beneficial to see performance on a dataset with larger variation than WaterBirds and Celeb-A (e.g., YFCC), but that is beyond the scope of this paper.\nQuestions: \nI am curious to know if it is possible to obtain data-dependent bounds for the 3 settings under this framework?\nLimitations: The authors have not explicitly discussed limitations of their approach. Since this work is theoretical, it is unlikely it will have potential negative societal impacts.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 3 good\nContribution: 4 excellent\nRating: 8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The authors propose learning algorithms for multi-distribution learning problems and establish optimal sample complexity bounds for the proposed algorithms. The authors improve upon the existing results and also correct an error in an existing result to provide lower bounds for their framework. Specifically, the authors present results for two settings of collaborative learning and group DRO formulation. The developed algorithms rely on the stochastic algorithms utilized to solve stochastic zero-sum games.\nStrengths And Weaknesses: Overall, the paper is well written and the presented results are strong. The authors improve upon the state-of-the-art complexity bounds (both upper and lower bounds) by significant factors. The paper feels a bit difficult to read and dense, the authors should try to make the paper more reader-friendly. Here are some comments the authors might consider addressing. \n\nThe algorithms authors have proposed for solving the problems are based on popular min-max formulations and the algorithms are similar to stochastic gradient descent ascent algorithms. Please comment. \n\nIt is not clear what is the difference between Algorithm 1 and 2. Both the algorithms look more or less similar. Why both the algorithms are required in the main text of the paper. \n\nIn lines 198-199 it is not clear why Errv(w(1:T))\u2265Reg-Min(p,q)+Reg-Max(p,q). Please add a discussion/reference. \n\nIn eq (7), why the gradients are defined by loss functions. It would be helpful if the authors can clarify. \n\nIn Line 203 the authors mention with noisy estimates of the gradients the no-regret algorithms become advantageous. Please clarify why this is the case?\n\nThe authors should discuss the relevance of Lemma 3.1. Moreover, it is not clear why the total cost of randomness is 2t, specifically, why the total cost of randomness is independent of T?\n\nIn Theorem 5.1, why compactness of parameter space \u0398 is required? For general optimization problems, this compactness is not required in general. \n\nThe context of on-demand sampling is not clear from the Algorithms, maybe the authors can add some discussion about the on-demand sampling after stating the algorithms.\n\n\nMinor Comments:\n\nPlease define the dimension of w~ in eq. (4). I assume that w~ is a constructed by stacking w~i's. \nThe use of the term \"multi-agent tradeoffs\" in the first sentence of the abstract is not clear. \nIn the statement of Lemma 2.1 please correct the notation {w}t=1T\nIn line 189 \u03d5(i,j) is not properly defined please clarify that i\u2208H and j\u2208D.\nThe definition of the deterministic estimator hpMaj is not clear.\nQuestions: This is a theoretical work that improves upon the existing results. The paper is very dense which makes it a little difficult to read, the authors might consider updating the paper by moving some redundant parts to the appendix for improving the readability of the paper.\nLimitations: Yes.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 3 good\nContribution: 4 excellent\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper investigates the on-demand sample complexity of multi-distribution learning. The authors establish the optimal sample complexity of collaborative, group distributionally robust, and agnostic federated learning. These results improve upon the best-known sample complexity in the prior work. The main approach is to regard the problem as a stochastic zero-sum game and apply a variant of stochastic mirror descent approach.\nStrengths And Weaknesses: Strengths:\n\nThe studied problem is important in the machine learning area.\nThe theoretical results are optimal, which closes this direction.\nThe approaches are standard, which widens the application of stochastic mirror descent.\n\nWeaknesses:\n\nIt may be better to provide some empirical results on the proposed algorithms. The theoretical results will be more convincing if the performance beats the baselines in prior works.\nQuestions: The paper considers n predefined distributions. \n\nCan the result generalize to a family of distributions that has a certain bounded capacity, e.g., all exponential distributions?\nCan we reduce the dependence on n if these distributions have some relations, e.g., each one is a uniform distribution on a certain subset of k elements?\nLimitations: Not\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper gives improved algorithms for three settings of learning from multiple distributions: collaborative, group distributionally robust, and fair federated learning. Previous results usually bounds the sample complexity by a certain overhead factor multiplied by the number of samples needed for learning a single distribution. In contrast, the sample complexity bounds derived in this work only have additive overheads.\nIn more detail, for (\u03f5,\u03b4)-collaborative learning on hypothesis class H and n distributions, Theorem 4.1 gives an upper bound of O(\u03f5\u22122(log\u2061|H|+nlog\u2061(n/\u03b4))), which exceeds the O(\u03f5\u22122log\u2061(|H|/\u03b4)) bound for single-distribution learning by an additive term of (nlog\u2061n)/\u03f52 (when \u03b4=\u03a9(1)). In contrast, the previous best bound of Nguyen and Zakynthinou (2018) is at least (log\u2061n)\u22c5(log\u2061|H|/\u03f55). Theorem 4.3 gives an improved lower bound, which matches the upper bound when n and log\u2061|H| are polynomially related.\nThe approach taken by the authors (which is implicit in prior work) is to view the collaborative learning setting as a zero-sum game between the learner (which selects a hypothesis) and an adversary (which chooses one of the n data distributions). The major task is then to find an (approximate) equilibrium of this game, using as few samples as possible. The key technical observation is an asymmetry between the two players in terms of how much data is needed for getting an unbiased estimate of the gradient, and to what extent these data can be reused for estimating the gradient at different locations.\nStrengths And Weaknesses: This work introduces new tools to the line of research on learning from multiple distributions and further closes the gap between the upper and lower bounds. Both the results and the techniques should be interesting to the community. The new algorithm and its analysis seem highly nontrivial, and I thought the authors did a good job in sketching the proof in the main paper. In summary, this is a solid and well-presented work and should be accepted.\nOne weakness of the paper is that the algorithms are computationally inefficient. While the main focus is sample complexity, some discussion on the computational aspect seems necessary.\nQuestions: \nAre there any natural/simple/structured hypothesis classes for which that the algorithm could be efficiently implemented?\n\nThe algorithm outputs a (weighted) majority vote of hypotheses. Are previous algorithms also improper, and are there evidence that the problem becomes hard for proper learning?\n\n\nMinor comments:\n\nLine 195: What is \"VI\"?\nLimitations: Limitations were not discussed.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper studies the problem of multi-distribution learning. Specifically, the paper proposes several sample complexity bounds for on-demand learning. The central contribution of the paper is to first frame collaborative learning as a zero-sum game with stochastic payoff and then use tools from the framework of stochastic mirror descent to obtain sharp rates for various collaborative learning settings. The authors obtain near-optimal rates for agnostic collaborative learning, group DRO, and agnostic federated learning.",
                "Strengths And Weaknesses": "The paper is well organized and very easy to understand. The main contributions are listed clearly, and the authors provide a good overview of the approach as well.\nThe approach appears to be novel and is a general technique to handle learning from multiple distributions. The authors provide near-optimal rates for a variety of problems that improve over the prior state-of-the-art by a significant amount.\nThe experimental results confirm an improvement in worst-case accuracy on 3 datasets. It would be beneficial to see performance on a dataset with larger variation than WaterBirds and Celeb-A (e.g., YFCC), but that is beyond the scope of this paper.",
                "Questions": "I am curious to know if it is possible to obtain data-dependent bounds for the 3 settings under this framework?",
                "Limitations": "The authors have not explicitly discussed limitations of their approach. Since this work is theoretical, it is unlikely it will have potential negative societal impacts.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "3 good",
                "Contribution": "4 excellent",
                "Rating": "8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors propose learning algorithms for multi-distribution learning problems and establish optimal sample complexity bounds for the proposed algorithms. The authors improve upon the existing results and also correct an error in an existing result to provide lower bounds for their framework. Specifically, the authors present results for two settings of collaborative learning and group DRO formulation. The developed algorithms rely on the stochastic algorithms utilized to solve stochastic zero-sum games.",
                "Strengths And Weaknesses": "Overall, the paper is well written and the presented results are strong. The authors improve upon the state-of-the-art complexity bounds (both upper and lower bounds) by significant factors. The paper feels a bit difficult to read and dense, the authors should try to make the paper more reader-friendly. Here are some comments the authors might consider addressing. \n\nThe algorithms authors have proposed for solving the problems are based on popular min-max formulations and the algorithms are similar to stochastic gradient descent ascent algorithms. Please comment. \n\nIt is not clear what is the difference between Algorithm 1 and 2. Both the algorithms look more or less similar. Why both the algorithms are required in the main text of the paper. \n\nIn lines 198-199 it is not clear why Errv(w(1:T))\u2265Reg-Min(p,q)+Reg-Max(p,q). Please add a discussion/reference. \n\nIn eq (7), why the gradients are defined by loss functions. It would be helpful if the authors can clarify. \n\nIn Line 203 the authors mention with noisy estimates of the gradients the no-regret algorithms become advantageous. Please clarify why this is the case?\n\nThe authors should discuss the relevance of Lemma 3.1. Moreover, it is not clear why the total cost of randomness is 2t, specifically, why the total cost of randomness is independent of T?\n\nIn Theorem 5.1, why compactness of parameter space \u0398 is required? For general optimization problems, this compactness is not required in general. \n\nThe context of on-demand sampling is not clear from the Algorithms, maybe the authors can add some discussion about the on-demand sampling after stating the algorithms.\n\n\nMinor Comments:\n\nPlease define the dimension of w~ in eq. (4). I assume that w~ is a constructed by stacking w~i's. \nThe use of the term \"multi-agent tradeoffs\" in the first sentence of the abstract is not clear. \nIn the statement of Lemma 2.1 please correct the notation {w}t=1T\nIn line 189 \u03d5(i,j) is not properly defined please clarify that i\u2208H and j\u2208D.\nThe definition of the deterministic estimator hpMaj is not clear.",
                "Questions": "This is a theoretical work that improves upon the existing results. The paper is very dense which makes it a little difficult to read, the authors might consider updating the paper by moving some redundant parts to the appendix for improving the readability of the paper.",
                "Limitations": "Yes.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "3 good",
                "Contribution": "4 excellent",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper investigates the on-demand sample complexity of multi-distribution learning. The authors establish the optimal sample complexity of collaborative, group distributionally robust, and agnostic federated learning. These results improve upon the best-known sample complexity in the prior work. The main approach is to regard the problem as a stochastic zero-sum game and apply a variant of stochastic mirror descent approach.",
                "Strengths And Weaknesses": "Strengths:\n\nThe studied problem is important in the machine learning area.\nThe theoretical results are optimal, which closes this direction.\nThe approaches are standard, which widens the application of stochastic mirror descent.\n\nWeaknesses:\n\nIt may be better to provide some empirical results on the proposed algorithms. The theoretical results will be more convincing if the performance beats the baselines in prior works.",
                "Questions": "The paper considers n predefined distributions. \n\nCan the result generalize to a family of distributions that has a certain bounded capacity, e.g., all exponential distributions?\nCan we reduce the dependence on n if these distributions have some relations, e.g., each one is a uniform distribution on a certain subset of k elements?",
                "Limitations": "Not",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper gives improved algorithms for three settings of learning from multiple distributions: collaborative, group distributionally robust, and fair federated learning. Previous results usually bounds the sample complexity by a certain overhead factor multiplied by the number of samples needed for learning a single distribution. In contrast, the sample complexity bounds derived in this work only have additive overheads.\nIn more detail, for (\u03f5,\u03b4)-collaborative learning on hypothesis class H and n distributions, Theorem 4.1 gives an upper bound of O(\u03f5\u22122(log\u2061|H|+nlog\u2061(n/\u03b4))), which exceeds the O(\u03f5\u22122log\u2061(|H|/\u03b4)) bound for single-distribution learning by an additive term of (nlog\u2061n)/\u03f52 (when \u03b4=\u03a9(1)). In contrast, the previous best bound of Nguyen and Zakynthinou (2018) is at least (log\u2061n)\u22c5(log\u2061|H|/\u03f55). Theorem 4.3 gives an improved lower bound, which matches the upper bound when n and log\u2061|H| are polynomially related.\nThe approach taken by the authors (which is implicit in prior work) is to view the collaborative learning setting as a zero-sum game between the learner (which selects a hypothesis) and an adversary (which chooses one of the n data distributions). The major task is then to find an (approximate) equilibrium of this game, using as few samples as possible. The key technical observation is an asymmetry between the two players in terms of how much data is needed for getting an unbiased estimate of the gradient, and to what extent these data can be reused for estimating the gradient at different locations.",
                "Strengths And Weaknesses": "This work introduces new tools to the line of research on learning from multiple distributions and further closes the gap between the upper and lower bounds. Both the results and the techniques should be interesting to the community. The new algorithm and its analysis seem highly nontrivial, and I thought the authors did a good job in sketching the proof in the main paper. In summary, this is a solid and well-presented work and should be accepted.\nOne weakness of the paper is that the algorithms are computationally inefficient. While the main focus is sample complexity, some discussion on the computational aspect seems necessary.",
                "Questions": "Are there any natural/simple/structured hypothesis classes for which that the algorithm could be efficiently implemented?\n\nThe algorithm outputs a (weighted) majority vote of hypotheses. Are previous algorithms also improper, and are there evidence that the problem becomes hard for proper learning?\n\n\nMinor comments:\n\nLine 195: What is \"VI\"?",
                "Limitations": "Limitations were not discussed.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 7.25,
        "confidence_avg": 3.0,
        "soundness_avg": 3.5,
        "presentation_avg": 3.0,
        "contribution_avg": 3.5,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that this paper makes significant contributions to the field of multi-distribution learning. The authors propose novel algorithms and establish optimal sample complexity bounds for collaborative learning, group distributionally robust optimization, and agnostic federated learning. The results improve upon the state-of-the-art and close the gap between upper and lower bounds.\n\nThe paper is well-organized and easy to understand, with clear explanations of the main contributions and approach. The experimental results also confirm the improvement in worst-case accuracy on three datasets.\n\nWhile there are some minor concerns raised by the reviewers, such as the need for clarification on certain parts of the paper and the computational efficiency of the algorithms, these do not outweigh the strengths and contributions of the work.\n\nTherefore, I recommend accepting this paper. The confidence in this recommendation is certain, as the reviewers have provided positive assessments of the paper and there are no unaddressed ethical considerations."
    },
    "Logical_Activation_Functions:_Logit-space_equivalents_of_Probabilistic_Boolean_Operators": {
        "link": "https://openreview.net//forum?id=m6HNNpQO8dc",
        "pub_url": "https://openreview.net/forum?id=m6HNNpQO8dc",
        "pdf_link": "https://openreview.net//pdf?id=m6HNNpQO8dc",
        "paper_id": "m6HNNpQO8dc",
        "title": "Logical_Activation_Functions:_Logit-space_equivalents_of_Probabilistic_Boolean_Operators",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nThe review ratings were above the acceptance threshold. The reviewers valued quite positively the originality of this paper that studied advantages of multivariate activate functions, as well as extensive numerical experiments across a wide range of tasks in order to explore their effectiveness. Upon reading the reviews, the author responses, subsequent discussion between the reviewers and the authors, as well as the paper itself, I thought that the restriction of the consideration in this paper to those derived from approximation of Boolean operators on independent Bernoullis was not well motivated nor described. At the same time, the empirical evidences demonstrating the potential usefulness of the proposal are quite interesting, so that I would like to recommend acceptance of this paper, and would expect further discussion on this subject among the attendees of the conference.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper introduces a set of novel activation functions for\nartificial neural networks, inspired by the Boolean logic gates for\nAND, OR and XNOR.  After defining and motivating the functions, the\npaper derives approximated versions that are more computationally\nefficient, and demonstrates their use on a few test problems.\nStrengths And Weaknesses: Strengths\nThe question addressed by the paper is reasonably original,\nand the proposed activation functions are derived and described\nclearly.\nWeaknesses\nIn my view the main weakness of the paper is insufficient\nmotivation and significance. Why is it interesting to have activation\nfunctions that mimic logical gates? No clear motivation is given,\neither from a theoretical standpoint (e.g., networks with such\nactivation functions may be expected to learn more efficiently for\nsome reason), or from the standpoint of biological inspiration (a few\nwords are spent on dendritic computation, but logical operations are\nnot what defines dendritic computation - they are just one particular\nabstraction that is sometimes applied to it). At the same time, in the\nexperiments section there is no clear sign of particular empirical\nadvantages conferred by the proposed activation functions. Therefore,\nto summarize, the logical activation functions, although defined in a\nconsistent and reasonable way, lack a-priori theoretical motivation as\nwell as a-posteriori demonstrations of empirical usefulness.\nI'll now expand on what I meant by \"no sign of empirical advantages\"\nabove. In my view, the results section presents an overly-optimistic\ninterpretation of the empirical results. Throughout the various\nexamples, a range of choices of activation functions is explored, but\nno choice is shown to be consistently better than the others across\ntasks (perhaps with the exception of learning the parity of the\ninputs; but that case is more of a sanity check, as it is the natural\noperation implemented by the XNOR gate). Indeed:\n\nin 4.2 (MLP on Bach chorales) there is no statistically significant\nadvantage;\nin 4.3 (MNIST) the results are mixed and overinterpreted: for the\nMLP the text says that one of the proposed gates is matched for best\nplace with one of the alternatives considered for comparison, but\nthis is not even evident from the plot (there are hyperparameter\nregimes where that choice of gate is the one that performs the\nworst). For the CNN case, a different choice of logical-gate\nactivations is claimed to be among the ones performing best, but\nagain from the plot it looks like the \"Max\" activation function is\nthe best overall.\nin 4.4, the gate that was identified as the best performer in\n4.3/MLP is now the worst performer, so much so that it is not even\nincluded in the plot. The other gates all produce mixed results with\nno clear winner. The activation that most consistently performs\nbetter than others in this section seems to be SiLU, but in the text\nit is grouped together with Max and ORAIL (one of the proposed\ngates). For some reason the results of this section don't have error\nbars.\nsection 4.5 (transfer learning) also fails to find a scenario where\nthe proposed activations consistently perform better than the\nalternatives.\n\nFinally, the experiments section is at times made hard to interpret by\nlack of methodological details. For instance, it is not clear to me\nhow the number of parameters is balanced across activation function\nchoices, since the different structure of 1-to-1 and 2-to-1\nactivations (e.g. ReLU vs the activations introduced in this paper)\nimply a different organization of the network. Moreover, some p-values\nare given without giving any information on the test (such as line\n262, \"For the MLP, XNORAIL performed best along with signed_geomean (p\n< 0.1)\", and some results seem to lack any statistical analysis/error\nbars (e.g. Figure 6).\nQuestions: \nWhy is it important for network to possess Boolean activation\n  functions, given that large enough networks can approximate any\n  arbitrary function?\nOf all the combinations of activation functions explored in the\n  experiments section, which one should I pick to use in my next deep\n  net architecture? Is there a principle, a strategy or a rule of\n  thumb that I could use to choose one (or more) activation function\n  without having to train and test my network with all possible\n  alternatives?\nLimitations: I couldn't find much in terms of explicit analysis of limitations.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 2 fair\nContribution: 2 fair\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper presents a new set of activation functions based on the approximation of  logit arithmetic AND/OR/XOR operation. The effectiveness of the proposed activity functions are demonstrated on many tasks including image classification, transfer learning, abstract reasoning, and compositional zero-shot learning.\nStrengths And Weaknesses: Originality:\n\n(+) To my knowledge, the idea proposed in this paper that uses  n->1 activation functions via approximating logit-space boolean operations is novel and interesting\n\nQuality:\n\n(+) The paper technically sounds correct and claims well supported by theoretical analysis and experimental results.\n(+) Related works are covered and discussed.\n(+)  Experiments are conducted extensively in different type of tasks and the results are discussed thoroughly.\n\nClarity:\n\n(+) This paper is well written and organised.\n(-) it would be better to have a table accompanying figures such as figure 6 as the result can be difficult to read given the amount of legend. Especially for figure 5, 6, the table for legend given is impossible to distinguish between silu and OR, XNOR d\n\nSignificance:\nAs demonstrated in the experimental results, the accuracy gain in CIFAR datasets in the transfer learning tests are quite big. I would assume that the proposed activation functions can be quite effective in certain types of tasks.\nQuestions: \nDoes it improve or worsen the training time? \nWhy is the performance of AIL better than IL in most cases(such as show in Table 1)? Especially in cases like stfCars that XNOR_IL has barely any accuracy. \nCan different layers use different settings? (some use XNOR, some use XNOR/OR d, etc)\nLimitations: The authors did discuss the limitations of the proposed method, such as the method being suitable for certain tasks based on experimental results.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: In this paper the authors presents new activation functions based on a relaxation of the logical operators AND, OR, XNOR. Moreover, the authors present approximations that are more efficient based on simple max, min and addition operations.  This is motivated by the behavior of the operators under the logit space equivalence. As these binary operators are reduction operations, i.e., they convert two inputs into one, the authors connect to the MaxOut. Furthermore, they provide ensemble alternatives to adapt neural network architectures to use the presented boolean activation functions. Finally, the authors provide empirical results showing how the different potential combinations of logical activation functions behave for different datasets and architectures.\nStrengths And Weaknesses: Here, the authors present new activation functions. One weakness could be that they make independency assumptions, however, this does not seem to negatively affect the performance of the models. \nThe empirical evaluation is sound, and demonstrates the activation functions behave well and even improve the performance in some cases. They achieve this without significantly adding more parameters by using ensembles of activation functions. This is an interesting contribution as previously (MaxOut) would significantly increase the number of weights in order to have the same number of outputs.\nQuestions: Do you think that these activation functions could provide a path for explainability of neural networks?\nI see this paper somehow related to continuous logic functions, and I'm wondering whether composition of more complex logical functions would also make sense, e.g., introducing an implication activation, etc.\nLimitations: no negative societal impact\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper introduces a set of novel activation functions for\nartificial neural networks, inspired by the Boolean logic gates for\nAND, OR and XNOR.  After defining and motivating the functions, the\npaper derives approximated versions that are more computationally\nefficient, and demonstrates their use on a few test problems.",
                "Strengths And Weaknesses": "Strengths\nThe question addressed by the paper is reasonably original,\nand the proposed activation functions are derived and described\nclearly.\nWeaknesses\nIn my view the main weakness of the paper is insufficient\nmotivation and significance. Why is it interesting to have activation\nfunctions that mimic logical gates? No clear motivation is given,\neither from a theoretical standpoint (e.g., networks with such\nactivation functions may be expected to learn more efficiently for\nsome reason), or from the standpoint of biological inspiration (a few\nwords are spent on dendritic computation, but logical operations are\nnot what defines dendritic computation - they are just one particular\nabstraction that is sometimes applied to it). At the same time, in the\nexperiments section there is no clear sign of particular empirical\nadvantages conferred by the proposed activation functions. Therefore,\nto summarize, the logical activation functions, although defined in a\nconsistent and reasonable way, lack a-priori theoretical motivation as\nwell as a-posteriori demonstrations of empirical usefulness.\nI'll now expand on what I meant by \"no sign of empirical advantages\"\nabove. In my view, the results section presents an overly-optimistic\ninterpretation of the empirical results. Throughout the various\nexamples, a range of choices of activation functions is explored, but\nno choice is shown to be consistently better than the others across\ntasks (perhaps with the exception of learning the parity of the\ninputs; but that case is more of a sanity check, as it is the natural\noperation implemented by the XNOR gate). Indeed:\n\nin 4.2 (MLP on Bach chorales) there is no statistically significant\nadvantage;\nin 4.3 (MNIST) the results are mixed and overinterpreted: for the\nMLP the text says that one of the proposed gates is matched for best\nplace with one of the alternatives considered for comparison, but\nthis is not even evident from the plot (there are hyperparameter\nregimes where that choice of gate is the one that performs the\nworst). For the CNN case, a different choice of logical-gate\nactivations is claimed to be among the ones performing best, but\nagain from the plot it looks like the \"Max\" activation function is\nthe best overall.\nin 4.4, the gate that was identified as the best performer in\n4.3/MLP is now the worst performer, so much so that it is not even\nincluded in the plot. The other gates all produce mixed results with\nno clear winner. The activation that most consistently performs\nbetter than others in this section seems to be SiLU, but in the text\nit is grouped together with Max and ORAIL (one of the proposed\ngates). For some reason the results of this section don't have error\nbars.\nsection 4.5 (transfer learning) also fails to find a scenario where\nthe proposed activations consistently perform better than the\nalternatives.\n\nFinally, the experiments section is at times made hard to interpret by\nlack of methodological details. For instance, it is not clear to me\nhow the number of parameters is balanced across activation function\nchoices, since the different structure of 1-to-1 and 2-to-1\nactivations (e.g. ReLU vs the activations introduced in this paper)\nimply a different organization of the network. Moreover, some p-values\nare given without giving any information on the test (such as line\n262, \"For the MLP, XNORAIL performed best along with signed_geomean (p\n< 0.1)\", and some results seem to lack any statistical analysis/error\nbars (e.g. Figure 6).",
                "Questions": "Why is it important for network to possess Boolean activation\n  functions, given that large enough networks can approximate any\n  arbitrary function?\nOf all the combinations of activation functions explored in the\n  experiments section, which one should I pick to use in my next deep\n  net architecture? Is there a principle, a strategy or a rule of\n  thumb that I could use to choose one (or more) activation function\n  without having to train and test my network with all possible\n  alternatives?",
                "Limitations": "I couldn't find much in terms of explicit analysis of limitations.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper presents a new set of activation functions based on the approximation of  logit arithmetic AND/OR/XOR operation. The effectiveness of the proposed activity functions are demonstrated on many tasks including image classification, transfer learning, abstract reasoning, and compositional zero-shot learning.",
                "Strengths And Weaknesses": "Originality:\n\n(+) To my knowledge, the idea proposed in this paper that uses  n->1 activation functions via approximating logit-space boolean operations is novel and interesting\n\nQuality:\n\n(+) The paper technically sounds correct and claims well supported by theoretical analysis and experimental results.\n(+) Related works are covered and discussed.\n(+)  Experiments are conducted extensively in different type of tasks and the results are discussed thoroughly.\n\nClarity:\n\n(+) This paper is well written and organised.\n(-) it would be better to have a table accompanying figures such as figure 6 as the result can be difficult to read given the amount of legend. Especially for figure 5, 6, the table for legend given is impossible to distinguish between silu and OR, XNOR d\n\nSignificance:\nAs demonstrated in the experimental results, the accuracy gain in CIFAR datasets in the transfer learning tests are quite big. I would assume that the proposed activation functions can be quite effective in certain types of tasks.",
                "Questions": "Does it improve or worsen the training time? \nWhy is the performance of AIL better than IL in most cases(such as show in Table 1)? Especially in cases like stfCars that XNOR_IL has barely any accuracy. \nCan different layers use different settings? (some use XNOR, some use XNOR/OR d, etc)",
                "Limitations": "The authors did discuss the limitations of the proposed method, such as the method being suitable for certain tasks based on experimental results.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "In this paper the authors presents new activation functions based on a relaxation of the logical operators AND, OR, XNOR. Moreover, the authors present approximations that are more efficient based on simple max, min and addition operations.  This is motivated by the behavior of the operators under the logit space equivalence. As these binary operators are reduction operations, i.e., they convert two inputs into one, the authors connect to the MaxOut. Furthermore, they provide ensemble alternatives to adapt neural network architectures to use the presented boolean activation functions. Finally, the authors provide empirical results showing how the different potential combinations of logical activation functions behave for different datasets and architectures.",
                "Strengths And Weaknesses": "Here, the authors present new activation functions. One weakness could be that they make independency assumptions, however, this does not seem to negatively affect the performance of the models. \nThe empirical evaluation is sound, and demonstrates the activation functions behave well and even improve the performance in some cases. They achieve this without significantly adding more parameters by using ensembles of activation functions. This is an interesting contribution as previously (MaxOut) would significantly increase the number of weights in order to have the same number of outputs.",
                "Questions": "Do you think that these activation functions could provide a path for explainability of neural networks?\nI see this paper somehow related to continuous logic functions, and I'm wondering whether composition of more complex logical functions would also make sense, e.g., introducing an implication activation, etc.",
                "Limitations": "no negative societal impact",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.667,
        "confidence_avg": 3.333,
        "soundness_avg": 2.667,
        "presentation_avg": 3.0,
        "contribution_avg": 2.667,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that the paper introduces a novel set of activation functions for artificial neural networks. While there are some concerns raised about the motivation and empirical advantages of these functions, overall the paper is technically sound and well-supported by theoretical analysis and experimental results. The experiments conducted extensively on different tasks demonstrate the effectiveness of the proposed activation functions. The limitations of the proposed method are also discussed. The paper is well-written and organized, although some improvements in clarity, such as providing tables for figures with complex legends, could be made. The reviewers have raised interesting questions regarding the training time, the performance comparison between different activation functions, and the possibility of using different settings for different layers. The paper makes a significant contribution to the field and has the potential for high impact. Therefore, I recommend accepting the paper."
    },
    "Dynamic_pricing_and_assortment_under_a_contextual_MNL_demand": {
        "link": "https://openreview.net//forum?id=OptX3Db1P4",
        "pub_url": "https://openreview.net/forum?id=OptX3Db1P4",
        "pdf_link": "https://openreview.net//pdf?id=OptX3Db1P4",
        "paper_id": "OptX3Db1P4",
        "title": "Dynamic_pricing_and_assortment_under_a_contextual_MNL_demand",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nIn this paper the authors study the problem of dynamic multi-product pricing and assort under the Multinomial Logit model (MNL). For multi-product pricing problems, they propose the Online Newton method for multiple product pricing  with provable regret bound of O(d\\sqrt(T)\\logT). For the assort problems, they proposed OFU-MNL with better dependency on the problem-dependent parameter.\nOverall, the authors have done a good job addressing the reviewers' concerns. While there is still lots of things to do in order to update the paper to meet the suggestions of the reviewers, I think this is a good paper and worth being published at NeurIPS, subject to the aforementioned edits.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper studied dynamic multi-product pricing and assort problems under the Multinomial Logit Model (MNL). For multi-product pricing problems, they proposed the Online Newton method for multiple product pricing algorithms with O(dTlog\u2061(T)) regret bound. For assort problems, they proposed OFU-MNL with better dependency on the problem-dependent parameter \u03ba.\nStrengths And Weaknesses: For dynamic pricing, the paper extends the current literature to multiple products with feature-dependent price sensitivities. I believe it is an important extension and has many applications in practice. The idea is that it can consider the problem as an online convex optimization problem and use a famous technique (Online Newton step) to deal with it. However, due to the existence of uninformative prices, it can break the ONS algorithm. Therefore, the proposed algorithm needs to introduce random shock to increase exploration. \nTechnically, both online newton step and random shocks have been applied to dynamic pricing under different settings as the authors pointed out in the literature, therefore I am not surprised when the authors can derive the regret bound for a new setting of multiple products. I think a very strong assumption in the paper compared to the related work is that after each round t, the seller can observe qt, the customer probability of buying products (so that the seller can update the estimate \u03b3t). In Xu and Wang's work (Logarithmic Regret in Feature-based Dynamic Pricing), it seems that they only require observing indicator yt of customer buying the product or not, which is more practical. \nExperiment: the experiment results in Appendix D show an advantage of the proposed algorithm compared to a similar online Newton method (ONSP) with a single product. However, the experiment result is not convincing since it is based on a stochastic setting whereas all the theoretical results in this paper focus on adversarial counterparts.\nQuestions: The author mentioned that optimal regret bound (O(T)) is achievable in the case of a single product with Feature-based dynamic pricing. Does it mean that if we apply the algorithm in the paper to a single product, it will lead to a slightly worse regret bound compared to the optimal one? \nCan the author comment on the running of Algorithm 1? Since it requires an inverse of a Hessian matrix at every time step, it may not be as efficient as first-order methods.\nLimitations: There is no potential societal impact.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: In this paper, the authors studied contextual dynamic pricing and assortment optimization problems under the MNL choice model. They proposed two algorithms: (1) a dynamic pricing algorithm which combines a variant of the ONS algorithm and random price shocks, and showed that this algorithm achieves O(dTlog\u2061T) regret under adversarial arrival. (2) an optimistic algorithm for the adversarial MNL contextual bandits problem, and showed that it achieves better dependency on parameter \u03ba than existing algorithms, where \u03ba is a problem-dependent constant that measures deviation from the linear model.\nStrengths And Weaknesses: Strengths:\n\nThe dynamic pricing policy proposed in Section 2 uses interesting ideas that combine ONS method with random price shocks, and is shown to attain near-optimal performance. \nThe optimistic algorithm for adversarial MNL contextual bandits proposed in Section 3 is shown to achieve better dependency on \u03ba, and does not assume knowledge of \u03ba a priori. \nThe authors provide clear and thorough proof for their theoretical results.\n\nWeaknesses: \n\nThe authors provided a brief discussion of related literature on contextual dynamic pricing/assortment problems in the beginning of section 1. It could be desirable to have a separate and more detailed discussion of related work that compares this work with the previous literature. \nWhile the regret bounds are theoretically sound, it could be good to also include some numerical studies here to demonstrate the performance of the algorithm and verify the dependency on parameters T and d of the regret bound. Another thing that is missing from the current work is the runtime for both algorithms. \nIt appears that the design of the algorithms leverages the self-concordant property of the MNL log likelihood function. More discussions can be provided here to motivate why the use of self-concordant property is important to the proof.\nQuestions: \nIn Algorithm 2, there is a step that requires one to choose the set of K items maximizing the expected revenue. Are you simply selecting the K items with the highest xt,i\u22a4\u03b8~i here? \nIf so, any ideas what will happen when the rewards are no longer uniform and we also need to consider assortments with size less than K?\nLimitations: None.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: In this work, the authors study two different online-learing problems, a multi-product dynamic pricing problem and a multi-product dynamic assortment optimization problems, under a multinomial logit (MNL) model choice model. In the pricing problem, at each round t, a customer comes with a candidate set of features describing her preference on corresponding products, and the seller (we) are asked to set prices for these candidate products. After seeing these prices, the customer will choose at most one of them to buy, according to the MNL model with linear parameters. The goal is to maximize the expected revenue. In the assorting problem, the situation is slightly different: At each round t, a customer comes with a set of features describing her preference on all products, and the seller (we) are asked to propose a list of \u2264K products as candidates. After seeing these candidates, the customer would take at most one product from these candidates. In the assorting problem, the goal is to maximize the probability of not-buying-empty.\nIn this work, the authors propose algorithms for both problems: For the pricing prolem, they propose an Online-Newton (ON)-based pricing algorithm which achieves an O(dlog\u2061TT) regret. This result matches the existing information-theoretic lower bound at O~(T). For the assorting problem, they propose an OFU-MNL algorithm that achieves an O(d\u03baT+d2log\u2061(T)\u03ba) regret. This result improve the existing results by reducing the dependence on 1\u03ba as \u03ba=o(1).\nStrengths And Weaknesses: Strength:\n1, This work studies online multi-product pricing and assortment problems and proposes provable algorithms. The problem setting is meaningful. Their regret upper bounds are either optimal (for pricing) or better than existing results (for assortments).\n2, For the pricing problem, they use Online Newton method + self-concordant-like property to substitute the role of an ONS algorithm, while also saving the regret dependence on constants. Their numerical result (in Appendix) also shows the significance of their work over existing methods in practice.\nWeakness:\n1, Their improvement from existing theoretical results on the assorting problem is not substantial.\n2, Problem formulation and literature reviews are insufficient: It is unclear how to place this work in the stream of pricing/assorting researches.\nOverall, this is a good work to get in, and I would like to raise my score as long as the authors properly address my concerns.\nQuestions: Please point it out directly in the rebuttal if I am wrong in the following questions/suggestions.\n1, In Line 34 the authors mentioned the regret on the assorting problem, without firstly describing the goal of assorting and the (informal) definition of its regret. This could be confusing to the readers.\n2, In Line 86, the authors mentioned that an O(dlog\u2061T) regret is implied by their result for single-product pricing problem. However, I did not find such a reduction in the paper. Is there a remark/corollary regarding this, or a trivial reduction to this result?\n3, In Line 93, the authors mentioned that their ON-based pricing algorithm outperforms the ONS-based pricing algorithm in [41] by improving the dependence on a \"potentially exponentially small constant\". However, I did not find (1) how the small constant is like and (2) what improvement this work has made, in either the main pages or Appendix D. Only descriptive words are in Line 181-191\nI guess this small constant could be \u03ba as is mentioned in Line 190-191, but I am not quite sure: (1) a \u03ba is defined for the assorting problem (see Line 267) instead of the pricing problem (as they have different definitions on the qt,j functions), and (2) the constant in the regret of Algorithm 1 is also \u03a9(1\u03ba2 (see Line 592). Please explain this issue briefly as [41] adopts a quite similar method and this work indeed outperforms [41] in practice.\n4, In Line 139, I think it is not a proper way to describe the probabilistic distribution like this: As the authors only specified the probability of product j being purchased, a straightforward question could be: how are these purchases correlated to each other? Of course, we know from context that these purchases are mutually exclusive and the probability is a multinomial on these products, but this could still be very misleading. I suggest the authors clarify this part by saying \"the customer purchases one product j\u2208[kt]\u222a0 ...\".\n5, There should be an explanation on Assumption 2.3. My understanding: price elasticity (or \"price sensitivity\" in this work) should not be too small (i.e., close to 0). This is reasonable and practical, but needs explanation.\n6, In Line 166, where does this \u03bb sequence come from? This makes the adjacent paragraph (Line 166-169) unclear. (A minor issue: for the convexity of lt, either prove it or cite it.)\n7, In Line 196, the author said that they treated K as a constant. This is important for regret analysis and comparison, so I suggest the authors to make it as an assumption and state it with other assumptions (e.g., after Assumption 2.3).\n8, In Line 219, the author said \"it is meaningful only with random price experimentation\". This seems not very clear to me. Does it mean that you have to further make use of the randomness of pt,j to upper bound the first term of (1)?\nMaybe an equation showing how to apply Lemma 2.6 to the proof of Theorem 2.4 would be more informative and concise.\n9, In Line 257, the author denoted the \"optimal assortment\" as St\u2217. My understanding: S\u2217=arg\u2061maxSqt,j(S,\u03b8\u2217), i.e., minimize the prob of choosing nothing. This is equivalent to maximizing the sum of expx\u22a4\u03b8? Is that right?\nBesides, I noticed a number of notation inconsistence in this paper. Therefore, I strongly recommend the authors to carefully examine the paper and fix all notation issues.\nLimitations: The authors indeed discussed the potential extension of this work (e.g., \"the nested logit model\" as mentioned in their conclusions). However, there's not much on the social impact. This is not a big issue as it is a theoretic-oriented research, but I recommend the authors to discuss more on the limitations and potential social impacts (especially these negative aspects) in their Appendix.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 2 fair\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper studied dynamic multi-product pricing and assort problems under the Multinomial Logit Model (MNL). For multi-product pricing problems, they proposed the Online Newton method for multiple product pricing algorithms with O(dTlog\u2061(T)) regret bound. For assort problems, they proposed OFU-MNL with better dependency on the problem-dependent parameter \u03ba.",
                "Strengths And Weaknesses": "For dynamic pricing, the paper extends the current literature to multiple products with feature-dependent price sensitivities. I believe it is an important extension and has many applications in practice. The idea is that it can consider the problem as an online convex optimization problem and use a famous technique (Online Newton step) to deal with it. However, due to the existence of uninformative prices, it can break the ONS algorithm. Therefore, the proposed algorithm needs to introduce random shock to increase exploration. \nTechnically, both online newton step and random shocks have been applied to dynamic pricing under different settings as the authors pointed out in the literature, therefore I am not surprised when the authors can derive the regret bound for a new setting of multiple products. I think a very strong assumption in the paper compared to the related work is that after each round t, the seller can observe qt, the customer probability of buying products (so that the seller can update the estimate \u03b3t). In Xu and Wang's work (Logarithmic Regret in Feature-based Dynamic Pricing), it seems that they only require observing indicator yt of customer buying the product or not, which is more practical. \nExperiment: the experiment results in Appendix D show an advantage of the proposed algorithm compared to a similar online Newton method (ONSP) with a single product. However, the experiment result is not convincing since it is based on a stochastic setting whereas all the theoretical results in this paper focus on adversarial counterparts.",
                "Questions": "The author mentioned that optimal regret bound (O(T)) is achievable in the case of a single product with Feature-based dynamic pricing. Does it mean that if we apply the algorithm in the paper to a single product, it will lead to a slightly worse regret bound compared to the optimal one? \nCan the author comment on the running of Algorithm 1? Since it requires an inverse of a Hessian matrix at every time step, it may not be as efficient as first-order methods.",
                "Limitations": "There is no potential societal impact.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "In this paper, the authors studied contextual dynamic pricing and assortment optimization problems under the MNL choice model. They proposed two algorithms: (1) a dynamic pricing algorithm which combines a variant of the ONS algorithm and random price shocks, and showed that this algorithm achieves O(dTlog\u2061T) regret under adversarial arrival. (2) an optimistic algorithm for the adversarial MNL contextual bandits problem, and showed that it achieves better dependency on parameter \u03ba than existing algorithms, where \u03ba is a problem-dependent constant that measures deviation from the linear model.",
                "Strengths And Weaknesses": "Strengths:\n\nThe dynamic pricing policy proposed in Section 2 uses interesting ideas that combine ONS method with random price shocks, and is shown to attain near-optimal performance. \nThe optimistic algorithm for adversarial MNL contextual bandits proposed in Section 3 is shown to achieve better dependency on \u03ba, and does not assume knowledge of \u03ba a priori. \nThe authors provide clear and thorough proof for their theoretical results.\n\nWeaknesses: \n\nThe authors provided a brief discussion of related literature on contextual dynamic pricing/assortment problems in the beginning of section 1. It could be desirable to have a separate and more detailed discussion of related work that compares this work with the previous literature. \nWhile the regret bounds are theoretically sound, it could be good to also include some numerical studies here to demonstrate the performance of the algorithm and verify the dependency on parameters T and d of the regret bound. Another thing that is missing from the current work is the runtime for both algorithms. \nIt appears that the design of the algorithms leverages the self-concordant property of the MNL log likelihood function. More discussions can be provided here to motivate why the use of self-concordant property is important to the proof.",
                "Questions": "In Algorithm 2, there is a step that requires one to choose the set of K items maximizing the expected revenue. Are you simply selecting the K items with the highest xt,i\u22a4\u03b8~i here? \nIf so, any ideas what will happen when the rewards are no longer uniform and we also need to consider assortments with size less than K?",
                "Limitations": "None.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "In this work, the authors study two different online-learing problems, a multi-product dynamic pricing problem and a multi-product dynamic assortment optimization problems, under a multinomial logit (MNL) model choice model. In the pricing problem, at each round t, a customer comes with a candidate set of features describing her preference on corresponding products, and the seller (we) are asked to set prices for these candidate products. After seeing these prices, the customer will choose at most one of them to buy, according to the MNL model with linear parameters. The goal is to maximize the expected revenue. In the assorting problem, the situation is slightly different: At each round t, a customer comes with a set of features describing her preference on all products, and the seller (we) are asked to propose a list of \u2264K products as candidates. After seeing these candidates, the customer would take at most one product from these candidates. In the assorting problem, the goal is to maximize the probability of not-buying-empty.\nIn this work, the authors propose algorithms for both problems: For the pricing prolem, they propose an Online-Newton (ON)-based pricing algorithm which achieves an O(dlog\u2061TT) regret. This result matches the existing information-theoretic lower bound at O~(T). For the assorting problem, they propose an OFU-MNL algorithm that achieves an O(d\u03baT+d2log\u2061(T)\u03ba) regret. This result improve the existing results by reducing the dependence on 1\u03ba as \u03ba=o(1).",
                "Strengths And Weaknesses": "Strength:\n1, This work studies online multi-product pricing and assortment problems and proposes provable algorithms. The problem setting is meaningful. Their regret upper bounds are either optimal (for pricing) or better than existing results (for assortments).\n2, For the pricing problem, they use Online Newton method + self-concordant-like property to substitute the role of an ONS algorithm, while also saving the regret dependence on constants. Their numerical result (in Appendix) also shows the significance of their work over existing methods in practice.\nWeakness:\n1, Their improvement from existing theoretical results on the assorting problem is not substantial.\n2, Problem formulation and literature reviews are insufficient: It is unclear how to place this work in the stream of pricing/assorting researches.\nOverall, this is a good work to get in, and I would like to raise my score as long as the authors properly address my concerns.",
                "Questions": "Please point it out directly in the rebuttal if I am wrong in the following questions/suggestions.\n1, In Line 34 the authors mentioned the regret on the assorting problem, without firstly describing the goal of assorting and the (informal) definition of its regret. This could be confusing to the readers.\n2, In Line 86, the authors mentioned that an O(dlog\u2061T) regret is implied by their result for single-product pricing problem. However, I did not find such a reduction in the paper. Is there a remark/corollary regarding this, or a trivial reduction to this result?\n3, In Line 93, the authors mentioned that their ON-based pricing algorithm outperforms the ONS-based pricing algorithm in [41] by improving the dependence on a \"potentially exponentially small constant\". However, I did not find (1) how the small constant is like and (2) what improvement this work has made, in either the main pages or Appendix D. Only descriptive words are in Line 181-191\nI guess this small constant could be \u03ba as is mentioned in Line 190-191, but I am not quite sure: (1) a \u03ba is defined for the assorting problem (see Line 267) instead of the pricing problem (as they have different definitions on the qt,j functions), and (2) the constant in the regret of Algorithm 1 is also \u03a9(1\u03ba2 (see Line 592). Please explain this issue briefly as [41] adopts a quite similar method and this work indeed outperforms [41] in practice.\n4, In Line 139, I think it is not a proper way to describe the probabilistic distribution like this: As the authors only specified the probability of product j being purchased, a straightforward question could be: how are these purchases correlated to each other? Of course, we know from context that these purchases are mutually exclusive and the probability is a multinomial on these products, but this could still be very misleading. I suggest the authors clarify this part by saying \"the customer purchases one product j\u2208[kt]\u222a0 ...\".\n5, There should be an explanation on Assumption 2.3. My understanding: price elasticity (or \"price sensitivity\" in this work) should not be too small (i.e., close to 0). This is reasonable and practical, but needs explanation.\n6, In Line 166, where does this \u03bb sequence come from? This makes the adjacent paragraph (Line 166-169) unclear. (A minor issue: for the convexity of lt, either prove it or cite it.)\n7, In Line 196, the author said that they treated K as a constant. This is important for regret analysis and comparison, so I suggest the authors to make it as an assumption and state it with other assumptions (e.g., after Assumption 2.3).\n8, In Line 219, the author said \"it is meaningful only with random price experimentation\". This seems not very clear to me. Does it mean that you have to further make use of the randomness of pt,j to upper bound the first term of (1)?\nMaybe an equation showing how to apply Lemma 2.6 to the proof of Theorem 2.4 would be more informative and concise.\n9, In Line 257, the author denoted the \"optimal assortment\" as St\u2217. My understanding: S\u2217=arg\u2061maxSqt,j(S,\u03b8\u2217), i.e., minimize the prob of choosing nothing. This is equivalent to maximizing the sum of expx\u22a4\u03b8? Is that right?\nBesides, I noticed a number of notation inconsistence in this paper. Therefore, I strongly recommend the authors to carefully examine the paper and fix all notation issues.",
                "Limitations": "The authors indeed discussed the potential extension of this work (e.g., \"the nested logit model\" as mentioned in their conclusions). However, there's not much on the social impact. This is not a big issue as it is a theoretic-oriented research, but I recommend the authors to discuss more on the limitations and potential social impacts (especially these negative aspects) in their Appendix.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.667,
        "confidence_avg": 3.0,
        "soundness_avg": 3.333,
        "presentation_avg": 2.667,
        "contribution_avg": 2.667,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is clear that this paper makes a significant contribution to the field of dynamic multi-product pricing and assortment optimization problems. The proposed algorithms for both pricing and assortment problems are theoretically sound and achieve near-optimal performance. The authors provide clear and thorough proofs for their results.\n\nWhile there are some minor weaknesses pointed out by the reviewers, such as the need for more detailed discussions on related work and numerical studies, these do not outweigh the strengths of the paper. The limitations of the work are also acknowledged by the authors.\n\nOverall, this is a technically solid paper with moderate-to-high impact. The reviewers have raised some concerns, but they are not major and can be addressed in the revision. Therefore, I recommend accepting this paper."
    },
    "Off-Team_Learning": {
        "link": "https://openreview.net//forum?id=uOdTKkg2FtP",
        "pub_url": "https://openreview.net/forum?id=uOdTKkg2FtP",
        "pdf_link": "https://openreview.net//pdf?id=uOdTKkg2FtP",
        "paper_id": "uOdTKkg2FtP",
        "title": "Off-Team_Learning",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Less certain\nThe authors propose an improvement to off-belief learning, Off-Team learning, which closes the gap between belief models trained on fixed policies, and evaluation on learned policies for ZSC coordination problems. All reviewers have voted to weak/borderline accept - since I see no conceptual issues with the proposed framework and the evaluation seems sound, I will also vote to accept. The major area of constructive criticism, is that the work seems to be somewhat incremental with respect to Hu et al. (ICML 21).",
        "reviews": [
            "Reviewer 1: \nSummary: This paper identifies weaknesses in Off-belief Learning [ICML 2021] that lead to large distribution shifts at test-time evaluation in zero-shot coordination (particularly when evaluated with human players.) The paper contributes two extensions (off-team belief learning and off-team reinforcement learning) which together improve cross-play evaluation and zero-shot coordination with another agent (rank bot) and human proxy (clone bot).\nStrengths And Weaknesses: The proposed methods are original extensions to an increasingly specific approach to zero-shot coordination in Hanabi. However, the diminishing returns in improvements to this system and limited scope of its evaluation weaken the significance of this finding. Most notably the improvement in ad-hoc teamplay evaluation with rank-bot (line 326) is insignificant when considering the variance of both methods evaluated and the effect size of the improvement in proxy human-AI coordination (line 327) is tiny. Furthermore, no evidence is given in this paper that the clone bot used for proxy human-AI coordination is a good human proxy.\nThe overall clarity of the contribution made is significantly weakened by the paper's over reliance on references to \"Off-belief Learning\" [Hu et al. ICML 2021] causing the paper to not be a standalone reference to reproduce the work. For example (but not limited to) the zero-shot coordination task or cross-play metric used throughout the paper are not formally defined. For details on the critical process of training the policy and belief model readers are deferred in line 209 to \"follow practices in the original OBL paper [Hu et al. ICML 2021]\" and the core contributions of this paper (OT-BL and OT-RL) are then defined just by how they differ to this past work. \nThe specific details of how the proposed extensions differ from the past work are also incomplete and potentially incorrect in parts:\na) In Figure 1 left should the arrows into \\pi from \\tau_t and \\tau_t+1 be reversed or the same as OT-BL (Figure 1 Right)? \nb) In Figure 1 Right, the blue fictitious transitions use \\pi in the illustration and \\pi_L in the caption? Algorithm 1 also uses \\pi and not \\pi_L. Is it just the caption on Figure 1 that is incorrect?\nc) The loss in Equation 1 is not defined.\nd) Is it intentional that the only difference in Figure 2 left (OBL) and Figure 2 right (OT-RL) is the policy used to sample real actions?\ne) On line 273, does P_{pi_L} mean both players play using policy \\pi_L?\nQuestions: During the discussion period, I'm particularly keen to hear from the authors on the following prioritized list of questions that could improve my current rating of this paper:\n\nWhat additional evidence can the authors provide that clone-bot is a good human proxy?\n\nAssuming clone-bot is a good human proxy, what evidence is there that the small improvement in proxy human-AI coordination (line 327) is a significant advancement?\n\nPlease clarify the issues (a)-(e) regarding specific details raised in the section on strengths and weaknesses above.\n\nPlease justify the very strong claim in the abstract that \"Zero-shot coordination is a ... pre-requisite for human-AI coordination\".\nLimitations: The paper includes a sufficient broader impact section. However, the closing sentence regarding \"working in purely cooperative settings\" is a short sighted conclusion. I encourage the authors to consider the issues raised in Section 5 of \"Open Problems in Cooperative AI\" Dafoe et al. Arxiv 2020.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper introduces the concept of off-team learning, where a target joint policy is learned using a behavior joint policy to address covariate shift in off-belief learning (OBL). First off-team belief learning (OT-BL) is proposed to address covariate shift, where the belief model is iteratively updated on fictitious transitions. Second, off-team reinforcement learning (OT-RL) is proposed to address test time covariate shift with respect to unseen agents, where Q-values can be learned with belief models of any distribution. Both approaches are evaluated in the Hanabi challenge. The belief model of OT-BL is shown to produce more valid fictitious samples than OBL, while OT-RL is shown to outperform OBL in various settings.\nStrengths And Weaknesses: \nOriginality: The idea and concepts presented in the paper are novel, interesting, and highly relevant to current applications and challenges of multi-agent systems.\nQuality: The paper is technically sound. The explanations and experiments are presented well and the results clearly support the claims. \nClarity: The paper is well-written, clearly structured, and easy to follow. \nSignificance: The experiment design and results indicate a clear improvement over OBL.\n\nThe authors did a great job on motivating and presenting their approach. Since a fundamental issue is addressed, a smaller toy problem like the cooperative communication game from the OBL paper would have been helpful.\nMinor comments:\n\nThe tables should highlight the best performing result in boldface for better readability.\nText and labels in Fig. 1 and 2 are very small and hard to read when printed.\nQuestions: None\nLimitations: Limitations and potential negative societal impact are adequately addressed in the paper.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper investigates the problem of off-policy learning in cooperative games. Within this area, they address a problem they call \"off-team (OT) learning\", where the teammates that generated the experience differ from the target teammates. They accomplish this by disentangling the belief in the trajectory, specifically the previous joint actions, from action evaluation. As a result, a policy can be learned that may adapt to a target team through its belief maintenance. Their algorithm is evaluated in a variety of Hanabi settings and shows some empirical improvements.\nStrengths And Weaknesses: Strengths\n\nTheir algorithms are described in the text, graphics, and pseudocode allowing for diverse learning styles to approach the material.\nEvaluations include some amount of ablations/sensitivity-analysis to better understand the merits of the proposed algorithm.\n\nWeaknesses\n\nThe paper is dense with jargon and heavily marked symbols with detailed meanings making it more challenging to read than I believe is necessary. \nMaintaining and correcting for beliefs as a way to make strategic adjustments has been in many flavors, making this work's originality small.\nQuestions: \n\"Off-team learning\" relies on the learned belief model bein accurate up to time t-1. This seems unrealistic in practice to rely on as an assumption when the algorithm is jointly learning it alongside the policy. Can the authors comment on the need for accuracy in the belief model both in terms of the theoretical guarantees of the algorithm and the empirical performance? \n\nCoordination games may exhibit many diverse equilibria. How does this algorithm cope with target teammates that play equilibrium vastly different than that expressed by the behavioural teammates?\n\nThe authors claim L224: \"The goal of ZSC is to evaluate the consistency of an algorithm across different seeds.\" This is not true. The goal of ZSC is to coordinate productively with unseen opponents. If the authors' statement was true any deterministic algorithm solves this problem.  \n\nIn L236 the authors discuss the robustness of their algorithm given covariate shift with respect to the environment dynamics. However, it seems to me, that is mostly orthogonal to the work. In the abstract it seems the focus is on only differing teammates. Shouldn't the emphasis be on covariate shift to radically different teammates? And/or the combination of the two changes? Could the authors explain this focus and why they de-emphasized these other facets? \n\nL283, could the authors explain \"only a small number, o=3200, of trajectories\"? How many trajectories are 3200 observations? Why is it measured in observations?\nLimitations: The broader impact section could be improved to reflect the impact belief-modelling style algorithms can have on biases.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 2 fair\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper identifies weaknesses in Off-belief Learning [ICML 2021] that lead to large distribution shifts at test-time evaluation in zero-shot coordination (particularly when evaluated with human players.) The paper contributes two extensions (off-team belief learning and off-team reinforcement learning) which together improve cross-play evaluation and zero-shot coordination with another agent (rank bot) and human proxy (clone bot).",
                "Strengths And Weaknesses": "The proposed methods are original extensions to an increasingly specific approach to zero-shot coordination in Hanabi. However, the diminishing returns in improvements to this system and limited scope of its evaluation weaken the significance of this finding. Most notably the improvement in ad-hoc teamplay evaluation with rank-bot (line 326) is insignificant when considering the variance of both methods evaluated and the effect size of the improvement in proxy human-AI coordination (line 327) is tiny. Furthermore, no evidence is given in this paper that the clone bot used for proxy human-AI coordination is a good human proxy.\nThe overall clarity of the contribution made is significantly weakened by the paper's over reliance on references to \"Off-belief Learning\" [Hu et al. ICML 2021] causing the paper to not be a standalone reference to reproduce the work. For example (but not limited to) the zero-shot coordination task or cross-play metric used throughout the paper are not formally defined. For details on the critical process of training the policy and belief model readers are deferred in line 209 to \"follow practices in the original OBL paper [Hu et al. ICML 2021]\" and the core contributions of this paper (OT-BL and OT-RL) are then defined just by how they differ to this past work. \nThe specific details of how the proposed extensions differ from the past work are also incomplete and potentially incorrect in parts:\na) In Figure 1 left should the arrows into \\pi from \\tau_t and \\tau_t+1 be reversed or the same as OT-BL (Figure 1 Right)? \nb) In Figure 1 Right, the blue fictitious transitions use \\pi in the illustration and \\pi_L in the caption? Algorithm 1 also uses \\pi and not \\pi_L. Is it just the caption on Figure 1 that is incorrect?\nc) The loss in Equation 1 is not defined.\nd) Is it intentional that the only difference in Figure 2 left (OBL) and Figure 2 right (OT-RL) is the policy used to sample real actions?\ne) On line 273, does P_{pi_L} mean both players play using policy \\pi_L?",
                "Questions": "During the discussion period, I'm particularly keen to hear from the authors on the following prioritized list of questions that could improve my current rating of this paper:\n\nWhat additional evidence can the authors provide that clone-bot is a good human proxy?\n\nAssuming clone-bot is a good human proxy, what evidence is there that the small improvement in proxy human-AI coordination (line 327) is a significant advancement?\n\nPlease clarify the issues (a)-(e) regarding specific details raised in the section on strengths and weaknesses above.\n\nPlease justify the very strong claim in the abstract that \"Zero-shot coordination is a ... pre-requisite for human-AI coordination\".",
                "Limitations": "The paper includes a sufficient broader impact section. However, the closing sentence regarding \"working in purely cooperative settings\" is a short sighted conclusion. I encourage the authors to consider the issues raised in Section 5 of \"Open Problems in Cooperative AI\" Dafoe et al. Arxiv 2020.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper introduces the concept of off-team learning, where a target joint policy is learned using a behavior joint policy to address covariate shift in off-belief learning (OBL). First off-team belief learning (OT-BL) is proposed to address covariate shift, where the belief model is iteratively updated on fictitious transitions. Second, off-team reinforcement learning (OT-RL) is proposed to address test time covariate shift with respect to unseen agents, where Q-values can be learned with belief models of any distribution. Both approaches are evaluated in the Hanabi challenge. The belief model of OT-BL is shown to produce more valid fictitious samples than OBL, while OT-RL is shown to outperform OBL in various settings.",
                "Strengths And Weaknesses": "Originality: The idea and concepts presented in the paper are novel, interesting, and highly relevant to current applications and challenges of multi-agent systems.\nQuality: The paper is technically sound. The explanations and experiments are presented well and the results clearly support the claims. \nClarity: The paper is well-written, clearly structured, and easy to follow. \nSignificance: The experiment design and results indicate a clear improvement over OBL.\n\nThe authors did a great job on motivating and presenting their approach. Since a fundamental issue is addressed, a smaller toy problem like the cooperative communication game from the OBL paper would have been helpful.\nMinor comments:\n\nThe tables should highlight the best performing result in boldface for better readability.\nText and labels in Fig. 1 and 2 are very small and hard to read when printed.",
                "Questions": "None",
                "Limitations": "Limitations and potential negative societal impact are adequately addressed in the paper.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper investigates the problem of off-policy learning in cooperative games. Within this area, they address a problem they call \"off-team (OT) learning\", where the teammates that generated the experience differ from the target teammates. They accomplish this by disentangling the belief in the trajectory, specifically the previous joint actions, from action evaluation. As a result, a policy can be learned that may adapt to a target team through its belief maintenance. Their algorithm is evaluated in a variety of Hanabi settings and shows some empirical improvements.",
                "Strengths And Weaknesses": "Strengths\n\nTheir algorithms are described in the text, graphics, and pseudocode allowing for diverse learning styles to approach the material.\nEvaluations include some amount of ablations/sensitivity-analysis to better understand the merits of the proposed algorithm.\n\nWeaknesses\n\nThe paper is dense with jargon and heavily marked symbols with detailed meanings making it more challenging to read than I believe is necessary. \nMaintaining and correcting for beliefs as a way to make strategic adjustments has been in many flavors, making this work's originality small.",
                "Questions": "\"Off-team learning\" relies on the learned belief model bein accurate up to time t-1. This seems unrealistic in practice to rely on as an assumption when the algorithm is jointly learning it alongside the policy. Can the authors comment on the need for accuracy in the belief model both in terms of the theoretical guarantees of the algorithm and the empirical performance? \n\nCoordination games may exhibit many diverse equilibria. How does this algorithm cope with target teammates that play equilibrium vastly different than that expressed by the behavioural teammates?\n\nThe authors claim L224: \"The goal of ZSC is to evaluate the consistency of an algorithm across different seeds.\" This is not true. The goal of ZSC is to coordinate productively with unseen opponents. If the authors' statement was true any deterministic algorithm solves this problem.  \n\nIn L236 the authors discuss the robustness of their algorithm given covariate shift with respect to the environment dynamics. However, it seems to me, that is mostly orthogonal to the work. In the abstract it seems the focus is on only differing teammates. Shouldn't the emphasis be on covariate shift to radically different teammates? And/or the combination of the two changes? Could the authors explain this focus and why they de-emphasized these other facets? \n\nL283, could the authors explain \"only a small number, o=3200, of trajectories\"? How many trajectories are 3200 observations? Why is it measured in observations?",
                "Limitations": "The broader impact section could be improved to reflect the impact belief-modelling style algorithms can have on biases.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.0,
        "confidence_avg": 3.333,
        "soundness_avg": 3.0,
        "presentation_avg": 2.333,
        "contribution_avg": 2.333,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that this paper introduces novel concepts and approaches to address the problem of off-policy learning in cooperative games. The proposed off-team learning algorithms, OT-BL and OT-RL, are technically sound and supported by well-designed experiments. The paper is well-written and presents the ideas clearly.\n\nWhile there are some concerns raised by the reviewers, such as the limited scope of evaluation and the need for clarification on certain details, these issues do not outweigh the strengths of the paper. The improvements over the existing approach, as demonstrated in the experiments, indicate the significance of the proposed algorithms.\n\nOverall, this paper makes a solid contribution to the field and has the potential for high impact. Therefore, I recommend accepting it for publication."
    },
    "A_Deep_Reinforcement_Learning_Framework_for_Column_Generation": {
        "link": "https://openreview.net//forum?id=zBlj0Cs6dw1",
        "pub_url": "https://openreview.net/forum?id=zBlj0Cs6dw1",
        "pdf_link": "https://openreview.net//pdf?id=zBlj0Cs6dw1",
        "paper_id": "zBlj0Cs6dw1",
        "title": "A_Deep_Reinforcement_Learning_Framework_for_Column_Generation",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nThe reviewers all agree that the paper meets the acceptance bar.\nAt the same time, I would like to encourage the authors to seriously consider adding more experiments to the final paper as recommended by the reviews:\n\nGiven the motivation in the paper, the recommendation of Reviewer 8Csh about running some experiments for MIP is quite reasonable, and would make the story much more convincing. It would be a significant improvement, worth the extra software engineering efforts.\nI do not quite agree with the reasons the authors rejected comparison with algorithms recommended by Reviewer Eksw. It was argued that these algorithms are superseded by the one-step lookahead algorithm. However, the latter is a greedy algorithm, while the ML based methods may deviate from it, which could be beneficial (especially, Babaki et al can try to learn a better sequential baseline if available). Some of these papers also consider adding multiple columns, as also suggested by Reviewer DMVD, and accepted as future work by the authors. Hence, comparison to these papers could partially answer that question.\nIncluding the validation curves for curriculum learning as requested by Reviewer Eksw would also be quite interesting.\n\nI sincerely hope that authors can run these experiments while preparing the final version.",
        "reviews": [
            "Reviewer 1: \nSummary: The paper proposes a reinforcement-learning-based approach for column selection within a column generation procedure to solve an LP relaxation. Candidate columns come from a set of solutions encountered while solving the column generation subproblem, and Q-learning is applied to choose a column, rewarding large changes in objective value and few iterations. Computational results on cutting stock and vehicle routing problems show that this approach reduces number of iterations and solve times by a significant margin compared to standard column generation (at the cost of training on instances from the same family).\nStrengths And Weaknesses: This paper is a solid step in improving the scalability of problems in Operations Research using machine learning techniques. Column generation is an important technique to solve large-scale problems with exponentially-many columns, and the paper provides concrete evidence that a reinforcement-learning-based approach can be successful at selecting good columns, assuming one has a set of instances that can be trained on. While the RL formulation and neural network architecture mostly follow the literature standard, it is sound and novel (as far as I know). Furthermore, it is useful to know that curriculum learning helps in this approach. The computational experiments are well-designed and reasonably extensive: it includes hyperparameter tuning and a good number of practical instances. The improvements from this method are substantial in the context of machine learning techniques for OR, particularly for larger instances.\nI do not have any major concerns with the paper. The paper might have been slightly stronger if it compared with column generation with stabilization, but the method is already taking fewer iterations than a look-ahead expert, and thus this comparison might not be necessary.\nOverall, everything looks solid in the paper and I believe this is a valuable contribution. I recommend this paper to be accepted.\nQuestions: Minor suggestions related to clarity and details:\n\nPlease specify in Appendix C which PoolSearchMode parameter you are using in Gurobi to find the 10 candidate columns. It is useful to know if these are the top 10 candidates, or 10 incidental candidates during search.\n\nIn Appendix C, it refers to the code for the network structure. Could you please describe the network structure in the appendix?\n\nNotes on text: Missing figure reference in line 176. Typo \"hyperparemeters\" in line 304. Some of the citations need to be with parenthesis.\n\n\nI have a few questions that are not necessary for this submission, but mostly for my own curiosity:\n\nHave you considered keeping some of the older column candidates, perhaps with some system to age them out of the graph as needed? This could be helpful in two ways: a previous good column is still there if the RL agent ends up choosing a bad column by mistake, or if there is more than one column worth selecting in an iteration.\n\nHave you considered adding more than one column per iteration (i.e. between subproblem solves)? This would be an easy way to consider multiple columns. It might work better if you keep older candidates as described above.\n\nDo you know what features were important to select good columns? If this is insightful (e.g. if a particular feature that is not reduced cost stands out, or if it is still mainly reduced cost), I believe this would be a nice contribution to include in the paper. It would be great to know if one can extract heuristic insights that can be incorporated back into standard column generation, without lengthy training times. In addition, I am curious how much the problem-specific features matter, since ideally it would be good to have this work out-of-the-box without problem-specific features.\nLimitations: No further limitations other than the ones discussed above. The paper does a decent job at discussing its limitations at the end.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 4 excellent\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This work considers the problem of using machine learning (ML) to speed up the time to solve linear programmes (LPs) with a large number of columns (variables). Approaches to solving such problems fall under the category of column generation (CG); an approach whereby columns (variables) in the LP are iteratively selected from among the candidates to add to the restricted master problem (RMP) until no more columns with a negative reduced cost in the RMP are available, at which point a provably optimal solution to the LP will have been found. Classical approaches to CG typically follow a greedy policy whereby the column which leads to the most negative reduced cost is selected at each iteration. The authors posit that such a myopic approach does not necessarily lead to the fewest overall iterations to find the optimal solution to the LP. Instead, the authors propose a reinforcement learning for column generation (RLCG) method which treats column generation (CG) as a Markov decision process (MDP). Using this formulation, the authors train a policy parameterised by a graph neural network (GNN) with deep Q-learning (DQN) to, at each CG iteration, select the column which maximises the long-term return (which, in their setting, corresponds to minimising the overall number of CG iterations). The authors test their approach on the canonical cutting stock problem (CSP) and vehicle routing problem with time windows (VRPTW). They demonstrate that their method can outperform both a greedy heuristic and a 1-step-lookahead expert in terms of both solving time and decision quality (as measured by the overall number of CG iterations).\nStrengths And Weaknesses: Strong points:\n\nConsiders an important application area of machine learning; improved column generation algorithms have the potential to address a variety of real-world continuous and discrete optimisation problems.\nFor the most part, the paper is excellently written and easy to follow.\nThe RL agent outperforms the brute-force 1-step-lookahead expert in terms of decision quality on larger instances, which is an impressive result.\n\nWeak points:\n\nThe related work is missing some key ML-for-CG references.\nThe experiments section lacks a comparison to any ML-for-CG agent despite multiple options being available in the literature.\nThe curriculum learning approach and results seem unclear.\nQuestions: \nMissing related work and context: The authors discuss the work of Morabit et al. 2021, which they claim is the only prior work to have applied ML to CG. However, a quick search revealed there are at least a couple of other ML-for-CO approaches which have been proposed (e.g. Shen et al. 2021 and Babaki et al. 2022). The related work section should be more comprehensive to put the authors\u2019 work in the context of the current literature.\n\nMissing experimental baseline comparisons: \n\nDespite the availability of the above ML-for-CG algorithms, and despite the authors referring to the work of Morabit et al. 2021, the authors provide no comparison to any ML-for-CG baseline in the experiments section. Instead, the authors only compare to a simple greedy heuristic and to the 1-step-lookahead expert used by Morabit et al. 2021 for the data labeling process. The authors justify omission of the Morabit et al. 2021 ML agent by claiming that the expert they used provides an upper-bound on the best possible performance of the ML agent. While this is true in terms of decision quality, the ML agent of Morabit et al. 2021 should have a much faster solving time than that of the the 1-step-lookahead expert it imitates. Therefore, the authors should compare the solving time of RLCG to that of the ML agent of Morabit et al. 2021 - this should also enable more baselines than just greedy to be added to the VRPTW benchmark, which the authors claim is too computationally expensive to apply the 1-step-lookahead expert.\n\nIn relation to the above, the authors might also consider comparing RLCG to the work of Shen et al. 2021 and Babaki et al. 2022. In particular, Shen et al. 2021 appear to compare their ML-for-CG agent to a more comprehensive set of CG solvers than those considered by the authors (e.g. see Fig 2 of their paper). Are such baselines not relevant to the authors\u2019 RLCG work?\n\n\n\nMissing discussion of agent performance trend: Why do the authors think in Fig 2 that the RL agent performs better than the expert in terms of number of iterations on the larger instances but not on the smaller instances (e.g. Fig 2a vs. Fig 2c)? This seems counter intuitive, since the expert is doing a 1-step lookahead regardless of the size of the problem, so I would have thought that the larger state-action space would have no effect on the expert but would present a familiar challenge for the RL agent. Is it really the case that this is down to longer episodes and therefore greater opportunity for non-myopic CG agents? Fig 2a already has episodes 40-80 iterations long, which seems ample opportunity to outperform a 1-step lookahead policy. Would this indicate that, for some reason, non-myopic policies only have an advantage (in terms of decision quality) over myopic agents when making column selection decisions which can influence future selections \u2265200 steps later?\n\nCurriculum learning analysis and discussion: It is interesting that the authors emphasise the importance of curriculum learning on the final attainable results of RLCG. However, I do not fully follow the curriculum learning schedule or its effects described in the Appendix.\n\nIn Fig 7 of the Appendix, the authors label their figures as \u2018learning curves\u2019. However, this is confusing terminology; usually learning curves show how the agent performs as a function of the number of training iterations/epochs it has undergone. The authors have instead plotted the instance index on the x-axis. As such, this is not really a curve showing how the agent is learning during training, but rather a plot of the agent\u2019s performance for each instance. Furthermore, it is not clear what Fig 7 is showing; when indexing the instances from easy to hard and then randomly indexing the instances, is it not obvious that the former will lead to an upwards trend and the latter will lead to a random noise graph? How does this show the influence of curriculum learning on the agent in terms of learning stability and/or final attainable performance? I think a simple validation plot showing the performance of the curriculum and w/o curriculum agents on the validation set as a function of learner epochs would be more useful and demonstrate the efficacy of curriculum learning.\nIn Table 5 of the Appendix, the authors show how they split the instances into easy, medium, and hard instance types, but I cannot see what the curriculum schedule is in terms of when the agent progresses to the next level of difficulty. When does the agent move from easy to normal to hard? This should be carefully and clearly described given the claimed importance of curriculum learning.\nFinally, although not essential, if space allows I would consider moving some of the curriculum learning results and/or their analysis and discussion into the main paper.\n\n\nAnalysis and discussion of proposed method's sensitivity to the introduced hyperparameter: Does the sensitivity of RLCG to \u03b1 in the reward function change for different problem types? What is the advantage of having this explicit balancing between the two components of the reward function?\n\n\nMiscellaneous minor issues\n\nPg 7 Fig 2: The figure text is too small to read.\n\nAppendix pg 16 line 523 typo: \u2018Similarly,the...\u2019\n\n\nReferences\n\nMouad Morabit, Guy Desaulniers, and Andrea Lodi. Machine-learning\u2013based column selection for column generation. Transportation Science, 55(4):815\u2013831, 2021.\n\nYunzhuang Shen, Yuan Sun, Xiaodong Li, Andrew Eberhard and Andreas Ernst. Enhancing Column Generation by a Machine-Learning-Based Pricing Heuristic for Graph Coloring. AAAI, 2022.\n\nBehrouz Babaki, Sanjay Dominik Jena and Laurent Charlin. Neural Column Generation for Capacitated Vehicle Routing. AAAI ML4OR Workshop, 2022.\nLimitations: N/A\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This work focuses on using Column Generation (CG) as an algorithm to solve large-scale linear programs. A DQN algorithm (called RLCG) combined with Graph Neural Networks is used to improve the column generation procedure. Specifically, RL is used to select columns for linear programs with many variables. To do so, it assumes that the Sub-Problem (SP) is solved at each iteration and a near-optimal set of column candidates G is returned. The greedy approach selects columns with the most negative reduced cost whereas the RL approach selects columns from G according to the Q-function learned by RLCG. RLCG converges faster and generates fewer iterations for the Cutting Stock Problem (CSP) and the Vehicle Routing Problem with Time Windows (VRPTW), compared to a greedy policy. In some cases it has similar performance to MILPs, although as the problem size increases, appears to outperform them as well.\nStrengths And Weaknesses: Originality: \nThis paper appears to be original as I am unaware of RL being used for Column Generation. Utilizing graphnets to encode the state of the CG algorithm as well as the structure of the LP instance also appears to be a novel contribution.\nQuality: \nThe paper is well written and the authors appear to do a good experimental comparison with the baseline algorithms. In addition, experimental results are shown on multiple domains which further strengthens the results.\nClarity: \nColumn Generation is only introduced on the 3rd page. The authors need to restructure this as many readers will probably not be familiar with CG and will therefore not understand much in the first 2 pages.\nFigure 2: The axes are very hard to read\nSignificance: \nIt is difficult for me to judge the significance of the results. When introducing the CG problem, the authors mention that it is the workhorse for tackling large scale integer linear programs. However, the authors then state that they do not tackle the integer case (line 39). This paper would be greatly strengthened, in my opinion, if the authors explain the significance of their results or alternatively, provide an example tackling the integer case.\nQuestions: Column Generation is only introduced on the 3rd page. The authors need to restructure this as many readers will probably not be familiar with CG and will therefore not understand much in the first 2 pages.\nYou mention that RLCG is unable to train on instances of n=750 as it is expensive to solve such instances during training. Is scalability a fundamental limitation of the approach?\nHow sensitive is the curriculum training process? Is it easy to build a curriculum? What happens if you do not use a curriculum?\nFor the Vehicle Routing problem, how does RL compare to MILPs?\nLine 39: The authors don\u2019t seem to tackle the integer case which is what they claimed CG is mainly used for. As such, I\u2019d like the authors to help me better understand the significance of these results.\nLimitations: The authors mention some limitations, such as adding a single column per CG iteration. However, there are a couple of other limitations that I think should be noted:\n1.Scalability - it seems that, as the problem size increases, it becomes increasingly expensive to train the agent, to the point where it is not feasible. I do not have good intuition as to whether n=750 is difficult in the CSP problem for example, so it would be good for the authors to discuss the scalability challenges and significance of their results in more depth.\n\nPerformance compared to MILP - the authors need to be more specific as to how their method compares to MILP as they are both competitive. A statistical analysis would be important here to better understand where each method has its strengths and weaknesses. Replacing Figure 3 with this analysis would be helpful, as I dont get much insight from these figures.\n\nWhen introducing the CG problem, the authors mention that it is the workhorse for tackling large scale integer linear programs. However, the authors then state that they do not tackle the integer case (line 39). This paper would be greatly strengthened, in my opinion, if the authors explain the significance of their results and/or provide an example tackling the integer case. A strong argument here will influence my score.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper studies the use of reinforcement learning to improve the column generation algorithm. In particular, the authors design a state space around a bipartite graph containing column nodes and constraint nodes, and an action space derived from RMP and SP formulations of the problem. These two aspects are the main challenge of the translation, the reward function is then set to a reasonable choice, and a standard RL algorithm (DQN) is applied. Testing in two problems (cutting stock and vehicle routing) show their method outperforms a baseline.\nStrengths And Weaknesses: Strong:\n\nThe application of RL to combinatorial optimization is a relevant research topic that gets more and more attention.\nThe method outperforms the baseline on two relevant problems (cutting stock problem and vehicle routing problem with time windows).  \nI like Figure 1, it clarifies a lot. \nYou open source your code.\n\nWeak:\n\nSee questions section. \nThere are very little details on the RL side of things (like a DQN update equation or target computation). I understand your focus is on the adaptation of column generation to RL, but I do think one or two paragraph with an equation would help a lot. \nYou repeatedly point to Figure 6 in Appendix A, but if that is important to explain your method, it should appear in the main paper. \nIn general you have quite a lot of text and little conceptual illustration. I think a good Figure 1 showing your method could help a lot.\nQuestions: Questions:\n\nSec. 3: I have trouble understanding how the SP formulation follows from the RMP formulation (Line 130). The transition here is very abrupt, where does \\pi come from, how is it computed from the RMP, etc. A figure (conceptual example) would help here a lot as well.   \nL165-168: You design column node features and constraint node features based \u201cbased on our previous experience\u201d. Are these features problem independent? How vital are they for your method? Can you really defer this to the appendix? \nL 172: It is unclear from the text how the exact GNN looks like. I do understand the bipartite graph structure, but how are all combined node embeddings mapped to the Q-function output? You need to at least briefly mention something about this in the main paper text.\n\nConclusion: This is a decent paper. The main contribution of the paper is the adaptation of CG to the RL setting. The main challenge is the way to represent the state space (as a bipartite graph), and the use of RMP and SP formulations to design an action space at each iteration. They can then apply any standard RL method, like DQN in this paper. The method subsequently outperforms the baseline. There have been many new applications of RL to combinatorial optimization problems in recent years (which makes the paper less groundbreaking), but it does seem to be a valuable addition.\nLimitations:\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The paper proposes a reinforcement-learning-based approach for column selection within a column generation procedure to solve an LP relaxation. Candidate columns come from a set of solutions encountered while solving the column generation subproblem, and Q-learning is applied to choose a column, rewarding large changes in objective value and few iterations. Computational results on cutting stock and vehicle routing problems show that this approach reduces number of iterations and solve times by a significant margin compared to standard column generation (at the cost of training on instances from the same family).",
                "Strengths And Weaknesses": "This paper is a solid step in improving the scalability of problems in Operations Research using machine learning techniques. Column generation is an important technique to solve large-scale problems with exponentially-many columns, and the paper provides concrete evidence that a reinforcement-learning-based approach can be successful at selecting good columns, assuming one has a set of instances that can be trained on. While the RL formulation and neural network architecture mostly follow the literature standard, it is sound and novel (as far as I know). Furthermore, it is useful to know that curriculum learning helps in this approach. The computational experiments are well-designed and reasonably extensive: it includes hyperparameter tuning and a good number of practical instances. The improvements from this method are substantial in the context of machine learning techniques for OR, particularly for larger instances.\nI do not have any major concerns with the paper. The paper might have been slightly stronger if it compared with column generation with stabilization, but the method is already taking fewer iterations than a look-ahead expert, and thus this comparison might not be necessary.\nOverall, everything looks solid in the paper and I believe this is a valuable contribution. I recommend this paper to be accepted.",
                "Questions": "Minor suggestions related to clarity and details:\n\nPlease specify in Appendix C which PoolSearchMode parameter you are using in Gurobi to find the 10 candidate columns. It is useful to know if these are the top 10 candidates, or 10 incidental candidates during search.\n\nIn Appendix C, it refers to the code for the network structure. Could you please describe the network structure in the appendix?\n\nNotes on text: Missing figure reference in line 176. Typo \"hyperparemeters\" in line 304. Some of the citations need to be with parenthesis.\n\n\nI have a few questions that are not necessary for this submission, but mostly for my own curiosity:\n\nHave you considered keeping some of the older column candidates, perhaps with some system to age them out of the graph as needed? This could be helpful in two ways: a previous good column is still there if the RL agent ends up choosing a bad column by mistake, or if there is more than one column worth selecting in an iteration.\n\nHave you considered adding more than one column per iteration (i.e. between subproblem solves)? This would be an easy way to consider multiple columns. It might work better if you keep older candidates as described above.\n\nDo you know what features were important to select good columns? If this is insightful (e.g. if a particular feature that is not reduced cost stands out, or if it is still mainly reduced cost), I believe this would be a nice contribution to include in the paper. It would be great to know if one can extract heuristic insights that can be incorporated back into standard column generation, without lengthy training times. In addition, I am curious how much the problem-specific features matter, since ideally it would be good to have this work out-of-the-box without problem-specific features.",
                "Limitations": "No further limitations other than the ones discussed above. The paper does a decent job at discussing its limitations at the end.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "4 excellent",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This work considers the problem of using machine learning (ML) to speed up the time to solve linear programmes (LPs) with a large number of columns (variables). Approaches to solving such problems fall under the category of column generation (CG); an approach whereby columns (variables) in the LP are iteratively selected from among the candidates to add to the restricted master problem (RMP) until no more columns with a negative reduced cost in the RMP are available, at which point a provably optimal solution to the LP will have been found. Classical approaches to CG typically follow a greedy policy whereby the column which leads to the most negative reduced cost is selected at each iteration. The authors posit that such a myopic approach does not necessarily lead to the fewest overall iterations to find the optimal solution to the LP. Instead, the authors propose a reinforcement learning for column generation (RLCG) method which treats column generation (CG) as a Markov decision process (MDP). Using this formulation, the authors train a policy parameterised by a graph neural network (GNN) with deep Q-learning (DQN) to, at each CG iteration, select the column which maximises the long-term return (which, in their setting, corresponds to minimising the overall number of CG iterations). The authors test their approach on the canonical cutting stock problem (CSP) and vehicle routing problem with time windows (VRPTW). They demonstrate that their method can outperform both a greedy heuristic and a 1-step-lookahead expert in terms of both solving time and decision quality (as measured by the overall number of CG iterations).",
                "Strengths And Weaknesses": "Strong points:\n\nConsiders an important application area of machine learning; improved column generation algorithms have the potential to address a variety of real-world continuous and discrete optimisation problems.\nFor the most part, the paper is excellently written and easy to follow.\nThe RL agent outperforms the brute-force 1-step-lookahead expert in terms of decision quality on larger instances, which is an impressive result.\n\nWeak points:\n\nThe related work is missing some key ML-for-CG references.\nThe experiments section lacks a comparison to any ML-for-CG agent despite multiple options being available in the literature.\nThe curriculum learning approach and results seem unclear.",
                "Questions": "Missing related work and context: The authors discuss the work of Morabit et al. 2021, which they claim is the only prior work to have applied ML to CG. However, a quick search revealed there are at least a couple of other ML-for-CO approaches which have been proposed (e.g. Shen et al. 2021 and Babaki et al. 2022). The related work section should be more comprehensive to put the authors\u2019 work in the context of the current literature.\n\nMissing experimental baseline comparisons: \n\nDespite the availability of the above ML-for-CG algorithms, and despite the authors referring to the work of Morabit et al. 2021, the authors provide no comparison to any ML-for-CG baseline in the experiments section. Instead, the authors only compare to a simple greedy heuristic and to the 1-step-lookahead expert used by Morabit et al. 2021 for the data labeling process. The authors justify omission of the Morabit et al. 2021 ML agent by claiming that the expert they used provides an upper-bound on the best possible performance of the ML agent. While this is true in terms of decision quality, the ML agent of Morabit et al. 2021 should have a much faster solving time than that of the the 1-step-lookahead expert it imitates. Therefore, the authors should compare the solving time of RLCG to that of the ML agent of Morabit et al. 2021 - this should also enable more baselines than just greedy to be added to the VRPTW benchmark, which the authors claim is too computationally expensive to apply the 1-step-lookahead expert.\n\nIn relation to the above, the authors might also consider comparing RLCG to the work of Shen et al. 2021 and Babaki et al. 2022. In particular, Shen et al. 2021 appear to compare their ML-for-CG agent to a more comprehensive set of CG solvers than those considered by the authors (e.g. see Fig 2 of their paper). Are such baselines not relevant to the authors\u2019 RLCG work?\n\n\n\nMissing discussion of agent performance trend: Why do the authors think in Fig 2 that the RL agent performs better than the expert in terms of number of iterations on the larger instances but not on the smaller instances (e.g. Fig 2a vs. Fig 2c)? This seems counter intuitive, since the expert is doing a 1-step lookahead regardless of the size of the problem, so I would have thought that the larger state-action space would have no effect on the expert but would present a familiar challenge for the RL agent. Is it really the case that this is down to longer episodes and therefore greater opportunity for non-myopic CG agents? Fig 2a already has episodes 40-80 iterations long, which seems ample opportunity to outperform a 1-step lookahead policy. Would this indicate that, for some reason, non-myopic policies only have an advantage (in terms of decision quality) over myopic agents when making column selection decisions which can influence future selections \u2265200 steps later?\n\nCurriculum learning analysis and discussion: It is interesting that the authors emphasise the importance of curriculum learning on the final attainable results of RLCG. However, I do not fully follow the curriculum learning schedule or its effects described in the Appendix.\n\nIn Fig 7 of the Appendix, the authors label their figures as \u2018learning curves\u2019. However, this is confusing terminology; usually learning curves show how the agent performs as a function of the number of training iterations/epochs it has undergone. The authors have instead plotted the instance index on the x-axis. As such, this is not really a curve showing how the agent is learning during training, but rather a plot of the agent\u2019s performance for each instance. Furthermore, it is not clear what Fig 7 is showing; when indexing the instances from easy to hard and then randomly indexing the instances, is it not obvious that the former will lead to an upwards trend and the latter will lead to a random noise graph? How does this show the influence of curriculum learning on the agent in terms of learning stability and/or final attainable performance? I think a simple validation plot showing the performance of the curriculum and w/o curriculum agents on the validation set as a function of learner epochs would be more useful and demonstrate the efficacy of curriculum learning.\nIn Table 5 of the Appendix, the authors show how they split the instances into easy, medium, and hard instance types, but I cannot see what the curriculum schedule is in terms of when the agent progresses to the next level of difficulty. When does the agent move from easy to normal to hard? This should be carefully and clearly described given the claimed importance of curriculum learning.\nFinally, although not essential, if space allows I would consider moving some of the curriculum learning results and/or their analysis and discussion into the main paper.\n\n\nAnalysis and discussion of proposed method's sensitivity to the introduced hyperparameter: Does the sensitivity of RLCG to \u03b1 in the reward function change for different problem types? What is the advantage of having this explicit balancing between the two components of the reward function?\n\n\nMiscellaneous minor issues\n\nPg 7 Fig 2: The figure text is too small to read.\n\nAppendix pg 16 line 523 typo: \u2018Similarly,the...\u2019\n\n\nReferences\n\nMouad Morabit, Guy Desaulniers, and Andrea Lodi. Machine-learning\u2013based column selection for column generation. Transportation Science, 55(4):815\u2013831, 2021.\n\nYunzhuang Shen, Yuan Sun, Xiaodong Li, Andrew Eberhard and Andreas Ernst. Enhancing Column Generation by a Machine-Learning-Based Pricing Heuristic for Graph Coloring. AAAI, 2022.\n\nBehrouz Babaki, Sanjay Dominik Jena and Laurent Charlin. Neural Column Generation for Capacitated Vehicle Routing. AAAI ML4OR Workshop, 2022.",
                "Limitations": "N/A",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This work focuses on using Column Generation (CG) as an algorithm to solve large-scale linear programs. A DQN algorithm (called RLCG) combined with Graph Neural Networks is used to improve the column generation procedure. Specifically, RL is used to select columns for linear programs with many variables. To do so, it assumes that the Sub-Problem (SP) is solved at each iteration and a near-optimal set of column candidates G is returned. The greedy approach selects columns with the most negative reduced cost whereas the RL approach selects columns from G according to the Q-function learned by RLCG. RLCG converges faster and generates fewer iterations for the Cutting Stock Problem (CSP) and the Vehicle Routing Problem with Time Windows (VRPTW), compared to a greedy policy. In some cases it has similar performance to MILPs, although as the problem size increases, appears to outperform them as well.",
                "Strengths And Weaknesses": "Originality: \nThis paper appears to be original as I am unaware of RL being used for Column Generation. Utilizing graphnets to encode the state of the CG algorithm as well as the structure of the LP instance also appears to be a novel contribution.\nQuality: \nThe paper is well written and the authors appear to do a good experimental comparison with the baseline algorithms. In addition, experimental results are shown on multiple domains which further strengthens the results.\nClarity: \nColumn Generation is only introduced on the 3rd page. The authors need to restructure this as many readers will probably not be familiar with CG and will therefore not understand much in the first 2 pages.\nFigure 2: The axes are very hard to read\nSignificance: \nIt is difficult for me to judge the significance of the results. When introducing the CG problem, the authors mention that it is the workhorse for tackling large scale integer linear programs. However, the authors then state that they do not tackle the integer case (line 39). This paper would be greatly strengthened, in my opinion, if the authors explain the significance of their results or alternatively, provide an example tackling the integer case.",
                "Questions": "Column Generation is only introduced on the 3rd page. The authors need to restructure this as many readers will probably not be familiar with CG and will therefore not understand much in the first 2 pages.\nYou mention that RLCG is unable to train on instances of n=750 as it is expensive to solve such instances during training. Is scalability a fundamental limitation of the approach?\nHow sensitive is the curriculum training process? Is it easy to build a curriculum? What happens if you do not use a curriculum?\nFor the Vehicle Routing problem, how does RL compare to MILPs?\nLine 39: The authors don\u2019t seem to tackle the integer case which is what they claimed CG is mainly used for. As such, I\u2019d like the authors to help me better understand the significance of these results.",
                "Limitations": "The authors mention some limitations, such as adding a single column per CG iteration. However, there are a couple of other limitations that I think should be noted:\n1.Scalability - it seems that, as the problem size increases, it becomes increasingly expensive to train the agent, to the point where it is not feasible. I do not have good intuition as to whether n=750 is difficult in the CSP problem for example, so it would be good for the authors to discuss the scalability challenges and significance of their results in more depth.\n\nPerformance compared to MILP - the authors need to be more specific as to how their method compares to MILP as they are both competitive. A statistical analysis would be important here to better understand where each method has its strengths and weaknesses. Replacing Figure 3 with this analysis would be helpful, as I dont get much insight from these figures.\n\nWhen introducing the CG problem, the authors mention that it is the workhorse for tackling large scale integer linear programs. However, the authors then state that they do not tackle the integer case (line 39). This paper would be greatly strengthened, in my opinion, if the authors explain the significance of their results and/or provide an example tackling the integer case. A strong argument here will influence my score.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper studies the use of reinforcement learning to improve the column generation algorithm. In particular, the authors design a state space around a bipartite graph containing column nodes and constraint nodes, and an action space derived from RMP and SP formulations of the problem. These two aspects are the main challenge of the translation, the reward function is then set to a reasonable choice, and a standard RL algorithm (DQN) is applied. Testing in two problems (cutting stock and vehicle routing) show their method outperforms a baseline.",
                "Strengths And Weaknesses": "Strong:\n\nThe application of RL to combinatorial optimization is a relevant research topic that gets more and more attention.\nThe method outperforms the baseline on two relevant problems (cutting stock problem and vehicle routing problem with time windows).  \nI like Figure 1, it clarifies a lot. \nYou open source your code.\n\nWeak:\n\nSee questions section. \nThere are very little details on the RL side of things (like a DQN update equation or target computation). I understand your focus is on the adaptation of column generation to RL, but I do think one or two paragraph with an equation would help a lot. \nYou repeatedly point to Figure 6 in Appendix A, but if that is important to explain your method, it should appear in the main paper. \nIn general you have quite a lot of text and little conceptual illustration. I think a good Figure 1 showing your method could help a lot.",
                "Questions": "Questions:\n\nSec. 3: I have trouble understanding how the SP formulation follows from the RMP formulation (Line 130). The transition here is very abrupt, where does \\pi come from, how is it computed from the RMP, etc. A figure (conceptual example) would help here a lot as well.   \nL165-168: You design column node features and constraint node features based \u201cbased on our previous experience\u201d. Are these features problem independent? How vital are they for your method? Can you really defer this to the appendix? \nL 172: It is unclear from the text how the exact GNN looks like. I do understand the bipartite graph structure, but how are all combined node embeddings mapped to the Q-function output? You need to at least briefly mention something about this in the main paper text.\n\nConclusion: This is a decent paper. The main contribution of the paper is the adaptation of CG to the RL setting. The main challenge is the way to represent the state space (as a bipartite graph), and the use of RMP and SP formulations to design an action space at each iteration. They can then apply any standard RL method, like DQN in this paper. The method subsequently outperforms the baseline. There have been many new applications of RL to combinatorial optimization problems in recent years (which makes the paper less groundbreaking), but it does seem to be a valuable addition.",
                "Limitations": "",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "soundness_avg": 3.0,
        "presentation_avg": 2.75,
        "contribution_avg": 3.0,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \nBased on the reviews from other reviewers, it is clear that this paper makes a valuable contribution to the field of Operations Research by proposing a reinforcement-learning-based approach for column selection within a column generation procedure. The paper is well-written and provides concrete evidence that the proposed approach can significantly reduce the number of iterations and solve times compared to standard column generation techniques. The computational experiments are well-designed and extensive, and the improvements from this method are substantial, particularly for larger instances. \n\nWhile there are some minor suggestions related to clarity and details, overall the paper is technically solid and has a high impact on the field. The limitations of the paper are well-discussed, and the authors have addressed most of the concerns raised by the reviewers. \n\nTherefore, I recommend accepting this paper for publication."
    },
    "Sublinear_Algorithms_for_Hierarchical_Clustering": {
        "link": "https://openreview.net//forum?id=VPhhd5pv0Qs",
        "pub_url": "https://openreview.net/forum?id=VPhhd5pv0Qs",
        "pdf_link": "https://openreview.net//pdf?id=VPhhd5pv0Qs",
        "paper_id": "VPhhd5pv0Qs",
        "title": "Sublinear_Algorithms_for_Hierarchical_Clustering",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nThe paper presents new algorithm for hierarchical clustering in different regimes. In particular they show a new algorithm for a (dynamic) edge streaming model, for a neighbor query model and for the MPC model. The paper contains both nice theory results and in the rebuttal phase the author(s) supported them with interesting experimental results.\nOverall, we suggest to accept the paper as poster.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper designs sublinear algorithms for hierarchical clustering in dynamic streaming model, query model and MPC model over very large graphs. Minimum cost hierarchical partitioning is the optimization objection (Dasgupta\u2019s cost function). From the theoretical aspect, this paper proved the bounds including lower and upper bound respectively for the three given models. They prove a general structural result that shows that a cut sparsifier can be used to recover a (1 +o(1))-approximation to the underlying HC instance.\nStrengths And Weaknesses: Although this research problem is not novel, sublinear algorithms for hierarchical clustering is one of the fundamental issue in the studies of graphs. Lots of applications need the sublinear algorithms especially for massive graphs. The paper is well written with a good presentation. It supplies enough theoretical proofs for the complexity and (1 +o(1))-approximation is a good general structural result in the three models. However, I have some concerns about the approach and applications.\n1.\tSome recent works prove a seem better bound for the same problem. The authors should compare to them. For example, Assadi S, Chatziafratis V, Mirrokni V, et al. Hierarchical Clustering in Graph Streams: Single-Pass Algorithms and Space Lower Bounds[C]//Conference on Learning Theory. PMLR, 2022: 4643-4702.\n2.\tAlthough proofs on bounds are good evidence for showing the performance, it would be better and attractive to give some practical experimental studies to show the real effectiveness in massive graphs. In some cases, a well theoretical complexity still be not enough for the real huge graphs.\nMinor problem:\nAlthough the presentation is relatively well, some necessary examples are needed for the readers to follow clearly.\nQuestions: none\nLimitations: \n   Some recent works prove a seem better bound for the same problem. The authors should compare to them. For example, Assadi S, Chatziafratis V, Mirrokni V, et al. Hierarchical Clustering in Graph Streams: Single-Pass Algorithms and Space Lower Bounds[C]//Conference on Learning Theory. PMLR, 2022: 4643-4702.\n   Although proofs on bounds are good evidence for showing the performance, it would be better and attractive to give some practical experimental studies to show the real effectiveness in massive graphs. In some cases, a well theoretical complexity still be not enough for the real huge graphs.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper considers developing resource efficient algorithms for hierarchical clustering of weighted graphs in several settings (streaming, graph query model, mpc model).  Following recent work which developed an objective function for hierarchical clustering (Dasgupta 2016), the goal is to develop algorithms with sublinear resource usage (in the number of edges) in each model while producing an O(\u03d5)-approximation to the optimal tree for Dasgupta's objective function.  The main results of this paper are to achieve exactly this.  By making a key observation about the structure of the objective function, the authors show that this problem reduces to efficiently constructing a cut sparsifier.  In some settings (e.g. streaming using O~(n) space), this can be done immediately via known techniques for constructing cut sparsifiers.  For the other settings (graph query model and the mpc model), a more relaxed notion of cut sparsifier is proposed (which allows for some additive error in addition to the multiplicative error), and the authors give sublinear algorithms for constructing such a relaxed cut sparsifier in the remaining settings.  Lower bounds showing near optimality of the results are also given.\nStrengths And Weaknesses: There has been significant interest in hierarchical clustering recently and one issue that many algorithms suffer from is scalability.  This paper helps to address this problem in several settings from the perspective of Dasgupta's objective function.  The techniques are natural and are well explained.\nOne thing that is missing from this paper (but not probably not necessary) is an experimental evaluation to demonstrate the practical effectiveness of the proposed algorithms.\nQuestions: How would the proposed algorithms compare to practically efficient algorithms? e.g. Sumengen, Baris, et al. \"Scaling hierarchical agglomerative clustering to billion-sized datasets.\" arXiv preprint arXiv:2105.11653 (2021).\nLimitations: N/A\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 4 excellent\nRating: 8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: Hierarchical clustering over graphs ha been mathematically formalized with a natural objective function introduced by Dasgupta [STOC2016]. Unfortunately, this function is hard to optimize and approximation algorithms have been proposed in the TCS literature. This paper studies this problem in the regime of sublinear computational resources, specifically, for three models of computations:\n\nstreaming model = sublinear space\nquery model = sublinear time\nMPC model = sublinear communication\nFor each model, upper and lower bounds are provided.\nStrengths And Weaknesses: The paper presents informal statements for the main results proven in Appendix. The results appear to be new. There is a recent COLT paper [5] with similar results in the streaming setting.\nThis paper is well-written and deals with theoretical results.\nThe motivation for these results is very far from any practical application.\nQuestions: I am not sure I understand the motivation for the authors to submit this paper to Neurips and I would like to hear their arguments explaining why it is more appropriate to publish this work at Neurips instead of a TCS conference like SODA, STOC, FOCS? I did count 12 references in JACM, STOC, SODA and FOCS. \nI like cross-disciplinary work but then you need a lot more work to motivate your results. As it is written, I hardly see any possible impact for this paper in the ML community. Even the computational models will only be known from a minority of the audience, so that the main results will not be understood.\nSimilarly, the lower bounds are obtained by constructing very contrived graphs. I understand that these hard instances are instructive in order to understand the worst-case performance of algorithms. But what is the motivation for these bounds in a machine learning setting?\nLimitations: NA\nEthics Flag: No\nSoundness: 3 good\nPresentation: 1 poor\nContribution: 1 poor\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper focuses on hierarchical clustering over graphs with the objective function of Dasgupta. Sublinear algorithms w.r.t. the number of edges in the input graph are developed in three models of computation, including the dynamic streaming model, the query model, and the massively parallel computation (MPC) model. Interesting matching lower bounds are provided for the upper bounded resource above. Specifically, a 1-pass semi-streaming algorithm naturally follow from existing algorithm [1] and their observation. In the query model, combining existing methods [14,37] and their observation leads to sublinear time algorithms for graphs of different sparsity. For the MPC model, a 2-round O~(m)-memory algorithm and a 1-round \u0398~(m4/3)-memory algorithm are developed based on [1]. All above algorithms rely on the crucial observations that, from a graph cut perspective, the objective function can be well approximated in a cut sparsifier of the input graph. Moreover, two hard instances are designed to derive time and communication lower bounds in the query and MPC models, respectively. Finally, the extensions to other related hierarchical clustering objectives such as the dissimilarity [15] are discussed.\nStrengths And Weaknesses: Strengths:\n\nThe idea of using cut sparsifiers in improving the computational resource of graph algorithms has been widely used. But using it in hierarchical clustering and providing theoretical analysis on the required resource and approximation factor is not well studied with only a few related work, e.g., [5]. The problem of hierarchical clustering is reduced to the problem of constructing cut sparsifiers with limited resource based on the observations that cut sparsifiers can approximately preserve the cost of a dendrogram. Comprehensive studies on 3 models of computation are performed and upper bounds are complemented with almost matching lower bounds.\nThe developed lower bounds in the query and MPC models are quite interesting and need to overcome multiple challenges. The authors are able to describe the high-level overview in the main text and then refer to the full details in the Appendix.\nThe organization of this work is good. I like the discussions in Sections 4 and 5, providing context on related works and extensions to other objective functions of hierarchical clustering. I browsed some contents in the Appendix and the quality of writing remains good compared to the main text.\n\nWeaknesses:\n\nThe computational upper bounds developed in Section 2 are not very challenging and based on existing methods in the respective models. The upper and lower bounds in the dynamic streaming model are straightforward.\nAs a reader of a hierarchical clustering paper in NeurIPS, I would expect to see some experimental results on the developed algorithm unless the theoretical contributions are very novel and significant. It would be much better if experiments on some of the algorithms had been implemented and evaluated in real-world datasets.\nQuestions: In the alternative view of the objective based on S-T cut, a sparsifier approximately preserving all S-T cut values suffers from the lower bound of \u03a9(m). When transforming the S-T cut to graph cut (S,S\u00af)-cut, why the barrier of lower bound can be broken?\nLimitations: No\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper designs sublinear algorithms for hierarchical clustering in dynamic streaming model, query model and MPC model over very large graphs. Minimum cost hierarchical partitioning is the optimization objection (Dasgupta\u2019s cost function). From the theoretical aspect, this paper proved the bounds including lower and upper bound respectively for the three given models. They prove a general structural result that shows that a cut sparsifier can be used to recover a (1 +o(1))-approximation to the underlying HC instance.",
                "Strengths And Weaknesses": "Although this research problem is not novel, sublinear algorithms for hierarchical clustering is one of the fundamental issue in the studies of graphs. Lots of applications need the sublinear algorithms especially for massive graphs. The paper is well written with a good presentation. It supplies enough theoretical proofs for the complexity and (1 +o(1))-approximation is a good general structural result in the three models. However, I have some concerns about the approach and applications.\n1.\tSome recent works prove a seem better bound for the same problem. The authors should compare to them. For example, Assadi S, Chatziafratis V, Mirrokni V, et al. Hierarchical Clustering in Graph Streams: Single-Pass Algorithms and Space Lower Bounds[C]//Conference on Learning Theory. PMLR, 2022: 4643-4702.\n2.\tAlthough proofs on bounds are good evidence for showing the performance, it would be better and attractive to give some practical experimental studies to show the real effectiveness in massive graphs. In some cases, a well theoretical complexity still be not enough for the real huge graphs.\nMinor problem:\nAlthough the presentation is relatively well, some necessary examples are needed for the readers to follow clearly.",
                "Questions": "none",
                "Limitations": "Some recent works prove a seem better bound for the same problem. The authors should compare to them. For example, Assadi S, Chatziafratis V, Mirrokni V, et al. Hierarchical Clustering in Graph Streams: Single-Pass Algorithms and Space Lower Bounds[C]//Conference on Learning Theory. PMLR, 2022: 4643-4702.\n   Although proofs on bounds are good evidence for showing the performance, it would be better and attractive to give some practical experimental studies to show the real effectiveness in massive graphs. In some cases, a well theoretical complexity still be not enough for the real huge graphs.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper considers developing resource efficient algorithms for hierarchical clustering of weighted graphs in several settings (streaming, graph query model, mpc model).  Following recent work which developed an objective function for hierarchical clustering (Dasgupta 2016), the goal is to develop algorithms with sublinear resource usage (in the number of edges) in each model while producing an O(\u03d5)-approximation to the optimal tree for Dasgupta's objective function.  The main results of this paper are to achieve exactly this.  By making a key observation about the structure of the objective function, the authors show that this problem reduces to efficiently constructing a cut sparsifier.  In some settings (e.g. streaming using O~(n) space), this can be done immediately via known techniques for constructing cut sparsifiers.  For the other settings (graph query model and the mpc model), a more relaxed notion of cut sparsifier is proposed (which allows for some additive error in addition to the multiplicative error), and the authors give sublinear algorithms for constructing such a relaxed cut sparsifier in the remaining settings.  Lower bounds showing near optimality of the results are also given.",
                "Strengths And Weaknesses": "There has been significant interest in hierarchical clustering recently and one issue that many algorithms suffer from is scalability.  This paper helps to address this problem in several settings from the perspective of Dasgupta's objective function.  The techniques are natural and are well explained.\nOne thing that is missing from this paper (but not probably not necessary) is an experimental evaluation to demonstrate the practical effectiveness of the proposed algorithms.",
                "Questions": "How would the proposed algorithms compare to practically efficient algorithms? e.g. Sumengen, Baris, et al. \"Scaling hierarchical agglomerative clustering to billion-sized datasets.\" arXiv preprint arXiv:2105.11653 (2021).",
                "Limitations": "N/A",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "4 excellent",
                "Rating": "8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "Hierarchical clustering over graphs ha been mathematically formalized with a natural objective function introduced by Dasgupta [STOC2016]. Unfortunately, this function is hard to optimize and approximation algorithms have been proposed in the TCS literature. This paper studies this problem in the regime of sublinear computational resources, specifically, for three models of computations:\n\nstreaming model = sublinear space\nquery model = sublinear time\nMPC model = sublinear communication\nFor each model, upper and lower bounds are provided.",
                "Strengths And Weaknesses": "The paper presents informal statements for the main results proven in Appendix. The results appear to be new. There is a recent COLT paper [5] with similar results in the streaming setting.\nThis paper is well-written and deals with theoretical results.\nThe motivation for these results is very far from any practical application.",
                "Questions": "I am not sure I understand the motivation for the authors to submit this paper to Neurips and I would like to hear their arguments explaining why it is more appropriate to publish this work at Neurips instead of a TCS conference like SODA, STOC, FOCS? I did count 12 references in JACM, STOC, SODA and FOCS. \nI like cross-disciplinary work but then you need a lot more work to motivate your results. As it is written, I hardly see any possible impact for this paper in the ML community. Even the computational models will only be known from a minority of the audience, so that the main results will not be understood.\nSimilarly, the lower bounds are obtained by constructing very contrived graphs. I understand that these hard instances are instructive in order to understand the worst-case performance of algorithms. But what is the motivation for these bounds in a machine learning setting?",
                "Limitations": "NA",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "1 poor",
                "Contribution": "1 poor",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper focuses on hierarchical clustering over graphs with the objective function of Dasgupta. Sublinear algorithms w.r.t. the number of edges in the input graph are developed in three models of computation, including the dynamic streaming model, the query model, and the massively parallel computation (MPC) model. Interesting matching lower bounds are provided for the upper bounded resource above. Specifically, a 1-pass semi-streaming algorithm naturally follow from existing algorithm [1] and their observation. In the query model, combining existing methods [14,37] and their observation leads to sublinear time algorithms for graphs of different sparsity. For the MPC model, a 2-round O~(m)-memory algorithm and a 1-round \u0398~(m4/3)-memory algorithm are developed based on [1]. All above algorithms rely on the crucial observations that, from a graph cut perspective, the objective function can be well approximated in a cut sparsifier of the input graph. Moreover, two hard instances are designed to derive time and communication lower bounds in the query and MPC models, respectively. Finally, the extensions to other related hierarchical clustering objectives such as the dissimilarity [15] are discussed.",
                "Strengths And Weaknesses": "Strengths:\n\nThe idea of using cut sparsifiers in improving the computational resource of graph algorithms has been widely used. But using it in hierarchical clustering and providing theoretical analysis on the required resource and approximation factor is not well studied with only a few related work, e.g., [5]. The problem of hierarchical clustering is reduced to the problem of constructing cut sparsifiers with limited resource based on the observations that cut sparsifiers can approximately preserve the cost of a dendrogram. Comprehensive studies on 3 models of computation are performed and upper bounds are complemented with almost matching lower bounds.\nThe developed lower bounds in the query and MPC models are quite interesting and need to overcome multiple challenges. The authors are able to describe the high-level overview in the main text and then refer to the full details in the Appendix.\nThe organization of this work is good. I like the discussions in Sections 4 and 5, providing context on related works and extensions to other objective functions of hierarchical clustering. I browsed some contents in the Appendix and the quality of writing remains good compared to the main text.\n\nWeaknesses:\n\nThe computational upper bounds developed in Section 2 are not very challenging and based on existing methods in the respective models. The upper and lower bounds in the dynamic streaming model are straightforward.\nAs a reader of a hierarchical clustering paper in NeurIPS, I would expect to see some experimental results on the developed algorithm unless the theoretical contributions are very novel and significant. It would be much better if experiments on some of the algorithms had been implemented and evaluated in real-world datasets.",
                "Questions": "In the alternative view of the objective based on S-T cut, a sparsifier approximately preserving all S-T cut values suffers from the lower bound of \u03a9(m). When transforming the S-T cut to graph cut (S,S\u00af)-cut, why the barrier of lower bound can be broken?",
                "Limitations": "No",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.0,
        "confidence_avg": 3.0,
        "soundness_avg": 2.75,
        "presentation_avg": 2.75,
        "contribution_avg": 2.5,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is clear that this paper presents a technically solid and well-written contribution to the field of hierarchical clustering in graphs. The paper addresses the problem of developing sublinear algorithms for hierarchical clustering in various computational models, and provides upper and lower bounds for each model. The reviewers have acknowledged the novelty and significance of the results, and have highlighted the natural and well-explained techniques used in the paper.\n\nWhile there are some minor concerns raised by the reviewers, such as the need for comparison with recent works and the lack of experimental evaluation, these concerns do not outweigh the strengths of the paper. The theoretical contributions and the comprehensive studies on the different computational models make this paper a valuable addition to the field.\n\nTherefore, I recommend accepting this paper for publication."
    },
    "A_Few_Expert_Queries_Suffices_for_Sample-Efficient_RL_with_Resets_and_Linear_Value_Approximation": {
        "link": "https://openreview.net//forum?id=d19Dsqtw421",
        "pub_url": "https://openreview.net/forum?id=d19Dsqtw421",
        "pdf_link": "https://openreview.net//pdf?id=d19Dsqtw421",
        "paper_id": "d19Dsqtw421",
        "title": "A_Few_Expert_Queries_Suffices_for_Sample-Efficient_RL_with_Resets_and_Linear_Value_Approximation",
        "is_accepted": true,
        "meta_review": "Recommendation: Accept\nConfidence: Certain\nWe thank the authors for their submission.\nThe paper studies finite-horizon MDPs in which only the optimal value function is realized by a linear function. The learner has access to the MDP via a generative model and has to minimize its sample complexity for finding a policy with approximately optimal value function. This was shown by prior work to require a number of samples exponential in the problem parameters.\nContributions: First, an algorithm that guarantees polynomial sample complexity if the learner has additional access to O(d) expert demonstrations. Second, a lower bound of \u03a9(d) on the required number of expert queries. \nThe work adds to our understanding of when MDPs with linear function approximation are solvable, showing that a hard RL problem becomes easy with a small amount of additional information. It is very well-written.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper studies the problem of reinforcement learning of reinforcement learning with a linearly realizable optimal value function. While this problem is infeasible in general (as shown by recent lower bounds), this paper shows that two additional assumptions are sufficient for sample efficiency in this setting: O(d) queries to an expert and the ability to resample arbitrarily many times from the most recent state visited. A new algorithm is proposed that achieves poly sample complexity under these assumptions. Lower bounds are shown justifying at least O(\\sqrt{d}) queries from the expert.\nStrengths And Weaknesses: \nIn my view, the results constitute contributions to both reinforcement learning (specifically to the study of weaker forms of realizability) and imitation learning. On the RL side, we learn that a notoriously harder problem is solvable with a limited amount of side information in the form of expert actions. On the IL side, we get a clearer picture of how much interactive expert information is actually necessary to learn in a sample efficient manner.\nThe paper is very well written and easy to understand. It does a good job of placing itself in the literature and making clear what is and is not possible with existing results.\nThe insight of how to use the expert queries is interesting and seems to be new.\n\nWeaknesses\n\nThe algorithm requires a resetting assumption (this is weaker than a full generative model but stronger than the standard episodic RL setup)\nThere is a gap between the sqrt{d} lower bound and d upper bound.\nQuestions: \nWhile the paper\u2019s theoretical contributions are already very strong, I am curious why there were no experiments, especially considering the algorithm is advertised as being computationally efficient? How do you think this algorithm will compare to IL algorithms like BC, Dagger, and Aggrevate? How would it compare to RL algorithms?\nI\u2019m also curious about how necessary Assumption 2.3 (resets) is. It is clear that it plays an important role in the proposed algorithm to identify states for which there is consistency. What seems to be the technical challenges needed to remove this? \nCan you also comment on to what extent using Assumption 2.3 might be helping with the linear realizability assumption? For example, in some offline RL papers, one sometimes sees that double-sampling enables sample-efficient guarantees even with few assumptions on the function class (like completeness), so I am curious if something similar is happening under the hood here. Clearly resetting is not enough by itself given the existing lower bounds, but I am curious to know how much it helps / if it's necessary.\nLimitations: The limitations are adequately addressed.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: Assuming that only the optimal value function is linearly-realizable for the homogeneous finite horizon MDP, this paper proposes a sample-efficient algorithm with access to interactive demonstrations from an expert policy.\nStrengths And Weaknesses: The authors exaggerate their results due to misunderstanding others' conclusions.\nSpecifically, the exponential lower bounds (w.r.t. H, d) in [WAS21] and [WWK21] are constructed based on exponentially large action spaces.\nAs far as I know, the prior arts only establish the poly(d,H,A,1/\u03b5) lower bound.\nThe authors should correct their claim throughout the paper, if they cannot provide the exponential lower bounds (w.r.t. H, d, A).\nIn addition, it seems a better result is given in [AJKS19] for the infinite horizon MDP, which I see in Section 5. \nIf this is right, the authors should discuss the difficulties of this extension.\nThe writing should be improved due to many typos.\nQuestions: The authors exaggerate their results due to misunderstanding others' conclusions.\nLimitations: The authors exaggerate their results due to misunderstanding others' conclusions.\nEthics Flag: No\nSoundness: 1 poor\nPresentation: 2 fair\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: Recent work has shown that linear realizability of the optimal value function is not a sufficient condition for sample-efficient RL (i.e. you need exponentially many samples to find a near optimal policy). This work shows that it is possible to learn a near-optimal policy using only polynomially many samples if the learner is also given access to an oracle it can query and which will return a \u201cgood\u201d action at a given state. In particular, they show that if the value function of this oracle can be parameterized by a d-dimensional feature vector, then with O(d) calls to the oracle, it is possible to learn a near-optimal policy using only polynomially many samples. In addition, a lower bound is given which shows that at least \u03a9(d) oracle queries are necessary for sample-efficient learning.\nStrengths And Weaknesses: Strengths:\n\nUnderstanding when sample-efficient learning in RL is possible is an important question that has been of much interest in recent years. This work makes a non-trivial contribution to developing our understanding of this. I believe it is interesting and not obvious that by making limited oracle queries a previously intractable problem becomes tractable, though I have some concerns on the rate (see below).\n\nWeaknesses:\n\nI believe the primary weakness of this work is the gap between the O(d) upper bound on the oracle queries, and the \u03a9(d) lower bound. It is easy to construct settings where O(d) calls to an oracle trivially solves the problem. For example, if we consider a tabular MDP with S states and A actions, the typical mapping from tabular to a linearly parameterized MDP has dimension d=SA. In this setting, if we query an oracle SA times, that will simply give us the oracle policy, and the problem is solved. A similar conclusion can be reached in linear MDPs. Even in the more difficult setting considered in this work, the proposed algorithm seems to be doing something similar: since it assumes the oracle policy has a linearly realizable value function, it essentially just queries it in a spanning set of directions, which allows the value function to be approximately recovered. It does not seem too surprising this is possible, but doing this in O(d) oracle calls seems much less trivial, as in that case the learner would have to do a significant amount of learning without relying on the oracle. Thus, I think closing this gap between O(d) and \u03a9(d) is essential for this to be a convincing result, but I don\u2019t think the style of algorithm proposed here is able to do this. \nOne suggestion for improving this would be to restrict the learner so it can only access the oracle in the state it is currently visiting. The proposed algorithm only requires this type of access, and it would make it at least somewhat less trivial to solve easier problems with an oracle, as some exploration would still be required. \nIs the assumption that the oracle policy is linear in the features necessary? It seems essential to the algorithm. I don\u2019t think this is a critical issue since, if we take the oracle policy to simply be the optimal policy, this will be satisfied by our linear realizability assumption, but relaxing this assumption would still strengthen the results.\nQuestions: None.\nLimitations: Limitations are discussed. No discussion is given on societal impact. While the work is primarily theoretical and may not have obvious immediate societal impact, it is contributing to the larger field of RL which does have practical impact. Given this, I would encourage the authors to consider what such impacts might be, and how negative impacts might be mitigated.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: The paper studies the RL problem of approximating the behavior of an expert demonstrator in a setting where the learner is allowed to both interactively query the environment and query the expert. Under the assumption that the value function of the expert is linearly realizable in a known feature mapping, the authors prove that the Delphi algorithm finds an eps optimal policy using O(d) samples and polynomially many samples in the other problem parameters.\nStrengths And Weaknesses: The paper makes significant progress towards understanding the possibilities (and limitations) of learning a good policy in MDPs under linear function approximation. They introduce a new (and sensible) sufficient condition for the problem to be statistically tractable. \nThe paper is very clearly written. It nicely communicates the intuition behind the algorithm and why we might expect it to work. The lower bounds on the number of expert queries that are necessary nicely complement the analysis of the Delphi algorithm and add to the picture of learning with expert demonstrations. The robustness results regarding mispecified dynamics and value functions are also interesting.\nQuestions: In L:124, the authors claim that assumption 2.1 is necessary. This isn\u2019t supported by the theoretical results. The assumption is definitinitely sufficient, but it isn\u2019t strictly necessary? There could be other assumptions (distinct from 2.1) that could enable sample efficient learning. \nI can see that the expert policy is consistent if it corresponds to the optimal policy, but why should we expect this to hold generically for non-optimal policies?\nIn Theorem 3.1, the authors claim that the algorithm is computationally efficient. What is the precise, formal statement here? There is no formal runtime bound that is provided.\nLimitations: These are adequately adressed.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 4 excellent\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper studies the problem of reinforcement learning of reinforcement learning with a linearly realizable optimal value function. While this problem is infeasible in general (as shown by recent lower bounds), this paper shows that two additional assumptions are sufficient for sample efficiency in this setting: O(d) queries to an expert and the ability to resample arbitrarily many times from the most recent state visited. A new algorithm is proposed that achieves poly sample complexity under these assumptions. Lower bounds are shown justifying at least O(\\sqrt{d}) queries from the expert.",
                "Strengths And Weaknesses": "In my view, the results constitute contributions to both reinforcement learning (specifically to the study of weaker forms of realizability) and imitation learning. On the RL side, we learn that a notoriously harder problem is solvable with a limited amount of side information in the form of expert actions. On the IL side, we get a clearer picture of how much interactive expert information is actually necessary to learn in a sample efficient manner.\nThe paper is very well written and easy to understand. It does a good job of placing itself in the literature and making clear what is and is not possible with existing results.\nThe insight of how to use the expert queries is interesting and seems to be new.\n\nWeaknesses\n\nThe algorithm requires a resetting assumption (this is weaker than a full generative model but stronger than the standard episodic RL setup)\nThere is a gap between the sqrt{d} lower bound and d upper bound.",
                "Questions": "While the paper\u2019s theoretical contributions are already very strong, I am curious why there were no experiments, especially considering the algorithm is advertised as being computationally efficient? How do you think this algorithm will compare to IL algorithms like BC, Dagger, and Aggrevate? How would it compare to RL algorithms?\nI\u2019m also curious about how necessary Assumption 2.3 (resets) is. It is clear that it plays an important role in the proposed algorithm to identify states for which there is consistency. What seems to be the technical challenges needed to remove this? \nCan you also comment on to what extent using Assumption 2.3 might be helping with the linear realizability assumption? For example, in some offline RL papers, one sometimes sees that double-sampling enables sample-efficient guarantees even with few assumptions on the function class (like completeness), so I am curious if something similar is happening under the hood here. Clearly resetting is not enough by itself given the existing lower bounds, but I am curious to know how much it helps / if it's necessary.",
                "Limitations": "The limitations are adequately addressed.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "Assuming that only the optimal value function is linearly-realizable for the homogeneous finite horizon MDP, this paper proposes a sample-efficient algorithm with access to interactive demonstrations from an expert policy.",
                "Strengths And Weaknesses": "The authors exaggerate their results due to misunderstanding others' conclusions.\nSpecifically, the exponential lower bounds (w.r.t. H, d) in [WAS21] and [WWK21] are constructed based on exponentially large action spaces.\nAs far as I know, the prior arts only establish the poly(d,H,A,1/\u03b5) lower bound.\nThe authors should correct their claim throughout the paper, if they cannot provide the exponential lower bounds (w.r.t. H, d, A).\nIn addition, it seems a better result is given in [AJKS19] for the infinite horizon MDP, which I see in Section 5. \nIf this is right, the authors should discuss the difficulties of this extension.\nThe writing should be improved due to many typos.",
                "Questions": "The authors exaggerate their results due to misunderstanding others' conclusions.",
                "Limitations": "The authors exaggerate their results due to misunderstanding others' conclusions.",
                "Ethics Flag": "No",
                "Soundness": "1 poor",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "Recent work has shown that linear realizability of the optimal value function is not a sufficient condition for sample-efficient RL (i.e. you need exponentially many samples to find a near optimal policy). This work shows that it is possible to learn a near-optimal policy using only polynomially many samples if the learner is also given access to an oracle it can query and which will return a \u201cgood\u201d action at a given state. In particular, they show that if the value function of this oracle can be parameterized by a d-dimensional feature vector, then with O(d) calls to the oracle, it is possible to learn a near-optimal policy using only polynomially many samples. In addition, a lower bound is given which shows that at least \u03a9(d) oracle queries are necessary for sample-efficient learning.",
                "Strengths And Weaknesses": "Strengths:\n\nUnderstanding when sample-efficient learning in RL is possible is an important question that has been of much interest in recent years. This work makes a non-trivial contribution to developing our understanding of this. I believe it is interesting and not obvious that by making limited oracle queries a previously intractable problem becomes tractable, though I have some concerns on the rate (see below).\n\nWeaknesses:\n\nI believe the primary weakness of this work is the gap between the O(d) upper bound on the oracle queries, and the \u03a9(d) lower bound. It is easy to construct settings where O(d) calls to an oracle trivially solves the problem. For example, if we consider a tabular MDP with S states and A actions, the typical mapping from tabular to a linearly parameterized MDP has dimension d=SA. In this setting, if we query an oracle SA times, that will simply give us the oracle policy, and the problem is solved. A similar conclusion can be reached in linear MDPs. Even in the more difficult setting considered in this work, the proposed algorithm seems to be doing something similar: since it assumes the oracle policy has a linearly realizable value function, it essentially just queries it in a spanning set of directions, which allows the value function to be approximately recovered. It does not seem too surprising this is possible, but doing this in O(d) oracle calls seems much less trivial, as in that case the learner would have to do a significant amount of learning without relying on the oracle. Thus, I think closing this gap between O(d) and \u03a9(d) is essential for this to be a convincing result, but I don\u2019t think the style of algorithm proposed here is able to do this. \nOne suggestion for improving this would be to restrict the learner so it can only access the oracle in the state it is currently visiting. The proposed algorithm only requires this type of access, and it would make it at least somewhat less trivial to solve easier problems with an oracle, as some exploration would still be required. \nIs the assumption that the oracle policy is linear in the features necessary? It seems essential to the algorithm. I don\u2019t think this is a critical issue since, if we take the oracle policy to simply be the optimal policy, this will be satisfied by our linear realizability assumption, but relaxing this assumption would still strengthen the results.",
                "Questions": "None.",
                "Limitations": "Limitations are discussed. No discussion is given on societal impact. While the work is primarily theoretical and may not have obvious immediate societal impact, it is contributing to the larger field of RL which does have practical impact. Given this, I would encourage the authors to consider what such impacts might be, and how negative impacts might be mitigated.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper studies the RL problem of approximating the behavior of an expert demonstrator in a setting where the learner is allowed to both interactively query the environment and query the expert. Under the assumption that the value function of the expert is linearly realizable in a known feature mapping, the authors prove that the Delphi algorithm finds an eps optimal policy using O(d) samples and polynomially many samples in the other problem parameters.",
                "Strengths And Weaknesses": "The paper makes significant progress towards understanding the possibilities (and limitations) of learning a good policy in MDPs under linear function approximation. They introduce a new (and sensible) sufficient condition for the problem to be statistically tractable. \nThe paper is very clearly written. It nicely communicates the intuition behind the algorithm and why we might expect it to work. The lower bounds on the number of expert queries that are necessary nicely complement the analysis of the Delphi algorithm and add to the picture of learning with expert demonstrations. The robustness results regarding mispecified dynamics and value functions are also interesting.",
                "Questions": "In L:124, the authors claim that assumption 2.1 is necessary. This isn\u2019t supported by the theoretical results. The assumption is definitinitely sufficient, but it isn\u2019t strictly necessary? There could be other assumptions (distinct from 2.1) that could enable sample efficient learning. \nI can see that the expert policy is consistent if it corresponds to the optimal policy, but why should we expect this to hold generically for non-optimal policies?\nIn Theorem 3.1, the authors claim that the algorithm is computationally efficient. What is the precise, formal statement here? There is no formal runtime bound that is provided.",
                "Limitations": "These are adequately adressed.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "4 excellent",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.25,
        "confidence_avg": 3.25,
        "soundness_avg": 2.75,
        "presentation_avg": 3.0,
        "contribution_avg": 2.75,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that this paper makes significant contributions to the field of reinforcement learning and imitation learning. The paper is well-written and easy to understand, and it effectively places itself in the existing literature. The proposed algorithm shows promise in solving a notoriously difficult problem with limited side information. However, there are some concerns raised by the reviewers regarding the gap between the upper and lower bounds, as well as the necessity of certain assumptions. Despite these concerns, the overall consensus is that the paper is technically solid and has high impact. Therefore, I recommend accepting this paper."
    },
    "Context-enriched_molecule_representations_improve_few-shot_drug_discovery": {
        "link": "https://openreview.net//forum?id=kXXPLBEBVGH",
        "pub_url": "https://openreview.net/forum?id=kXXPLBEBVGH",
        "pdf_link": "https://openreview.net//pdf?id=kXXPLBEBVGH",
        "paper_id": "kXXPLBEBVGH",
        "title": "Context-enriched_molecule_representations_improve_few-shot_drug_discovery",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nThis paper proposes a context-enriched molecular representation approach for few-shot drug discovery. Specifically, they show that the proposed MHNfs outperform existing methods on standard benchmarks including FS-Mol and the Tox21.\nThe proposed approach is analogous to the retrieval-based approach or generation models by editing prototypes in the deep learning community, which enrich molecular representations through querying from a massive reference space, namely first looks at a group of context drug-like molecules, and then using self-attention to distribute that information among the query and support set molecules. \nThis is a borderline paper and the main concern of this paper is the limited insights in result analysis (e.g., what did the model learn from the context). I recommend the authors to address the weaknesses above and resubmit to another venue.",
        "reviews": [
            "Reviewer 1: \nSummary: The authors proposed a few-shot learning model to tackle the lack-of-data problem in drug discovery, where they demonstrated the proposed MHNfs model on benchmark dataset FS-Mol and the Tox21 dataset, reportedly outperforming existing methods. I find this paper clearly written with key concepts well explained. The central idea behind the proposed method, which is to enrich molecular representations through querying from a massive reference space (i.e., the context) is reasonable, since it is what a human expert would do in this scenario. Technical details are concisely discussed in the main text as well as the supplementary information, where non-domain experts should be able to understand and appreciate their work.\nStrengths And Weaknesses: Strengths\n[originality] The proposed model architecture is novel for the few-shot learning task, compared to existing models listed in Table1.\n[quality] The paper is well written with a clear story line and very few typos or grammar issues.\n[clarity] The key idea is clearly explained and model architecture is accurately described.\n[significance] The proposed method aims at solving a severe problem commonly encountered in drug discovery. The model seems to outperform all other existing models on the two prediction tasks demonstrated in the paper.\n\nWeakness\n[originality] The attention mechanism has been heavily exploited in the MHNfs model. Although the authors explained the difference between the proposed CM, CAM modules, they eventually both break down to the attention mechanism, which relies on computing the cosine similarity of linearly transformed key, query, and value embeddings. To that end, the novelty of the network architecture is not that significant in my opinion, regardless of the jargons and module names used to wrap these operations. That being said, the authors should probably spend more effort discussing and analyzing the significance of explicitly separating the support and context set, in comparison to other traditional methods. \n[quality] It would be ideal to have more discussions or insights on how the enrichment process benefits the predictive tasks (e.g., what did the model learn that made it better?), not just presenting tables with superior metrics. In addition, the authors used hand-crafted features (fingerprints and physical properties) for molecular embedding, I think it is widely accepted that there exists better molecular encoders, e.g., graph representations.\n[clarity] No major concerns.\n[significance] Regarding the quantitative model evaluation results, it would help the readers better appreciate the significance of this work by providing some sense of \"a good model\". Outperforming existing models is, of course, a significant contribution -- but readers who are not familiar with the specific predictive tasks may find it hard to judge whether the proposed method actually solved the proposed problem. For instance, in Table2, is AUC 0.679 good enough for the Tox21 task, or just a marginal performance gain compared to other methods?\nQuestions: Major concerns\n\nFor a real drug discovery problem, how should we choose the context dataset? The authors used part of the training set for the FS-Mol and Tox21 datasets, where the molecular data came from the same database, i.e., they are similar/related in some sense. However, when we only have access to, say, 16 known drug molecules for a particular disease, what would be the reasonable way to choose the context set? The authors should add more discussions about this problem. \n\nA follow-up to the previous concern, is it possible to use a general molecular database, e.g., GEOM-drugs, as the context set, and use the same support and query set for FS-Mol and Tox21 predictions? If that works, then the proposed context-enrichment method really works.\n\nIn the main text, line 82-84, \"Those retrieved representations have amplified co-occurrences and covariance\n83 structures, while peculiarities and spurious co-occurrences of the query and support set molecules are\n84 averaged out.\" Is it possible to illustrate this with an example, or somehow support the claim in your case?\n\nIn the main text, line 110-113, the authors discussed the limitations of standard supervised ML on data-scarce problems. I understand the point here, but I'm not sure if the statements here are accurate. Not all ML models will overfit the dataset, especially if somehow the model learns a proper similarity kernel function, which is exactly what the MHNfs model is doing.\n\nAs far as I know attention-based models are data-hungry, and takes time and computation to extract meaningful hidden patterns. However, given the dimension of the hidden space (thousands) used in this work, the number of data points (thousands) in the context set, and the number of epochs (20), I was wondering if the model has been properly trained. Can you please show some learning curvs, if possible? I am also kind of curious to see if there is overfitting problem in this case.\n\n\nMinor concerns\n\nIn the main text, line 79, \"as an associative memory\".\n\nIn the main text, line 92, \"and a domain shift experiment\".\n\nIn the main text, line 122, \"three consecutive modules that feed into each other\". It is a bit confusing to me since the architecture is a simple feed-forward model, I don't see the modules feeding into each other.\n\nI am curious about the balancing strategy described in Equation 10. Na\u00efvely, the kernel already provides a correlation between m and x, should we just attend to those with high correlation, and make some kind of vote from the highly correlated support set molecules, instead of using a weight based on the positive/negative ratio in the support set? Those molecules with small k(,) values may not contribute to the final voting. Any thoughts?\n\nIn the main text, line 320, the authors claimed \"significantly outperformed\". From the numerical values, I get the \"outperformed\" part, but please justify the use of \"significantly\" in this case.\nLimitations: \nThe authors wrote in line 336 that \"the model cannot be used for molecules such as RNA, DNA, or proteins\". I do not agree with this statement. Given the fact that the proposed method essentially captures the similarity through an attention-based kernel function by referencing from the context set, regardless of the underlying molecular representation, this method should be applicable to macromolecules as well. (E.g., I personally find the MSA blocks in AlphaFold2 similar to the CM module here) In fact, this few-shot learning method is potentially applicable to other data-scarce problems, as long as we could define a kernel function for similarity assessment.\n\nIn conclusion, I think the key problem that this work tried to address is evaluating molecular similarity in some embedding space, and use that information to facilitate model predictions with few support data. I would love to see how different molecular representations perform in terms of similarity assessment, and whether hand-crafted features outperform representations learned in a data-driven manner.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper proposes a context-enabled few shot learning method, which performs few shot classification by first looking at a group of context drug-like molecules, and then uses self-attention to distribute that information among the query and support set molecules. The authors show good empirical performance on FS-Mol, as well as ablations of the different parts of their model. Finally, the authors also present a FrequentHitters baseline, which performs very well despite ignoring the support set, yielding useful insight into why some of the FS-Mol baselines fail and how they could be improved.\nStrengths And Weaknesses: === Strengths === \n\n(S1): The paper considers an important (and still somewhat underexplored) problem of few-shot drug design, proposing a method based on an interesting mechanism of context lookup. The model design is clear and reasonable, and empirical performance is encouraging. \n\n(S2): Apart from outlining their main method, the authors also discuss a FrequentHitters baseline, which ignores the support set and yet performs very well, which is intriguing, and could inform improvements to existing methods (see (Q4) for further thoughts on this). \n\n(S3): The paper is well-written, with clear explanations and visualizations (in particular, Figure 1 is quite nice). The discussion is well-structured, most design decisions are clearly explained and ablated. The text flows smoothly, with very few minor typos or grammar errors.\n\n\n=== Weaknesses === \n\n(W1): The paper only reports results with support set size 16, ignoring {32, 64, 128, 256} which are also commonly evaluated (e.g. in the original FS-Mol paper [1], and some other papers reporting results on that benchmark like [2]). It would be very interesting to see a plot akin to Figure 2a in [1]. As a start, it would be interesting to see the result for at least one larger support set size e.g. 128 (at 256 some FS-Mol-specific quirks kick in, and this leads to some artifacts in the performance of some of the methods). \n\n(W2): Despite most aspects of the work being well-explained, some things are still not clear to me (see the \"Questions\" section). Further clarifying these would help polish the paper further. In particular, addressing (Q5) would be helpful for understanding why MHNfs works well.\n\n\n=== Summary === \nOverall, this paper proposes a clear and reasonable approach, that (despite its simplicity) works very well on an important benchmark. The authors also propose an interesting baseline, which performs surprisingly well, leading to some useful insights. Finally, the paper is pleasant to read and the results seem reproducible. I think the paper is in good shape and a useful contribution to NeurIPS, hence I vote for acceptance. \n=== Other comments === \nHere I include various other comments, which had only a small impact on my score. \n\n(O1): Table 1 misses a (very recent) result of [2], which (looking at their Figure 1a) gets a very similar context-size-16 result to MHNfs. I'm curious as to what the comparison is for larger support set sizes. \n\n(O2): The authors say they use MHNs, as opposed to attention, attributing this to MHNs being more general. As far as I understand (but please correct me if I'm wrong), the main part where MHNs are practically more general than cross attention is that the formulation of MHNs considers the possibility of sequentially updating the \"attention weights\" several times before returning the output (this is different from having several sets of parallel attention weights, i.e. heads). However, it seems to me many papers using MHNs don't make use of this sequential update, which reduces to standard cross attention. In particular, while I agree with the authors that Equation (9) is a special case of Equation (7), the latter looks like standard cross attention to me (i.e. it's obviously not self-attention, but it looks like the kind of attention a decoder would do over the outputs of an encoder in a translation model). In general, I'm not too strongly opposed to calling cross-attention MHNs to make a connection to some theoretical results or leave the possibility of doing the iterative update of attention weights, but if the flavour of MHNs used is synonymous to attention (which I understand is the case for this work), I think this should be made more clear.\n\n\n=== Nitpicks === \nHere I include some final nitpicks, which did not affect my score; they are here just to help improve the paper.\n\nLine 92: \"an domain shift experiment\" - \"an\" -> \"a\" \n\nLine 108: \"predicts y for a x\" - \"a\" -> \"an\"; \"the model that generalizes\" - I'd say \"a model\" \n\nMissing space in lines 149 and 237\n\nLine 241: \"wich\" -> \"which\" \n\nLine 254: \"dataset on related task and then adapting\" -> \"dataset of related tasks and then adapt\" \n\nLine 262: \"support support\" \n\nLine 324: the last sentence of the paragraph reads a bit off, might be useful to rephrase it (even though it may technically be grammatically correct) \n\nLine 346: \"material science dataset\" -> \"material science datasets\" \n\nLine 363: \"This, might\" - drop the comma \n\nLine 647 (appendix): \"fingerprints Morgan\" -> \"Morgan fingerprints\"\n\n\n=== References === \n[1] Stanley et al, \"FS-Mol: A Few-Shot Learning Dataset of Molecules\" \n[2] Chen et al, \"Meta-learning Adaptive Deep Kernel Gaussian Processes for Molecular Property Prediction\"\nQuestions: \n(Q1): It's interesting that MHNfs works so well with a very simple encoder (just a single linear layer on fingerprints/descriptors). Did the authors try using a more complex (e.g. GNN-based) encoder? If training this end-to-end is not feasible due to overfitting, one approach could be to replace the rdkit-based input to the linear encoder with a frozen pretrained feature extractor, such as a GNN or a graph transformer. \n\n(Q2): Is there any intuition behind the label balancing strategy in Section 3.4? \n\n(Q3): It is not clear to me from Section 4.1 what the input to the linear encoder is: whether it's a fingerprint, descriptors from rdkit, or a concatenation of both. Appendix A.1.1 suggests a concatenation (although calling it \"an additive combination\"?), but that part of the paper is only about the FrequentHitters baseline. Generally, I think the input to the encoder should be clear from reading the main paper. \n\n(Q4): The fact that some of the methods developed for FS-Mol are outperformed by FrequentHitters seems to point to one issue with how some of these methods are designed: there doesn't seem to be a direct way for similarity-based models to learn a \"frequent hitter bias\" that only depends on the query molecule. I wonder if combining a frequent hitter branch (which would directly predict the output from the embedding of the query) with some of the methods would further improve them. In particular, given that MHNfs is similarity-based, could such an addition improve results further? It's not obvious that it would, as MHNfs already performs better than FrequentHitters, but maybe FH succeeds in some of the places where MHNfs fails. \n\n(Q5): Do the authors have any intuition as to what the context module is doing? What is it attending to? What kind of information can be extracted from looking at a seemingly random collection of drug-like molecules? Could it be focusing on some implicit signal, e.g. that active molecules may be more \"popular\" i.e. their variations may be also present in the context set as they were tested for activity against other targets?\nLimitations: The limitations of the method are discussed at length, and I have no concerns about that part of the paper. Perhaps one thing that would contribute to improving the understanding of the limitations is addressing (W1), as it would show whether MHNfs only works for very small support set sizes, or it can be considered a go-to method across a larger range.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: Considering few-shot drug discovery, the paper proposes to enrich molecular representation by associating molecules from the support set and query set with additional context molecules. The proposed method consists of (i) context module designed upon Modern Hopfield  Network, (ii) cross attention module, and (iii) similarity module. \nThe authors conduct experiments on FS-Mol dataset.\nStrengths And Weaknesses: Strength\n\nFigure 1 is nicely plotted, which conveys the flow of the proposed MHNfs.\nThe authors provide concise reproduction details in appendix.\n\nWeakness\n\nMotivation: The authors did not provide convincing motivations or necessity for using Modern Hopfield Networks. \nRelated Works: The paper lacks a related work section. It seems that the authors plan to describe this part in the introduction section. However, the literature review is not enough. In the past, several few-shot drug discovery works appear [a1,a2]. But the authors neglect them all. \nExperiments: Existing works [a1,a2,a3] use classic molecular property prediction datasets (i.e., Tox21, MUV, SIDER). While the authors only consider FS-Mol. FS-Mol is a new dataset published in dataset track of NeurIPS 2021, which naturally has only been tested by naive baselines. To show the proposed MHNfs indeed works the best on few-shot drug discovery, the authors can either (i) directly compare with [a1,a2] on FS-Mol, or (ii) test the proposed MHNfs on Tox21, MUV and SIDER, such that the performance can be compared with [a1,a2,a3]. \nWriting: The paper should be carefully proofread to correct title case, typos and grammar issues. In Table 1, the author only mark one result in bold while neglecting the others.\n\n[a1] Few-Shot Graph Learning for Molecular Property Prediction, WWW, 2021\n[a2] Property-Aware Relation Networks for Few-Shot Molecular Property Prediction, NeurIPS, 2021\n[a3] Low Data Drug Discovery with One-Shot Learning, ACS Cent. Sci., 2017\nQuestions: Please reply to my concerns in weakness. \nKey questions: \n\nThere exists a number of works using external memory, such as [b1,b2]. Why consider Modern Hopfield Networks instead? Any strength?\nPlease provide discussion and empirical comparison w.r.t [a1,a2].\n\n[b1] Meta-learning with memory-augmented neural networks, ICML, 2017\n[b2] Few-shot visual learning with contextual memory and fine-grained calibration, IJCAI, 2020\nLimitations: The authors provide discussion on limitations (including application domain and hyperparameter choices) and broader impact. The authors did not mention limitations of the proposed MHNfs from the perspective of methodology.\nEthics Flag: No\nSoundness: 1 poor\nPresentation: 2 fair\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The authors proposed a few-shot learning model to tackle the lack-of-data problem in drug discovery, where they demonstrated the proposed MHNfs model on benchmark dataset FS-Mol and the Tox21 dataset, reportedly outperforming existing methods. I find this paper clearly written with key concepts well explained. The central idea behind the proposed method, which is to enrich molecular representations through querying from a massive reference space (i.e., the context) is reasonable, since it is what a human expert would do in this scenario. Technical details are concisely discussed in the main text as well as the supplementary information, where non-domain experts should be able to understand and appreciate their work.",
                "Strengths And Weaknesses": "Strengths\n[originality] The proposed model architecture is novel for the few-shot learning task, compared to existing models listed in Table1.\n[quality] The paper is well written with a clear story line and very few typos or grammar issues.\n[clarity] The key idea is clearly explained and model architecture is accurately described.\n[significance] The proposed method aims at solving a severe problem commonly encountered in drug discovery. The model seems to outperform all other existing models on the two prediction tasks demonstrated in the paper.\n\nWeakness\n[originality] The attention mechanism has been heavily exploited in the MHNfs model. Although the authors explained the difference between the proposed CM, CAM modules, they eventually both break down to the attention mechanism, which relies on computing the cosine similarity of linearly transformed key, query, and value embeddings. To that end, the novelty of the network architecture is not that significant in my opinion, regardless of the jargons and module names used to wrap these operations. That being said, the authors should probably spend more effort discussing and analyzing the significance of explicitly separating the support and context set, in comparison to other traditional methods. \n[quality] It would be ideal to have more discussions or insights on how the enrichment process benefits the predictive tasks (e.g., what did the model learn that made it better?), not just presenting tables with superior metrics. In addition, the authors used hand-crafted features (fingerprints and physical properties) for molecular embedding, I think it is widely accepted that there exists better molecular encoders, e.g., graph representations.\n[clarity] No major concerns.\n[significance] Regarding the quantitative model evaluation results, it would help the readers better appreciate the significance of this work by providing some sense of \"a good model\". Outperforming existing models is, of course, a significant contribution -- but readers who are not familiar with the specific predictive tasks may find it hard to judge whether the proposed method actually solved the proposed problem. For instance, in Table2, is AUC 0.679 good enough for the Tox21 task, or just a marginal performance gain compared to other methods?",
                "Questions": "Major concerns\n\nFor a real drug discovery problem, how should we choose the context dataset? The authors used part of the training set for the FS-Mol and Tox21 datasets, where the molecular data came from the same database, i.e., they are similar/related in some sense. However, when we only have access to, say, 16 known drug molecules for a particular disease, what would be the reasonable way to choose the context set? The authors should add more discussions about this problem. \n\nA follow-up to the previous concern, is it possible to use a general molecular database, e.g., GEOM-drugs, as the context set, and use the same support and query set for FS-Mol and Tox21 predictions? If that works, then the proposed context-enrichment method really works.\n\nIn the main text, line 82-84, \"Those retrieved representations have amplified co-occurrences and covariance\n83 structures, while peculiarities and spurious co-occurrences of the query and support set molecules are\n84 averaged out.\" Is it possible to illustrate this with an example, or somehow support the claim in your case?\n\nIn the main text, line 110-113, the authors discussed the limitations of standard supervised ML on data-scarce problems. I understand the point here, but I'm not sure if the statements here are accurate. Not all ML models will overfit the dataset, especially if somehow the model learns a proper similarity kernel function, which is exactly what the MHNfs model is doing.\n\nAs far as I know attention-based models are data-hungry, and takes time and computation to extract meaningful hidden patterns. However, given the dimension of the hidden space (thousands) used in this work, the number of data points (thousands) in the context set, and the number of epochs (20), I was wondering if the model has been properly trained. Can you please show some learning curvs, if possible? I am also kind of curious to see if there is overfitting problem in this case.\n\n\nMinor concerns\n\nIn the main text, line 79, \"as an associative memory\".\n\nIn the main text, line 92, \"and a domain shift experiment\".\n\nIn the main text, line 122, \"three consecutive modules that feed into each other\". It is a bit confusing to me since the architecture is a simple feed-forward model, I don't see the modules feeding into each other.\n\nI am curious about the balancing strategy described in Equation 10. Na\u00efvely, the kernel already provides a correlation between m and x, should we just attend to those with high correlation, and make some kind of vote from the highly correlated support set molecules, instead of using a weight based on the positive/negative ratio in the support set? Those molecules with small k(,) values may not contribute to the final voting. Any thoughts?\n\nIn the main text, line 320, the authors claimed \"significantly outperformed\". From the numerical values, I get the \"outperformed\" part, but please justify the use of \"significantly\" in this case.",
                "Limitations": "The authors wrote in line 336 that \"the model cannot be used for molecules such as RNA, DNA, or proteins\". I do not agree with this statement. Given the fact that the proposed method essentially captures the similarity through an attention-based kernel function by referencing from the context set, regardless of the underlying molecular representation, this method should be applicable to macromolecules as well. (E.g., I personally find the MSA blocks in AlphaFold2 similar to the CM module here) In fact, this few-shot learning method is potentially applicable to other data-scarce problems, as long as we could define a kernel function for similarity assessment.\n\nIn conclusion, I think the key problem that this work tried to address is evaluating molecular similarity in some embedding space, and use that information to facilitate model predictions with few support data. I would love to see how different molecular representations perform in terms of similarity assessment, and whether hand-crafted features outperform representations learned in a data-driven manner.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposes a context-enabled few shot learning method, which performs few shot classification by first looking at a group of context drug-like molecules, and then uses self-attention to distribute that information among the query and support set molecules. The authors show good empirical performance on FS-Mol, as well as ablations of the different parts of their model. Finally, the authors also present a FrequentHitters baseline, which performs very well despite ignoring the support set, yielding useful insight into why some of the FS-Mol baselines fail and how they could be improved.",
                "Strengths And Weaknesses": "=== Strengths === \n\n(S1): The paper considers an important (and still somewhat underexplored) problem of few-shot drug design, proposing a method based on an interesting mechanism of context lookup. The model design is clear and reasonable, and empirical performance is encouraging. \n\n(S2): Apart from outlining their main method, the authors also discuss a FrequentHitters baseline, which ignores the support set and yet performs very well, which is intriguing, and could inform improvements to existing methods (see (Q4) for further thoughts on this). \n\n(S3): The paper is well-written, with clear explanations and visualizations (in particular, Figure 1 is quite nice). The discussion is well-structured, most design decisions are clearly explained and ablated. The text flows smoothly, with very few minor typos or grammar errors.\n\n\n=== Weaknesses === \n\n(W1): The paper only reports results with support set size 16, ignoring {32, 64, 128, 256} which are also commonly evaluated (e.g. in the original FS-Mol paper [1], and some other papers reporting results on that benchmark like [2]). It would be very interesting to see a plot akin to Figure 2a in [1]. As a start, it would be interesting to see the result for at least one larger support set size e.g. 128 (at 256 some FS-Mol-specific quirks kick in, and this leads to some artifacts in the performance of some of the methods). \n\n(W2): Despite most aspects of the work being well-explained, some things are still not clear to me (see the \"Questions\" section). Further clarifying these would help polish the paper further. In particular, addressing (Q5) would be helpful for understanding why MHNfs works well.\n\n\n=== Summary === \nOverall, this paper proposes a clear and reasonable approach, that (despite its simplicity) works very well on an important benchmark. The authors also propose an interesting baseline, which performs surprisingly well, leading to some useful insights. Finally, the paper is pleasant to read and the results seem reproducible. I think the paper is in good shape and a useful contribution to NeurIPS, hence I vote for acceptance. \n=== Other comments === \nHere I include various other comments, which had only a small impact on my score. \n\n(O1): Table 1 misses a (very recent) result of [2], which (looking at their Figure 1a) gets a very similar context-size-16 result to MHNfs. I'm curious as to what the comparison is for larger support set sizes. \n\n(O2): The authors say they use MHNs, as opposed to attention, attributing this to MHNs being more general. As far as I understand (but please correct me if I'm wrong), the main part where MHNs are practically more general than cross attention is that the formulation of MHNs considers the possibility of sequentially updating the \"attention weights\" several times before returning the output (this is different from having several sets of parallel attention weights, i.e. heads). However, it seems to me many papers using MHNs don't make use of this sequential update, which reduces to standard cross attention. In particular, while I agree with the authors that Equation (9) is a special case of Equation (7), the latter looks like standard cross attention to me (i.e. it's obviously not self-attention, but it looks like the kind of attention a decoder would do over the outputs of an encoder in a translation model). In general, I'm not too strongly opposed to calling cross-attention MHNs to make a connection to some theoretical results or leave the possibility of doing the iterative update of attention weights, but if the flavour of MHNs used is synonymous to attention (which I understand is the case for this work), I think this should be made more clear.\n\n\n=== Nitpicks === \nHere I include some final nitpicks, which did not affect my score; they are here just to help improve the paper.\n\nLine 92: \"an domain shift experiment\" - \"an\" -> \"a\" \n\nLine 108: \"predicts y for a x\" - \"a\" -> \"an\"; \"the model that generalizes\" - I'd say \"a model\" \n\nMissing space in lines 149 and 237\n\nLine 241: \"wich\" -> \"which\" \n\nLine 254: \"dataset on related task and then adapting\" -> \"dataset of related tasks and then adapt\" \n\nLine 262: \"support support\" \n\nLine 324: the last sentence of the paragraph reads a bit off, might be useful to rephrase it (even though it may technically be grammatically correct) \n\nLine 346: \"material science dataset\" -> \"material science datasets\" \n\nLine 363: \"This, might\" - drop the comma \n\nLine 647 (appendix): \"fingerprints Morgan\" -> \"Morgan fingerprints\"\n\n\n=== References === \n[1] Stanley et al, \"FS-Mol: A Few-Shot Learning Dataset of Molecules\" \n[2] Chen et al, \"Meta-learning Adaptive Deep Kernel Gaussian Processes for Molecular Property Prediction\"",
                "Questions": "(Q1): It's interesting that MHNfs works so well with a very simple encoder (just a single linear layer on fingerprints/descriptors). Did the authors try using a more complex (e.g. GNN-based) encoder? If training this end-to-end is not feasible due to overfitting, one approach could be to replace the rdkit-based input to the linear encoder with a frozen pretrained feature extractor, such as a GNN or a graph transformer. \n\n(Q2): Is there any intuition behind the label balancing strategy in Section 3.4? \n\n(Q3): It is not clear to me from Section 4.1 what the input to the linear encoder is: whether it's a fingerprint, descriptors from rdkit, or a concatenation of both. Appendix A.1.1 suggests a concatenation (although calling it \"an additive combination\"?), but that part of the paper is only about the FrequentHitters baseline. Generally, I think the input to the encoder should be clear from reading the main paper. \n\n(Q4): The fact that some of the methods developed for FS-Mol are outperformed by FrequentHitters seems to point to one issue with how some of these methods are designed: there doesn't seem to be a direct way for similarity-based models to learn a \"frequent hitter bias\" that only depends on the query molecule. I wonder if combining a frequent hitter branch (which would directly predict the output from the embedding of the query) with some of the methods would further improve them. In particular, given that MHNfs is similarity-based, could such an addition improve results further? It's not obvious that it would, as MHNfs already performs better than FrequentHitters, but maybe FH succeeds in some of the places where MHNfs fails. \n\n(Q5): Do the authors have any intuition as to what the context module is doing? What is it attending to? What kind of information can be extracted from looking at a seemingly random collection of drug-like molecules? Could it be focusing on some implicit signal, e.g. that active molecules may be more \"popular\" i.e. their variations may be also present in the context set as they were tested for activity against other targets?",
                "Limitations": "The limitations of the method are discussed at length, and I have no concerns about that part of the paper. Perhaps one thing that would contribute to improving the understanding of the limitations is addressing (W1), as it would show whether MHNfs only works for very small support set sizes, or it can be considered a go-to method across a larger range.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "Considering few-shot drug discovery, the paper proposes to enrich molecular representation by associating molecules from the support set and query set with additional context molecules. The proposed method consists of (i) context module designed upon Modern Hopfield  Network, (ii) cross attention module, and (iii) similarity module. \nThe authors conduct experiments on FS-Mol dataset.",
                "Strengths And Weaknesses": "Strength\n\nFigure 1 is nicely plotted, which conveys the flow of the proposed MHNfs.\nThe authors provide concise reproduction details in appendix.\n\nWeakness\n\nMotivation: The authors did not provide convincing motivations or necessity for using Modern Hopfield Networks. \nRelated Works: The paper lacks a related work section. It seems that the authors plan to describe this part in the introduction section. However, the literature review is not enough. In the past, several few-shot drug discovery works appear [a1,a2]. But the authors neglect them all. \nExperiments: Existing works [a1,a2,a3] use classic molecular property prediction datasets (i.e., Tox21, MUV, SIDER). While the authors only consider FS-Mol. FS-Mol is a new dataset published in dataset track of NeurIPS 2021, which naturally has only been tested by naive baselines. To show the proposed MHNfs indeed works the best on few-shot drug discovery, the authors can either (i) directly compare with [a1,a2] on FS-Mol, or (ii) test the proposed MHNfs on Tox21, MUV and SIDER, such that the performance can be compared with [a1,a2,a3]. \nWriting: The paper should be carefully proofread to correct title case, typos and grammar issues. In Table 1, the author only mark one result in bold while neglecting the others.\n\n[a1] Few-Shot Graph Learning for Molecular Property Prediction, WWW, 2021\n[a2] Property-Aware Relation Networks for Few-Shot Molecular Property Prediction, NeurIPS, 2021\n[a3] Low Data Drug Discovery with One-Shot Learning, ACS Cent. Sci., 2017",
                "Questions": "Please reply to my concerns in weakness. \nKey questions: \n\nThere exists a number of works using external memory, such as [b1,b2]. Why consider Modern Hopfield Networks instead? Any strength?\nPlease provide discussion and empirical comparison w.r.t [a1,a2].\n\n[b1] Meta-learning with memory-augmented neural networks, ICML, 2017\n[b2] Few-shot visual learning with contextual memory and fine-grained calibration, IJCAI, 2020",
                "Limitations": "The authors provide discussion on limitations (including application domain and hyperparameter choices) and broader impact. The authors did not mention limitations of the proposed MHNfs from the perspective of methodology.",
                "Ethics Flag": "No",
                "Soundness": "1 poor",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.333,
        "confidence_avg": 4.0,
        "soundness_avg": 2.333,
        "presentation_avg": 3.0,
        "contribution_avg": 2.667,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: The proposed few-shot learning model for drug discovery is well-written and the central idea of enriching molecular representations through querying from a massive reference space is reasonable. The paper has strengths in terms of originality, quality, clarity, and significance. However, there are some weaknesses, such as the lack of discussion on the significance of explicitly separating the support and context set, the use of hand-crafted features for molecular embedding, and the need for more quantitative evaluation results. The reviewers have raised some major and minor concerns, including the choice of the context dataset, the possibility of using a general molecular database as the context set, and the need for more training details and learning curves. Overall, the paper is technically solid and makes a good contribution to the field of few-shot drug discovery."
    },
    "The_Slingshot_Mechanism:_An_Empirical_Study_of_Adaptive_Optimizers_and_the_\\emph{Grokking_Phenomenon}": {
        "link": "https://openreview.net//forum?id=dJgYhYKvr1",
        "pub_url": "https://openreview.net/forum?id=dJgYhYKvr1",
        "pdf_link": "https://openreview.net//pdf?id=dJgYhYKvr1",
        "paper_id": "dJgYhYKvr1",
        "title": "The_Slingshot_Mechanism:_An_Empirical_Study_of_Adaptive_Optimizers_and_the_\\emph{Grokking_Phenomenon}",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Less certain\nThe paper examines a widely known phenomenon when training neural networks with adaptive optimizers, where the training loss cyclically alternates in later stages. Some evidence is given that, in the absence of explicit regularization, this is associated with improved generalization. The more concrete contribution of the paper is to show a strong link between the aforementioned cyclicity and sudden cyclic growth in the weight of the last layer of the network. The main concern is that beyond this empirical observation a specific mechanism behind the phenomenon is not identified, nor a clear connection is made with the apparent benefit to generalization. While the observations have merit, it is hard to determine whether cause-effect relationships exist between them, making the paper feel as a work-in-progress and only weakly significant to the community (judging by the reviewers being underwhelmed). If the authors are convinced of their message that \"slingshots\" cause \"grokking\" (in contrast to, e.g., being a by-product while the real mechanism lies elsewhere), then they are advised to show exactly that in the further elaboration of their work.",
        "reviews": [
            "Reviewer 1: \nSummary: The paper presents an empirical study on an optimization anomaly, which is referred to as the Slingshot Mechanism/Effect by the authors, when adaptive optimizers (e.g., Adams) are used for solving supervised learning problems. Specifically, it was found that, when adaptive optimizers were used, cyclic phase transitions between stable and unstable training occurred and were correlated with how the norm of the last-layer weights changed. The authors also reported findings on the correlations between the onset of the Slingshot Mechanism and the glokking phenomenon.\nStrengths And Weaknesses: Strengths:\n\nThe reported findings hint that extra care may be required when adaptive optimizers are used. The results may also promote further theoretical studies on the limitations of using adaptive optimizers in supervised learning.\n\nWeaknesses:\n\nAdditional numerical experiments could have been conducted to help future theorists better understand the source of issues. In particular, some rather simple diagnoses could have been done but were missing from the paper.\nThere is much room for improvement in presentation of the paper. See the specific comments in the Questions section.\nQuestions: Is the reported phenomenon unique to \"deep models\"?\nI did not see any numerical experiments on \"shallow models.\" From the appendix, I only see experiments with a transformer (12 layers and 10 million parameters), a CNN with VGG-like architecture (which I assume to be a deep model), a deep MLP with 6 layers, and a deep linear model with 6 layers. Without experiments with simple/shallow models, it is premature to draw the conclusion that Slingshot is a general phenomenon as the authors claimed in Lines 154-162. \nAs a matter of fact, given that the authors tried to illustrate the phenomenon using simple quadratic functions (Line 174), could the authors conduct a set of numerical experiments using quadratic functions to see whether the phenomenon still persists?\nSome simple numerical diagnoses could have been done.\nAs evident from Line 178, one issue with the adaptive optimization schemes considered is that the effective step size \u03bc/(|g|+\u03f5) can be much larger than the unnormalized step size \u03bc when the magnitude of the gradient g is small and \u03f5 is small. (Here, a small \u03f5 is assumed; otherwise, the update rule will not adapt much to the magnitude of g.) This implies that, when the magnitude of g is small, i.e., when the current iterate is near a stationary point, the next iterate of the gradient-based update can be very far from the stationary point, potentially leading to a sudden increase in the loss. \nFor gradient-based updates, when the objective function is smooth, it is known that a sufficient condition for decrease is to choose the step size to be less than 2/L, where L is the Lipschitz constant of the gradient (and is related to the Hessian). It would be useful to plot in Figure 3 the effective step size, given by \u03bc/(|g|+\u03f5), along with the sharpness to see if the step size is still small enough for the sufficient condition for decrease to hold. If the violation of the condition coincides with the increase in the loss, then this would provide a simple explanation of the Slingshot Effect.\nComments on presentation and typos:\n\nAre the Slingshot Mechanism and the Slingshot Effect the same thing? Both terms are used throughout the paper.\nFigure 1 and its first citation are too far apart: Figure 1 appears on the first page (even before the main text), but it citation does not appear until Line 158. \nA typo in Line 190: \"...evidence of Elingshot Effects.\"\nLine 230: What is 3.10e\u2212044? Also, it uncommon to write 10\u221204 instead of 10\u22124. This has occurred several times throughout the paper.\nLimitations: I do not have any comments on this.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper studies the grokking phenomenon introduced by Power et al [1], which is a curious phenomenon of delayed generalization. This paper describes a characteristic of training termed the \"slingshot mechanism\", that is found in a number of tasks and optimization settings. The slingshot mechanism refers to periods of instability found in adaptive optimizers in the late stages of training. These periods of instability are accompanied by norm increases in the classification layer, as well as an improvement in generalization performance for the grokking tasks introduced in [1]. The paper studies this phenomenon and finds that it occurs in a number of different tasks more general than those in [1], and find that it is controlled by the epsilon parameter in adaptive optimizers.\nStrengths And Weaknesses: Strengths\n\nThe paper has a good and comprehensive discussion of related work.\nThe paper characterizes an interesting phenomenon that is sometimes found in the optimization trajectory of adaptive optimizers.\nInteresting observations regarding the effect of epsilon on the slingshot behavior.\n\nWeaknesses\n\nThere is no explanation, empirical or otherwise, for how the slingshot mechanism may relate to generalization. Understanding the delayed generalization is an important aspect of why the grokking phenomenon in [1] is interesting to the community. I believe that in the current state, without a deeper understanding, this work may be more appropriate for a workshop submission.\nThe paper claims that the slingshot mechansim is a general phenomenon, however on CIFAR10 the phenomenon was mostly observed when training with extremely small training data (e.g. 200 examples), and no correlation to better generalization was shown. There is one experiment in the Appendix where the full CIFAR10 dataset is used in training a ViT model, but this model only achieves a final test accuracy of <80% and it's not clear how much test accuracy is improved due to the slingshot mechanism due to a single run and increasing test loss. This calls into question how relevant or general the identified behavior is to modern day neural networks.\nQuestions: \nIn Figure 3(d), why do we not see a corresponding spike in sharpness at the onset of the second plateau? Based on the hypothesis that the weights are flung to a new region in parameter space when the curvature grows too large, I would expect to see the curvature spike at each transition.\n\nFigure 5, what is the accuracy being plotted? Is it training accuracy or test accuracy? If test accuracy, what is the training accuracy of these models? Do all the runs achieve 100% training accuracy? It is unclear whether correlation with better generalization comes from the appearance of slingshots or from the bad hyperparameter choices required to remove slingshot behavior from the training trajectory. \n\nDataset size is a crucial parameter in determining whether grokking / generalization occurs in [1]. How does the correlation between generalization vs slingshot behavior change when models are trained with differing data size? Does slingshots exist regardless of whether the model generalizes?\nLimitations: Beyond the weaknesses I listed, the authors were good at addressing several limitations of this work.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The authors describe a \"slingshot\" effect present in the use of Adam (and cousins). This purportedly cyclic effect can be observed when the norm of the final layer sharply increases, often accompanied by an increase in train loss. The authors offer the slingshot effect as a possible explanation for the ability of Adam to induce generalization even without explicit regularization.\nStrengths And Weaknesses: This is overall a nicely executed empirical paper that reveals a moderately interesting phenomenon. A cyclic regime of generalization would be quite remarkable and this paper offers preliminary evidence that supports the authors' hypothesis. It is also refreshing that the authors did not attempt to handwave nonsense poorly-motivated math into the paper, which is unfortunately a severe problem even in 2022.\nMy main concerns are the following:\n\nSignificance: Given that this effect explains generalization in unregularized optimization, the overall impact to practical deep learning is somewhat muted.\nStrength of evidence: the results in the paper leave me with certain questions (most notably #6 below) as to whether the authors have sufficiently validated their hypothesized effect.\nImplications: the paper enumerates a number of interesting facts (e.g. dependence on \u03f5) but doesn't really dive deeper beyond some of those facts, leaving the reader wondering as to why those facts were presented.\n\nOverall, I enjoyed reading this paper. I don't think it's super noteworthy in terms of immediate impact, but it is (as far as I can tell) a novel discovery that may serve as a waypoint on our path to better understanding of oddball generalization phenomena in deep learning.\nQuestions: \nIs there a reason validation error/loss is not depicted in Fig 1? Given the emphasis in this paper on generalization, it seems odd not to depict in the headline figure.\nFigure 2(c) looks either incorrect or misgenerated\u2014the validation loss should not be zero at the beginning of training, unless I am missing something.\nDo the authors have any explanation for why Figure 3(d) doesn't show a high-curvature update on the second plateau?\nCan the authors elaborate more on the implications of the larger \u03f5 result? To me, larger \u03f5 ruining the grokking effect sort of implies that non-adaptive methods (e.g. plain GD) don't benefit from slingshotting either (which is exactly what the authors found empirically). But it would still be good to explicitly connect the dots here.\nI am also left wondering about the result on the paragraph starting on line 243. It's cool that the authors discovered it but what is it supposed to tell me? What about low-dim data makes the slingshot effect less likely to occur?\nFinally, is it fair to call this effect cyclic when most empirical examples only have two cycles (with a few having 3)? Is there a setup where we can see n distinct plateaus and sharp norm increases for some n>>3?\nLimitations: The authors do a good job not overclaiming, and they explicitly enumerate a number of other regimes that achieve the results despite lack of \"slingshot\". Certain items are left unaddressed (see \"Questions\").\nMinor\n\nLine 84: missing author name\nLine 112: what is \"Adam without momentum\" and how is it different from RMSProp?\nLine 145: \"layers\" \u2192 \"layer\"\nLine 170: \"has\" \u2192 \"have\"\nLine 245: \"choices\" \u2192 \"choice\"\nLine 254: \"it's\" \u2192 \"its\"\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The paper presents an empirical study on an optimization anomaly, which is referred to as the Slingshot Mechanism/Effect by the authors, when adaptive optimizers (e.g., Adams) are used for solving supervised learning problems. Specifically, it was found that, when adaptive optimizers were used, cyclic phase transitions between stable and unstable training occurred and were correlated with how the norm of the last-layer weights changed. The authors also reported findings on the correlations between the onset of the Slingshot Mechanism and the glokking phenomenon.",
                "Strengths And Weaknesses": "Strengths:\n\nThe reported findings hint that extra care may be required when adaptive optimizers are used. The results may also promote further theoretical studies on the limitations of using adaptive optimizers in supervised learning.\n\nWeaknesses:\n\nAdditional numerical experiments could have been conducted to help future theorists better understand the source of issues. In particular, some rather simple diagnoses could have been done but were missing from the paper.\nThere is much room for improvement in presentation of the paper. See the specific comments in the Questions section.",
                "Questions": "Is the reported phenomenon unique to \"deep models\"?\nI did not see any numerical experiments on \"shallow models.\" From the appendix, I only see experiments with a transformer (12 layers and 10 million parameters), a CNN with VGG-like architecture (which I assume to be a deep model), a deep MLP with 6 layers, and a deep linear model with 6 layers. Without experiments with simple/shallow models, it is premature to draw the conclusion that Slingshot is a general phenomenon as the authors claimed in Lines 154-162. \nAs a matter of fact, given that the authors tried to illustrate the phenomenon using simple quadratic functions (Line 174), could the authors conduct a set of numerical experiments using quadratic functions to see whether the phenomenon still persists?\nSome simple numerical diagnoses could have been done.\nAs evident from Line 178, one issue with the adaptive optimization schemes considered is that the effective step size \u03bc/(|g|+\u03f5) can be much larger than the unnormalized step size \u03bc when the magnitude of the gradient g is small and \u03f5 is small. (Here, a small \u03f5 is assumed; otherwise, the update rule will not adapt much to the magnitude of g.) This implies that, when the magnitude of g is small, i.e., when the current iterate is near a stationary point, the next iterate of the gradient-based update can be very far from the stationary point, potentially leading to a sudden increase in the loss. \nFor gradient-based updates, when the objective function is smooth, it is known that a sufficient condition for decrease is to choose the step size to be less than 2/L, where L is the Lipschitz constant of the gradient (and is related to the Hessian). It would be useful to plot in Figure 3 the effective step size, given by \u03bc/(|g|+\u03f5), along with the sharpness to see if the step size is still small enough for the sufficient condition for decrease to hold. If the violation of the condition coincides with the increase in the loss, then this would provide a simple explanation of the Slingshot Effect.\nComments on presentation and typos:\n\nAre the Slingshot Mechanism and the Slingshot Effect the same thing? Both terms are used throughout the paper.\nFigure 1 and its first citation are too far apart: Figure 1 appears on the first page (even before the main text), but it citation does not appear until Line 158. \nA typo in Line 190: \"...evidence of Elingshot Effects.\"\nLine 230: What is 3.10e\u2212044? Also, it uncommon to write 10\u221204 instead of 10\u22124. This has occurred several times throughout the paper.",
                "Limitations": "I do not have any comments on this.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper studies the grokking phenomenon introduced by Power et al [1], which is a curious phenomenon of delayed generalization. This paper describes a characteristic of training termed the \"slingshot mechanism\", that is found in a number of tasks and optimization settings. The slingshot mechanism refers to periods of instability found in adaptive optimizers in the late stages of training. These periods of instability are accompanied by norm increases in the classification layer, as well as an improvement in generalization performance for the grokking tasks introduced in [1]. The paper studies this phenomenon and finds that it occurs in a number of different tasks more general than those in [1], and find that it is controlled by the epsilon parameter in adaptive optimizers.",
                "Strengths And Weaknesses": "Strengths\n\nThe paper has a good and comprehensive discussion of related work.\nThe paper characterizes an interesting phenomenon that is sometimes found in the optimization trajectory of adaptive optimizers.\nInteresting observations regarding the effect of epsilon on the slingshot behavior.\n\nWeaknesses\n\nThere is no explanation, empirical or otherwise, for how the slingshot mechanism may relate to generalization. Understanding the delayed generalization is an important aspect of why the grokking phenomenon in [1] is interesting to the community. I believe that in the current state, without a deeper understanding, this work may be more appropriate for a workshop submission.\nThe paper claims that the slingshot mechansim is a general phenomenon, however on CIFAR10 the phenomenon was mostly observed when training with extremely small training data (e.g. 200 examples), and no correlation to better generalization was shown. There is one experiment in the Appendix where the full CIFAR10 dataset is used in training a ViT model, but this model only achieves a final test accuracy of <80% and it's not clear how much test accuracy is improved due to the slingshot mechanism due to a single run and increasing test loss. This calls into question how relevant or general the identified behavior is to modern day neural networks.",
                "Questions": "In Figure 3(d), why do we not see a corresponding spike in sharpness at the onset of the second plateau? Based on the hypothesis that the weights are flung to a new region in parameter space when the curvature grows too large, I would expect to see the curvature spike at each transition.\n\nFigure 5, what is the accuracy being plotted? Is it training accuracy or test accuracy? If test accuracy, what is the training accuracy of these models? Do all the runs achieve 100% training accuracy? It is unclear whether correlation with better generalization comes from the appearance of slingshots or from the bad hyperparameter choices required to remove slingshot behavior from the training trajectory. \n\nDataset size is a crucial parameter in determining whether grokking / generalization occurs in [1]. How does the correlation between generalization vs slingshot behavior change when models are trained with differing data size? Does slingshots exist regardless of whether the model generalizes?",
                "Limitations": "Beyond the weaknesses I listed, the authors were good at addressing several limitations of this work.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors describe a \"slingshot\" effect present in the use of Adam (and cousins). This purportedly cyclic effect can be observed when the norm of the final layer sharply increases, often accompanied by an increase in train loss. The authors offer the slingshot effect as a possible explanation for the ability of Adam to induce generalization even without explicit regularization.",
                "Strengths And Weaknesses": "This is overall a nicely executed empirical paper that reveals a moderately interesting phenomenon. A cyclic regime of generalization would be quite remarkable and this paper offers preliminary evidence that supports the authors' hypothesis. It is also refreshing that the authors did not attempt to handwave nonsense poorly-motivated math into the paper, which is unfortunately a severe problem even in 2022.\nMy main concerns are the following:\n\nSignificance: Given that this effect explains generalization in unregularized optimization, the overall impact to practical deep learning is somewhat muted.\nStrength of evidence: the results in the paper leave me with certain questions (most notably #6 below) as to whether the authors have sufficiently validated their hypothesized effect.\nImplications: the paper enumerates a number of interesting facts (e.g. dependence on \u03f5) but doesn't really dive deeper beyond some of those facts, leaving the reader wondering as to why those facts were presented.\n\nOverall, I enjoyed reading this paper. I don't think it's super noteworthy in terms of immediate impact, but it is (as far as I can tell) a novel discovery that may serve as a waypoint on our path to better understanding of oddball generalization phenomena in deep learning.",
                "Questions": "Is there a reason validation error/loss is not depicted in Fig 1? Given the emphasis in this paper on generalization, it seems odd not to depict in the headline figure.\nFigure 2(c) looks either incorrect or misgenerated\u2014the validation loss should not be zero at the beginning of training, unless I am missing something.\nDo the authors have any explanation for why Figure 3(d) doesn't show a high-curvature update on the second plateau?\nCan the authors elaborate more on the implications of the larger \u03f5 result? To me, larger \u03f5 ruining the grokking effect sort of implies that non-adaptive methods (e.g. plain GD) don't benefit from slingshotting either (which is exactly what the authors found empirically). But it would still be good to explicitly connect the dots here.\nI am also left wondering about the result on the paragraph starting on line 243. It's cool that the authors discovered it but what is it supposed to tell me? What about low-dim data makes the slingshot effect less likely to occur?\nFinally, is it fair to call this effect cyclic when most empirical examples only have two cycles (with a few having 3)? Is there a setup where we can see n distinct plateaus and sharp norm increases for some n>>3?",
                "Limitations": "The authors do a good job not overclaiming, and they explicitly enumerate a number of other regimes that achieve the results despite lack of \"slingshot\". Certain items are left unaddressed (see \"Questions\").\nMinor\n\nLine 84: missing author name\nLine 112: what is \"Adam without momentum\" and how is it different from RMSProp?\nLine 145: \"layers\" \u2192 \"layer\"\nLine 170: \"has\" \u2192 \"have\"\nLine 245: \"choices\" \u2192 \"choice\"\nLine 254: \"it's\" \u2192 \"its\"",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.333,
        "confidence_avg": 3.0,
        "soundness_avg": 2.667,
        "presentation_avg": 3.0,
        "contribution_avg": 2.0,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the paper presents an interesting phenomenon and provides valuable insights into the limitations of using adaptive optimizers in supervised learning. The reported findings on the slingshot mechanism and its correlation with norm increases and generalization performance are significant contributions to the field.\n\nWhile there are some weaknesses and limitations pointed out by the reviewers, such as the lack of explanation for the relationship between the slingshot mechanism and generalization, the limited evaluation on CIFAR10, and the need for further exploration of the implications of larger epsilon values, these do not outweigh the strengths of the paper.\n\nThe reviewers have also raised some questions and suggestions for improvement, such as conducting additional numerical experiments with simple/shallow models, performing simple numerical diagnoses, and providing more explanations for certain results and implications. These suggestions can be addressed in a revised version of the paper.\n\nOverall, the paper is technically solid and has the potential for moderate-to-high impact. The limitations and weaknesses can be addressed in future work, and the findings presented in the paper are valuable for the research community. Therefore, I recommend accepting the paper."
    },
    "Evident:_a_Development_Methodology_and_a_Knowledge_Base_Topology_for_Data_Mining,_Machine_Learning_and_General_Knowledge_Management": {
        "link": "https://openreview.net//forum?id=_1bgdFHhA70",
        "pub_url": "https://openreview.net/forum?id=_1bgdFHhA70",
        "pdf_link": "https://openreview.net//pdf?id=_1bgdFHhA70",
        "paper_id": "_1bgdFHhA70",
        "title": "Evident:_a_Development_Methodology_and_a_Knowledge_Base_Topology_for_Data_Mining,_Machine_Learning_and_General_Knowledge_Management",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nThe paper identifies relevant issues in the current software development process for machine learning, data mining, and knowledge management, however it does not provide any practical evidence that the proposed directions can solve the identified issues. The content of the paper is more suited for a position paper than for a technical scientific paper, which is the target of NeurIPS. So, while recognising some value in the contribution of the paper, I believe its nature does not completely match the NeurIPS expectations, and it would be more suitable for conferences where position papers are one of the components of the technical program.",
        "reviews": [
            "Reviewer 1: \nSummary: The paper proposes a new software development methodology (Evident) for machine learning, data mining, and knowledge management. It discusses pitfalls of traditional software processes related to the waterfall and agile models and explains why they may not be sufficient for these fields. Further, the paper describes the main concepts related to Evident. The main idea centers around modeling the relationships between observations, hypotheses, and tests. Finally, the paper describes how this methodology may help to alleviate common pain points in ML, DM, and knowledge management.\nStrengths And Weaknesses: Strengths:\nS1- The paper aims to make a contribution to the important problem of improving development processes for ML and more. \nWeaknesses:\nW1- It is difficult to judge the effectiveness of the contribution without any user studies with development teams that have applied Evident. At the very least, it would have been useful to see a few case studies and qualitative remarks on how teams could apply this in practice. This would instantiate the presented terminology (knowledges, containers, hypotheses, observations etc) with concrete tasks and terms of a given project.\nW2- Often the paper makes strong claim regarding the ineffectiveness of Agile (or other processes like CRISP-DM) and the effectiveness of of Evident but the justifications are mostly abstract and sometimes handwaving potential benefits without a proper either theoretical or rigorous framework to prove these claims. \nW3- It is not clear how the authors distilled the presented challenges in Table 2 from related work. How did they decide to include or leave a challenge out of the table? Plus, there is a lot more work on methods and processes for ML by now that could also be considered. Some of the challenges are also very generic and they may as well apply to any software that may not include ML (e.g. dead code paths, Prototype Algo may be accidentally run in production causing damages).\nLiterature on challenges in ML software development:\nSoftware Engineering for Machine Learning: A Case Study\nSoftware 2.0 https://karpathy.medium.com/software-2-0-a64152b37c35\nMachine learning testing: Survey, landscapes and horizons\n\u201cEveryone wants to do the model work, not the data work\u201d: Data Cascades in High-Stakes AI\nAn empirical study of common challenges in developing deep learning applications\nQuestions: \nHas this process been applied in practice? Are there any insights to share to this end?\n\nFor future versions of the paper it may be useful to be more specific and highlight for which of the challenges in Table 2, Evident may work better than other methodologies and why.\nLimitations: I do not think the authors have really described or mentioned the limitations of their approach. In contrary, the contributions are sometimes hyperbolically described claiming that the process can advance society, philosophy, and science, without any factual evidence.\nEthics Flag: No\nSoundness: 1 poor\nPresentation: 2 fair\nContribution: 1 poor\nRating: 2: Strong Reject: For instance, a paper with major technical flaws, and/or poor evaluation, limited impact, poor reproducibility and mostly unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper discusses problems (called pain points in the paper) in using the agile methodology for Data mining/Machine learning/knowledge management. It then presents a software development methodology for data mining tasks that can also be used for machine learning and knowledge management. Activities in a project are broken down into observations, hypotheses and tests that denote facts, knowledge and evaluation respectively. These serve as containers that can also used for storing and managing project related artefacts.\nStrengths And Weaknesses: Strength:\n\nThe paper identifies the need for having a software development methodology for DM/ML/KM\nThe paper presents a summary of pain points for DM/ML/KM\n\nWeaknesses:\n\nThe paper lacks scientific rigor. Although some of the ideas are interesting, there is no experimentation/evaluation to substantiate the proposed methodology\nThe paper does not present any literature review of the area, that raises questions about whether the work in the paper is indeed a novel contribution\nQuestions: \nThe authors have discussed the agile methodology and problems in its application for software development and artefact management for dm/ml/km. However, why compare with agile only? It would be better to compare with other DM methodologies that have been proposed. For example, the paper talks about the CRISP-DM, but lists limitations of this methodology briefly. No other methodology is mentioned. \n\nHow have goals and approaches been differentiated? For example, how is Individuals and interactions over processes and tools an approach and Responding to change over following a plan a goal\n\nThe paper says only four principles are actionable, but lists only three\n\nThe fact that agile is unfalsifiable is mentioned, and treated as a drawback. However, it is not clear which development methodologies  (if any) are falsifiable\n\nThe paper says the scope of Agile is not defined. Again,  it would be good to mention whether all other methodologies have scope defined\n\nHow have the pain points in Table 2 been identified? What is the last column?\n\nHow do the  Fig 3 a), b) and c) represent induction, abduction and deduction? Some explanation is required\n\nWere experiments not carried out using Evident? At least something concrete is required, perhaps a case study with examples. Otherwise, the claims about alleviation of pain points in section 5 are not justified.\n\nThe paper title mentions topology. Where is this discussed subsequently? \n\nI am not sure I understand what is meant by the following:\n\n\n\"This paper discusses limitations in agile as a scientific claim\"\n\"Beyond software development, Evident is illustrated to be applicable in many aspects of society\"\n\"Although control experiment challenges or absence of quantitative project Agility measurements may explain no measurable scientific evidence,....\"\n\"DM has not been regarded highly collaborative and scalable activities to deliver high throughput Knowledge\"\n\"resulting in the under performance of production Algo\"\nLimitations: As far as sections are concerned, the authors have mentioned pain points not alleviated under section 6.3.\nEthics Flag: No\nSoundness: 1 poor\nPresentation: 2 fair\nContribution: 1 poor\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper proposes a project management/artifact management framework (Evident) in the form of a knowledge base topology. Throughout the paper, the authors discuss about the challenges presently faced by the AI community - including in knowledge representation and utilisation of traditional relational databases for ML/AI workflows. The paper is interesting and the problem being solved is relevant.\nStrengths And Weaknesses: Weaknesses:\nVery limited novelty in terms of the contributions of the paper. While the framework and discussions surrounding Evident are interesting, they do not add much substance from an AI perspective and from the project management perspective, it is not very clear how and why the proposed workflow is the way to go for the AI community. While the authors have described \"pain points of DM, ML and KM\", it is very theoretical with limited examples, limited practical scenarios and above all, limited interrelation with the substance related to AI over project management.\nStrengths:\nInteresting topic being discussed in the paper, very well written paper.\nQuestions: This reviewer believes that the paper is very theoretical and oriented more towards the \"project management\" audience in comparison to the substance which an AI audience would be interested in. It would have been useful if this paper had more interaction with AI - beyond the very common pitfalls (\"pain points\") that the paper describes which are mostly well known in terms of consensus in the community. Also, without any user-studies or real-world use of this framework, the value which Evident can deliver is very hypothetically presented in the paper which makes it less rigorous. This reviewer suggests that paper would be more suitable for a journal relevant to AI and project management etc. in its current form.\nLimitations: Mostly the limitations have been addressed. However, there is not much added value or substance which the paper describes beyond the \"Pain points not alleviated\" described in Section 6.3 - the hypothetical nature of the Evident framework makes the paper read more like an essay (being very verbose) which affects the overall contributions outlined in the paper.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 2 fair\nContribution: 1 poor\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The paper proposes a new software development methodology (Evident) for machine learning, data mining, and knowledge management. It discusses pitfalls of traditional software processes related to the waterfall and agile models and explains why they may not be sufficient for these fields. Further, the paper describes the main concepts related to Evident. The main idea centers around modeling the relationships between observations, hypotheses, and tests. Finally, the paper describes how this methodology may help to alleviate common pain points in ML, DM, and knowledge management.",
                "Strengths And Weaknesses": "Strengths:\nS1- The paper aims to make a contribution to the important problem of improving development processes for ML and more. \nWeaknesses:\nW1- It is difficult to judge the effectiveness of the contribution without any user studies with development teams that have applied Evident. At the very least, it would have been useful to see a few case studies and qualitative remarks on how teams could apply this in practice. This would instantiate the presented terminology (knowledges, containers, hypotheses, observations etc) with concrete tasks and terms of a given project.\nW2- Often the paper makes strong claim regarding the ineffectiveness of Agile (or other processes like CRISP-DM) and the effectiveness of of Evident but the justifications are mostly abstract and sometimes handwaving potential benefits without a proper either theoretical or rigorous framework to prove these claims. \nW3- It is not clear how the authors distilled the presented challenges in Table 2 from related work. How did they decide to include or leave a challenge out of the table? Plus, there is a lot more work on methods and processes for ML by now that could also be considered. Some of the challenges are also very generic and they may as well apply to any software that may not include ML (e.g. dead code paths, Prototype Algo may be accidentally run in production causing damages).\nLiterature on challenges in ML software development:\nSoftware Engineering for Machine Learning: A Case Study\nSoftware 2.0 https://karpathy.medium.com/software-2-0-a64152b37c35\nMachine learning testing: Survey, landscapes and horizons\n\u201cEveryone wants to do the model work, not the data work\u201d: Data Cascades in High-Stakes AI\nAn empirical study of common challenges in developing deep learning applications",
                "Questions": "Has this process been applied in practice? Are there any insights to share to this end?\n\nFor future versions of the paper it may be useful to be more specific and highlight for which of the challenges in Table 2, Evident may work better than other methodologies and why.",
                "Limitations": "I do not think the authors have really described or mentioned the limitations of their approach. In contrary, the contributions are sometimes hyperbolically described claiming that the process can advance society, philosophy, and science, without any factual evidence.",
                "Ethics Flag": "No",
                "Soundness": "1 poor",
                "Presentation": "2 fair",
                "Contribution": "1 poor",
                "Rating": "2: Strong Reject: For instance, a paper with major technical flaws, and/or poor evaluation, limited impact, poor reproducibility and mostly unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper discusses problems (called pain points in the paper) in using the agile methodology for Data mining/Machine learning/knowledge management. It then presents a software development methodology for data mining tasks that can also be used for machine learning and knowledge management. Activities in a project are broken down into observations, hypotheses and tests that denote facts, knowledge and evaluation respectively. These serve as containers that can also used for storing and managing project related artefacts.",
                "Strengths And Weaknesses": "Strength:\n\nThe paper identifies the need for having a software development methodology for DM/ML/KM\nThe paper presents a summary of pain points for DM/ML/KM\n\nWeaknesses:\n\nThe paper lacks scientific rigor. Although some of the ideas are interesting, there is no experimentation/evaluation to substantiate the proposed methodology\nThe paper does not present any literature review of the area, that raises questions about whether the work in the paper is indeed a novel contribution",
                "Questions": "The authors have discussed the agile methodology and problems in its application for software development and artefact management for dm/ml/km. However, why compare with agile only? It would be better to compare with other DM methodologies that have been proposed. For example, the paper talks about the CRISP-DM, but lists limitations of this methodology briefly. No other methodology is mentioned. \n\nHow have goals and approaches been differentiated? For example, how is Individuals and interactions over processes and tools an approach and Responding to change over following a plan a goal\n\nThe paper says only four principles are actionable, but lists only three\n\nThe fact that agile is unfalsifiable is mentioned, and treated as a drawback. However, it is not clear which development methodologies  (if any) are falsifiable\n\nThe paper says the scope of Agile is not defined. Again,  it would be good to mention whether all other methodologies have scope defined\n\nHow have the pain points in Table 2 been identified? What is the last column?\n\nHow do the  Fig 3 a), b) and c) represent induction, abduction and deduction? Some explanation is required\n\nWere experiments not carried out using Evident? At least something concrete is required, perhaps a case study with examples. Otherwise, the claims about alleviation of pain points in section 5 are not justified.\n\nThe paper title mentions topology. Where is this discussed subsequently? \n\nI am not sure I understand what is meant by the following:\n\n\n\"This paper discusses limitations in agile as a scientific claim\"\n\"Beyond software development, Evident is illustrated to be applicable in many aspects of society\"\n\"Although control experiment challenges or absence of quantitative project Agility measurements may explain no measurable scientific evidence,....\"\n\"DM has not been regarded highly collaborative and scalable activities to deliver high throughput Knowledge\"\n\"resulting in the under performance of production Algo\"",
                "Limitations": "As far as sections are concerned, the authors have mentioned pain points not alleviated under section 6.3.",
                "Ethics Flag": "No",
                "Soundness": "1 poor",
                "Presentation": "2 fair",
                "Contribution": "1 poor",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposes a project management/artifact management framework (Evident) in the form of a knowledge base topology. Throughout the paper, the authors discuss about the challenges presently faced by the AI community - including in knowledge representation and utilisation of traditional relational databases for ML/AI workflows. The paper is interesting and the problem being solved is relevant.",
                "Strengths And Weaknesses": "Weaknesses:\nVery limited novelty in terms of the contributions of the paper. While the framework and discussions surrounding Evident are interesting, they do not add much substance from an AI perspective and from the project management perspective, it is not very clear how and why the proposed workflow is the way to go for the AI community. While the authors have described \"pain points of DM, ML and KM\", it is very theoretical with limited examples, limited practical scenarios and above all, limited interrelation with the substance related to AI over project management.\nStrengths:\nInteresting topic being discussed in the paper, very well written paper.",
                "Questions": "This reviewer believes that the paper is very theoretical and oriented more towards the \"project management\" audience in comparison to the substance which an AI audience would be interested in. It would have been useful if this paper had more interaction with AI - beyond the very common pitfalls (\"pain points\") that the paper describes which are mostly well known in terms of consensus in the community. Also, without any user-studies or real-world use of this framework, the value which Evident can deliver is very hypothetically presented in the paper which makes it less rigorous. This reviewer suggests that paper would be more suitable for a journal relevant to AI and project management etc. in its current form.",
                "Limitations": "Mostly the limitations have been addressed. However, there is not much added value or substance which the paper describes beyond the \"Pain points not alleviated\" described in Section 6.3 - the hypothetical nature of the Evident framework makes the paper read more like an essay (being very verbose) which affects the overall contributions outlined in the paper.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "2 fair",
                "Contribution": "1 poor",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 2.667,
        "confidence_avg": 3.0,
        "soundness_avg": 1.333,
        "presentation_avg": 2.0,
        "contribution_avg": 1.0,
        "ai_sum_meta": "Recommendation: Reject\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that the paper lacks scientific rigor and experimental evaluation to substantiate the proposed methodology. The paper also lacks novelty and does not provide much substance from an AI perspective. The theoretical nature of the framework and the limited examples and practical scenarios make it less rigorous. Additionally, the paper does not adequately address the limitations and does not provide enough interrelation with AI over project management. Therefore, I recommend rejecting the paper."
    },
    "Efficient_Sequence_Packing_without_Cross-contamination:_Accelerating_Large_Language_Models_without_Impacting_Performance": {
        "link": "https://openreview.net//forum?id=e2M4CNa-UOS",
        "pub_url": "https://openreview.net/forum?id=e2M4CNa-UOS",
        "pdf_link": "https://openreview.net//pdf?id=e2M4CNa-UOS",
        "paper_id": "e2M4CNa-UOS",
        "title": "Efficient_Sequence_Packing_without_Cross-contamination:_Accelerating_Large_Language_Models_without_Impacting_Performance",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nThis paper draws attention to the importance of good packing to avoid padding when creating batches. This problem is indeed important in practice and the paper does a good job studying the paper. That being said, the machine learning novelty seems limited. One reviewer was strongly supportive of acceptance while the other two thought this paper was below the cut-off. The meta reviewer thinks that there isn't sufficient ML novelty for NeurIPS.",
        "reviews": [
            "Reviewer 1: \nSummary: The paper proposes speeding large-scale pre-training by constructing the data pipeline with the explicit goal of minimizing the need for padding tokens, which only lead to wasted computation. The approach is to consider the dataset as a whole and apply bin-packing algorithms to merge several short examples into one longer example, which is done up-front as part of preprocessing. Two bin packing strategies (SPFHP and NNLSHP) are proposed and evaluated. Pre-training may be sped up by up to 2x compared to a naive approach.\nStrengths And Weaknesses: The main strengths include, of course, the ability to achieve sizable speed-ups in practice. Moreover, the idea of having a whole-dataset preprocessing step aimed at optimizing it for accelerator use is a very general one. Bringing this to the attention of the community, and suggesting how to think about this in terms of concepts/terminology/abstractions, could lead to less computationally wasteful practices across the board in the field. It's especially helpful to see a quantitative analysis that reveals that padding is a big source of inefficiency in pre-training, where one might naively assume that it's not an issue because the underlying Wikipedia articles are actually quite long.\nIn terms of weaknesses, my immediate impression reading the paper for the first time is that many aspects of the idea of packing examples together are not, in fact, novel. The paper acknowledges that frameworks already concatenate short examples as a way to speed up training, and that this practice is commonly referred to as \"packing\". The claim in Sec 3.2.2 that the paper \"propose[s] directly masking the attention matrix\" is not novel either. (As prior art, see tensor2tensor for code essentially the same as Figure 2). Likewise for positional embedding and loss adjustment.\nIt seems that the actual novelty of the paper is in highlighting packing efficiency as a key criterion in designing a data pipeline, proposing to optimize this criterion at a whole-dataset level (instead of ad-hoc or streaming-based approaches), as well as showing that this can be done in a way that is scalable to large-scale datasets. At least for me, the writing of the paper did not succeed in delineating the scope of the contribution from what has been done in prior work. Additionally, the term \"packing\" has acquired a certain meaning in the context of modern transformer training, and I would recommend that the authors adopt distinct terminology to differentiate their approach. [Edit: to clarify, I am not referring to the use of the term \"packing\" in the title (which is fine), but usages like \"packed\" in Table 3 or even \"packed (our approach)\" in Figure 5. For example, looking at Table 3 / Figure 5 in isolation would be confusing to readers that have a different prior conception of what the term \"packing\" refers to].\nI also would have found it helpful if the paper had made explicit its assumption that packing takes place during an up-front pre-processing stage where the whole dataset is available for random access, and not in an on-line streaming manner. Approaches like padding and greedy concatenation would all work when streaming the data from storage one example at a time, while the proposed method does not. Even if engineering practice in the narrow area of pre-training does data processing up-front, the corresponding academic literature often doesn't necessarily go into this and sometimes presents a picture that leaves open an interpretation where padding/packing/batching or even tokenization are done via streaming processing.\nIn summary, the main weakness of the paper is how it frames the discussion for an academic audience, including how it contrasts its contributions from the literature as a whole.\nQuestions: none\nLimitations: Yes\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper proposes two methods for reducing the padding tokens when packing multiple sentences into a single sequence: shortest-pack-first histogram-packing and non-negative least squares histogram-packing. Both these packing methods alter the input sequences provided to NLP models. As a result, the paper proposes basic alterations for BERT models so they can interpret packed input sequences correctly. With these changes, the paper demonstrates that a nearly 2x acceleration can be achieved versus a model using a naive token padding approach without any effect on performance.\nStrengths And Weaknesses: Strengths:\n\nPotential broader applicability to many NLP tasks. While the paper mainly focuses the packing algorithms on BERT, it could also apply to nearly all transformer-related architectures.\nMultiple factors, such as packing efficiency, processing speed-up, load balancing, convergence behavior, are considered when analyzing the validity of packing algorithms.\nClear writing and explanation; detailed background; helpful supplemental materials\n\nWeaknesses:\n\nIncremental contribution. Bin packing is mature topic. While the specific context and constraints are different in the scope of this paper, it is unclear why many other existing bin packing algorithms cannot be applied (with reasonable modifications). The proposed two schemes are also very simple.\nResults for SORT are a bit surprising and conflicting. Section 4 concludes that SORT \u201ccause a major overhead that exceeds the benefits of avoiding the padding\u201d, yet Section 1 mentions that sorted batching is being used in the \u201cFaster Transformer , lingvo, fairseq, and RoBERTa\u201d. The seems to imply that either the evaluation results are inaccurate,or SORT has other benefits that are not discussed explicitly/clearly in the paper.\nLack of supporting evidence for certain claims and not evaluating all parts of proposition thoroughly. For instance, on line 236, there is no provided data to support the claim that \u201cthe best speed-up is obtained with NNLSHP at depth 3\u201d. Additionally, nearly no specifications for the training setup are provided, such as the specific GPU used. This makes the claim that the NNLSHP packing algorithm runs \u201cout of memory for larger depth\u201d on line 237 challenging to interpret. Also, a minor complaint is that Table 1 uses the notation >>100 and << 1.000; it would be more useful if actual numbers are provided (this is not a figure where very large/small data may not be represented well).\nQuestions: \nThe paper mentions that \u201cThe best speed-up is obtained with NNLSHP at depth 3 which required 28.4s for processing and ran out of memory for larger depth.\u201d  Is there any data to support this claim? Are there circumstances where the approach would run out of memory when a depth of 3 is used?\nOn lines 288-290, the paper mentions that when not using an adjusted positional embedding calculation with one of its packing algorithms, \u201cthe accuracy stalls at 71.8% and does not reach the target accuracy of 72.1%.  So overall, both adjustments are crucial.\u201d  However, when examining the percentages and Figure 4, this claim does not seem valid.  The need for the adjustment makes sense, but is there another reason why it is a crucial change? Additionally, in Figure 4, is there a reason the lines for \u201cpacked BERT baseline\u201d and \u201cno pos. emb. Adjustment\u201d end before the line for \u201cno mask adjustment\u201d ends?\nIt feels as though an important metric is missing; for instance, why do \u201cFaster Transformer [21], lingvo [28] fairseq [22], and RoBERTa\u201d on line 40 all use sorted batching (SORT) to reduce padding tokens when it appears to be unviable given the results in Table 1?\nLimitations: n/a\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper describes an approach for packing sequences into batches in order to improve the training efficiency of large-scale language models (and related tasks). \nFirst, several datasets are analyzed with respect to their sequence length variations and the potential speed-up if batches were packed with minimized padding. The paper then formalizes the packing problem and proposes two new algorithms, that in turn require slight model adaptations for the example of BERT. In experiments on BERT pre-training, they showcase the packing efficiency on IPUs and resulting realized speed-up in comparison to other packing (or none) algorithms, and investigate required hyperparameter changes on the MLPerf benchmark. An ablation study of the model adaptations of BERT confirm that these are indeed necessary, and that packed pretraining does not negatively affect fine-tuning (non-packed) on the SQuAD benchmark.\nStrengths And Weaknesses: Strengths:\n\nThe paper sheds light on a problem that has previously been hidden in NLP implementations and has not been clearly documented/researched/discussed, despite its effect on required training resources, hyperparameters, and model quality. The paper is educational for anyone who has not delved deeply into this topic or has not implemented packing themselves (like myself included), and brings transparency into the choice of packing implementations and their impact.\nAs the paper outlines in Section 2, the potential gain of efficiency is large, since sequence length varies a lot in many NLP tasks. The proposed solution is therefore a very impactful contribution to NLP implementations, thereby the efficiency of NLP research. \nThe empirical results are strong, with theoretical speed-ups being close to be realized with little overhead.\n\nWeaknesses:\n\nPacking is only applied during pre-training, not during fine-tuning. Adding an experiment on top of the existing SQuAD experiments where packing is continued during fine-tuning would make the proposed approach more convincing, especially since Section 2 lists fine-tuning datasets for motivation.\nThe experimental conditions for 4.1 are not well introduced. Is it BERT pre-training?\nQuestions: \nWhich BERT pre-processing is referred to in Section 1 (line 23)?\nLimitations: The authors mention more challenging applications in computer vision as a next step, and potential difficulties with the implementation. I'd appreciate if the limitations of the current approach would be discussed in more depth: are there any edge cases where the overhead would be prohibitively large? In which data conditions should this packing approach be avoided?\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 4 excellent\nRating: 8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The paper proposes speeding large-scale pre-training by constructing the data pipeline with the explicit goal of minimizing the need for padding tokens, which only lead to wasted computation. The approach is to consider the dataset as a whole and apply bin-packing algorithms to merge several short examples into one longer example, which is done up-front as part of preprocessing. Two bin packing strategies (SPFHP and NNLSHP) are proposed and evaluated. Pre-training may be sped up by up to 2x compared to a naive approach.",
                "Strengths And Weaknesses": "The main strengths include, of course, the ability to achieve sizable speed-ups in practice. Moreover, the idea of having a whole-dataset preprocessing step aimed at optimizing it for accelerator use is a very general one. Bringing this to the attention of the community, and suggesting how to think about this in terms of concepts/terminology/abstractions, could lead to less computationally wasteful practices across the board in the field. It's especially helpful to see a quantitative analysis that reveals that padding is a big source of inefficiency in pre-training, where one might naively assume that it's not an issue because the underlying Wikipedia articles are actually quite long.\nIn terms of weaknesses, my immediate impression reading the paper for the first time is that many aspects of the idea of packing examples together are not, in fact, novel. The paper acknowledges that frameworks already concatenate short examples as a way to speed up training, and that this practice is commonly referred to as \"packing\". The claim in Sec 3.2.2 that the paper \"propose[s] directly masking the attention matrix\" is not novel either. (As prior art, see tensor2tensor for code essentially the same as Figure 2). Likewise for positional embedding and loss adjustment.\nIt seems that the actual novelty of the paper is in highlighting packing efficiency as a key criterion in designing a data pipeline, proposing to optimize this criterion at a whole-dataset level (instead of ad-hoc or streaming-based approaches), as well as showing that this can be done in a way that is scalable to large-scale datasets. At least for me, the writing of the paper did not succeed in delineating the scope of the contribution from what has been done in prior work. Additionally, the term \"packing\" has acquired a certain meaning in the context of modern transformer training, and I would recommend that the authors adopt distinct terminology to differentiate their approach. [Edit: to clarify, I am not referring to the use of the term \"packing\" in the title (which is fine), but usages like \"packed\" in Table 3 or even \"packed (our approach)\" in Figure 5. For example, looking at Table 3 / Figure 5 in isolation would be confusing to readers that have a different prior conception of what the term \"packing\" refers to].\nI also would have found it helpful if the paper had made explicit its assumption that packing takes place during an up-front pre-processing stage where the whole dataset is available for random access, and not in an on-line streaming manner. Approaches like padding and greedy concatenation would all work when streaming the data from storage one example at a time, while the proposed method does not. Even if engineering practice in the narrow area of pre-training does data processing up-front, the corresponding academic literature often doesn't necessarily go into this and sometimes presents a picture that leaves open an interpretation where padding/packing/batching or even tokenization are done via streaming processing.\nIn summary, the main weakness of the paper is how it frames the discussion for an academic audience, including how it contrasts its contributions from the literature as a whole.",
                "Questions": "none",
                "Limitations": "Yes",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposes two methods for reducing the padding tokens when packing multiple sentences into a single sequence: shortest-pack-first histogram-packing and non-negative least squares histogram-packing. Both these packing methods alter the input sequences provided to NLP models. As a result, the paper proposes basic alterations for BERT models so they can interpret packed input sequences correctly. With these changes, the paper demonstrates that a nearly 2x acceleration can be achieved versus a model using a naive token padding approach without any effect on performance.",
                "Strengths And Weaknesses": "Strengths:\n\nPotential broader applicability to many NLP tasks. While the paper mainly focuses the packing algorithms on BERT, it could also apply to nearly all transformer-related architectures.\nMultiple factors, such as packing efficiency, processing speed-up, load balancing, convergence behavior, are considered when analyzing the validity of packing algorithms.\nClear writing and explanation; detailed background; helpful supplemental materials\n\nWeaknesses:\n\nIncremental contribution. Bin packing is mature topic. While the specific context and constraints are different in the scope of this paper, it is unclear why many other existing bin packing algorithms cannot be applied (with reasonable modifications). The proposed two schemes are also very simple.\nResults for SORT are a bit surprising and conflicting. Section 4 concludes that SORT \u201ccause a major overhead that exceeds the benefits of avoiding the padding\u201d, yet Section 1 mentions that sorted batching is being used in the \u201cFaster Transformer , lingvo, fairseq, and RoBERTa\u201d. The seems to imply that either the evaluation results are inaccurate,or SORT has other benefits that are not discussed explicitly/clearly in the paper.\nLack of supporting evidence for certain claims and not evaluating all parts of proposition thoroughly. For instance, on line 236, there is no provided data to support the claim that \u201cthe best speed-up is obtained with NNLSHP at depth 3\u201d. Additionally, nearly no specifications for the training setup are provided, such as the specific GPU used. This makes the claim that the NNLSHP packing algorithm runs \u201cout of memory for larger depth\u201d on line 237 challenging to interpret. Also, a minor complaint is that Table 1 uses the notation >>100 and << 1.000; it would be more useful if actual numbers are provided (this is not a figure where very large/small data may not be represented well).",
                "Questions": "The paper mentions that \u201cThe best speed-up is obtained with NNLSHP at depth 3 which required 28.4s for processing and ran out of memory for larger depth.\u201d  Is there any data to support this claim? Are there circumstances where the approach would run out of memory when a depth of 3 is used?\nOn lines 288-290, the paper mentions that when not using an adjusted positional embedding calculation with one of its packing algorithms, \u201cthe accuracy stalls at 71.8% and does not reach the target accuracy of 72.1%.  So overall, both adjustments are crucial.\u201d  However, when examining the percentages and Figure 4, this claim does not seem valid.  The need for the adjustment makes sense, but is there another reason why it is a crucial change? Additionally, in Figure 4, is there a reason the lines for \u201cpacked BERT baseline\u201d and \u201cno pos. emb. Adjustment\u201d end before the line for \u201cno mask adjustment\u201d ends?\nIt feels as though an important metric is missing; for instance, why do \u201cFaster Transformer [21], lingvo [28] fairseq [22], and RoBERTa\u201d on line 40 all use sorted batching (SORT) to reduce padding tokens when it appears to be unviable given the results in Table 1?",
                "Limitations": "n/a",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper describes an approach for packing sequences into batches in order to improve the training efficiency of large-scale language models (and related tasks). \nFirst, several datasets are analyzed with respect to their sequence length variations and the potential speed-up if batches were packed with minimized padding. The paper then formalizes the packing problem and proposes two new algorithms, that in turn require slight model adaptations for the example of BERT. In experiments on BERT pre-training, they showcase the packing efficiency on IPUs and resulting realized speed-up in comparison to other packing (or none) algorithms, and investigate required hyperparameter changes on the MLPerf benchmark. An ablation study of the model adaptations of BERT confirm that these are indeed necessary, and that packed pretraining does not negatively affect fine-tuning (non-packed) on the SQuAD benchmark.",
                "Strengths And Weaknesses": "Strengths:\n\nThe paper sheds light on a problem that has previously been hidden in NLP implementations and has not been clearly documented/researched/discussed, despite its effect on required training resources, hyperparameters, and model quality. The paper is educational for anyone who has not delved deeply into this topic or has not implemented packing themselves (like myself included), and brings transparency into the choice of packing implementations and their impact.\nAs the paper outlines in Section 2, the potential gain of efficiency is large, since sequence length varies a lot in many NLP tasks. The proposed solution is therefore a very impactful contribution to NLP implementations, thereby the efficiency of NLP research. \nThe empirical results are strong, with theoretical speed-ups being close to be realized with little overhead.\n\nWeaknesses:\n\nPacking is only applied during pre-training, not during fine-tuning. Adding an experiment on top of the existing SQuAD experiments where packing is continued during fine-tuning would make the proposed approach more convincing, especially since Section 2 lists fine-tuning datasets for motivation.\nThe experimental conditions for 4.1 are not well introduced. Is it BERT pre-training?",
                "Questions": "Which BERT pre-processing is referred to in Section 1 (line 23)?",
                "Limitations": "The authors mention more challenging applications in computer vision as a next step, and potential difficulties with the implementation. I'd appreciate if the limitations of the current approach would be discussed in more depth: are there any edge cases where the overhead would be prohibitively large? In which data conditions should this packing approach be avoided?",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "4 excellent",
                "Rating": "8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.333,
        "confidence_avg": 3.333,
        "soundness_avg": 3.333,
        "presentation_avg": 3.333,
        "contribution_avg": 2.667,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the paper proposes a novel approach for speeding up large-scale pre-training by minimizing the need for padding tokens. The main strengths of the paper include the potential for significant speed-ups in practice, the general idea of optimizing the data pipeline for accelerator use, and the quantitative analysis that highlights the inefficiency of padding in pre-training. \n\nHowever, there are some weaknesses identified by the reviewers. One reviewer points out that many aspects of the idea of packing examples together are not novel, and the paper could have done a better job in delineating the scope of its contribution from prior work. Another reviewer raises concerns about the lack of supporting evidence for certain claims and the conflicting results for the SORT algorithm. \n\nDespite these weaknesses, the overall consensus among the reviewers is that the paper is technically solid and makes a valuable contribution to the field. The proposed approach has the potential for broader applicability to many NLP tasks and the empirical results demonstrate significant speed-ups with little overhead. \n\nTherefore, based on the reviews and taking into account the strictness and confidence levels, I recommend accepting the paper."
    },
    "Uniqueness_and_Complexity_of_Inverse_MDP_Models": {
        "link": "https://openreview.net//forum?id=QYhUhMOI4C",
        "pub_url": "https://openreview.net/forum?id=QYhUhMOI4C",
        "pdf_link": "https://openreview.net//pdf?id=QYhUhMOI4C",
        "paper_id": "QYhUhMOI4C",
        "title": "Uniqueness_and_Complexity_of_Inverse_MDP_Models",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Less certain\nIn this paper, the authors concern the question of whether or not the 1-step inverse model, along with the policy, can determine the multi-step inverse model - or if the forward dynamics of an environment can be inferred by the inverse model along with the policy. The authors also dwell into other related questions. The authors provide insightful answers and discussions to these questions, but the paper is unfortunately written in a very unconventional format which makes it very hard to read. I hope the authors find the reviewer comments below help restructuring the paper to better enlighten the readers.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper concerns the question of if and when the transition dynamics of an MDP can be determined based on a policy together with its corresponding inverse dynamics. In the case of single-step inverse dynamics, they find that this is not the case, unless the number of actions is greater than the number of states, and each action corresponds to a full-rank transition matrix. The paper also studies a number of similar questions.\nStrengths And Weaknesses: Originality:\nThis question has, to be best of my knowledge, not been examined previously (at least not as thoroughly as in this paper). However, some of the results seem to be reasonably straightforward (for example, the fact that the transition dynamics cannot necessarily be inferred from a given policy together with its corresponding one-step inverse model is immediately clear if one considers any policy that samples actions independently from the state).\nQuality:\nI have not checked most of the calculations carefully, but based on what I have checked, the maths appears to be sound.\nClarity:\nThe clarity of the writing is reasonable, but could be improved. For example, the text takes time to explain elementary notions from linear algebra, and other facts that I think the reader could reasonably be assumed to be familiar with (such as e.g. the fact that matrices form a ring under ordinary matrix addition and matrix multiplication, etc). I also think the paper could be better organised. For example, the introduction does not make it clear what are the main results of the paper, or what their significance is, and it takes some digging to get a full overview of things.\nSignificance:\nI think that the significance of the results is not well explained in the paper, and this is one of its main weak points, in my opinion. The introduction states that the presented results are relevant to causal inference, but the example that is given afterwards is just an instance of normal retrodiction, which doesn't engage with most of the issues discussed in the current literature on causal inference. It is also stated that these results could be of interest for automatic planning, but this seems unclear to me (at least in their current form). It is also stated that the inverse model could be much smaller than the forward model, but it is again not clear to me why that is (practically or theoretically) significant.\nSummary:\nI have not recommended this paper for publication. The main reason for this is that the problems which are studied here are fairly niche, and it is somewhat unclear what their significance is. Moreover, many of the problems which are stated in the paper are not solved, and some of the ones which are solved are somewhat straightforward. For this reason, I do unfortunately not think that these results will be of significant interest to the wider NeurIPS readership.\nQuestions: What is the main (practical or theoretical) significance of these results? Which result is the most important?\nLimitations: The limitations are discussed, though this discussion is dispersed throughout the paper, rather than being collected in one place. There is no discussion of potential negative societal impacts (but I also do not think that is needed in this case).\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The authors pose the question of whether or not the 1-step inverse model, along with the policy \\pi, determine the multi-step inverse model p(a | ss^i) - or if the forward dynamics of an environment can be inferred by the inverse model plus policy. Besides this question, the work also looks to analyze other cases of whether or not the 1-step inverse model and policy can determine other forms of inverse dynamics, such as the multi-step inverse models, and present analysis and empirical evidence for when these cases hold or when they do not hold.\nStrengths And Weaknesses: I believe that the authors make a meaningful and well-justified contribution towards understanding the theory behind inverse dynamics models and reinforcement learning as a whole. The authors present interesting theoretical insights into the realizability and limitations of inverse models, along with algorithms to potentially calculate both the two-step inverse model and forward dynamics model from the inverse model plus policy. \nIn terms of weaknesses, one weakness that comes to mind from the perspective of someone not too familiar with this form of reinforcement learning theory is the writing itself - the writing style is hard to follow in many parts, taking multiple passes for even some of the non-notation heavy parts - this seems to come from the somewhat informal tone the authors take in this manuscript, that sometimes adds a bit of cognitive burden for a reader of this paper. While the authors might be very familiar with the notation and work, I believe it would improve the polish of the paper quite a bit if the authors were a bit more careful and precise with their use of language and notation.\nFinally, I believe the experimental section has a decent amount to be desired. While I don\u2019t think there\u2019s anything wrong with the fundamental methodology of their experiments, the authors have left out quite a bit of experimental details and forego presenting actual statistics of experimental results - instead they simply present two examples in the main work. While they do show a plot detailing the effect of adding noise to the inverse dynamics models, my biggest question is with the grid world generation itself. It seems that most of the grid worlds generated would have very sparse dynamics (like in the second grid world presented) - many of the positions/states would be unreachable from many other states. It would be more clear if the authors presented more details on their experiments done to validate their theory.\nOverall, while I not intimately familiar with the theory presented in this paper, I do think this work provides a valuable contribution to the field in terms of understanding the limitations of inverse dynamics models.\nQuestions: As an aside, many of these questions will be clarification questions - hopefully these questions will help polish the paper so that it\u2019s more clear for a more broad set of readers.\nSection 2:\nFor the end of section 2, could you give an example of how one of the 6 questions can be inferred from f(M) = f(W) -> M = W? I find it a bit hard to follow what this other MDP W relates to B^a and M^a.\nYour overloaded notation for EqIM is a bit confusing. You defined EqIM(ia) and EqIM(i+), but not EqIM(i).\nSection 4:\nFor the introduction to this section, it would be nice to relate back to the 6 questions the authors were trying to answer and how EqIM(1) and EqIM(2) relates to those questions. This also relates back to my question in Section 2 about your definition of EqIM and how it is another way of posing the questions.\nSection 5:\nAgain, it would be good to relate back to the questions. Correct me if I\u2019m wrong but this section tries to answer (iii) to (vi)?\nSection 6:\nI don\u2019t see the experimental details listed anywhere - how do you generate these randomized grid worlds? \nAlso instead of just showing samples of the true vs inferred forward dynamics matrices, I think it would be more prudent to show statistics gathered from experiments, instead of just one or two examples. See limitation for more suggestions for experimental section.\nLimitations: One limitation of this approach is the scalability to large-scale environments. While this is a limitation, I don\u2019t believe this is any issue in the analysis provided in this work, or with the claims made. That being said, it would be very interesting to see how well some of these theoretical claims hold in larger environments, with more complicated dynamics/inverse dynamics that can\u2019t be feasibly represented with tensors.\nAnother limitation of this work is with the experiments and empirical results. While the do run experiments to back up the theory they develop, they don\u2019t provide details of their experimental set up, nor do they present any meaningful statistics with regards to their main result - showing one or two examples from generated grid worlds in the main work (the first grid world does not match the canonical 4-room by the way - it is something akin to it), and presenting a few plots over noise added for noisy inverse models. There is also stochasticity from the grid world generation - was there a lot of variation in terms of inferred dynamics models in the deterministic case? How were the grid worlds generated? It seems that (based on the second grid world presented) the dynamics of the grid world would be quite sparse. As mentioned earlier, presenting a more detailed account and analysis of the experiments done would improve the paper.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper analyzes the prospects of inferring meaningful inverse models of discrete-time controlled Markov processes. In particular, the paper focuses on determining the existence/uniqueness properties of these inverse models, and investigate the computational complexity of computing them.\nStrengths And Weaknesses: Unfortunately, several technical parts of this paper concern me. There are several mathematical statements that I believe to be invalid (see the Questions section). Moreover, I found the structure of the paper to be extremely confusing, especially the recurring \"questions\" which are rephrased several times, some of which (as far as I'm concerned) are not rephrased correctly. Finally, the notation used in the paper is very difficult to parse.\nQuestions: General Question: As the authors acknowledge, the setting here is not that of inverse MDPs, but inverse controlled Markov processes. I'd argue actually that it's simply inverse Markov chains, since the policy appears to be fixed everywhere. How do the studies in this paper differ from those in the inverse kinematics literature?\n Motivation: causal inference, line 24: It is written that \"An\n  inverse model captures the likelihood that an action a was the\n  cause of the transition...\", but is this truly correct? To my\n  understanding, such a conditional model is incapable of inferring\n  causation. Wouldn't one need some sort of counterfactual analysis as\n  well?\n Marginalizing variables in transition tensors: On lines 120 and 121,\n  I believe there is an inconsistency in the notation. In the Notation\n  section, it is writen that M\u22c5\u22c5a is the matrix at\n  dimension a, but here it is written Ma. I'm assuming Ma,M\u22c5\u22c5a represent the same thing, but then maybe the\n  M\u22c5\u22c5a notation should be avoided altogether.\n Challenges with the backward model: Line 127 says Ba+\u2260Ba,\n  can this be expanded upon? This is unintuitive, at least to me. After\n  line 121, it says Bss\u2032a=p(a\u2223ss\u2032), and after line 129 it\n  says Bss\u2033a+=p(a\u2223ss\u2033), thus\n Bss\u2032a+=p(a\u2223ss\u2032)=Bss\u2032a\n  Which implies that Ba=Ba+ since all of their entries are\n  equal.\n The Questions: The six questions, first stated on line 46, are very\n  confusing. Firstly, they're stated in different terms several times,\n  which is confusing on its own. Why not list the questions only once,\n  in the most intuitive way? Moreover, the questions are too complicated\n  individually. I think it would be much clearer if you don't state all\n  of these questions explicitly, and rather prove the answers as\n  theorems/lemmas/propositions. It's very hard to remember which\n  question is which as you go through the text, and it's actually very\n  hard to digest what the paper is trying to do with such a dense list\n  of questions. In my opinion, the motivation for the paper is clear\n  enough on its own, and I don't think it'll be difficult to convince\n  most readers that understanding these inverse models is an important\n  task. But when the exact meaning of \"understanding\" is stated so\n  verbosely, it actually detracts from the clarity of the paper. One\n  example that is particularly confusing appears on line 139, where it\n  says \"Questions (i) - (vi) also have multiple variations\", followed by\n  a list of three questions. How do you go from 6 questions to 3, which\n  correspond to which? Now you're actually assuming that the reader will\n  recall at least 9 questions.\n  Moreover, if you must include these questions, it would be\n  tremendously more convenient if they can be hyperlinked.\n Line 149: Another rephrasing of the questions here says\n\nOne way to rephrase the questions is whether f(M)=f(W)\nimplies M=W or g(M)=g(W) for all (or most or some)\nM and W.\n\n  I don't understand this question at all. The property that f(M)=f(W)\u27f9M=W is more a property of the function f than the\n  objects M,W. Indeed, this property is known as\n  \"injectivity\". Likewise, \"whether f(M)=f(W) implies g(M)=g(W)\"\n  is also highly dependent on the particular properties of\n  f,g. Currently f,g are only assumed to be arbitrary functions, so\n  it is really unclear to me what the purpose of this question is. I had\n  a clearer understanding of the questions before reading this.\n Equations (8) and (9): Surely the notation can be improved here, it\n  is extremely difficult to parse. Why not use product notation\n  (\u220f)? Also, in equation (9), what is Ba+\u22ef+? Are there\n  i dots? Back to my previous comment, I believe Ba+\u22ef+\u2261Ba unless there's an inconsistency in the notation.\n  Later, on line 161, the term EqIM(1) is mentioned, but where\n  is that defined? Only equations EqIM(ia) and\n  EqIM(i+) are defined.\n Example violating (i, iii, v): It appears that what you're showing\n  is that for random variables X,Y distributed by \u03bcX,\u03bcY,\n  there may exist several distinct random variables (X,Y) with\n  marginals \u03bcX,\u03bcY. This is well known.\n Line 169: I don't understand how this relates to (i), (iii), (v) at\n  all. You're assuming that two MDPs encoded by M,W have the same\n  transition dynamics, and then based on that, the ability to infer\n  multistep models from fewer-step models is guaranteed? Something is\n  missing here. How does W fit in?\n Line 171: It says \"Note that Mss\u2032a\u2261p(s\u2032\u2223sa)\n  independent of a implies Ms+a independent of a...\" -- this\n  is only true if it holds /for every pair/ (s,s\u2032). Also, this whole\n  \"degenerate case\" is fairly trivial: M and W are only related via\n  \u03c0(a\u2223\u22c5), so if they're both actually independent of a,\n  then of course any equality of this sort must imply that the MDPs are\n  identical.\n Line 175: What does it mean for tensors to be \"nearly independent\"\n  of a?\n Line 178: Similarly to the \"independent of a\" case, why is this\n  even an interesting case to study? As pointed out, the consequences\n  are fairly obvious.\n  Altogether, I didn't find section 3 to be very informative.\n Non-linear manifold: On line 212, it says that Baa\u2032 forms a\n  non-linear manifold of dimension at least d(d\u2212k). But what is the\n  \"dimension\" of a non-linear manifold? Perhaps there is a definition\n  for this, but I doubt it's widely known to the Neurips audience. I'd\n  much prefer to have seen this definition in the background section in\n  place of the algebraic properties of tensors.\n Line 214: I believe this logic is flawed. It says \"... this now\n  gives an over-determined system which generally has no solution. But\n  by assumption, M is a solution, which gives hope that there may be\n  only one or a finite number of solutions\". What is being said here is\n  that the situation only makes sense if the \"over-determinacy\" is\n  redundant, so that it's not actually over-determined. This doesn't\n  give any hint about the number of solutions. There may very well be\n  infinitely-many solutions regardless of the fact that the system is\n  over-determined.\n Figure 1: This figure is never mentioned in the text, it would be\n  nice to have some discussion of the results it's presenting.\nMinor issues\n Contents section: On line 88 \"Appendix A\" is mentioned, but then\n  subsequent appendices are written \"(B)\", for instance, which is a\n  little confusing.\n Matrix notation: On line 105, it is written \"Capital letters... are\n  used for d\u00d7d matrices over [0;1]\u2282R...\".  Is\n  [0;1] the closed unit interval? Why not write \"Capital\n  letters... are used for matrices in [0,1]d\u00d7d\"?\n Tensor notation: On line 109,\n\nLet \u2299 denote element-wise (Hadamard)\nmultiplication... and similarly \u2298, while (no)\n\u22c5 represents (conventional) matrix multiplication\nand has operator preference over \u2299 and \u2298.\n\n  I don't understand this at all. What is \u2298? What is \u22c5?\n  I'm assuming that by \"similarly \u2298\" it is meant that \u2298\n  is element-wise division (this should be stated, because the sentence\n  doesn't make sense otherwise), and that \u22c5 represents matrix\n  multiplication. But what does \"while (no) \u22c5\" mean?\n Algebraic properties of tensors: Does this really need to be\n  included here? It's hard to read math packed into a paragraph like\n  this. Also many of these properties are very intuitive (i.e., I think\n  just about every reader will have inuition for the D\u2299Id\n  property without it being stated), and then some properties are highly\n  abstract (matrices form a ring...). I think it's fair to assume that\n  readers of this paper understand how to do algebra with matrices and\n  tensors, even if they don't know what a ring is.\nLimitations: The authors have addressed the limitations of their methods.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 1 poor\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper concerns the question of if and when the transition dynamics of an MDP can be determined based on a policy together with its corresponding inverse dynamics. In the case of single-step inverse dynamics, they find that this is not the case, unless the number of actions is greater than the number of states, and each action corresponds to a full-rank transition matrix. The paper also studies a number of similar questions.",
                "Strengths And Weaknesses": "Originality:\nThis question has, to be best of my knowledge, not been examined previously (at least not as thoroughly as in this paper). However, some of the results seem to be reasonably straightforward (for example, the fact that the transition dynamics cannot necessarily be inferred from a given policy together with its corresponding one-step inverse model is immediately clear if one considers any policy that samples actions independently from the state).\nQuality:\nI have not checked most of the calculations carefully, but based on what I have checked, the maths appears to be sound.\nClarity:\nThe clarity of the writing is reasonable, but could be improved. For example, the text takes time to explain elementary notions from linear algebra, and other facts that I think the reader could reasonably be assumed to be familiar with (such as e.g. the fact that matrices form a ring under ordinary matrix addition and matrix multiplication, etc). I also think the paper could be better organised. For example, the introduction does not make it clear what are the main results of the paper, or what their significance is, and it takes some digging to get a full overview of things.\nSignificance:\nI think that the significance of the results is not well explained in the paper, and this is one of its main weak points, in my opinion. The introduction states that the presented results are relevant to causal inference, but the example that is given afterwards is just an instance of normal retrodiction, which doesn't engage with most of the issues discussed in the current literature on causal inference. It is also stated that these results could be of interest for automatic planning, but this seems unclear to me (at least in their current form). It is also stated that the inverse model could be much smaller than the forward model, but it is again not clear to me why that is (practically or theoretically) significant.\nSummary:\nI have not recommended this paper for publication. The main reason for this is that the problems which are studied here are fairly niche, and it is somewhat unclear what their significance is. Moreover, many of the problems which are stated in the paper are not solved, and some of the ones which are solved are somewhat straightforward. For this reason, I do unfortunately not think that these results will be of significant interest to the wider NeurIPS readership.",
                "Questions": "What is the main (practical or theoretical) significance of these results? Which result is the most important?",
                "Limitations": "The limitations are discussed, though this discussion is dispersed throughout the paper, rather than being collected in one place. There is no discussion of potential negative societal impacts (but I also do not think that is needed in this case).",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors pose the question of whether or not the 1-step inverse model, along with the policy \\pi, determine the multi-step inverse model p(a | ss^i) - or if the forward dynamics of an environment can be inferred by the inverse model plus policy. Besides this question, the work also looks to analyze other cases of whether or not the 1-step inverse model and policy can determine other forms of inverse dynamics, such as the multi-step inverse models, and present analysis and empirical evidence for when these cases hold or when they do not hold.",
                "Strengths And Weaknesses": "I believe that the authors make a meaningful and well-justified contribution towards understanding the theory behind inverse dynamics models and reinforcement learning as a whole. The authors present interesting theoretical insights into the realizability and limitations of inverse models, along with algorithms to potentially calculate both the two-step inverse model and forward dynamics model from the inverse model plus policy. \nIn terms of weaknesses, one weakness that comes to mind from the perspective of someone not too familiar with this form of reinforcement learning theory is the writing itself - the writing style is hard to follow in many parts, taking multiple passes for even some of the non-notation heavy parts - this seems to come from the somewhat informal tone the authors take in this manuscript, that sometimes adds a bit of cognitive burden for a reader of this paper. While the authors might be very familiar with the notation and work, I believe it would improve the polish of the paper quite a bit if the authors were a bit more careful and precise with their use of language and notation.\nFinally, I believe the experimental section has a decent amount to be desired. While I don\u2019t think there\u2019s anything wrong with the fundamental methodology of their experiments, the authors have left out quite a bit of experimental details and forego presenting actual statistics of experimental results - instead they simply present two examples in the main work. While they do show a plot detailing the effect of adding noise to the inverse dynamics models, my biggest question is with the grid world generation itself. It seems that most of the grid worlds generated would have very sparse dynamics (like in the second grid world presented) - many of the positions/states would be unreachable from many other states. It would be more clear if the authors presented more details on their experiments done to validate their theory.\nOverall, while I not intimately familiar with the theory presented in this paper, I do think this work provides a valuable contribution to the field in terms of understanding the limitations of inverse dynamics models.",
                "Questions": "As an aside, many of these questions will be clarification questions - hopefully these questions will help polish the paper so that it\u2019s more clear for a more broad set of readers.\nSection 2:\nFor the end of section 2, could you give an example of how one of the 6 questions can be inferred from f(M) = f(W) -> M = W? I find it a bit hard to follow what this other MDP W relates to B^a and M^a.\nYour overloaded notation for EqIM is a bit confusing. You defined EqIM(ia) and EqIM(i+), but not EqIM(i).\nSection 4:\nFor the introduction to this section, it would be nice to relate back to the 6 questions the authors were trying to answer and how EqIM(1) and EqIM(2) relates to those questions. This also relates back to my question in Section 2 about your definition of EqIM and how it is another way of posing the questions.\nSection 5:\nAgain, it would be good to relate back to the questions. Correct me if I\u2019m wrong but this section tries to answer (iii) to (vi)?\nSection 6:\nI don\u2019t see the experimental details listed anywhere - how do you generate these randomized grid worlds? \nAlso instead of just showing samples of the true vs inferred forward dynamics matrices, I think it would be more prudent to show statistics gathered from experiments, instead of just one or two examples. See limitation for more suggestions for experimental section.",
                "Limitations": "One limitation of this approach is the scalability to large-scale environments. While this is a limitation, I don\u2019t believe this is any issue in the analysis provided in this work, or with the claims made. That being said, it would be very interesting to see how well some of these theoretical claims hold in larger environments, with more complicated dynamics/inverse dynamics that can\u2019t be feasibly represented with tensors.\nAnother limitation of this work is with the experiments and empirical results. While the do run experiments to back up the theory they develop, they don\u2019t provide details of their experimental set up, nor do they present any meaningful statistics with regards to their main result - showing one or two examples from generated grid worlds in the main work (the first grid world does not match the canonical 4-room by the way - it is something akin to it), and presenting a few plots over noise added for noisy inverse models. There is also stochasticity from the grid world generation - was there a lot of variation in terms of inferred dynamics models in the deterministic case? How were the grid worlds generated? It seems that (based on the second grid world presented) the dynamics of the grid world would be quite sparse. As mentioned earlier, presenting a more detailed account and analysis of the experiments done would improve the paper.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper analyzes the prospects of inferring meaningful inverse models of discrete-time controlled Markov processes. In particular, the paper focuses on determining the existence/uniqueness properties of these inverse models, and investigate the computational complexity of computing them.",
                "Strengths And Weaknesses": "Unfortunately, several technical parts of this paper concern me. There are several mathematical statements that I believe to be invalid (see the Questions section). Moreover, I found the structure of the paper to be extremely confusing, especially the recurring \"questions\" which are rephrased several times, some of which (as far as I'm concerned) are not rephrased correctly. Finally, the notation used in the paper is very difficult to parse.",
                "Questions": "General Question: As the authors acknowledge, the setting here is not that of inverse MDPs, but inverse controlled Markov processes. I'd argue actually that it's simply inverse Markov chains, since the policy appears to be fixed everywhere. How do the studies in this paper differ from those in the inverse kinematics literature?\n Motivation: causal inference, line 24: It is written that \"An\n  inverse model captures the likelihood that an action a was the\n  cause of the transition...\", but is this truly correct? To my\n  understanding, such a conditional model is incapable of inferring\n  causation. Wouldn't one need some sort of counterfactual analysis as\n  well?\n Marginalizing variables in transition tensors: On lines 120 and 121,\n  I believe there is an inconsistency in the notation. In the Notation\n  section, it is writen that M\u22c5\u22c5a is the matrix at\n  dimension a, but here it is written Ma. I'm assuming Ma,M\u22c5\u22c5a represent the same thing, but then maybe the\n  M\u22c5\u22c5a notation should be avoided altogether.\n Challenges with the backward model: Line 127 says Ba+\u2260Ba,\n  can this be expanded upon? This is unintuitive, at least to me. After\n  line 121, it says Bss\u2032a=p(a\u2223ss\u2032), and after line 129 it\n  says Bss\u2033a+=p(a\u2223ss\u2033), thus\n Bss\u2032a+=p(a\u2223ss\u2032)=Bss\u2032a\n  Which implies that Ba=Ba+ since all of their entries are\n  equal.\n The Questions: The six questions, first stated on line 46, are very\n  confusing. Firstly, they're stated in different terms several times,\n  which is confusing on its own. Why not list the questions only once,\n  in the most intuitive way? Moreover, the questions are too complicated\n  individually. I think it would be much clearer if you don't state all\n  of these questions explicitly, and rather prove the answers as\n  theorems/lemmas/propositions. It's very hard to remember which\n  question is which as you go through the text, and it's actually very\n  hard to digest what the paper is trying to do with such a dense list\n  of questions. In my opinion, the motivation for the paper is clear\n  enough on its own, and I don't think it'll be difficult to convince\n  most readers that understanding these inverse models is an important\n  task. But when the exact meaning of \"understanding\" is stated so\n  verbosely, it actually detracts from the clarity of the paper. One\n  example that is particularly confusing appears on line 139, where it\n  says \"Questions (i) - (vi) also have multiple variations\", followed by\n  a list of three questions. How do you go from 6 questions to 3, which\n  correspond to which? Now you're actually assuming that the reader will\n  recall at least 9 questions.\n  Moreover, if you must include these questions, it would be\n  tremendously more convenient if they can be hyperlinked.\n Line 149: Another rephrasing of the questions here says\n\nOne way to rephrase the questions is whether f(M)=f(W)\nimplies M=W or g(M)=g(W) for all (or most or some)\nM and W.\n\n  I don't understand this question at all. The property that f(M)=f(W)\u27f9M=W is more a property of the function f than the\n  objects M,W. Indeed, this property is known as\n  \"injectivity\". Likewise, \"whether f(M)=f(W) implies g(M)=g(W)\"\n  is also highly dependent on the particular properties of\n  f,g. Currently f,g are only assumed to be arbitrary functions, so\n  it is really unclear to me what the purpose of this question is. I had\n  a clearer understanding of the questions before reading this.\n Equations (8) and (9): Surely the notation can be improved here, it\n  is extremely difficult to parse. Why not use product notation\n  (\u220f)? Also, in equation (9), what is Ba+\u22ef+? Are there\n  i dots? Back to my previous comment, I believe Ba+\u22ef+\u2261Ba unless there's an inconsistency in the notation.\n  Later, on line 161, the term EqIM(1) is mentioned, but where\n  is that defined? Only equations EqIM(ia) and\n  EqIM(i+) are defined.\n Example violating (i, iii, v): It appears that what you're showing\n  is that for random variables X,Y distributed by \u03bcX,\u03bcY,\n  there may exist several distinct random variables (X,Y) with\n  marginals \u03bcX,\u03bcY. This is well known.\n Line 169: I don't understand how this relates to (i), (iii), (v) at\n  all. You're assuming that two MDPs encoded by M,W have the same\n  transition dynamics, and then based on that, the ability to infer\n  multistep models from fewer-step models is guaranteed? Something is\n  missing here. How does W fit in?\n Line 171: It says \"Note that Mss\u2032a\u2261p(s\u2032\u2223sa)\n  independent of a implies Ms+a independent of a...\" -- this\n  is only true if it holds /for every pair/ (s,s\u2032). Also, this whole\n  \"degenerate case\" is fairly trivial: M and W are only related via\n  \u03c0(a\u2223\u22c5), so if they're both actually independent of a,\n  then of course any equality of this sort must imply that the MDPs are\n  identical.\n Line 175: What does it mean for tensors to be \"nearly independent\"\n  of a?\n Line 178: Similarly to the \"independent of a\" case, why is this\n  even an interesting case to study? As pointed out, the consequences\n  are fairly obvious.\n  Altogether, I didn't find section 3 to be very informative.\n Non-linear manifold: On line 212, it says that Baa\u2032 forms a\n  non-linear manifold of dimension at least d(d\u2212k). But what is the\n  \"dimension\" of a non-linear manifold? Perhaps there is a definition\n  for this, but I doubt it's widely known to the Neurips audience. I'd\n  much prefer to have seen this definition in the background section in\n  place of the algebraic properties of tensors.\n Line 214: I believe this logic is flawed. It says \"... this now\n  gives an over-determined system which generally has no solution. But\n  by assumption, M is a solution, which gives hope that there may be\n  only one or a finite number of solutions\". What is being said here is\n  that the situation only makes sense if the \"over-determinacy\" is\n  redundant, so that it's not actually over-determined. This doesn't\n  give any hint about the number of solutions. There may very well be\n  infinitely-many solutions regardless of the fact that the system is\n  over-determined.\n Figure 1: This figure is never mentioned in the text, it would be\n  nice to have some discussion of the results it's presenting.\nMinor issues\n Contents section: On line 88 \"Appendix A\" is mentioned, but then\n  subsequent appendices are written \"(B)\", for instance, which is a\n  little confusing.\n Matrix notation: On line 105, it is written \"Capital letters... are\n  used for d\u00d7d matrices over [0;1]\u2282R...\".  Is\n  [0;1] the closed unit interval? Why not write \"Capital\n  letters... are used for matrices in [0,1]d\u00d7d\"?\n Tensor notation: On line 109,\n\nLet \u2299 denote element-wise (Hadamard)\nmultiplication... and similarly \u2298, while (no)\n\u22c5 represents (conventional) matrix multiplication\nand has operator preference over \u2299 and \u2298.\n\n  I don't understand this at all. What is \u2298? What is \u22c5?\n  I'm assuming that by \"similarly \u2298\" it is meant that \u2298\n  is element-wise division (this should be stated, because the sentence\n  doesn't make sense otherwise), and that \u22c5 represents matrix\n  multiplication. But what does \"while (no) \u22c5\" mean?\n Algebraic properties of tensors: Does this really need to be\n  included here? It's hard to read math packed into a paragraph like\n  this. Also many of these properties are very intuitive (i.e., I think\n  just about every reader will have inuition for the D\u2299Id\n  property without it being stated), and then some properties are highly\n  abstract (matrices form a ring...). I think it's fair to assume that\n  readers of this paper understand how to do algebra with matrices and\n  tensors, even if they don't know what a ring is.",
                "Limitations": "The authors have addressed the limitations of their methods.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "1 poor",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 4.0,
        "confidence_avg": 2.667,
        "soundness_avg": 2.667,
        "presentation_avg": 1.667,
        "contribution_avg": 2.333,
        "ai_sum_meta": "Recommendation: Reject\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that there are several weaknesses in this paper. Reviewer 1 points out that the significance of the results is not well explained and that many of the problems studied are not solved or are straightforward. Reviewer 2 also mentions weaknesses in the writing style and experimental section. Reviewer 3 raises concerns about the validity of mathematical statements, the confusing structure of the paper, and the difficulty in parsing the notation. Overall, there are technical flaws and weaknesses in the evaluation and presentation of the paper. Therefore, I recommend rejecting this paper."
    },
    "MMRR:_Unsupervised_Anomaly_Detection_through_Multi-Level_Masking_and_Restoration_with_Refinement": {
        "link": "https://openreview.net//forum?id=GBEimWWM9ii",
        "pub_url": "https://openreview.net/forum?id=GBEimWWM9ii",
        "pdf_link": "https://openreview.net//pdf?id=GBEimWWM9ii",
        "paper_id": "GBEimWWM9ii",
        "title": "MMRR:_Unsupervised_Anomaly_Detection_through_Multi-Level_Masking_and_Restoration_with_Refinement",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nThe paper proposes a Multi-Level Masking and Restoration with Refinement  to solve the hyperparameter sensitivity problem in anomaly detection studies. Reviewers had some concerns regarding this work including limited novelty, inconsistent numerical evaluation with prior works, lack of  discussions on benefits of using prior knowledge, etc. I appreciate that the authors were active during the rebuttal period to address these concerns but I think the paper needs a bit more work before being accepted.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper presents an unsupervised learning based anomaly detection method, which masks the images at multi-levels for restoration and then refine the restored images with refinement network. To overcome hyperparameter sensitivity, this work ensembles multiple restoration results from different level of masks and propose a novel mask generation and refinement method to achieve hyperparameter robustness.  Experiments are conducted on  several  benchmarks\nStrengths And Weaknesses: Strengths \n1.This work proposed a multi-level masking scheme for image restoration and ensemble restoration results to overcome hyperparameter sensitivity. \n2.The experiments are evaluated on multiple datasets.\nWeaknesses\n1.The novelty of this work is very limited. The mask-based restoration has been studied by search works, and they employed the ensembles of restoration results of different scale masks or different pattern masks.\n2.Some important related works are missing in the paper, and this work does not compare the AD performance with these works. E.g. \u201cCFLOW-AD: Real-Time Unsupervised Anomaly Detection with Localization via Conditional Normalizing Flows\u201d, \u201cLearning Semantic Context from Normal Samples for Unsupervised Anomaly Detection\u201d etc.\n3.The proposed method adopts a complicated framework including multiple restoration and refinement networks, but the AD performance on MVTEC and Cifar-10 dataset is far below the state-of-the-art.\nQuestions: What is the advantage of the proposed mask design method in comparison with the masking design in other works? Although the hypermeter issue is relieved to some degree, the restoration quality of designed mask scheme is worse than the peer works.\nLimitations: The paper didn't address the limitation and potential negative societal impact of the work.\nEthics Flag: No\nSoundness: 1 poor\nPresentation: 2 fair\nContribution: 1 poor\nRating: 2: Strong Reject: For instance, a paper with major technical flaws, and/or poor evaluation, limited impact, poor reproducibility and mostly unaddressed ethical considerations.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This work targeted the unsupervised anomaly detection problem and proposed a reconstruction-based method. Namely, by masking out features of the input data, and adding also noise to the features, the reconstruction and refinement network are only trained on the normal data to achieve small reconstruction errors. Therefore, any anomaly would generally suffer from high reconstruction errors. The evaluation is carried out in the one-vs-rest setup of the multi-class datasets MNIST, FMNIST, CIFAR10, and the defect detection benchmark MVTecAD. These benchmarks cover both semantic and non-semantic anomaly patterns, showing the covered use scenarios of the method.\nThe method's gain over SoTAs is quite diverse on the benchmarks. The authors argued an important advantage of the proposed method is its less sensitivity to hyperparameters, e.g., through an ensemble of different levels of masking, and the performance generally increases with more levels and is saturated at a certain level.\nStrengths And Weaknesses: Reconstruction is one type of method to address anomaly detection. It is an unsupervised approach, thus requiring little knowledge of anomalies. However, compared to other kinds of methods, it is generally underperforming. One common observation is the reconstruction network can also reconstruct the anomalies. For instance, Masked autoencoders can reconstruct the input with a masking ratio of more than 75% on the input space (surely the work is proposed for self-supervised learning, not anomaly detection). The authors' method showed reasonable performance, through feature-level masking, adding noise, and additive refinement. \nHowever, the achieved performance is not very strong. First, it does not provide consistent improvement over different cases. On average, it is on a par with some existing methods. It can be important and interesting to discuss why the method is effective in some cases and less effective in others. \nSecond, the authors argued prior work is more sensitive to hyperparameter settings. It is not a strong argument in my opinion. All these methods are thresholding-based methods, including the proposed one. Thus, they all somewhat need some validation data to set the threshold before deployment, e.g., finding the value based on the expected false positive or true positive ratio. AUROC and AUPR are threshold-free evaluation metrics, but a threshold is still needed to really make a decision. In practice, it is probably not difficult to obtain some anomalies for validation. The important question is if the choice of hyperparameters is good for unseen anomalies at test time.\nThird, at the training time, the model does not exploit any prior knowledge about anomaly patterns to train the reconstruction. In other words, the model decides on its own which cue to use for learning the best reconstruction strategy, largely depending on the given dataset. In other words, it is also hard to predict the model reacts to which type of anomalies. The evaluated benchmarks mainly considered either semantic or non-semantic anomalies. What if construct both semantic and non-semantic anomalies for the same in-distribution dataset, i.e., CIFAR10-dog as the inliers, CIFAR10-others as outliers, CIFAR10-corruption or some other non-semantic shift as another type of outliers.\nQuestions: \nAUPR evaluation: for an imbalanced evaluation set (the ratio of normal and abnormal samples is not balanced, AUPR is a more insightful metric to evaluate than AUROC.\n\nAnalysis of the learned masking patterns: how they behave differently on different datasets. For instance, in the visual example Fig. 3, while the model is trained on ship of CIFAR10, it can still reconstruct the deer class. This is a known observation of reconstruction-based methods. The proposed method does not seem to provide a different observation. The reconstruction difference is mainly on the local pixels. This leads to the question if the network really exploits the semantic structure to mask and reconstruct. This may explain why the performance on CIFAR10 is quite diverse across different classes.\n\nOn the MVTec benchmark, there are more competitive baselines, e.g., from https://paperswithcode.com/sota/anomaly-detection-on-mvtec-ad. \n\nOn the F/MNNIST and CIFAR10, the authors mainly evaluated on the one-vs-rest setting. how this approach can handle multi-class settings, namely, the inlier dataset is multi-class.\n\nHow well this approach can scale up to more diverse and higher-resolution datasets?\n\nMore discussion or empirical analysis of the effectiveness of feature masking. For instance, on which feature dimension, how does it change over different input resolutions or types of anomaly patterns, the importance of adding noise vs. just putting zeros, why the learned mask does not select a shortcut, e.g., masking out every n pixels (like a downsampling) to achieve good reconstruction.\nLimitations: The limitation discussion of this work is primarily focused on cases where the method is performing on a par or worse than baselines, and also on the ablation study part. However, as provided in the previous feedback sessions (weakness and questions), I think it is still unclear on which conditions/reasons the model is particularly good and in which scenarios it is expected to be underperforming. This is very important as so far the empirical results are quite diverse in terms of gains over SoTAs.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper introduces a reconstruction-based anomaly detection algorithm. The algorithm is based on autoencoders, and noise is added in the form of masking of one of the embedding layers, which then has to be reconstructed to match the original input; input-specific masks are computed using a masking network, with a given average masking level. A further refinement network is implemented to correct the residual error from the reconstruction. At test time, predictions from various masking levels are ensembled and the reconstruction error post refinement is used as the anomaly score. Experiments performed on benchmark image anomaly datasets show competitive results with recent methods.\nStrengths And Weaknesses: Overall, the paper presents a promising approach to anomaly detection but some aspects of the algorithm are not well motivated or validated, and the evaluation could be improved. Detailed comments follow.\nOriginality:\nThis work extends a long line of reconstruction-based anomaly detection methods using autoencoders, with recent ones including noise and even masking but at the input layers (see references below). The key difference here is in implementing the masking at the inner embedding layers, and the use of a refinement network to further improve the reconstructions. From this perspective, the proposed method seems incremental. \n\nOne-Class Learned Encoder-Decoder Network with Adversarial Context Masking for Novelty Detection. WACV 2022.\nSelf-Supervised Masking for Unsupervised Anomaly Detection and Localization. IEEE Transactions on Multimedia 2022.\n\nQuality:\nOverall the approach and evaluation are reasonable, though there are several aspects that need to be addressed:\n\nThe paper does not motivate well the need to mask embeddings versus input layers (I did not understand the justification provided on L142), nor are comparisons provided to input masking autoencoder methods provided which could help to motivate the method.\n\nThe paper differentiates through the mask generation step by assuming that the average masking level condition is satisfied (Line 169). However, it is not shown whether this condition is indeed satisfied in the paper - this should be verified to ensure that the method is technically sound. \n\nExperiments in the paper are limited to images, though the framework appears to be generic. It would be informative to include tabular datasets (e.g. from ODDS - http://odds.cs.stonybrook.edu/) so the generality of the masking strategy can be assessed. Moreover, \"side-information\" is not usually available for such data and would be better able to demonstrate the practical utility of the proposed method.\n\nGiven that the mask is in [0,1], the ablation study (L326) should also include masks with entries uniformly generated over [0,1].\n\n\nClarity:\n\nThe paper is largely clear but there are several typos scattered across the paper (e.g. L23 real-word, L154 successfullt, L158 owingto, L173 non-differential).\n\nIt would be helpful to provide the percentage of anomalies in each dataset.\n\nJust a suggestion: it may be clearer to revise the definition of masking to e~=e\u2299(1\u2212m)+\u03f5\u2299m, such that a higher m represents a higher masking level in that more of the input is removed.\n\n\nSignificance:\nOverall, while the method is interesting and has some novel elements, the significance of the results is not clear:\n\nIn terms of the method, the refinement module is independent of the masking approach, and could also be applied to other autoencoder methods; the notion of masking is somewhat interesting and broadly applicable, but the lack of good performance makes its significance unclear.\n\nIn terms of performance, given that other better performing methods exist on the image datasets evaluated on, it is unclear if the method will be practically useful as other training/model hyperparameters still need to be tuned in practice. As mentioned above, it would be useful to demonstrate good performance on other datasets for which side-information is not available.\n\nThe claim that this is the first paper presenting the \"hyperparameter sensitity\" is not quite true, as this has been reported in the following workshop paper.\n\n\nThe Effect of Hyperparameter Tuning on the Comparative Evaluation of Unsupervised Anomaly Detection Methods. 6th Outlier Detection and Description Workshop @ KDD 2021.\nOther comments:\n\nGiven that some results are pretty close, it would be informative to provide results from multiple runs along with standard deviations.\n\nIn addition, providing results with the more appropriate AUPRC metric for anomaly detection due to the class imbalance would be informative.\n\n\n** Post rebuttal update: **\nAs described in the comment below, the response has addressed some of my key concerns regarding comparison to other masked-based anomaly detection methods and I am raising my score to a 5.\nQuestions: \nDoes the root-finding algorithm find a solution to the equation in practice? Is the assumption used to derive the gradient in Eq (2) satisfied?\n\nHow does the method perform on tabular or other non-image datasets (e.g. ODDS datasets)?\n\nHow does the method perform relative to other masking-based autoencoders?\n\nWhat is the performance with a uniform mask (see above)?\nLimitations: While I agree that the proposed method does eliminate the choice of the masking level hyperparameter, the autoencoder architecture to use and training hyperparameters still have to be tuned for a specific dataset, so I think it is a bit of an overreach to claim that the proposed method solves the tuning issue. To be fair this is an issue with many other methods as well.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 2 fair\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper presents an unsupervised learning based anomaly detection method, which masks the images at multi-levels for restoration and then refine the restored images with refinement network. To overcome hyperparameter sensitivity, this work ensembles multiple restoration results from different level of masks and propose a novel mask generation and refinement method to achieve hyperparameter robustness.  Experiments are conducted on  several  benchmarks",
                "Strengths And Weaknesses": "Strengths \n1.This work proposed a multi-level masking scheme for image restoration and ensemble restoration results to overcome hyperparameter sensitivity. \n2.The experiments are evaluated on multiple datasets.\nWeaknesses\n1.The novelty of this work is very limited. The mask-based restoration has been studied by search works, and they employed the ensembles of restoration results of different scale masks or different pattern masks.\n2.Some important related works are missing in the paper, and this work does not compare the AD performance with these works. E.g. \u201cCFLOW-AD: Real-Time Unsupervised Anomaly Detection with Localization via Conditional Normalizing Flows\u201d, \u201cLearning Semantic Context from Normal Samples for Unsupervised Anomaly Detection\u201d etc.\n3.The proposed method adopts a complicated framework including multiple restoration and refinement networks, but the AD performance on MVTEC and Cifar-10 dataset is far below the state-of-the-art.",
                "Questions": "What is the advantage of the proposed mask design method in comparison with the masking design in other works? Although the hypermeter issue is relieved to some degree, the restoration quality of designed mask scheme is worse than the peer works.",
                "Limitations": "The paper didn't address the limitation and potential negative societal impact of the work.",
                "Ethics Flag": "No",
                "Soundness": "1 poor",
                "Presentation": "2 fair",
                "Contribution": "1 poor",
                "Rating": "2: Strong Reject: For instance, a paper with major technical flaws, and/or poor evaluation, limited impact, poor reproducibility and mostly unaddressed ethical considerations.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This work targeted the unsupervised anomaly detection problem and proposed a reconstruction-based method. Namely, by masking out features of the input data, and adding also noise to the features, the reconstruction and refinement network are only trained on the normal data to achieve small reconstruction errors. Therefore, any anomaly would generally suffer from high reconstruction errors. The evaluation is carried out in the one-vs-rest setup of the multi-class datasets MNIST, FMNIST, CIFAR10, and the defect detection benchmark MVTecAD. These benchmarks cover both semantic and non-semantic anomaly patterns, showing the covered use scenarios of the method.\nThe method's gain over SoTAs is quite diverse on the benchmarks. The authors argued an important advantage of the proposed method is its less sensitivity to hyperparameters, e.g., through an ensemble of different levels of masking, and the performance generally increases with more levels and is saturated at a certain level.",
                "Strengths And Weaknesses": "Reconstruction is one type of method to address anomaly detection. It is an unsupervised approach, thus requiring little knowledge of anomalies. However, compared to other kinds of methods, it is generally underperforming. One common observation is the reconstruction network can also reconstruct the anomalies. For instance, Masked autoencoders can reconstruct the input with a masking ratio of more than 75% on the input space (surely the work is proposed for self-supervised learning, not anomaly detection). The authors' method showed reasonable performance, through feature-level masking, adding noise, and additive refinement. \nHowever, the achieved performance is not very strong. First, it does not provide consistent improvement over different cases. On average, it is on a par with some existing methods. It can be important and interesting to discuss why the method is effective in some cases and less effective in others. \nSecond, the authors argued prior work is more sensitive to hyperparameter settings. It is not a strong argument in my opinion. All these methods are thresholding-based methods, including the proposed one. Thus, they all somewhat need some validation data to set the threshold before deployment, e.g., finding the value based on the expected false positive or true positive ratio. AUROC and AUPR are threshold-free evaluation metrics, but a threshold is still needed to really make a decision. In practice, it is probably not difficult to obtain some anomalies for validation. The important question is if the choice of hyperparameters is good for unseen anomalies at test time.\nThird, at the training time, the model does not exploit any prior knowledge about anomaly patterns to train the reconstruction. In other words, the model decides on its own which cue to use for learning the best reconstruction strategy, largely depending on the given dataset. In other words, it is also hard to predict the model reacts to which type of anomalies. The evaluated benchmarks mainly considered either semantic or non-semantic anomalies. What if construct both semantic and non-semantic anomalies for the same in-distribution dataset, i.e., CIFAR10-dog as the inliers, CIFAR10-others as outliers, CIFAR10-corruption or some other non-semantic shift as another type of outliers.",
                "Questions": "AUPR evaluation: for an imbalanced evaluation set (the ratio of normal and abnormal samples is not balanced, AUPR is a more insightful metric to evaluate than AUROC.\n\nAnalysis of the learned masking patterns: how they behave differently on different datasets. For instance, in the visual example Fig. 3, while the model is trained on ship of CIFAR10, it can still reconstruct the deer class. This is a known observation of reconstruction-based methods. The proposed method does not seem to provide a different observation. The reconstruction difference is mainly on the local pixels. This leads to the question if the network really exploits the semantic structure to mask and reconstruct. This may explain why the performance on CIFAR10 is quite diverse across different classes.\n\nOn the MVTec benchmark, there are more competitive baselines, e.g., from https://paperswithcode.com/sota/anomaly-detection-on-mvtec-ad. \n\nOn the F/MNNIST and CIFAR10, the authors mainly evaluated on the one-vs-rest setting. how this approach can handle multi-class settings, namely, the inlier dataset is multi-class.\n\nHow well this approach can scale up to more diverse and higher-resolution datasets?\n\nMore discussion or empirical analysis of the effectiveness of feature masking. For instance, on which feature dimension, how does it change over different input resolutions or types of anomaly patterns, the importance of adding noise vs. just putting zeros, why the learned mask does not select a shortcut, e.g., masking out every n pixels (like a downsampling) to achieve good reconstruction.",
                "Limitations": "The limitation discussion of this work is primarily focused on cases where the method is performing on a par or worse than baselines, and also on the ablation study part. However, as provided in the previous feedback sessions (weakness and questions), I think it is still unclear on which conditions/reasons the model is particularly good and in which scenarios it is expected to be underperforming. This is very important as so far the empirical results are quite diverse in terms of gains over SoTAs.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper introduces a reconstruction-based anomaly detection algorithm. The algorithm is based on autoencoders, and noise is added in the form of masking of one of the embedding layers, which then has to be reconstructed to match the original input; input-specific masks are computed using a masking network, with a given average masking level. A further refinement network is implemented to correct the residual error from the reconstruction. At test time, predictions from various masking levels are ensembled and the reconstruction error post refinement is used as the anomaly score. Experiments performed on benchmark image anomaly datasets show competitive results with recent methods.",
                "Strengths And Weaknesses": "Overall, the paper presents a promising approach to anomaly detection but some aspects of the algorithm are not well motivated or validated, and the evaluation could be improved. Detailed comments follow.\nOriginality:\nThis work extends a long line of reconstruction-based anomaly detection methods using autoencoders, with recent ones including noise and even masking but at the input layers (see references below). The key difference here is in implementing the masking at the inner embedding layers, and the use of a refinement network to further improve the reconstructions. From this perspective, the proposed method seems incremental. \n\nOne-Class Learned Encoder-Decoder Network with Adversarial Context Masking for Novelty Detection. WACV 2022.\nSelf-Supervised Masking for Unsupervised Anomaly Detection and Localization. IEEE Transactions on Multimedia 2022.\n\nQuality:\nOverall the approach and evaluation are reasonable, though there are several aspects that need to be addressed:\n\nThe paper does not motivate well the need to mask embeddings versus input layers (I did not understand the justification provided on L142), nor are comparisons provided to input masking autoencoder methods provided which could help to motivate the method.\n\nThe paper differentiates through the mask generation step by assuming that the average masking level condition is satisfied (Line 169). However, it is not shown whether this condition is indeed satisfied in the paper - this should be verified to ensure that the method is technically sound. \n\nExperiments in the paper are limited to images, though the framework appears to be generic. It would be informative to include tabular datasets (e.g. from ODDS - http://odds.cs.stonybrook.edu/) so the generality of the masking strategy can be assessed. Moreover, \"side-information\" is not usually available for such data and would be better able to demonstrate the practical utility of the proposed method.\n\nGiven that the mask is in [0,1], the ablation study (L326) should also include masks with entries uniformly generated over [0,1].\n\n\nClarity:\n\nThe paper is largely clear but there are several typos scattered across the paper (e.g. L23 real-word, L154 successfullt, L158 owingto, L173 non-differential).\n\nIt would be helpful to provide the percentage of anomalies in each dataset.\n\nJust a suggestion: it may be clearer to revise the definition of masking to e~=e\u2299(1\u2212m)+\u03f5\u2299m, such that a higher m represents a higher masking level in that more of the input is removed.\n\n\nSignificance:\nOverall, while the method is interesting and has some novel elements, the significance of the results is not clear:\n\nIn terms of the method, the refinement module is independent of the masking approach, and could also be applied to other autoencoder methods; the notion of masking is somewhat interesting and broadly applicable, but the lack of good performance makes its significance unclear.\n\nIn terms of performance, given that other better performing methods exist on the image datasets evaluated on, it is unclear if the method will be practically useful as other training/model hyperparameters still need to be tuned in practice. As mentioned above, it would be useful to demonstrate good performance on other datasets for which side-information is not available.\n\nThe claim that this is the first paper presenting the \"hyperparameter sensitity\" is not quite true, as this has been reported in the following workshop paper.\n\n\nThe Effect of Hyperparameter Tuning on the Comparative Evaluation of Unsupervised Anomaly Detection Methods. 6th Outlier Detection and Description Workshop @ KDD 2021.\nOther comments:\n\nGiven that some results are pretty close, it would be informative to provide results from multiple runs along with standard deviations.\n\nIn addition, providing results with the more appropriate AUPRC metric for anomaly detection due to the class imbalance would be informative.\n\n\n** Post rebuttal update: **\nAs described in the comment below, the response has addressed some of my key concerns regarding comparison to other masked-based anomaly detection methods and I am raising my score to a 5.",
                "Questions": "Does the root-finding algorithm find a solution to the equation in practice? Is the assumption used to derive the gradient in Eq (2) satisfied?\n\nHow does the method perform on tabular or other non-image datasets (e.g. ODDS datasets)?\n\nHow does the method perform relative to other masking-based autoencoders?\n\nWhat is the performance with a uniform mask (see above)?",
                "Limitations": "While I agree that the proposed method does eliminate the choice of the masking level hyperparameter, the autoencoder architecture to use and training hyperparameters still have to be tuned for a specific dataset, so I think it is a bit of an overreach to claim that the proposed method solves the tuning issue. To be fair this is an issue with many other methods as well.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 3.333,
        "confidence_avg": 4.333,
        "soundness_avg": 1.667,
        "presentation_avg": 2.333,
        "contribution_avg": 1.667,
        "ai_sum_meta": "Recommendation: Reject\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that the proposed paper has several weaknesses and limitations. The novelty of the work is limited, as mask-based restoration methods have been studied before. Important related works are missing and the proposed method does not compare well with state-of-the-art methods in terms of anomaly detection performance. The paper also lacks a discussion of the limitations and potential negative societal impact of the work. While the approach shows promise, there are several aspects that need to be addressed and validated. The evaluation could be improved by including tabular datasets and demonstrating the generality of the masking strategy. Overall, the significance of the results is not clear, and the method may not be practically useful without further tuning of training/model hyperparameters. Therefore, I recommend rejecting the paper."
    },
    "Near-optimal_Distributional_Reinforcement_Learning_towards_Risk-sensitive_Control": {
        "link": "https://openreview.net//forum?id=LsWxgJZpRl",
        "pub_url": "https://openreview.net/forum?id=LsWxgJZpRl",
        "pdf_link": "https://openreview.net//pdf?id=LsWxgJZpRl",
        "paper_id": "LsWxgJZpRl",
        "title": "Near-optimal_Distributional_Reinforcement_Learning_towards_Risk-sensitive_Control",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nWhile this work provides interesting insights on  distributional reinforcement learning for risk-sensitive control, it is unclear how beneficial these results are given the closely related work [22] (on the same problem with the same regret bound). The authors mentioned in the rebuttal that their algorithm may motivate the design of similar algorithms for other risk measures, but no concrete discussions and examples were provided. We believe that the paper would benefit from another round of revision to properly address these issues and make its contributions move convincing.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper considers finite episodic Markov decision processes aiming with risk-sensitivity. Two properties are identified to develop both the model-based and model-free algorithms for risk-sensitive distributional dynamic programming.  Both upper and lower bounds for regret haven been proved.\nStrengths And Weaknesses: Strengths:\n\nA specific entropic measure is used, enable the derivations of useful distributional Bellman optimality equation as well as risk-sensitive distributional dynamic programming. This contribution is very interesting. \n\nOFU principle has been used to develop deep RL algorithms with provable regret bounds. \n\nAn improved lower bound has been obtained when beta is positive. \n\nThe paper is well written. The presentation is clear.\n\n\nWeakness:\n\nThis paper focuses on the episodic MDP setting. The most common setting in the risk-sensitive control literature is the setting with continuous state/action spaces (see Jacobson 1973 or Whittle 1990). Then stability also becomes an important issue. It is unclear how useful the results in this paper will be for continuous control applications. Maybe rephrase and focus on \"risk-sensitive MDP\"?\n\nThis paper proposes two algorithms with provable regrets. However, it is unclear whether the proposed algorithms will really perform well on any MDP tasks. Numerical examples are needed in this case. This is different from analyzing existing algorithms which already perform well.\n\nCVaR vs Entropic Risk Measure (ERM):  CVaR has been used a lot in deep RL tasks and seems to be a better risk measure than ERM for deep RL. One reason why ERM was popular in some early risk-sensitive control literature is that for linear dynamics, ERM leads to a dynamical programming solution with relatively simple analytical form. In the deep RL setting, it is unclear whether ERM has any practical advantages over CVaR.\n\nThe regret analysis technique is not that new (similar analysis has been used to study episodic MDPs (without ERM) before).\nQuestions: How does the performance of the proposed algorithms compare to that of DRL algorithms using CVaR? Is it possible to extend the proposed algorithms for continuous control tasks, such as Cartpole or more complicated robotic learning application? Can the authors clarify the unique novelty of the regret analysis technique?\nLimitations: Yes, the authors have discussed the limitations of their theory. However, I mean some study on the actual performance is necessary for this paper. The proposed regret guarantees are meaningful only when the algorithms actually do perform well.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper is about distributional reinforcement learning (DRL), which aims at learning optimal policies (in terms of total payoff) in a Markov decision process. While the classical reinforcement learning (RL) paradigm is based on the expected total return, in DRL one is interested about the whole probability distribution of this total return. \nIn this work, the idea is to leverage this distributional information for risk-sensitivity purpose.\nThe focus is on the entropic risk-measure (ERM) of the total reward in an episodic MDP. Properties of ERM are given (additivity and monotonicity preserving) leading to an optimality principle akin to the classical one based on expected value.\nTwo algorithms (one model-free and the other model-based) called RODI are proposed: they both rely on the OFU principle applied to ERM.\nWhile most risk-aware DRL papers have no regret analysis, here both upper and lower regret bounds are provided.\nStrengths And Weaknesses: The paper is well-written and motivated by risk-sensitive applications. The DRL perspective makes a lot of sense to tackle risk-aware problems. The main strength of the paper is that its algorithmic RODI procedures are naturally derived from DRL applied to ERM and combined with the OFU principle.\nThe main weakness is the lack of numerical experiments, which is balanced by the theoretical nature of the paper.\nQuestions: (Minor) questions/comments:\n\nline 80: more accurate to say that P_h maps state-action pair to probability distribution over S, i.e. P_h : SxA -> Delta(S)\nline 108: replace Z(s) by Y(s)\nfootnote page 4: strange formulation? maybe rather say: \"The algorithms for random reward enjoy regret bounds of the same order\"\nnotational issue: at line 176, reference to \"c_h^k\" but in Algorithm 1 it is just written \"c_h\". Same holds for eta_h. Is it normal or a notation issue?\nwhat is f_h in Proposition 2?\nLimitations: The scope of the paper is limited to the ERM criterion, but it is a reasonable \"limitation\" in order to design a risk-sensitive DRL approach.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The paper deals with a risk-sensitive reinforcement learning problem where the risk functional is the entropic risk. The authors provide both the regret upper bounds for a proposed model-based algorithm and a model-free algorithm and a tighter regret lower bound compared to prior works.\nStrengths And Weaknesses: Strength: The ideas in the paper are clearly explained. A tighter lower bound is presented in the paper. \nWeakness: Given that prior works, e.g., [22, 23], have also used optimism to solve the exact same problem and achieve similar regret guarantees, it is unclear how much novelty/significance the newly proposed algorithms are.\nQuestions: \nThe authors suggest that the lower bound proof in [22] has a mistake. Can the authors elaborate more on this?\nCan the authors compare their proposed algorithms with that proposed in [22] in a more detailed way to explain how optimism may have been used differently in this paper and what that implies?\n\n\nStylistic suggestions:\n\nUsing ERM to refer to entropic risk measure may be confusing since ERM is known to be Empirical Risk Minimization in standard ML literature.\n\\citep should be used for the first two citations in L101.\nIn L168, (s,a)s may be confusing to the reader.\nLimitations: Yes.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This work proposes to build a distributional dynamic programming framework to optimize the entropic risk measure of the return. Under the new framework, both model-based and model-free algorithms are proposed, which achieve regret bound that matches one of the existing works in risk sensitive control. The lower bound of rish sensitive control problem is also improved using the new framework.\nStrengths And Weaknesses: Strengths: \n\nThe proposed distributional dynamics programming framework is novel to my best knowledge. Differences in the analysis between distributional RL and previous work [22] are discussed, which shows that the distributional analysis can avoid the explode factor and shows the significance of the proposed framework in theory.\n\nThe presentation of the paper is clear. Key steps in the analysis are highlighted, with detailed discussion on how they would affect the final regret bound. Algorithm designs are also explained in detail.\n\n\nWeaknesses: \n\nSince this work is highly relevant to [22], the significance of the work can benefit from a more comprehensive comparison  w.r.t. to previous work [22]; See Questions 1 and 2. Also, further discussion on another relevant work [1] can also improve the significance. \n\nThe novelty of the proposed algorithms can benefit from further discussion. The equivalence of the proposed model-based algorithm to ROVI is discussed, which raises a natural question: if distributional RL is somewhat equivalent to the existing algorithms, existing analysis could also apply to DRL, then is the claim in line 10 \"this is the first regret analysis of DRL\" still valid?\n\n\n[22] Yingjie Fei, Zhuoran Yang, Yudong Chen, and Zhaoran Wang. Exponential bellman equation and improved regret bounds for risk-sensitive reinforcement learning. Advances in Neural Information Processing Systems, 34, 2021.\nQuestions: \nIn Appendix A of [22], they also provide connections between risk-sensitive RL and distributional RL through the exponential Bellman equation. How is the proposed framework related to theirs? It would be helpful if there's a section dedicated to explain the relation and potential difference w.r.t. their analysis.\n\nIf Alg. 2 is actually equivalent to Alg. 3, what is the benefit of distributional framework over existing risk sensitive control approaches? E.g., what are the cases when the proposed framework is more favourable, either theoretically or empirically? \n\nDoes the improvement in the lower bound in Section 5.3 come from the newly proposed framework, or just different proof techniques?\nLimitations: The limitation of the proposed method are discussed, but not adequately.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper considers finite episodic Markov decision processes aiming with risk-sensitivity. Two properties are identified to develop both the model-based and model-free algorithms for risk-sensitive distributional dynamic programming.  Both upper and lower bounds for regret haven been proved.",
                "Strengths And Weaknesses": "Strengths:\n\nA specific entropic measure is used, enable the derivations of useful distributional Bellman optimality equation as well as risk-sensitive distributional dynamic programming. This contribution is very interesting. \n\nOFU principle has been used to develop deep RL algorithms with provable regret bounds. \n\nAn improved lower bound has been obtained when beta is positive. \n\nThe paper is well written. The presentation is clear.\n\n\nWeakness:\n\nThis paper focuses on the episodic MDP setting. The most common setting in the risk-sensitive control literature is the setting with continuous state/action spaces (see Jacobson 1973 or Whittle 1990). Then stability also becomes an important issue. It is unclear how useful the results in this paper will be for continuous control applications. Maybe rephrase and focus on \"risk-sensitive MDP\"?\n\nThis paper proposes two algorithms with provable regrets. However, it is unclear whether the proposed algorithms will really perform well on any MDP tasks. Numerical examples are needed in this case. This is different from analyzing existing algorithms which already perform well.\n\nCVaR vs Entropic Risk Measure (ERM):  CVaR has been used a lot in deep RL tasks and seems to be a better risk measure than ERM for deep RL. One reason why ERM was popular in some early risk-sensitive control literature is that for linear dynamics, ERM leads to a dynamical programming solution with relatively simple analytical form. In the deep RL setting, it is unclear whether ERM has any practical advantages over CVaR.\n\nThe regret analysis technique is not that new (similar analysis has been used to study episodic MDPs (without ERM) before).",
                "Questions": "How does the performance of the proposed algorithms compare to that of DRL algorithms using CVaR? Is it possible to extend the proposed algorithms for continuous control tasks, such as Cartpole or more complicated robotic learning application? Can the authors clarify the unique novelty of the regret analysis technique?",
                "Limitations": "Yes, the authors have discussed the limitations of their theory. However, I mean some study on the actual performance is necessary for this paper. The proposed regret guarantees are meaningful only when the algorithms actually do perform well.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper is about distributional reinforcement learning (DRL), which aims at learning optimal policies (in terms of total payoff) in a Markov decision process. While the classical reinforcement learning (RL) paradigm is based on the expected total return, in DRL one is interested about the whole probability distribution of this total return. \nIn this work, the idea is to leverage this distributional information for risk-sensitivity purpose.\nThe focus is on the entropic risk-measure (ERM) of the total reward in an episodic MDP. Properties of ERM are given (additivity and monotonicity preserving) leading to an optimality principle akin to the classical one based on expected value.\nTwo algorithms (one model-free and the other model-based) called RODI are proposed: they both rely on the OFU principle applied to ERM.\nWhile most risk-aware DRL papers have no regret analysis, here both upper and lower regret bounds are provided.",
                "Strengths And Weaknesses": "The paper is well-written and motivated by risk-sensitive applications. The DRL perspective makes a lot of sense to tackle risk-aware problems. The main strength of the paper is that its algorithmic RODI procedures are naturally derived from DRL applied to ERM and combined with the OFU principle.\nThe main weakness is the lack of numerical experiments, which is balanced by the theoretical nature of the paper.",
                "Questions": "(Minor) questions/comments:\n\nline 80: more accurate to say that P_h maps state-action pair to probability distribution over S, i.e. P_h : SxA -> Delta(S)\nline 108: replace Z(s) by Y(s)\nfootnote page 4: strange formulation? maybe rather say: \"The algorithms for random reward enjoy regret bounds of the same order\"\nnotational issue: at line 176, reference to \"c_h^k\" but in Algorithm 1 it is just written \"c_h\". Same holds for eta_h. Is it normal or a notation issue?\nwhat is f_h in Proposition 2?",
                "Limitations": "The scope of the paper is limited to the ERM criterion, but it is a reasonable \"limitation\" in order to design a risk-sensitive DRL approach.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper deals with a risk-sensitive reinforcement learning problem where the risk functional is the entropic risk. The authors provide both the regret upper bounds for a proposed model-based algorithm and a model-free algorithm and a tighter regret lower bound compared to prior works.",
                "Strengths And Weaknesses": "Strength: The ideas in the paper are clearly explained. A tighter lower bound is presented in the paper. \nWeakness: Given that prior works, e.g., [22, 23], have also used optimism to solve the exact same problem and achieve similar regret guarantees, it is unclear how much novelty/significance the newly proposed algorithms are.",
                "Questions": "The authors suggest that the lower bound proof in [22] has a mistake. Can the authors elaborate more on this?\nCan the authors compare their proposed algorithms with that proposed in [22] in a more detailed way to explain how optimism may have been used differently in this paper and what that implies?\n\n\nStylistic suggestions:\n\nUsing ERM to refer to entropic risk measure may be confusing since ERM is known to be Empirical Risk Minimization in standard ML literature.\n\\citep should be used for the first two citations in L101.\nIn L168, (s,a)s may be confusing to the reader.",
                "Limitations": "Yes.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This work proposes to build a distributional dynamic programming framework to optimize the entropic risk measure of the return. Under the new framework, both model-based and model-free algorithms are proposed, which achieve regret bound that matches one of the existing works in risk sensitive control. The lower bound of rish sensitive control problem is also improved using the new framework.",
                "Strengths And Weaknesses": "Strengths: \n\nThe proposed distributional dynamics programming framework is novel to my best knowledge. Differences in the analysis between distributional RL and previous work [22] are discussed, which shows that the distributional analysis can avoid the explode factor and shows the significance of the proposed framework in theory.\n\nThe presentation of the paper is clear. Key steps in the analysis are highlighted, with detailed discussion on how they would affect the final regret bound. Algorithm designs are also explained in detail.\n\n\nWeaknesses: \n\nSince this work is highly relevant to [22], the significance of the work can benefit from a more comprehensive comparison  w.r.t. to previous work [22]; See Questions 1 and 2. Also, further discussion on another relevant work [1] can also improve the significance. \n\nThe novelty of the proposed algorithms can benefit from further discussion. The equivalence of the proposed model-based algorithm to ROVI is discussed, which raises a natural question: if distributional RL is somewhat equivalent to the existing algorithms, existing analysis could also apply to DRL, then is the claim in line 10 \"this is the first regret analysis of DRL\" still valid?\n\n\n[22] Yingjie Fei, Zhuoran Yang, Yudong Chen, and Zhaoran Wang. Exponential bellman equation and improved regret bounds for risk-sensitive reinforcement learning. Advances in Neural Information Processing Systems, 34, 2021.",
                "Questions": "In Appendix A of [22], they also provide connections between risk-sensitive RL and distributional RL through the exponential Bellman equation. How is the proposed framework related to theirs? It would be helpful if there's a section dedicated to explain the relation and potential difference w.r.t. their analysis.\n\nIf Alg. 2 is actually equivalent to Alg. 3, what is the benefit of distributional framework over existing risk sensitive control approaches? E.g., what are the cases when the proposed framework is more favourable, either theoretically or empirically? \n\nDoes the improvement in the lower bound in Section 5.3 come from the newly proposed framework, or just different proof techniques?",
                "Limitations": "The limitation of the proposed method are discussed, but not adequately.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.75,
        "confidence_avg": 3.0,
        "soundness_avg": 3.0,
        "presentation_avg": 3.0,
        "contribution_avg": 2.75,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that this paper makes a significant contribution to the field of risk-sensitive reinforcement learning. The proposed distributional dynamic programming framework and the derived algorithms for risk-sensitive distributional dynamic programming are novel and well-motivated. The paper provides both upper and lower regret bounds, which is a strength compared to other risk-aware reinforcement learning papers. \n\nWhile there are some limitations and questions raised by the reviewers, such as the lack of numerical experiments and the need for further comparison with existing algorithms, these concerns do not outweigh the technical solidity and impact of the paper. The reviewers also acknowledge the theoretical nature of the paper, which justifies the focus on the entropic risk measure and episodic MDP setting.\n\nOverall, the strengths of the paper outweigh the weaknesses, and the technical contributions and impact make it suitable for acceptance at the conference."
    },
    "Adversarially_Robust_Learning_with_Tolerance": {
        "link": "https://openreview.net//forum?id=jwOg8J1yZ-a",
        "pub_url": "https://openreview.net/forum?id=jwOg8J1yZ-a",
        "pdf_link": "https://openreview.net//pdf?id=jwOg8J1yZ-a",
        "paper_id": "jwOg8J1yZ-a",
        "title": "Adversarially_Robust_Learning_with_Tolerance",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Less certain\nThe paper introduces an algorithm called \u201ctolerant perturb and smooth\u201d and analyzes it with the lens of tolerant PAC learning. The analysis applies to the robustly realizable setting and achieves tighter sample complexity bounds than previous work.\nHowever, there were concerns about the significance. The major issue is that their tolerance framework is not justified.\nFrom the discussion:\n<<\nOn the one hand, they do not specify how to choose a reasonable reference perturbation type U(x) given an actual perturbation type U(x) in definition 4. More precisely, the choice of tolerance parameter \\gamma in line 206 is unclear. I think this is very crucial and necessary in this framework. Consider the case where V(x)=0 and U(x) = B_{\\gamma}(x). Then the inequality between line 195 and 196 tells that the algorithm can find a classifier that has clean error smaller than that of adversarial bayes error within ball B_{\\gamma}(x), which is actually meaningless for any \\gamma since we know that the clean Bayes error must be less than that of adversarial Bayes error and the sample-efficient PAC learners for clean Bayes classifier is known.\nIn line 298 - 301, they want to set gamma to be above some threshold. Using their parameters of \\zeta=1, c =1000 and d=1000 in the provided example, the gamma is required to be larger than 1. It is hard to believe that such a large gamma is meaningful in terms of the tolerance of perturbation size.\nOn the other hand, they do not show negative results like \"some tolerance is necessary otherwise adversarial robustness is not possible\", which further limits the significance.\nTheir sample complexity such as that in Theorem 10 is independent of the actual permutation size r for adversarial robustness. Their proposed algorithm does not train on the worst-case perturbed samples. Instead, the algorithm only requires training on the randomly perturbed samples, which I feel is not useful for adversarial robustness. It will be surprising if such a tolerance framework is reliable based on these facts.\n\n\n\n\nThe referees raised serious concerns regarding the efficacy and significance of the algorithm. Given the lengths to which they went in running independent experience, I take these reservations very seriously and cannot recommend acceptance at this stage.",
        "reviews": [
            "Reviewer 1: \nSummary: The paper studies the PAC learnability of adversarial robustness in the tolerant setting. The paper reveals a learnability result showing that VC hypothesis sets are tolerantly PAC learnable in the realizable case using a ``perturb-and-smooth'\u2019 algorithm. As compared to previous non-tolerant results, their sample complexity has an exponential improvement on the dependence of VC dimension. The paper also reveals a learnability result in the agnostic setting through sample compression.\nStrengths And Weaknesses: Strengths:\n\nWell-written assumptions and theorems.\nNew tolerant framework is considered.\n\nWeaknesses:\nThe significance is limited. The major issue is that their tolerance framework is not justified.\nOn the one hand, they do not specify how to choose a reasonable reference perturbation type V(x) given an actual perturbation type U(x) in definition 4. More precisely, the choice of tolerance parameter \\gamma in line 206 is unclear. I think this is very crucial and necessary in this framework. Consider the case where V(x)=0 and U(x) = B_{\\gamma}(x). Then the inequality between line 195 and 196 tells that the algorithm can find a classifier with clean error smaller than the adversarial bayes error within ball B_{\\gamma}(x), which is actually meaningless for any \\gamma since we know that the clean bayes error must be less than the adversarial bayes error and the sample-efficient PAC learners for clean bayes classifier is known.\nIn line 298 - 301, they want to set gamma to be above some threshold. Using their parameters of \\zeta=1, c =1000 and d=1000 in the provided example, the gamma is required to be larger than 1. It is hard to believe that such a large gamma is meaningful in terms of the tolerance of perbutation size.\nOn the other hand, they do not show negative results like \"some tolerance is necessary otherwise adversarial robustness is not possible\", which further limits the significance.\nTheir sample complexity such as that in Theorem 10 is independent of the actual perturbation size r for adversarial robustness. Their proposed algorithm does not train on the worst case perturbed samples. Instead, the algorithm only trains on the randomly perturbed samples, which I think is not useful for adversarial robustness. These facts suggest that such a tolerance framework seems not reliable.\nQuestions: See the weaknesses.\nLimitations: The discussion was adequate.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper introduces an algorithm called \u201ctolerant perturb and smooth\u201d and analyzes it with the lens of tolerant PAC learning. The analysis applies to the robustly realizable setting. This analysis is able to tighter sample complexity bounds than previous work.\nStrengths And Weaknesses: Pros:\n    - I don\u2019t have the expertise to check the proofs, but I think the proofs in the paper are non-trivial and are likely to be correct\n\nCons:\n    - I\u2019m fairly confident that the algorithm TPAS algorithm does not work at all. I implemented the algorithm for linear models on MNIST and it got 5% adversarial test accuracy. That\u2019s worse than random guessing! I didn\u2019t even implement the real adversarial example algorithm that\u2019s aware of the random smoothing, I just generated adversarial examples off a single instantiation of the model on clean examples, so presumably the true adversarial error rate is even worse. Most of what I say in the review is low confidence but I am confident that the algorithm simply does not work.\n    - Similar algorithms that do work, as correctly discussed in the related work section, do things like train on more than one noisy sample per example, and use different aggregation metrics, rather than just the simple mean.\n    - To be clear, I\u2019m not saying that the PAC analysis in the paper is wrong, or that the paper over claims performance anywhere. It\u2019s possible to have low sample complexity by converging rapidly (as a function of dataset size) to very bad performance. The analysis in the paper is also restricted to the robustly realizable setting, meaning the final performance should be good, but this also restricts the applicability of the work significantly. For example, it means the paper is not actually applicable to my linear MNIST experiment.\n    - It\u2019s unclear to me whether there is any interesting data distribution (ImageNet etc) which is known to have a model class that satisfies robust realizability. For MNIST and small max norm balls, robust realizability may be possible, though it\u2019s not totally clear that the norm ball convolved with the true data distribution for one class does not overlap with the norm ball convolved with the true data distribution of another class. Certainly the norm balls centered on the finite MNIST test sets don\u2019t overlap, for the size of norm balls commonly used in the literature. Small convolutional neural networks are able to memorize the (adversarial) test set, so maybe these satisfy robust realizability.\n    - I also trained a small CNN using TPAS and it got ~1% accuracy against adversarial examples. Once again, this was with a non-adaptive attacker (not aware of the test time noise smoothing).\n        - I\u2019m assuming this result is still compatible with the claims in the paper, but I haven\u2019t spent any time trying to work out how so.\n    - Overall, I argue for rejection because I\u2019m concerned that as presented, the paper would be misinterpreted as arguing that TPAS is an effective defense against adversarial examples. The adversarial example topic has repeatedly proved to be prone to false memes spreading rapidly, becoming ingrained, and requiring people working on the topic to waste a lot of time and effort arguing against misconceptions. This could potentially be addressed by substantially revising the paper to be extremely up front about the limitations of TPAS and explaining the interpretation of the PAC theory in a way that makes it clear that the PAC theory does not imply that TPAS would result in good performance or even better than chance performance on, say an ImageNet benchmark. Another way of stating this objection is that, while the paper does not over claim, I feel like it omits too much discussion of (very significant) limitations.\n    - I have a second, weaker reason for arguing for rejection, which is simply that NeurIPS is a selective venue, publishing particularly interesting results rather than merely correct results. Due to the poor performance of the TPAS algorithm, I argue that theoretical analysis of the algorithm is not interesting enough to be ranked high enough for NeurIPS acceptance, regardless of the correctness of that analysis.\n\nComments on the dimensions:\n\nI don't know enough about PAC theory to assess originality or quality well.\nI argue that the work has poor clarity because it will appear to many readers to endorse TPAS as a defense against adversarial examples, when in fact I think it technically does not claim that this method will achieve good performance.\nI argue that the work has low significance because the algorithm analyzed does not work\n\nOne sentence I do think is mistaken: I think this sentence should be revised: \u201cThese works provide learning algorithms that guarantee low generalization error in the presence of adversarial perturbations in various settings.\u201d Unless I\u2019m mistaken, these algorithms guarantee that the generalization error is nearly optimal within the hypothesis space, but the optimal generalization error within the hypothesis space for many standard hypothesis spaces (like linear models, or some neural network) could be worse than random guessing.\nQuestions: Is there an argument that this work has higher significance than I've thought, despite the algorithm itself not working well? For example, is it a step on a path to performing an analysis of one of the methods from the related work section that works well?\nLimitations: My main objection to this paper is that I think it does not make the limitations clear enough to an audience that is interested in adversarial examples but not expert in PAC learning theory. I'm concerned that the paper comes across as proving that TPAS \"works\" as a defense when that's not the case and I think that's not technically what the paper is claiming.\nOne other limitation I didn't discuss above is Algorithm 1 uses an analytical expectation over x\u2019, rather than a finite number of samples, so the algorithm cannot be implemented in practice for most interesting models. I see that this is discussed at line 135 but I think the discussion should be more prominent, I think the problem is worse than being \u201cpotentially expensive\u201d for many models such as neural networks.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper introduce adversarial robust learning based on tolerance (i.e., training with larger random perturbation), estimator smoothing and sample compression. It present a rigorous sample complexity analysis. This paper focuses solely on theoretical analysis, and doesn't provide any concrete algorithm or simulation result.\nStrengths And Weaknesses: \nStrength: the results are mathematically sound.\nWeakness: despite the rigorous mathematical derivation, I am not sure how the presented PAC analysis result helps the community. One can directly apply the sample complexity analysis on the adversarial loss (say via Rademacher complexity). Does the presented result provide more insights or a better rate?\nWeakness: the paper doesn't actually provide an executable algorithm, but only an existence results, i.e., the existence of measure mu, the existence of sample compression scheme. Whether the rate results pair with a computational feasible algorithm is unclear, and there is no simulation to demonstrate empirical performance/comparison.\n4 Weakness: in conclusion, the paper neither provide a theoretical information limit result, nor an executable adversarial training algorithm.\nQuestions: \nHow realistic is the assumption of that \"P is V-robustly realizable\"? what happens if we let gamma go to infinity?\nProperty 1, the equation should be the expectation of an indicator function.\nTheorem 10 implicitly requires A_H to be an optimal PAC learning, which is not clearly mentioned.\nLimitations: N.A.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 3 good\nContribution: 2 fair\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: Setting and contributions:\nThe authors suggest a new realistic setting of adversarially robust PAC learning (to test time attacks) in metric spaces, \nsuch that the learner is tested at inference time on a slightly bigger perturbation set that is controlled by a parameter (gamma>0) for his choice. We refer to it as the tolerance parameter.\nObviously, by choosing a smaller gamma, the perturbation set at test time is getting closer to the one on training time, which is a harder benchmark. As a result, there is a trade-off between sample complexity and competing with a better benchmark. \nThe main results are two algorithms. \nThe first one is in the robust realizable setting, with sample complexity that depends exponentially on the metric space dimension (doubling dimension) and linearly in the VC dimension. The algorithm is simple and efficient.\nThe second algorithm, for the agnostic setting, incorporates the idea of the first one (perturb and smooth) with a sample compression scheme argument, suitable for the model with tolerance. The sample complexity is improved exponentially (linear in the doubling dimension), due to the strong generalization guarantees of sample compression.\nStrengths And Weaknesses: This theoretical setting is natural, and well-motivated by empirical work on adversarial examples.\nThe results are satisfying, specifically exploiting the metric space assumption for removing the dual VC that pops up in the case of general perturbation sets.\nI find the techniques simple and elegant.\nOverall, I think that it is a nice idea for studying robustness.\nQuestions: -What is the support of the distribution? Is it the clean examples, and for sampling from a perturbation set you first sample from a clean example?\nMore specifically, is it defined similarly to the previous papers on theoretical robust learning?\n-Can you please give a short explanation of how you avoid the dual VC in Lemma 14? I know why it pops up in the case of arbitrary perturbation sets.\nI read the proof, but not sure about the answer.\nI would be happy to figure it out and recommend the paper for acceptance.\nLimitations:\nEthics Flag: No\nEthics Review Area: I don\u2019t know\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The paper studies the PAC learnability of adversarial robustness in the tolerant setting. The paper reveals a learnability result showing that VC hypothesis sets are tolerantly PAC learnable in the realizable case using a ``perturb-and-smooth'\u2019 algorithm. As compared to previous non-tolerant results, their sample complexity has an exponential improvement on the dependence of VC dimension. The paper also reveals a learnability result in the agnostic setting through sample compression.",
                "Strengths And Weaknesses": "Strengths:\n\nWell-written assumptions and theorems.\nNew tolerant framework is considered.\n\nWeaknesses:\nThe significance is limited. The major issue is that their tolerance framework is not justified.\nOn the one hand, they do not specify how to choose a reasonable reference perturbation type V(x) given an actual perturbation type U(x) in definition 4. More precisely, the choice of tolerance parameter \\gamma in line 206 is unclear. I think this is very crucial and necessary in this framework. Consider the case where V(x)=0 and U(x) = B_{\\gamma}(x). Then the inequality between line 195 and 196 tells that the algorithm can find a classifier with clean error smaller than the adversarial bayes error within ball B_{\\gamma}(x), which is actually meaningless for any \\gamma since we know that the clean bayes error must be less than the adversarial bayes error and the sample-efficient PAC learners for clean bayes classifier is known.\nIn line 298 - 301, they want to set gamma to be above some threshold. Using their parameters of \\zeta=1, c =1000 and d=1000 in the provided example, the gamma is required to be larger than 1. It is hard to believe that such a large gamma is meaningful in terms of the tolerance of perbutation size.\nOn the other hand, they do not show negative results like \"some tolerance is necessary otherwise adversarial robustness is not possible\", which further limits the significance.\nTheir sample complexity such as that in Theorem 10 is independent of the actual perturbation size r for adversarial robustness. Their proposed algorithm does not train on the worst case perturbed samples. Instead, the algorithm only trains on the randomly perturbed samples, which I think is not useful for adversarial robustness. These facts suggest that such a tolerance framework seems not reliable.",
                "Questions": "See the weaknesses.",
                "Limitations": "The discussion was adequate.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper introduces an algorithm called \u201ctolerant perturb and smooth\u201d and analyzes it with the lens of tolerant PAC learning. The analysis applies to the robustly realizable setting. This analysis is able to tighter sample complexity bounds than previous work.",
                "Strengths And Weaknesses": "Pros:\n    - I don\u2019t have the expertise to check the proofs, but I think the proofs in the paper are non-trivial and are likely to be correct\n\nCons:\n    - I\u2019m fairly confident that the algorithm TPAS algorithm does not work at all. I implemented the algorithm for linear models on MNIST and it got 5% adversarial test accuracy. That\u2019s worse than random guessing! I didn\u2019t even implement the real adversarial example algorithm that\u2019s aware of the random smoothing, I just generated adversarial examples off a single instantiation of the model on clean examples, so presumably the true adversarial error rate is even worse. Most of what I say in the review is low confidence but I am confident that the algorithm simply does not work.\n    - Similar algorithms that do work, as correctly discussed in the related work section, do things like train on more than one noisy sample per example, and use different aggregation metrics, rather than just the simple mean.\n    - To be clear, I\u2019m not saying that the PAC analysis in the paper is wrong, or that the paper over claims performance anywhere. It\u2019s possible to have low sample complexity by converging rapidly (as a function of dataset size) to very bad performance. The analysis in the paper is also restricted to the robustly realizable setting, meaning the final performance should be good, but this also restricts the applicability of the work significantly. For example, it means the paper is not actually applicable to my linear MNIST experiment.\n    - It\u2019s unclear to me whether there is any interesting data distribution (ImageNet etc) which is known to have a model class that satisfies robust realizability. For MNIST and small max norm balls, robust realizability may be possible, though it\u2019s not totally clear that the norm ball convolved with the true data distribution for one class does not overlap with the norm ball convolved with the true data distribution of another class. Certainly the norm balls centered on the finite MNIST test sets don\u2019t overlap, for the size of norm balls commonly used in the literature. Small convolutional neural networks are able to memorize the (adversarial) test set, so maybe these satisfy robust realizability.\n    - I also trained a small CNN using TPAS and it got ~1% accuracy against adversarial examples. Once again, this was with a non-adaptive attacker (not aware of the test time noise smoothing).\n        - I\u2019m assuming this result is still compatible with the claims in the paper, but I haven\u2019t spent any time trying to work out how so.\n    - Overall, I argue for rejection because I\u2019m concerned that as presented, the paper would be misinterpreted as arguing that TPAS is an effective defense against adversarial examples. The adversarial example topic has repeatedly proved to be prone to false memes spreading rapidly, becoming ingrained, and requiring people working on the topic to waste a lot of time and effort arguing against misconceptions. This could potentially be addressed by substantially revising the paper to be extremely up front about the limitations of TPAS and explaining the interpretation of the PAC theory in a way that makes it clear that the PAC theory does not imply that TPAS would result in good performance or even better than chance performance on, say an ImageNet benchmark. Another way of stating this objection is that, while the paper does not over claim, I feel like it omits too much discussion of (very significant) limitations.\n    - I have a second, weaker reason for arguing for rejection, which is simply that NeurIPS is a selective venue, publishing particularly interesting results rather than merely correct results. Due to the poor performance of the TPAS algorithm, I argue that theoretical analysis of the algorithm is not interesting enough to be ranked high enough for NeurIPS acceptance, regardless of the correctness of that analysis.\n\nComments on the dimensions:\n\nI don't know enough about PAC theory to assess originality or quality well.\nI argue that the work has poor clarity because it will appear to many readers to endorse TPAS as a defense against adversarial examples, when in fact I think it technically does not claim that this method will achieve good performance.\nI argue that the work has low significance because the algorithm analyzed does not work\n\nOne sentence I do think is mistaken: I think this sentence should be revised: \u201cThese works provide learning algorithms that guarantee low generalization error in the presence of adversarial perturbations in various settings.\u201d Unless I\u2019m mistaken, these algorithms guarantee that the generalization error is nearly optimal within the hypothesis space, but the optimal generalization error within the hypothesis space for many standard hypothesis spaces (like linear models, or some neural network) could be worse than random guessing.",
                "Questions": "Is there an argument that this work has higher significance than I've thought, despite the algorithm itself not working well? For example, is it a step on a path to performing an analysis of one of the methods from the related work section that works well?",
                "Limitations": "My main objection to this paper is that I think it does not make the limitations clear enough to an audience that is interested in adversarial examples but not expert in PAC learning theory. I'm concerned that the paper comes across as proving that TPAS \"works\" as a defense when that's not the case and I think that's not technically what the paper is claiming.\nOne other limitation I didn't discuss above is Algorithm 1 uses an analytical expectation over x\u2019, rather than a finite number of samples, so the algorithm cannot be implemented in practice for most interesting models. I see that this is discussed at line 135 but I think the discussion should be more prominent, I think the problem is worse than being \u201cpotentially expensive\u201d for many models such as neural networks.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper introduce adversarial robust learning based on tolerance (i.e., training with larger random perturbation), estimator smoothing and sample compression. It present a rigorous sample complexity analysis. This paper focuses solely on theoretical analysis, and doesn't provide any concrete algorithm or simulation result.",
                "Strengths And Weaknesses": "Strength: the results are mathematically sound.\nWeakness: despite the rigorous mathematical derivation, I am not sure how the presented PAC analysis result helps the community. One can directly apply the sample complexity analysis on the adversarial loss (say via Rademacher complexity). Does the presented result provide more insights or a better rate?\nWeakness: the paper doesn't actually provide an executable algorithm, but only an existence results, i.e., the existence of measure mu, the existence of sample compression scheme. Whether the rate results pair with a computational feasible algorithm is unclear, and there is no simulation to demonstrate empirical performance/comparison.\n4 Weakness: in conclusion, the paper neither provide a theoretical information limit result, nor an executable adversarial training algorithm.",
                "Questions": "How realistic is the assumption of that \"P is V-robustly realizable\"? what happens if we let gamma go to infinity?\nProperty 1, the equation should be the expectation of an indicator function.\nTheorem 10 implicitly requires A_H to be an optimal PAC learning, which is not clearly mentioned.",
                "Limitations": "N.A.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "Setting and contributions:\nThe authors suggest a new realistic setting of adversarially robust PAC learning (to test time attacks) in metric spaces, \nsuch that the learner is tested at inference time on a slightly bigger perturbation set that is controlled by a parameter (gamma>0) for his choice. We refer to it as the tolerance parameter.\nObviously, by choosing a smaller gamma, the perturbation set at test time is getting closer to the one on training time, which is a harder benchmark. As a result, there is a trade-off between sample complexity and competing with a better benchmark. \nThe main results are two algorithms. \nThe first one is in the robust realizable setting, with sample complexity that depends exponentially on the metric space dimension (doubling dimension) and linearly in the VC dimension. The algorithm is simple and efficient.\nThe second algorithm, for the agnostic setting, incorporates the idea of the first one (perturb and smooth) with a sample compression scheme argument, suitable for the model with tolerance. The sample complexity is improved exponentially (linear in the doubling dimension), due to the strong generalization guarantees of sample compression.",
                "Strengths And Weaknesses": "This theoretical setting is natural, and well-motivated by empirical work on adversarial examples.\nThe results are satisfying, specifically exploiting the metric space assumption for removing the dual VC that pops up in the case of general perturbation sets.\nI find the techniques simple and elegant.\nOverall, I think that it is a nice idea for studying robustness.",
                "Questions": "-What is the support of the distribution? Is it the clean examples, and for sampling from a perturbation set you first sample from a clean example?\nMore specifically, is it defined similarly to the previous papers on theoretical robust learning?\n-Can you please give a short explanation of how you avoid the dual VC in Lemma 14? I know why it pops up in the case of arbitrary perturbation sets.\nI read the proof, but not sure about the answer.\nI would be happy to figure it out and recommend the paper for acceptance.",
                "Limitations": "",
                "Ethics Flag": "No",
                "Ethics Review Area": "I don\u2019t know",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "soundness_avg": 3.0,
        "presentation_avg": 3.0,
        "contribution_avg": 2.5,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is clear that there are some concerns and limitations with the paper. Reviewer 1 raises valid points about the justification of the tolerance framework and the choice of parameters. Reviewer 2 expresses concerns about the effectiveness of the proposed algorithm and suggests that the paper does not make the limitations clear enough. Reviewer 3 questions the significance of the presented results and the lack of an executable algorithm. Reviewer 4, on the other hand, finds the theoretical setting natural and well-motivated and appreciates the simplicity and elegance of the techniques.\n\nConsidering these reviews, it is evident that there are some weaknesses and limitations in the paper. However, the paper also presents rigorous mathematical derivations and provides a new realistic setting for adversarial robust learning. The results are satisfying and exploit the metric space assumption effectively. The techniques used are simple and elegant.\n\nTaking all of this into account, I believe that the paper makes a valuable contribution to the field and has the potential for high impact. While there are concerns and limitations, the strengths of the paper outweigh them. Therefore, I recommend accepting the paper."
    },
    "Faster_Reinforcement_Learning_with_Value_Target_Lower_Bounding": {
        "link": "https://openreview.net//forum?id=30bPCDjdxPU",
        "pub_url": "https://openreview.net/forum?id=30bPCDjdxPU",
        "pdf_link": "https://openreview.net//pdf?id=30bPCDjdxPU",
        "paper_id": "30bPCDjdxPU",
        "title": "Faster_Reinforcement_Learning_with_Value_Target_Lower_Bounding",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nAfter reading the reviews and the author feedback, I lean towards rejection. The paper is not ready for publication for the following reasons:\n\nReviewers found that there is a lack of comparisons to other baselines and not enough discussion on the difference between lower and upper bounding.\n\nReviewers found that the proposed algorithm has a limited scope (deterministic environments) and would like to know more about how to extend it to more general setting.\n\n\nHowever, the clarity and the simplicity of the approach have been appreciated by the reviewers. Therefore, we encourage the authors to improve their paper by answering reviewers concerns and resubmit.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper proposes value target lower bounding to improve the Bellman value target during value function learning. The proposed method computes and utilizes a lower bound for the value target during Bellman backup, and the resulting lower-bounded Bellman operator is claimed to converge to the same optimal value as using the vanilla Bellman operator in the tabular case. Additionally, the paper presents several ways of estimating the lower bound function in practice, such as using the episodic return in episodic tasks and n-step bootstrapped return in non-episodic tasks, and shows the effectiveness of value target lower bounding on several RL environments.\nStrengths And Weaknesses: Strengths:\n\nThe related work is well cited and discussed in the paper, and it is clear how this work differs from previous contributions. \n\nThe proposed method is simple, reproducible, and compatible with most state-of-the-art RL algorithms.\n\n\nWeaknesses:\n\nThere are several technical concerns in the paper. Specifically, \n\nI believe the main theoretical result, Theorem 2.3, does not hold if the lower bound function f is fixed (or static). In the proof, for any s, where f(s)\u2265v\u2217(s) and f(s)\u2265B(v)(s), we have\n  |Bf(v)(s)\u2013v\u2217(s)|=|max(B(v)(s),f(s))\u2013v\u2217(s)|=|f(s)\u2013v\u2217(s)|=f(s)\u2013v\u2217(s)=Constant\n  So, the distance to the optimal value would not shrink under the new lower-bounded Bellman operator. If f is updated together with the value function during learning, please do make this clear and clearly show how f is updated together with v in the main paper. Based on the current presentation, Theorem 2.3 does not hold. \n\nResults from value iteration (VI) do not directly generalize to RL settings where the transition dynamics and the reward function are unknown to the RL agent. This leads to a fundamental problem in RL that does not exist in VI, exploration vs. exploitation. However, the paper did not mention or address/discuss the exploration problem when transitioning from VI to RL, and thus the proposed method is not well justified in the RL setting.              \n\nIn general, the episodic return (or Monte Carlo estimate of the return) is not guaranteed to be a lower bound of the optimal value (or the expected return following an optimal policy). Although the authors mentioned this in Section 6 (Related Works) as the limitation of their work, it is still concerning to me in terms of the soundness and the algorithmic design of the proposed method.\n\n\n\nThe clarity of the paper could be further improved, and the paper needs to be better organized in my opinion. I encourage the authors to move key results and plots to the main paper. Putting all experimental figures in the appendix would jeopardize the readability of the paper.\n\n\nOverall, the paper feels more like a work in progress to me, and certain technical details may need a bit rework and the paper could be better organized. Unfortunately, I don\u2019t think the current version can be accepted and vote for rejection.\nQuestions: Questions & Suggestions:\n\n[Technical Part]\n\n\n1.a. Please check Theorem 2.3. If f is updated during training, please include the update rule/equation for f in the main paper and in Algorithm 1.          \n\n1.b. Value iteration (VI) results do not directly generalize to RL settings and are not sufficient to rigorously justify performance in RL in my opinion. The authors may refer to Rmax [1] or randomized value function [2] for examples of rigorous analysis in the RL setting. \n\n1.c. Exploration is crucial for efficient/faster RL. In the example of Section 4.3, it would be more interesting to discuss for instance how value target lower bounding may help the agent reach the target state faster (with fewer number of episodes of training). Propagating the value back is a less interesting problem once the target state has been reached.\n\n\n\n[Clarity]\n\n\n2.a. In the actual implementation, is the lower bound function f(s) fixed? or being constantly updated? It seems that the observed episodic return is written into the buffer and read out during training as the lower bound. So, f(s) is updated by the newly-observed episodic return? Please try to clarify this in the paper revision.    \n\n2.b. Is a larger value always a better Bellman target? Breakout in Figure 2 and 3 could be a good counter-example. In Figure 3, lb\u00ad-DR on Breakout shows consistently 25-30% larger value targets than the baseline, which is also the highest percentage among all the 20 environments. However, the performance of lb-DR is much worse than the baseline (and I believe Breakout is a deterministic environment where the proposed lower-bounding should apply based on the claims in the paper). Further investigation is needed to better understand when lower bounding the target is helpful.\n\n\n[1] Brafman, Ronen I., and Moshe Tennenholtz. \"R-max-a general polynomial time algorithm for near-optimal reinforcement learning.\" Journal of Machine Learning Research 3.Oct (2002): 213-231.\n[2] Osband, Ian, et al. \"Deep Exploration via Randomized Value Functions.\" J. Mach. Learn. Res. 20.124 (2019): 1-62.\nLimitations: The authors have mentioned the limitation of their work in Section 6, and I would encourage the authors to discuss a bit more on scenarios where the proposed lower-bounding method may fail, e.g., why the performance is poor on Breakout? The potential negative societal impact has not been discussed in the paper. As an illustrative example, what if the algorithm was used by a malicious user to build a robot? Targeting tasks with (sparse) rewards that lead to some harmful behaviors for a society? I believe such kind of scenario could be discussed. In addition, what can and should be done to prevent it from happening?\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 2 fair\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper proposes value target lower bounding, where a function lower bounds the maximum achievable value is used as the target value.  Such a function admits the same convergence with the original Bellman operator but converges faster. The proposed value target lower bounding is claimed to be general and can be combined with any off-policy RL algorithms. The experiments verify this on SAC and DDPG.\nStrengths And Weaknesses: Strengths\n\nThe proposed method appears to be simple and effective empirically.  \nThe proposed method is evaluated in several configurations. \nThe writing is clear and easy to follow.\n\nWeaknesses\n\nThe main concern is why the proposed method is not evaluated on DQN. The proposed method is claimed to be general (\"The value target lower bounds can be readily plugged into RL algorithms that regress value to a target, e.g. DQN, DDPG or SAC.\"), but only evaluated on off-policy actor-critic style methods, like SAC and DDPG. Is this because it does not work well on DQN?\nCurrently, the empirical return (or n-step return) is taken as the lower bounding function, which limits the proposed method to only valid when the environment is deterministic. This is one limitation of this work. \nFaster learning is only shown empirically and intuitively. Are there theoretical results to support this claim?\nIt will be better to show the difference between the lower bounding and upper bounding (He et al., 2017).\n\noriginality and significance\n\nIt is not totally new to use the bounding of target value.\n\n\nAFTER REBUTTAL\nI thank the authors for the response. After reading the response and other reviews, I think the paper still has a few weaknesses/limitations: (1) limited to deterministic environments. It is better to show how to extend it to stochastic environments; (2) better to compare it with other methods, like upper bounding. \nNevertheless, I still enjoy seeing such a simple method works well empirically. So, I keep my score.\nQuestions: Refer to above\nLimitations: Limitations are discussed in Section 7.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper suggests that learning a lower bound of the value function can facilitate dynamic programming such enhance RL performance. The author(s) provided theoretical insights about the optimality of the value function learning with their lower bounding method. It was claimed the proposed methods showed effectiveness in a wide range of tasks.\nStrengths And Weaknesses: Strengths:\n\nThe proposed method seems simple but somehow effective.\nNovel theoretical insights about lowerbounding the value function.\nThe author(s) carefully explained the novelty of the proposed method in Sec.6.\n\nHowever, I could not evaluate the effectiveness of the proposed methods because all the empirical results are in the appendix. Meanwhile, as I have shortly scanned the appendix, the are also other things to notice, which I will details below.\nI think the manuscript in its current form is not acceptable as a NeurIPS conference paper. Because the important methods (how to implement in deep RL) and experimental results are all in the appendix, as well as some other problems exist. If the authors(s) cannot include all the essential methods and results in a conference paper, I recommand to submit to a journal.\nWeaknesses:\n\nAs I said, the paper should be self-contained with essential practical algorithms and experimental results in its main texts.\nEstimating value function has always been an vital problem in deep RL. Although the paper discussed related work about lower bounding the value function, there are other studies pointed out that Q-learning like algorithms, e.g., SAC, tend to over-estimate the value targets , which is bad and should be regularized. For example, [1][2][3] used different methods to control the over-estimating bias of SAC and observed very large performance gain. The paper should discuss the relation to them and conduct comparison to at least one of them.\n\nminor issue I found:\nline 140, \"action value\" --> \"state-action value\"\n[1] Kuznetsov, Arsenii, et al. \"Controlling overestimation bias with truncated mixture of continuous distributional quantile critics.\" International Conference on Machine Learning. PMLR, 2020.\n[2] Chen, Xinyue, et al. \"Randomized Ensembled Double Q-Learning: Learning Fast Without a Model.\" International Conference on Learning Representations. 2021.\n[3] Hiraoka, Takuya, et al. \"Dropout Q-Functions for Doubly Efficient Reinforcement Learning.\" International Conference on Learning Representations. 2022.\nQuestions: How to implement your method in deep RL? Because Algorithm 1 is for tabular case.\nLimitations: See Weaknesses.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 1 poor\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper proposes a form of target value lower bounding, which induces a new Bellman operator. The authors show the operator is a contraction, and propose several lower bounds. Extensive experiments are conducted (provided in the supplementary material) to show the performance of the proposed approach.\nStrengths And Weaknesses: This paper is written clearly and the overall concept is interesting. There are several aspects of this paper that are problematic. \nFirst, theoretically, the paper is not strong. Theorem 2.3 does not present any interesting new theory, and it is unclear why this result is important. The authors do not show or prove any benefit of using the bounded Bellman operator. When would this operator be useful for cases that don't bound G\u221e? It would seem that due to over-optimism of the Bellman operator, G0 will usually maximize G\u00af. \nSecond, the examples for lower bounds in the paper require deterministic environments. The lower bounds themselves feel somewhat trivial. It is unclear why these lower bounds are good. \nFinally, the experiments do not show any significant improvement using the proposed approach. Also, the experiments themselves are shown only in the appendix, which should not be used to place major contributions. The authors chose to do this due to space constraints, which is not fair to other reviewed papers.\nStrengths:\n\nPaper is clearly written\nProposed Bellman operator may be having interesting characteristics to be researched\nAuthors conducted extensive experiments\n\nWeaknesses:\n\nLack of theory, and unsure about novelty\nSetting is limited. Examples require deterministic environments. Unsure why G\u00af is useful.\nExperiments don't show a clear benefit of approach. Also, experiments are only provided in appendix which does not need to be evaluated for review.\nQuestions: \nFor the proposed lower bounds - are the theoretical gaps between the deterministic and non-deterministic settings?\nWhen is G\u00af more beneficial than G\u221e\nWhy does Bf improve convergence?\nHow does Bf affect the overestimation problem?\nLimitations: The authors discuss limitations of their work. Particularly, deterministic requirements.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper proposes value target lower bounding to improve the Bellman value target during value function learning. The proposed method computes and utilizes a lower bound for the value target during Bellman backup, and the resulting lower-bounded Bellman operator is claimed to converge to the same optimal value as using the vanilla Bellman operator in the tabular case. Additionally, the paper presents several ways of estimating the lower bound function in practice, such as using the episodic return in episodic tasks and n-step bootstrapped return in non-episodic tasks, and shows the effectiveness of value target lower bounding on several RL environments.",
                "Strengths And Weaknesses": "Strengths:\n\nThe related work is well cited and discussed in the paper, and it is clear how this work differs from previous contributions. \n\nThe proposed method is simple, reproducible, and compatible with most state-of-the-art RL algorithms.\n\n\nWeaknesses:\n\nThere are several technical concerns in the paper. Specifically, \n\nI believe the main theoretical result, Theorem 2.3, does not hold if the lower bound function f is fixed (or static). In the proof, for any s, where f(s)\u2265v\u2217(s) and f(s)\u2265B(v)(s), we have\n  |Bf(v)(s)\u2013v\u2217(s)|=|max(B(v)(s),f(s))\u2013v\u2217(s)|=|f(s)\u2013v\u2217(s)|=f(s)\u2013v\u2217(s)=Constant\n  So, the distance to the optimal value would not shrink under the new lower-bounded Bellman operator. If f is updated together with the value function during learning, please do make this clear and clearly show how f is updated together with v in the main paper. Based on the current presentation, Theorem 2.3 does not hold. \n\nResults from value iteration (VI) do not directly generalize to RL settings where the transition dynamics and the reward function are unknown to the RL agent. This leads to a fundamental problem in RL that does not exist in VI, exploration vs. exploitation. However, the paper did not mention or address/discuss the exploration problem when transitioning from VI to RL, and thus the proposed method is not well justified in the RL setting.              \n\nIn general, the episodic return (or Monte Carlo estimate of the return) is not guaranteed to be a lower bound of the optimal value (or the expected return following an optimal policy). Although the authors mentioned this in Section 6 (Related Works) as the limitation of their work, it is still concerning to me in terms of the soundness and the algorithmic design of the proposed method.\n\n\n\nThe clarity of the paper could be further improved, and the paper needs to be better organized in my opinion. I encourage the authors to move key results and plots to the main paper. Putting all experimental figures in the appendix would jeopardize the readability of the paper.\n\n\nOverall, the paper feels more like a work in progress to me, and certain technical details may need a bit rework and the paper could be better organized. Unfortunately, I don\u2019t think the current version can be accepted and vote for rejection.",
                "Questions": "Questions & Suggestions:\n\n[Technical Part]\n\n\n1.a. Please check Theorem 2.3. If f is updated during training, please include the update rule/equation for f in the main paper and in Algorithm 1.          \n\n1.b. Value iteration (VI) results do not directly generalize to RL settings and are not sufficient to rigorously justify performance in RL in my opinion. The authors may refer to Rmax [1] or randomized value function [2] for examples of rigorous analysis in the RL setting. \n\n1.c. Exploration is crucial for efficient/faster RL. In the example of Section 4.3, it would be more interesting to discuss for instance how value target lower bounding may help the agent reach the target state faster (with fewer number of episodes of training). Propagating the value back is a less interesting problem once the target state has been reached.\n\n\n\n[Clarity]\n\n\n2.a. In the actual implementation, is the lower bound function f(s) fixed? or being constantly updated? It seems that the observed episodic return is written into the buffer and read out during training as the lower bound. So, f(s) is updated by the newly-observed episodic return? Please try to clarify this in the paper revision.    \n\n2.b. Is a larger value always a better Bellman target? Breakout in Figure 2 and 3 could be a good counter-example. In Figure 3, lb\u00ad-DR on Breakout shows consistently 25-30% larger value targets than the baseline, which is also the highest percentage among all the 20 environments. However, the performance of lb-DR is much worse than the baseline (and I believe Breakout is a deterministic environment where the proposed lower-bounding should apply based on the claims in the paper). Further investigation is needed to better understand when lower bounding the target is helpful.\n\n\n[1] Brafman, Ronen I., and Moshe Tennenholtz. \"R-max-a general polynomial time algorithm for near-optimal reinforcement learning.\" Journal of Machine Learning Research 3.Oct (2002): 213-231.\n[2] Osband, Ian, et al. \"Deep Exploration via Randomized Value Functions.\" J. Mach. Learn. Res. 20.124 (2019): 1-62.",
                "Limitations": "The authors have mentioned the limitation of their work in Section 6, and I would encourage the authors to discuss a bit more on scenarios where the proposed lower-bounding method may fail, e.g., why the performance is poor on Breakout? The potential negative societal impact has not been discussed in the paper. As an illustrative example, what if the algorithm was used by a malicious user to build a robot? Targeting tasks with (sparse) rewards that lead to some harmful behaviors for a society? I believe such kind of scenario could be discussed. In addition, what can and should be done to prevent it from happening?",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper proposes value target lower bounding, where a function lower bounds the maximum achievable value is used as the target value.  Such a function admits the same convergence with the original Bellman operator but converges faster. The proposed value target lower bounding is claimed to be general and can be combined with any off-policy RL algorithms. The experiments verify this on SAC and DDPG.",
                "Strengths And Weaknesses": "Strengths\n\nThe proposed method appears to be simple and effective empirically.  \nThe proposed method is evaluated in several configurations. \nThe writing is clear and easy to follow.\n\nWeaknesses\n\nThe main concern is why the proposed method is not evaluated on DQN. The proposed method is claimed to be general (\"The value target lower bounds can be readily plugged into RL algorithms that regress value to a target, e.g. DQN, DDPG or SAC.\"), but only evaluated on off-policy actor-critic style methods, like SAC and DDPG. Is this because it does not work well on DQN?\nCurrently, the empirical return (or n-step return) is taken as the lower bounding function, which limits the proposed method to only valid when the environment is deterministic. This is one limitation of this work. \nFaster learning is only shown empirically and intuitively. Are there theoretical results to support this claim?\nIt will be better to show the difference between the lower bounding and upper bounding (He et al., 2017).\n\noriginality and significance\n\nIt is not totally new to use the bounding of target value.\n\n\nAFTER REBUTTAL\nI thank the authors for the response. After reading the response and other reviews, I think the paper still has a few weaknesses/limitations: (1) limited to deterministic environments. It is better to show how to extend it to stochastic environments; (2) better to compare it with other methods, like upper bounding. \nNevertheless, I still enjoy seeing such a simple method works well empirically. So, I keep my score.",
                "Questions": "Refer to above",
                "Limitations": "Limitations are discussed in Section 7.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper suggests that learning a lower bound of the value function can facilitate dynamic programming such enhance RL performance. The author(s) provided theoretical insights about the optimality of the value function learning with their lower bounding method. It was claimed the proposed methods showed effectiveness in a wide range of tasks.",
                "Strengths And Weaknesses": "Strengths:\n\nThe proposed method seems simple but somehow effective.\nNovel theoretical insights about lowerbounding the value function.\nThe author(s) carefully explained the novelty of the proposed method in Sec.6.\n\nHowever, I could not evaluate the effectiveness of the proposed methods because all the empirical results are in the appendix. Meanwhile, as I have shortly scanned the appendix, the are also other things to notice, which I will details below.\nI think the manuscript in its current form is not acceptable as a NeurIPS conference paper. Because the important methods (how to implement in deep RL) and experimental results are all in the appendix, as well as some other problems exist. If the authors(s) cannot include all the essential methods and results in a conference paper, I recommand to submit to a journal.\nWeaknesses:\n\nAs I said, the paper should be self-contained with essential practical algorithms and experimental results in its main texts.\nEstimating value function has always been an vital problem in deep RL. Although the paper discussed related work about lower bounding the value function, there are other studies pointed out that Q-learning like algorithms, e.g., SAC, tend to over-estimate the value targets , which is bad and should be regularized. For example, [1][2][3] used different methods to control the over-estimating bias of SAC and observed very large performance gain. The paper should discuss the relation to them and conduct comparison to at least one of them.\n\nminor issue I found:\nline 140, \"action value\" --> \"state-action value\"\n[1] Kuznetsov, Arsenii, et al. \"Controlling overestimation bias with truncated mixture of continuous distributional quantile critics.\" International Conference on Machine Learning. PMLR, 2020.\n[2] Chen, Xinyue, et al. \"Randomized Ensembled Double Q-Learning: Learning Fast Without a Model.\" International Conference on Learning Representations. 2021.\n[3] Hiraoka, Takuya, et al. \"Dropout Q-Functions for Doubly Efficient Reinforcement Learning.\" International Conference on Learning Representations. 2022.",
                "Questions": "How to implement your method in deep RL? Because Algorithm 1 is for tabular case.",
                "Limitations": "See Weaknesses.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "1 poor",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposes a form of target value lower bounding, which induces a new Bellman operator. The authors show the operator is a contraction, and propose several lower bounds. Extensive experiments are conducted (provided in the supplementary material) to show the performance of the proposed approach.",
                "Strengths And Weaknesses": "This paper is written clearly and the overall concept is interesting. There are several aspects of this paper that are problematic. \nFirst, theoretically, the paper is not strong. Theorem 2.3 does not present any interesting new theory, and it is unclear why this result is important. The authors do not show or prove any benefit of using the bounded Bellman operator. When would this operator be useful for cases that don't bound G\u221e? It would seem that due to over-optimism of the Bellman operator, G0 will usually maximize G\u00af. \nSecond, the examples for lower bounds in the paper require deterministic environments. The lower bounds themselves feel somewhat trivial. It is unclear why these lower bounds are good. \nFinally, the experiments do not show any significant improvement using the proposed approach. Also, the experiments themselves are shown only in the appendix, which should not be used to place major contributions. The authors chose to do this due to space constraints, which is not fair to other reviewed papers.\nStrengths:\n\nPaper is clearly written\nProposed Bellman operator may be having interesting characteristics to be researched\nAuthors conducted extensive experiments\n\nWeaknesses:\n\nLack of theory, and unsure about novelty\nSetting is limited. Examples require deterministic environments. Unsure why G\u00af is useful.\nExperiments don't show a clear benefit of approach. Also, experiments are only provided in appendix which does not need to be evaluated for review.",
                "Questions": "For the proposed lower bounds - are the theoretical gaps between the deterministic and non-deterministic settings?\nWhen is G\u00af more beneficial than G\u221e\nWhy does Bf improve convergence?\nHow does Bf affect the overestimation problem?",
                "Limitations": "The authors discuss limitations of their work. Particularly, deterministic requirements.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "soundness_avg": 2.0,
        "presentation_avg": 2.25,
        "contribution_avg": 2.25,
        "ai_sum_meta": "Recommendation: Reject\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that there are several weaknesses and concerns with the paper. Reviewer 1 raises technical concerns about the main theoretical result not holding and the lack of justification for the proposed method in the RL setting. Reviewer 2 points out the limited evaluation and the lack of comparison with other methods. Reviewer 3 highlights the lack of essential methods and results in the main text and suggests submitting to a journal instead. Reviewer 4 questions the theoretical strength, the limited setting, and the lack of significant improvement shown in the experiments. Considering these concerns and weaknesses, I agree with the reviewers' assessments and recommend rejecting the paper."
    },
    "Securing_Secure_Aggregation:_Mitigating_Multi-Round_Privacy_Leakage_in_Federated_Learning": {
        "link": "https://openreview.net//forum?id=nVV6S2sb_UL",
        "pub_url": "https://openreview.net/forum?id=nVV6S2sb_UL",
        "pdf_link": "https://openreview.net//pdf?id=nVV6S2sb_UL",
        "paper_id": "nVV6S2sb_UL",
        "title": "Securing_Secure_Aggregation:_Mitigating_Multi-Round_Privacy_Leakage_in_Federated_Learning",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Less certain\nThe secure aggregation protocol is a basic building block in federated learning. It allows a central entity to learn the sum of vectors held by the clients, without being able to (noticeably) distinguish two different sets of vectors that lead to the same sum. This paper studies the question of how much privacy is leaked across multiple rounds of the secure aggregation protocol. It proposes a new \u201cmulti-round privacy\u201d notion which aims to quantify the privacy leakage across multiple rounds of the secure aggregation protocol. The paper shows that the commonly used random subsampling protocol would violate this notion of privacy after a number of rounds that is linear in the number of users. The paper gives another algorithm, Multi-RoundSecAgg, which has better privacy properties, according to the proposed notion.\nThere are several drawbacks of this paper, several pointed out by the reviewers:\n\nIt is well-known that federated learning without differential privacy (DP) is vulnerable to the leakage of user\u2019s sensitive information (e.g., inversion attacks), which this paper seeks to protect. E.g., from the aggregate vectors, one could directly read sensitive information pertaining to one user (e.g., if the individual vectors are sparse and have disjoint supports).\nThe argument provided by the authors in the rebuttal -- that they chose not to consider differential privacy since it hurts model accuracy -- is not satisfactory. In fact, the paper itself argues that even for the proposed multi round notion of privacy, for a more stringent privacy level to give the same utility, a larger number of rounds is needed until convergence. So even with the new notion, privacy does not come for free and has to be traded-off at least against efficiency (more precisely convergence speed).\nIt is also worth pointing out that in the case of DP, the multi-round leakage is already handled through composition theorems, and accounted for. See, e.g., the \u201cPractical and Private (Deep) Learning Without Sampling or Shuffling\u201d paper of Kairouz et al. (ICML 2019).\n\nAs pointed out by one of the reviewers, reconstructing an individual model after a number of rounds larger than the number of users is not realistic. Typical federated learning models are indeed trained for a number of rounds much smaller than the number of users. A detailed discussion of this limitation would be expected in the paper.\n\nThe claim that the worst-case is achieved when the local models do not change at all seems a bit hand-wavy to me. On a high level, it seems to ignore the correlation between the different models that would arise during the training process. Due to this correlation, it might be that all the users\u2019 local models converge to the first user\u2019s model. In this case, wouldn\u2019t that be worse than having the models not change at all? Formalizing this claim, and its proof, would be helpful.\n\nGiven that the paper proposes a new privacy notion, discussing the qualitative properties and limitations of this notion is expected. E.g., does this notion compose across multiple applications? How does this notion behave in the presence of side information?\n\n\nOverall, in its present form, and for the reasons listed above, the paper falls short of the acceptance bar at NeurIPS.",
        "reviews": [
            "Reviewer 1: \nSummary: The paper proposes a framework for sampling clients in each round of a Federated Learning training session. The proposed framework balances a notion of privacy (essentially a lower bound on number of sumands of any partial sum a server my reconstruct via linear combination of model updates retrieved throughout training), fairness gap (average gap in client participation across all rounds), and aggregation cardinality (average number of sumands in each round). The paper studies the relationship between these metrics, in relation to the convergence of the training. This is done by proposing new client sampling strategies, studying their properties, and comparing with naural baselines. The authors also provide experiments to support the analytical findings.\nStrengths And Weaknesses: \nI am unsure about the practical relevance of the assumptions regarding values of K and N.\nThere does not seem to exist a lot of literature in client selection in FL with the purpose of improving privacy with respect to the server. The framework of differential privacy seeems important in that discussion, but the submission does not discuss that.\nThe privacy guarantee is defined with respect to a particular time of reconstruction attack.\nThe technical results give a good intuition on how the different metrics interact, even with baseline client selection strategies, which might be useful to practitioners. However, the assumption that dropout probability is the same across all clients seems unrealistic (although hard to avoid).\nQuestions: \nI am unsure about the practical relevance of the assumptions regarding values of K and N. For example, See Table 1 in https://arxiv.org/pdf/1912.04977.pdf. This seems to suggest that in practice N is huge with respect to K (several orders of magnitude), and that the number of training rounds is also smaller than N. I am thinking: K in the 100s, N in the millions, and number of training rounds L in the thousands. With this in my opinion more relevant setting in mind, a given client will participate in no more than 2 sums. The results in appendix H, as refelected in the experiments section, seems to rely on N and L being of the same order. It be useful for the paper to state upfront some examples of values of N, K, L of relevance to the paper, and found in practice.\nThe privacy guarantee is defined with respect to a particular time of reconstruction attack. In fact the sort of differentiation attacks that you describe motivates differential privacy. Using DP, one could ensure that a particular sumand does not alter the sum too much. Of course, if a user participates in many rounds this guarantee will degrade quickly, but that goes back to the choice of N, K.\nHow does one implement your proposed mechanim at the scale of the above numbers (and the ones in the referenced paper)? Are there any challenges there? The experiments use small values of K and N.\nLimitations:\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 1 poor\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper explores the question of multi-round privacy leakage in federated learning with secure aggregation. To this end, the paper proposes a novel metric for multi-round privacy in FL. Existing FL secure aggregation protocols guarantee that the server can only learn the sum of N local models in any single round. The proposed multi-round privacy metric extends this guarantee to all training rounds. The paper motivates the need for multi-round privacy guarantees by demonstrating theoretically and experimentally that, under the assumption of partial user participation, existing secure aggregation protocols are vulnerable to attacks that aggregate models across multiple training rounds. To address this vulnerability, the paper proposes Multi-RoundSecAgg, a novel algorithm that provides a multi-round privacy guarantee. Theoretical analyses of the multi-round privacy, aggregation fairness gap and average aggregation cardinality guarantees of the proposed method are presented, as well as a convergence analysis. Finally, the proposed method is validated experimentally over range of FL settings and image datasets.\nStrengths And Weaknesses: Strengths\nA. The writing and figures are very clear.\nB. Strong motivation. The paper demonstrates that, under the assumption of partial user participation, existing secure aggregation protocols are vulnerable to attacks that aggregate models across multiple training rounds. This is an important limitation of existing methods, which merits attention from the community.\nC. Strong novelty. The paper presents a novel multi-round attack on existing secure aggregation protocols. The paper proposes a novel metric for multi-round privacy in FL. The paper proposes a novel secure aggregation method that provides a multi-round privacy guarantee. The paper provides novel theoretical results for both existing secure aggregation methods and the proposed method. All of these are important contributions.\nD. Strong theoretical results. The paper provides the theoretical guarantees of the proposed Multi-RoundSecAgg method in terms of multi-round privacy, aggregation fairness gap and average aggregation cardinality. The paper also provides a convergence analysis of the proposed Multi-RoundSecAgg method. These results provide important insights about the proposed method and its functioning.\nE. Strong experimental results. Relevant baselines are compared against over a range of FL settings and datasets. Across all evaluations, the proposed method shows a better multi-round privacy guarantee, yet comparable test accuracy compared to the baselines.\nWeaknesses\nF. Experimental evaluations with real-world datasets and SOA model architectures would strengthen the paper. That said, this is not a major issue given the novelty of the work and breadth of theoretical results.\nG. Given the focus on reconstruction attacks, the paper is missing a discussion of differentially private federated learning as a potential solution to the multi-round privacy vulnerability.\nQuestions: H. Given that T=4 is not a very strong privacy guarantee and that for T=6 the convergence rate already starts to take a significant hit, I wonder whether you're not better off adding noise to the gradients as in DP-FedAvg to protect the local data. Did you consider this option?\nLimitations: The authors adequately address the limitations and potential negative societal impact of their work.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 4 excellent\nRating: 8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: Secure aggregation-based protocols can leak privacy over multiple training rounds in FL and do not provide long-term privacy guarantees. The partial user selection enables the reconstruction of the client's models. The authors propose a user-selection strategy that will provide long-term privacy guarantees and provide theoretical and convergence analysis. New metrics are proposed to capture the privacy guarantees.\nStrengths And Weaknesses: Strengths:\n\nThe paper is well-written and clear.\nMulti-RoundSecAgg is a novel scheme that provides privacy in FL in long term. It also ensures a fair selection of clients and shows tradeoffs between convergence and privacy.\nProposed metrics are interesting, they allow for comparison between different user selection schemes in terms of privacy and that all clients participate in an equal number of rounds.\nComparison with baseline experiments demonstrates the effectiveness of the metrics proposed.\nThe remarks and assumptions provided are a plus.\n\nWeaknesses:\n\nThe privacy leakage of the aggregated models over multiple rounds is not addressed. This may be considered as future work.\nApplicability to cross-device only is missing.\nQuestions: 1- Will multi-secagg work for cross-silo setup with partial user selection?\n2- Will experiments with N=K show any deviation?\nminor edits:\nLine 113: \"their.\"\nLine 41-42: Refer/Cite the basis\nLine 224: \"number of selected at each\"\nLimitations: Limitations are discussed in form of assumptions and remarks.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: The paper concentrates on privacy-leakage in federated learning over multiple rounds. The authors note that secure aggregation protocols only have guarantees for a single aggregation round, whereas in federated learning the model is trained iteratively.  The paper proposes to measure and mitigate this privacy leakage over iterations. The main idea in the mitigation is to choose fixed groups of parties for model updates, so that an adversary can only ever see a contribution from the fixed group. This makes identifying any single individual party's contribution based on differences between iterations harder, since the individual contribution is always mixed in with the other group members. The proposed method essentially involves creating fixed subsets of users who are always chosen together for model updates. Another consideration is fairness in the sens of each party contributing an equal number of updates: the authors also propose a method by which all parties are chosen for updates an equal number of times on expectation. The paper then analyses convergence properties of the proposed method, and tests it empirically with several standard network structures and datasets.\nStrengths And Weaknesses: Update after discussions\nAfter the rebuttal and the discussions, I raise my score to recommend acceptance. I trust that the authors will improve the paper based on the discussions.\nStrengths\n\nThe idea of having some secure aggregation-type guarantees over several iterations seems like a fine one.\nThe theoretical results backing up the method are comforting, e.g., in the sense that the proposed method can be shown to converge under some fairly standard assumptions.\n\nWeaknesses\n\nThe most glaring issue with the paper is that it completely omits discussing or even mentioning differential privacy (DP) and related definitions, which have been the standard privacy definition in machine learning for years, and that have also been widely used with federated learning (see e.g. Kairouz et al. 2019 for a quick overview of the basic idea in the context of federated learning, Dwork & Roth 2014 for a basic introduction to DP). Instead, the privacy discussed in the current paper is more related to secure computation, where the formal guarantees are on revealing only the end result of a computation. Calling such definitions privacy preserving is problematic for various reasons. One major issue is that the end result might well give out the input data in the clear without having any problems in satisfying this kind of definition of privacy-preserving (e.g. by choosing local loss functions s.t. the optimal value is an actual data point for a single client and 0 for everyone else would give out the single data point while still satisfying this kind of privacy guarantees). \nThe guarantees are also brittle in the sense that any side information might lead to a catastrophic privacy breach, where one or more input data points are suddenly revealed (e.g. consider what happens to others if one of the fixed group members gives out it's updates, or an adversary gains information on such values from other sources).\nAs an immediate fix, I would suggest including some discussion on the privacy-definition that also considers DP, clarifying the claims that this is the first paper that considers privacy-leakage in federated learning over iterations (e.g. lines 51, 84-88), and changing the emphasis to be less on general privacy-preservation and more specifically on what this method tries to protect. More interesting, although also more work-intensive and hence probably out of the question for now, would be to try and combine the current papers' results with DP and show that the proposed method does indeed enable better privacy by limiting the amount of information an adversary can gain.\nRelated to the previous point: I have a hard time understanding what are the consequences of providing privacy in the sense used in this paper.\n\nReferences\nDwork & Roth 2014: The algorithmic foundations of differential privacy.\nKairouz et al. 2019: Advances and open problems in federated learning.\nQuestions: \nIn the experiments, is there some reason to stop training when you do? Would e.g. the partition baseline eventually reach ~ same performance, and the main issue is convergence speed, or is there some other reason why it would perform worse?\n\nIt seems that the proposed method assumes that the other parties in the same group are honest(?). Please mention the actual assumption as part of the the threat model.\n\nI think Remark 7 on lines 290-295 would make more sense as a separate theorem: this seems like an important property that should be stated more formally.\n\n\nMinor details:\nPlease add a table on the notation to Appendix: trying to follow the derivations can be frankly painful when one needs to hunt for the meaning of symbols all over the place. Fix typos on lines 113,224.\nLimitations: There is no discussion on the limitations of the proposed method, including in Section 7, which is pointed out as containing such discussion in the paper checklist.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The paper proposes a framework for sampling clients in each round of a Federated Learning training session. The proposed framework balances a notion of privacy (essentially a lower bound on number of sumands of any partial sum a server my reconstruct via linear combination of model updates retrieved throughout training), fairness gap (average gap in client participation across all rounds), and aggregation cardinality (average number of sumands in each round). The paper studies the relationship between these metrics, in relation to the convergence of the training. This is done by proposing new client sampling strategies, studying their properties, and comparing with naural baselines. The authors also provide experiments to support the analytical findings.",
                "Strengths And Weaknesses": "I am unsure about the practical relevance of the assumptions regarding values of K and N.\nThere does not seem to exist a lot of literature in client selection in FL with the purpose of improving privacy with respect to the server. The framework of differential privacy seeems important in that discussion, but the submission does not discuss that.\nThe privacy guarantee is defined with respect to a particular time of reconstruction attack.\nThe technical results give a good intuition on how the different metrics interact, even with baseline client selection strategies, which might be useful to practitioners. However, the assumption that dropout probability is the same across all clients seems unrealistic (although hard to avoid).",
                "Questions": "I am unsure about the practical relevance of the assumptions regarding values of K and N. For example, See Table 1 in https://arxiv.org/pdf/1912.04977.pdf. This seems to suggest that in practice N is huge with respect to K (several orders of magnitude), and that the number of training rounds is also smaller than N. I am thinking: K in the 100s, N in the millions, and number of training rounds L in the thousands. With this in my opinion more relevant setting in mind, a given client will participate in no more than 2 sums. The results in appendix H, as refelected in the experiments section, seems to rely on N and L being of the same order. It be useful for the paper to state upfront some examples of values of N, K, L of relevance to the paper, and found in practice.\nThe privacy guarantee is defined with respect to a particular time of reconstruction attack. In fact the sort of differentiation attacks that you describe motivates differential privacy. Using DP, one could ensure that a particular sumand does not alter the sum too much. Of course, if a user participates in many rounds this guarantee will degrade quickly, but that goes back to the choice of N, K.\nHow does one implement your proposed mechanim at the scale of the above numbers (and the ones in the referenced paper)? Are there any challenges there? The experiments use small values of K and N.",
                "Limitations": "",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "1 poor",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper explores the question of multi-round privacy leakage in federated learning with secure aggregation. To this end, the paper proposes a novel metric for multi-round privacy in FL. Existing FL secure aggregation protocols guarantee that the server can only learn the sum of N local models in any single round. The proposed multi-round privacy metric extends this guarantee to all training rounds. The paper motivates the need for multi-round privacy guarantees by demonstrating theoretically and experimentally that, under the assumption of partial user participation, existing secure aggregation protocols are vulnerable to attacks that aggregate models across multiple training rounds. To address this vulnerability, the paper proposes Multi-RoundSecAgg, a novel algorithm that provides a multi-round privacy guarantee. Theoretical analyses of the multi-round privacy, aggregation fairness gap and average aggregation cardinality guarantees of the proposed method are presented, as well as a convergence analysis. Finally, the proposed method is validated experimentally over range of FL settings and image datasets.",
                "Strengths And Weaknesses": "Strengths\nA. The writing and figures are very clear.\nB. Strong motivation. The paper demonstrates that, under the assumption of partial user participation, existing secure aggregation protocols are vulnerable to attacks that aggregate models across multiple training rounds. This is an important limitation of existing methods, which merits attention from the community.\nC. Strong novelty. The paper presents a novel multi-round attack on existing secure aggregation protocols. The paper proposes a novel metric for multi-round privacy in FL. The paper proposes a novel secure aggregation method that provides a multi-round privacy guarantee. The paper provides novel theoretical results for both existing secure aggregation methods and the proposed method. All of these are important contributions.\nD. Strong theoretical results. The paper provides the theoretical guarantees of the proposed Multi-RoundSecAgg method in terms of multi-round privacy, aggregation fairness gap and average aggregation cardinality. The paper also provides a convergence analysis of the proposed Multi-RoundSecAgg method. These results provide important insights about the proposed method and its functioning.\nE. Strong experimental results. Relevant baselines are compared against over a range of FL settings and datasets. Across all evaluations, the proposed method shows a better multi-round privacy guarantee, yet comparable test accuracy compared to the baselines.\nWeaknesses\nF. Experimental evaluations with real-world datasets and SOA model architectures would strengthen the paper. That said, this is not a major issue given the novelty of the work and breadth of theoretical results.\nG. Given the focus on reconstruction attacks, the paper is missing a discussion of differentially private federated learning as a potential solution to the multi-round privacy vulnerability.",
                "Questions": "H. Given that T=4 is not a very strong privacy guarantee and that for T=6 the convergence rate already starts to take a significant hit, I wonder whether you're not better off adding noise to the gradients as in DP-FedAvg to protect the local data. Did you consider this option?",
                "Limitations": "The authors adequately address the limitations and potential negative societal impact of their work.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "4 excellent",
                "Rating": "8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "Secure aggregation-based protocols can leak privacy over multiple training rounds in FL and do not provide long-term privacy guarantees. The partial user selection enables the reconstruction of the client's models. The authors propose a user-selection strategy that will provide long-term privacy guarantees and provide theoretical and convergence analysis. New metrics are proposed to capture the privacy guarantees.",
                "Strengths And Weaknesses": "Strengths:\n\nThe paper is well-written and clear.\nMulti-RoundSecAgg is a novel scheme that provides privacy in FL in long term. It also ensures a fair selection of clients and shows tradeoffs between convergence and privacy.\nProposed metrics are interesting, they allow for comparison between different user selection schemes in terms of privacy and that all clients participate in an equal number of rounds.\nComparison with baseline experiments demonstrates the effectiveness of the metrics proposed.\nThe remarks and assumptions provided are a plus.\n\nWeaknesses:\n\nThe privacy leakage of the aggregated models over multiple rounds is not addressed. This may be considered as future work.\nApplicability to cross-device only is missing.",
                "Questions": "1- Will multi-secagg work for cross-silo setup with partial user selection?\n2- Will experiments with N=K show any deviation?\nminor edits:\nLine 113: \"their.\"\nLine 41-42: Refer/Cite the basis\nLine 224: \"number of selected at each\"",
                "Limitations": "Limitations are discussed in form of assumptions and remarks.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper concentrates on privacy-leakage in federated learning over multiple rounds. The authors note that secure aggregation protocols only have guarantees for a single aggregation round, whereas in federated learning the model is trained iteratively.  The paper proposes to measure and mitigate this privacy leakage over iterations. The main idea in the mitigation is to choose fixed groups of parties for model updates, so that an adversary can only ever see a contribution from the fixed group. This makes identifying any single individual party's contribution based on differences between iterations harder, since the individual contribution is always mixed in with the other group members. The proposed method essentially involves creating fixed subsets of users who are always chosen together for model updates. Another consideration is fairness in the sens of each party contributing an equal number of updates: the authors also propose a method by which all parties are chosen for updates an equal number of times on expectation. The paper then analyses convergence properties of the proposed method, and tests it empirically with several standard network structures and datasets.",
                "Strengths And Weaknesses": "Update after discussions\nAfter the rebuttal and the discussions, I raise my score to recommend acceptance. I trust that the authors will improve the paper based on the discussions.\nStrengths\n\nThe idea of having some secure aggregation-type guarantees over several iterations seems like a fine one.\nThe theoretical results backing up the method are comforting, e.g., in the sense that the proposed method can be shown to converge under some fairly standard assumptions.\n\nWeaknesses\n\nThe most glaring issue with the paper is that it completely omits discussing or even mentioning differential privacy (DP) and related definitions, which have been the standard privacy definition in machine learning for years, and that have also been widely used with federated learning (see e.g. Kairouz et al. 2019 for a quick overview of the basic idea in the context of federated learning, Dwork & Roth 2014 for a basic introduction to DP). Instead, the privacy discussed in the current paper is more related to secure computation, where the formal guarantees are on revealing only the end result of a computation. Calling such definitions privacy preserving is problematic for various reasons. One major issue is that the end result might well give out the input data in the clear without having any problems in satisfying this kind of definition of privacy-preserving (e.g. by choosing local loss functions s.t. the optimal value is an actual data point for a single client and 0 for everyone else would give out the single data point while still satisfying this kind of privacy guarantees). \nThe guarantees are also brittle in the sense that any side information might lead to a catastrophic privacy breach, where one or more input data points are suddenly revealed (e.g. consider what happens to others if one of the fixed group members gives out it's updates, or an adversary gains information on such values from other sources).\nAs an immediate fix, I would suggest including some discussion on the privacy-definition that also considers DP, clarifying the claims that this is the first paper that considers privacy-leakage in federated learning over iterations (e.g. lines 51, 84-88), and changing the emphasis to be less on general privacy-preservation and more specifically on what this method tries to protect. More interesting, although also more work-intensive and hence probably out of the question for now, would be to try and combine the current papers' results with DP and show that the proposed method does indeed enable better privacy by limiting the amount of information an adversary can gain.\nRelated to the previous point: I have a hard time understanding what are the consequences of providing privacy in the sense used in this paper.\n\nReferences\nDwork & Roth 2014: The algorithmic foundations of differential privacy.\nKairouz et al. 2019: Advances and open problems in federated learning.",
                "Questions": "In the experiments, is there some reason to stop training when you do? Would e.g. the partition baseline eventually reach ~ same performance, and the main issue is convergence speed, or is there some other reason why it would perform worse?\n\nIt seems that the proposed method assumes that the other parties in the same group are honest(?). Please mention the actual assumption as part of the the threat model.\n\nI think Remark 7 on lines 290-295 would make more sense as a separate theorem: this seems like an important property that should be stated more formally.\n\n\nMinor details:\nPlease add a table on the notation to Appendix: trying to follow the derivations can be frankly painful when one needs to hunt for the meaning of symbols all over the place. Fix typos on lines 113,224.",
                "Limitations": "There is no discussion on the limitations of the proposed method, including in Section 7, which is pointed out as containing such discussion in the paper checklist.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.25,
        "confidence_avg": 3.25,
        "soundness_avg": 3.5,
        "presentation_avg": 3.25,
        "contribution_avg": 2.75,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is clear that the paper proposes a novel framework for sampling clients in each round of a Federated Learning training session, with a focus on privacy guarantees and fairness. The paper provides theoretical analyses, experimental results, and comparisons with baseline methods to support the proposed framework.\n\nThe strengths of the paper include clear writing, strong motivation, novelty, theoretical results, and experimental evaluations. The reviewers appreciate the clarity of the paper, the importance of addressing privacy leakage in federated learning, and the contributions made by the proposed framework. The theoretical guarantees and convergence analysis are also seen as valuable insights.\n\nThere are some weaknesses mentioned by the reviewers, such as the lack of discussion on differential privacy as a potential solution, the omission of discussing privacy definitions related to secure computation, and the brittleness of the privacy guarantees. However, these weaknesses can be addressed by including a discussion on differential privacy, clarifying the claims made in the paper, and considering the combination of the proposed method with differential privacy.\n\nOverall, the paper is technically solid, with high impact and good evaluation. The limitations and potential negative societal impact of the work are adequately addressed. Therefore, I recommend accepting the paper."
    },
    "Multifidelity_Reinforcement_Learning_with_Control_Variates": {
        "link": "https://openreview.net//forum?id=yjybfsIUdNu",
        "pub_url": "https://openreview.net/forum?id=yjybfsIUdNu",
        "pdf_link": "https://openreview.net//pdf?id=yjybfsIUdNu",
        "paper_id": "yjybfsIUdNu",
        "title": "Multifidelity_Reinforcement_Learning_with_Control_Variates",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Less certain\nAll reviewers agree on the novelty and significance of the topic addressed by the paper and feel that the paper is at the borderline of being ready for publication. But in the end, as visible in the lengthy comments and discussions about the paper, there are too many details and clarifications missing in this paper to push it solidly across the acceptance threshold. Given all the technical discussions, the authors should be in an excellent position for a significantly improved resubmission in the future.",
        "reviews": [
            "Reviewer 1: \nSummary: The authors focus on improving the performance of reinforcement learning algorithms in the presence of multi-fidelity data through the use of control variates.\nStrengths And Weaknesses: General Comments\nI really like this paper, and hope that it gets accepted.  However there are a few, hopefully easy, problems that the authors need to address. First the literature review needs to be expanded to include background from variance reduction in classic RL, and asymmetric RL. Second, the assumptions and discussion surrounding policy iteration need to be more explicit in the main paper, or pointed to in the appendix. Lastly, they need to include, potentially in the appendix, other baseline algorithms in the NAS example. If these problems can be addressed in the rebuttal  period, I will increase my score. \nStrengths\n\nThis is actually a really clearly written paper that I enjoyed reading.\nI think that the area that it considers is an important one.\nThe experiments are clearly presented, and the weaknesses of the work, as well as their strengths are discussed in detail.\n\nWeaknesses\n\nThe authors seem to ignore the full literature surrounding the learning of baselines in general reinforcement learning which I think does not set the right context for why the question the authors answer is interesting. \nAlso ignores recent work in asymmetric reinforcement learning, which I think would benefit the larger story and analysis. Especially in connecting, in a more principled way, low fidelity and high-fidelity simulation. \nThe NAS experiments do not include other baseline algorithms. Though I am not familiar with this specific benchmark, I have no doubt there are other algorithms which should be included to give a point of reference for what the gap between RL based methods and other methods is. \nThe authors seem as though they are not being fully transparent about the types of MDPs for which this algorithm can currently be configured with. Does it only work with low-dimensional state-action spaces and toy problems, or can it be configured with more difficult continuous control tasks? \nThe discussion and assumptions surrounding the policy iteration alluded to in section 3.3 was basically non-existent. For better clarity it seems like a more explicit discussion should be included (either in the main paper or the appendix).\nQuestions: Preliminaries and related work\n\n\"It is well known that there exists at least one optimal policy \u03c0\u2217 such that V\u03c0\u2217 (s) = max \u03c0 V\u03c0 (s), \u2200s \u2208 S and Q\u03c0\u2217 (s, a) = max \u03c0 Q\u03c0 (s, a), \u2200s, a \u2208 S \u00d7 A [ 2]. Furthermore, a deterministic policy that selects the greedy action with respect to Q\u03c0\u2217 (s, a), \u2200s \u2208 S, is an optimal policy.\" -- If you make statements please include a citation. I believe that a good reference for this statement would be (1).\n\"Applications of the method of control variates extend beyond variance reduction. For example, the concept of control variates is used in [ 27 ] to design a fusion framework to combine an arbitrary number of surrogate models optimally.\" --Also the notion of a baseline in reinforcement learning has been well studied since the inception of policy gradient methods (2). The literature surrounding baselines should be mentioned if you are talking about variance reduction in RL methods (3,4).\n\"In [1], a policy search algorithm is proposed that leverages a crude approximate model \u02c6P of the true MDP to quickly learn to perform well on real systems.\" -- Can you state explicitly the policy search algorithm that is used. \n\"From an optimization viewpoint, this approach is reasonable only if the lower-fidelity value function lies in the vicinity of the optimal high-fidelity value function, a situation that cannot be guaranteed or known a priori in general.\" -- can you make this more explicit? Do you mean that it is close in terms of the true value function under co-simulation between low-fidelity and high-fidelity models?\nIt seems like this work is deeply related to asymmetric learning algorithms (5,6). Can you comment on the connection to this sub-field and how it relates to your work? It seems as though your analysis might benefit from viewing the low-fidelity process as a POMDP, and the high-fidelity process as the true underlying sequence of states.\n\nMultifidelity estimation in RL\n\n\"High-fidelity environments usually capture more state information than do low- fidelity environments so T can be a many-to-one map\" -- It seems like this would imply that the state-space would be implicitly or explicitly larger, which you would imagine might actually slow down learning. Can you comment on this?\n\"Notice that G hi and G lo are correlated r.vs. in this multifidelity setup\" -- This is only true for the first step of the monte-carlo rollout of the low fidelity simulator though. Meaning that for t > 0 all rewards could be de-correlated and the level of correlation of G should be dependent on the discount factor which close to 1 becomes vanishingly small.  Is this correct? \nEquation 7 implies that you are able to exactly estimate Q in the low-fidelity simulator which seems unrealistic in general. Is this the case, or did I misunderstand the notation?\nPlease include a reference for the policy improvement theorem in 3.3.2 as it does have some requirements that I am unsure are met in your setting. Depending on the variant (e.g. are we looking at exact policy iteration, asynchronous policy iteration or approximate policy iteration? \n\" This assumption basically ensures that all actions at the target state shi have been explored equally well and enables us to make fair comparisons about estimator performance.\" -- This statement seems inconsistent with the message expressed earlier which was that your algorithm in fact addresses the exploration issue in systems where correlation in the expected reward ahead is high between high and low fidelity simulators.\n\nNumerical experiments\n\nWhere are other common baselines for the neural architecture search? I appreciate the need to compare over the non-variance reduced baseline, but it seems like having examples from other algorithms in the paper is necessary to see exactly where this technology stands with respect to the larger NAS literature. \nWhat were the relative clock-times of NAS with and without the control-variate schemes? Were they comparable?\nThe plot for figure 3 seems incorrect as for the non-variance reduced algorithm the standard deviation does not fully overlap the mean, are you sure you did not report the mean and two quantiles?\n\nCitations mentioned\n(1) Bertsekas, Dimitri. Reinforcement learning and optimal control. Athena Scientific, 2019.\n(2) https://people.cs.umass.edu/~barto/courses/cs687/williams92simple.pdf\n(3) https://proceedings.neurips.cc/paper/2010/file/35cf8659cfcb13224cbd47863a34fc58-Paper.pdf\n(4) https://arxiv.org/pdf/1506.02438.pdf \n(5) https://arxiv.org/abs/1710.06542\n(6) https://arxiv.org/abs/2012.15566\nLimitations: The major weakness mentioned by the authors is the setting when the correlation between low fidelity and high-fidelity simulation is low their variance reduction algorithm can actually perform worse then the baseline. I again think that the authors need to include other baselines to give an idea of how performant their algorithm is by comparison. It need not beat these other algorithms, but other standard baselines (especially on NAS) should be included.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper presents a new methodology for multi-fidelity RL by leveraging low-fidelity data to decrease the variance in the MC-estimates of the value function.  The new algorithm, MFMCRL, leverages theory from control-variates to decrease the variance based on the observed correlation fbetween the high and low value returns.  This is a different approach than existing MFRL techniques that choose which simulator to gather data from and need bounds on the relationships between the simulators.  Theoretical results quantifying the improvements from this approach in both policy evaluation and policy improvement are derived.  Empirical results are presented with synthetic MDPs and in a NAS (hyperparameter tuning) environment.\nStrengths And Weaknesses: Overall I think this is a very clever idea and a nicely scoped paper.  The approach is novel compared to existing MFRL techniques in that it takes a very different approach to gathering data.  There are places though, where I think the paper needs to be more precise in its terminology and also point out some disadvantages of the current formulation with respect to prior MFRL work.  Details below:\nMore precise terminology needed:\nThe assumption of independence at line 110 (when i != j) and the related covariance construction in (11) are very confusing to me.  I and j here are indexing two different sets (the high fidelity and low fidelity one) from what I can tell where each element is the return of a trajectory in the related MDP.  So there are n trajectories from Lo and n from high, right?  In that case, isn\u2019t there likely non-zero covariance between lots of these trajectories?  That is, a rollout of the same policy in these two similar MDPs will produce correlated returns \u2013 if half of them take a right turn (stochastically) then we should expect 50% of the trajectories in Z to be correlated with another 50% in W.  So why would we expect 0 correlation just because the indexes don\u2019t match?  What is special about two matching indexes (Z_i and W_i)?  Can the authors provide a concrete example showing why we would expect i != j to be important?\nI was surprised the environment setup in Section 2.1 requires an episodic domain and specifically one with terminal states.  Is this necessary for the algorithm / analysis because it is based on MC sampling and are there natural extensions to non-episodic domains.\nThe sentence starting on line 120 could use a citation.\nLine 199 \u2013 A  note should be made here about why the new approach needs to use (inefficient) MC returns instead of utilizing bootstrapping in learning the value function.  I presume since the latter is a biased estimator it is not usable in this framework.  That is fine, but the point should be made directly here.\nI think the pseudocode block from the appendix needs to be in the main paper.  The current description of the algorithm in the main paper is not really usable without it.  If this paper gets accepted I suggest using the extra page to include that. \nOn potential disadvantages with regards to previous methods:\nI agree with the authors that the new approach has fewer assumptions about prior knowledge compared to previous MFRL methods. Being able to learn the correlations between the environments is a nice improvement.  But there are other dimensions where the current approach is not as efficient or flexible as previous MFRL approaches and those should be called out directly in the related work comparison.  Specifically (1) the current work always assumes there are only 2 environments (low and high) while previous work considered any number of environments \u2013 can the new framework accommodate multiple low-fidelity environments?  If so or if not this should be mentioned. (2) The new framework is doing value-based RL using MC returns, which is likely going to be very inefficient compared to the model based approaches used in prior work and (3) The authors make a point about not needing to use more complicated exploration strategies to decide what environment to sample from, but that will lead to inefficiencies.  The current approach will sample from both Low and High on every iteration, which could be very costly, whereas previous MFRL approaches only sample from High when they feel they are \u201cready\u201d to take on the high-fidelity environment.  So yes, the new approach will be more sample efficient than only sampling from High, but it seems it will be much less sample efficient than previous MFRL approaches in terms of sampling the highest fidelity environment.\nQuestions: Can the authors provide a more precise description of the i != j covariance construction and why the indexes should match up?\nWhy is the analysis restricted to only domains with terminal states?\nCan the authors comment on the dimensions [(1) (2) and (3) in the final paragraph above] where the new algorithm may not be as strong as earlier MFRL methods?\nLimitations: As mentioned above, while I think the new approach has a benefit of requiring less strict knowledge about the relationship between low and fidelity environments, there seem to be areas where the new approach is not as strong as prior approaches.  These specific areas are (1) accommodating more than 2 environments, (2) losing sample efficiency by learning from MC returns rather than doing model based learning, and (3) not actively choosing which environment to sample, which will not be as efficient in querying the expensive high-fidelity environment.  If these limitations hold with respect to prior work they should be mentioned in the paper.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 4 excellent\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The paper is framed in the setting of multi-fidelity Reinforcement Learning (RL), i.e., the setting in which multiple instances of the environment are available, each with a different accuracy on the reward function and transition dynamics. Specifically, the paper considers the presence of two instances (an exact one and an approximate one) and proposes an approach to effectively exploit this opportunity to improve the estimation of the value functions. In particular, by assuming that the reward random variable of the two environments are correlated, a suitable control variance is exploited to reduce the variance of the estimate and achieving smaller sample complexity. A theoretical analysis is provided, showing results regarding the accuracy of the value function and of the greedy policy. An experimental evaluation on both synthetic domains and on a NAS (neural architecture search) is provided, highlighting the advantages of the proposed approach.\nStrengths And Weaknesses: \nThe main strong point of the paper is the fact that it addresses a very relevant topic, i.e., multi-fidelity RL, that emerges in several real-world applications.\n\n[Novelty] The approach proposed in the paper is novel per se, although it can be considered an application of the control-variate techniques to the multi-fidelity setting. The theoretical evaluation is novel and succeeds in showing some advantages of the proposed approach (although I have some concerns that I will detail below)\n\n[About Correlation of the Rewards] The crucial assumption that makes the proposed approach work is that the reward random variables collected in the high-fidelity and low-fidelity environments in the same state are correlated in a statistical sense (i.e., with a non-zero correlation coefficient). This is quite different from the usual idea of fidelity in multi-armed bandits (e.g., \"Kandasamy, Kirthevasan, Gautam Dasarathy, Barnabas Poczos, and Jeff Schneider. \"The multi-fidelity multi-armed bandit.\" Advances in neural information processing systems 29 (2016).\") in which the fidelity is represented as a bias on the expected reward (so, it is not a correlation in the statistical sense). Consequently, in order for the approach to make sense, it must be that the reward is stochastic given the current state and action. It seems that the approach cannot be applied to rewards that are deterministic functions of the state-action pair. Indeed, in such a case, there would be no correlation. Requiring correlated reward random variables seems quite restrictive in my view. Can the authors elaborate on this point?\n\n[Estimation of $Q^{lo}{\\pi}$ ] As the authors acknowledge, in order to compute the control variate, it is necessary to have access to the value of the true low-fidelity value function Q^{lo}{\\pi}. This is not available in practice. The authors propose to collect a large number m of return samples from the low-fidelity environment. Although m can be chosen to be large (assuming that the cost of collecting samples in low-fidelity is negligible), it represents a further source of uncertainty that will impact the computation of all the relevant quantities. Moreover, in the control variate, the covariances and the correlation coefficient are estimated from samples as well. Are these further sources of uncertainty accounted for in the theoretical analysis of Section 3.3?\n\n\nOverall\nThe paper has some novelty and the experimental results, although limited to one realistic environment (and some synthetic ones), show some advantages of the proposed approach, I think the paper is currently borderline. I would appreciate it if the authors could clarify the concerns about the formulation of the fidelity (i.e., the correlation between the random variables).\nQuestions: I would appreciate it if the authors could clarify the issues [About Correlation of the Rewards] and [Estimation of Q^{lo}_{\\pi}]. Furthermore, I add some minor questions:\n\nIn Section 2.1, the authors require the state and action spaces to be finite. Is this a crucial assumption? Can the approach be employed in continuous state-action spaces?\n\nIn real-world applications of multi-fidelity RL, is it reasonable to assume that the mapping function from high-fidelity states to low-fidelity states T is known?\n\nIs the assumption that the low-fidelity environment admits a generative model-kind of interaction crucial for the approach? On the one hand, I guess it is because this is exploited for estimating the true value of  Q\u03c0lo. Can the authors elaborate?\nLimitations: The limitations and impact of the paper are properly addressed by the authors.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The authors focus on improving the performance of reinforcement learning algorithms in the presence of multi-fidelity data through the use of control variates.",
                "Strengths And Weaknesses": "General Comments\nI really like this paper, and hope that it gets accepted.  However there are a few, hopefully easy, problems that the authors need to address. First the literature review needs to be expanded to include background from variance reduction in classic RL, and asymmetric RL. Second, the assumptions and discussion surrounding policy iteration need to be more explicit in the main paper, or pointed to in the appendix. Lastly, they need to include, potentially in the appendix, other baseline algorithms in the NAS example. If these problems can be addressed in the rebuttal  period, I will increase my score. \nStrengths\n\nThis is actually a really clearly written paper that I enjoyed reading.\nI think that the area that it considers is an important one.\nThe experiments are clearly presented, and the weaknesses of the work, as well as their strengths are discussed in detail.\n\nWeaknesses\n\nThe authors seem to ignore the full literature surrounding the learning of baselines in general reinforcement learning which I think does not set the right context for why the question the authors answer is interesting. \nAlso ignores recent work in asymmetric reinforcement learning, which I think would benefit the larger story and analysis. Especially in connecting, in a more principled way, low fidelity and high-fidelity simulation. \nThe NAS experiments do not include other baseline algorithms. Though I am not familiar with this specific benchmark, I have no doubt there are other algorithms which should be included to give a point of reference for what the gap between RL based methods and other methods is. \nThe authors seem as though they are not being fully transparent about the types of MDPs for which this algorithm can currently be configured with. Does it only work with low-dimensional state-action spaces and toy problems, or can it be configured with more difficult continuous control tasks? \nThe discussion and assumptions surrounding the policy iteration alluded to in section 3.3 was basically non-existent. For better clarity it seems like a more explicit discussion should be included (either in the main paper or the appendix).",
                "Questions": "Preliminaries and related work\n\n\"It is well known that there exists at least one optimal policy \u03c0\u2217 such that V\u03c0\u2217 (s) = max \u03c0 V\u03c0 (s), \u2200s \u2208 S and Q\u03c0\u2217 (s, a) = max \u03c0 Q\u03c0 (s, a), \u2200s, a \u2208 S \u00d7 A [ 2]. Furthermore, a deterministic policy that selects the greedy action with respect to Q\u03c0\u2217 (s, a), \u2200s \u2208 S, is an optimal policy.\" -- If you make statements please include a citation. I believe that a good reference for this statement would be (1).\n\"Applications of the method of control variates extend beyond variance reduction. For example, the concept of control variates is used in [ 27 ] to design a fusion framework to combine an arbitrary number of surrogate models optimally.\" --Also the notion of a baseline in reinforcement learning has been well studied since the inception of policy gradient methods (2). The literature surrounding baselines should be mentioned if you are talking about variance reduction in RL methods (3,4).\n\"In [1], a policy search algorithm is proposed that leverages a crude approximate model \u02c6P of the true MDP to quickly learn to perform well on real systems.\" -- Can you state explicitly the policy search algorithm that is used. \n\"From an optimization viewpoint, this approach is reasonable only if the lower-fidelity value function lies in the vicinity of the optimal high-fidelity value function, a situation that cannot be guaranteed or known a priori in general.\" -- can you make this more explicit? Do you mean that it is close in terms of the true value function under co-simulation between low-fidelity and high-fidelity models?\nIt seems like this work is deeply related to asymmetric learning algorithms (5,6). Can you comment on the connection to this sub-field and how it relates to your work? It seems as though your analysis might benefit from viewing the low-fidelity process as a POMDP, and the high-fidelity process as the true underlying sequence of states.\n\nMultifidelity estimation in RL\n\n\"High-fidelity environments usually capture more state information than do low- fidelity environments so T can be a many-to-one map\" -- It seems like this would imply that the state-space would be implicitly or explicitly larger, which you would imagine might actually slow down learning. Can you comment on this?\n\"Notice that G hi and G lo are correlated r.vs. in this multifidelity setup\" -- This is only true for the first step of the monte-carlo rollout of the low fidelity simulator though. Meaning that for t > 0 all rewards could be de-correlated and the level of correlation of G should be dependent on the discount factor which close to 1 becomes vanishingly small.  Is this correct? \nEquation 7 implies that you are able to exactly estimate Q in the low-fidelity simulator which seems unrealistic in general. Is this the case, or did I misunderstand the notation?\nPlease include a reference for the policy improvement theorem in 3.3.2 as it does have some requirements that I am unsure are met in your setting. Depending on the variant (e.g. are we looking at exact policy iteration, asynchronous policy iteration or approximate policy iteration? \n\" This assumption basically ensures that all actions at the target state shi have been explored equally well and enables us to make fair comparisons about estimator performance.\" -- This statement seems inconsistent with the message expressed earlier which was that your algorithm in fact addresses the exploration issue in systems where correlation in the expected reward ahead is high between high and low fidelity simulators.\n\nNumerical experiments\n\nWhere are other common baselines for the neural architecture search? I appreciate the need to compare over the non-variance reduced baseline, but it seems like having examples from other algorithms in the paper is necessary to see exactly where this technology stands with respect to the larger NAS literature. \nWhat were the relative clock-times of NAS with and without the control-variate schemes? Were they comparable?\nThe plot for figure 3 seems incorrect as for the non-variance reduced algorithm the standard deviation does not fully overlap the mean, are you sure you did not report the mean and two quantiles?\n\nCitations mentioned\n(1) Bertsekas, Dimitri. Reinforcement learning and optimal control. Athena Scientific, 2019.\n(2) https://people.cs.umass.edu/~barto/courses/cs687/williams92simple.pdf\n(3) https://proceedings.neurips.cc/paper/2010/file/35cf8659cfcb13224cbd47863a34fc58-Paper.pdf\n(4) https://arxiv.org/pdf/1506.02438.pdf \n(5) https://arxiv.org/abs/1710.06542\n(6) https://arxiv.org/abs/2012.15566",
                "Limitations": "The major weakness mentioned by the authors is the setting when the correlation between low fidelity and high-fidelity simulation is low their variance reduction algorithm can actually perform worse then the baseline. I again think that the authors need to include other baselines to give an idea of how performant their algorithm is by comparison. It need not beat these other algorithms, but other standard baselines (especially on NAS) should be included.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper presents a new methodology for multi-fidelity RL by leveraging low-fidelity data to decrease the variance in the MC-estimates of the value function.  The new algorithm, MFMCRL, leverages theory from control-variates to decrease the variance based on the observed correlation fbetween the high and low value returns.  This is a different approach than existing MFRL techniques that choose which simulator to gather data from and need bounds on the relationships between the simulators.  Theoretical results quantifying the improvements from this approach in both policy evaluation and policy improvement are derived.  Empirical results are presented with synthetic MDPs and in a NAS (hyperparameter tuning) environment.",
                "Strengths And Weaknesses": "Overall I think this is a very clever idea and a nicely scoped paper.  The approach is novel compared to existing MFRL techniques in that it takes a very different approach to gathering data.  There are places though, where I think the paper needs to be more precise in its terminology and also point out some disadvantages of the current formulation with respect to prior MFRL work.  Details below:\nMore precise terminology needed:\nThe assumption of independence at line 110 (when i != j) and the related covariance construction in (11) are very confusing to me.  I and j here are indexing two different sets (the high fidelity and low fidelity one) from what I can tell where each element is the return of a trajectory in the related MDP.  So there are n trajectories from Lo and n from high, right?  In that case, isn\u2019t there likely non-zero covariance between lots of these trajectories?  That is, a rollout of the same policy in these two similar MDPs will produce correlated returns \u2013 if half of them take a right turn (stochastically) then we should expect 50% of the trajectories in Z to be correlated with another 50% in W.  So why would we expect 0 correlation just because the indexes don\u2019t match?  What is special about two matching indexes (Z_i and W_i)?  Can the authors provide a concrete example showing why we would expect i != j to be important?\nI was surprised the environment setup in Section 2.1 requires an episodic domain and specifically one with terminal states.  Is this necessary for the algorithm / analysis because it is based on MC sampling and are there natural extensions to non-episodic domains.\nThe sentence starting on line 120 could use a citation.\nLine 199 \u2013 A  note should be made here about why the new approach needs to use (inefficient) MC returns instead of utilizing bootstrapping in learning the value function.  I presume since the latter is a biased estimator it is not usable in this framework.  That is fine, but the point should be made directly here.\nI think the pseudocode block from the appendix needs to be in the main paper.  The current description of the algorithm in the main paper is not really usable without it.  If this paper gets accepted I suggest using the extra page to include that. \nOn potential disadvantages with regards to previous methods:\nI agree with the authors that the new approach has fewer assumptions about prior knowledge compared to previous MFRL methods. Being able to learn the correlations between the environments is a nice improvement.  But there are other dimensions where the current approach is not as efficient or flexible as previous MFRL approaches and those should be called out directly in the related work comparison.  Specifically (1) the current work always assumes there are only 2 environments (low and high) while previous work considered any number of environments \u2013 can the new framework accommodate multiple low-fidelity environments?  If so or if not this should be mentioned. (2) The new framework is doing value-based RL using MC returns, which is likely going to be very inefficient compared to the model based approaches used in prior work and (3) The authors make a point about not needing to use more complicated exploration strategies to decide what environment to sample from, but that will lead to inefficiencies.  The current approach will sample from both Low and High on every iteration, which could be very costly, whereas previous MFRL approaches only sample from High when they feel they are \u201cready\u201d to take on the high-fidelity environment.  So yes, the new approach will be more sample efficient than only sampling from High, but it seems it will be much less sample efficient than previous MFRL approaches in terms of sampling the highest fidelity environment.",
                "Questions": "Can the authors provide a more precise description of the i != j covariance construction and why the indexes should match up?\nWhy is the analysis restricted to only domains with terminal states?\nCan the authors comment on the dimensions [(1) (2) and (3) in the final paragraph above] where the new algorithm may not be as strong as earlier MFRL methods?",
                "Limitations": "As mentioned above, while I think the new approach has a benefit of requiring less strict knowledge about the relationship between low and fidelity environments, there seem to be areas where the new approach is not as strong as prior approaches.  These specific areas are (1) accommodating more than 2 environments, (2) losing sample efficiency by learning from MC returns rather than doing model based learning, and (3) not actively choosing which environment to sample, which will not be as efficient in querying the expensive high-fidelity environment.  If these limitations hold with respect to prior work they should be mentioned in the paper.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "4 excellent",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper is framed in the setting of multi-fidelity Reinforcement Learning (RL), i.e., the setting in which multiple instances of the environment are available, each with a different accuracy on the reward function and transition dynamics. Specifically, the paper considers the presence of two instances (an exact one and an approximate one) and proposes an approach to effectively exploit this opportunity to improve the estimation of the value functions. In particular, by assuming that the reward random variable of the two environments are correlated, a suitable control variance is exploited to reduce the variance of the estimate and achieving smaller sample complexity. A theoretical analysis is provided, showing results regarding the accuracy of the value function and of the greedy policy. An experimental evaluation on both synthetic domains and on a NAS (neural architecture search) is provided, highlighting the advantages of the proposed approach.",
                "Strengths And Weaknesses": "The main strong point of the paper is the fact that it addresses a very relevant topic, i.e., multi-fidelity RL, that emerges in several real-world applications.\n\n[Novelty] The approach proposed in the paper is novel per se, although it can be considered an application of the control-variate techniques to the multi-fidelity setting. The theoretical evaluation is novel and succeeds in showing some advantages of the proposed approach (although I have some concerns that I will detail below)\n\n[About Correlation of the Rewards] The crucial assumption that makes the proposed approach work is that the reward random variables collected in the high-fidelity and low-fidelity environments in the same state are correlated in a statistical sense (i.e., with a non-zero correlation coefficient). This is quite different from the usual idea of fidelity in multi-armed bandits (e.g., \"Kandasamy, Kirthevasan, Gautam Dasarathy, Barnabas Poczos, and Jeff Schneider. \"The multi-fidelity multi-armed bandit.\" Advances in neural information processing systems 29 (2016).\") in which the fidelity is represented as a bias on the expected reward (so, it is not a correlation in the statistical sense). Consequently, in order for the approach to make sense, it must be that the reward is stochastic given the current state and action. It seems that the approach cannot be applied to rewards that are deterministic functions of the state-action pair. Indeed, in such a case, there would be no correlation. Requiring correlated reward random variables seems quite restrictive in my view. Can the authors elaborate on this point?\n\n[Estimation of $Q^{lo}{\\pi}$ ] As the authors acknowledge, in order to compute the control variate, it is necessary to have access to the value of the true low-fidelity value function Q^{lo}{\\pi}. This is not available in practice. The authors propose to collect a large number m of return samples from the low-fidelity environment. Although m can be chosen to be large (assuming that the cost of collecting samples in low-fidelity is negligible), it represents a further source of uncertainty that will impact the computation of all the relevant quantities. Moreover, in the control variate, the covariances and the correlation coefficient are estimated from samples as well. Are these further sources of uncertainty accounted for in the theoretical analysis of Section 3.3?\n\n\nOverall\nThe paper has some novelty and the experimental results, although limited to one realistic environment (and some synthetic ones), show some advantages of the proposed approach, I think the paper is currently borderline. I would appreciate it if the authors could clarify the concerns about the formulation of the fidelity (i.e., the correlation between the random variables).",
                "Questions": "I would appreciate it if the authors could clarify the issues [About Correlation of the Rewards] and [Estimation of Q^{lo}_{\\pi}]. Furthermore, I add some minor questions:\n\nIn Section 2.1, the authors require the state and action spaces to be finite. Is this a crucial assumption? Can the approach be employed in continuous state-action spaces?\n\nIn real-world applications of multi-fidelity RL, is it reasonable to assume that the mapping function from high-fidelity states to low-fidelity states T is known?\n\nIs the assumption that the low-fidelity environment admits a generative model-kind of interaction crucial for the approach? On the one hand, I guess it is because this is exploited for estimating the true value of  Q\u03c0lo. Can the authors elaborate?",
                "Limitations": "The limitations and impact of the paper are properly addressed by the authors.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.667,
        "confidence_avg": 3.667,
        "soundness_avg": 3.0,
        "presentation_avg": 3.0,
        "contribution_avg": 2.667,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is clear that the paper addresses a relevant topic in multi-fidelity reinforcement learning and presents a novel approach. The paper is well-written and the experiments are clearly presented. \n\nReviewer 1 raises some valid concerns regarding the literature review, the inclusion of other baseline algorithms in the NAS experiments, and the discussion surrounding policy iteration. These issues should be addressed in the rebuttal period. However, overall, the reviewer finds the paper to be technically solid with moderate-to-high impact and no major concerns.\n\nReviewer 2 also acknowledges the novelty of the approach and appreciates the clear scope of the paper. They suggest including the pseudocode block from the appendix in the main paper for better understanding. They also point out some potential disadvantages of the current formulation compared to previous multi-fidelity RL methods, such as the restriction to only two environments and the use of MC returns instead of model-based learning. These limitations should be mentioned in the paper.\n\nReviewer 3 raises concerns about the assumption of correlated rewards and the estimation of Q^{lo}_{\\pi}. They suggest that requiring correlated reward random variables may be restrictive and question if the uncertainties in the estimation of Q^{lo}_{\\pi} and the control variate are accounted for in the theoretical analysis. These concerns should be addressed in the paper.\n\nOverall, while there are some valid concerns raised by the reviewers, the paper presents a novel approach to multi-fidelity RL and provides experimental results that highlight its advantages. With the necessary revisions and clarifications, the paper has the potential to make a significant contribution to the field. Therefore, I recommend accepting the paper."
    },
    "CogVideo:_Large-scale_Pretraining_for_Text-to-Video_Generation_via_Transformers": {
        "link": "https://openreview.net//forum?id=n7XbkHOwKn6",
        "pub_url": "https://openreview.net/forum?id=n7XbkHOwKn6",
        "pdf_link": "https://openreview.net//pdf?id=n7XbkHOwKn6",
        "paper_id": "n7XbkHOwKn6",
        "title": "CogVideo:_Large-scale_Pretraining_for_Text-to-Video_Generation_via_Transformers",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Less certain\nThe authors address an important problem of text-to-video generation in this work. Although there is a set of solid contributions that are specific to video generation, author-reviewer discussion as well as the following reviewer-area chair discussion did not address all the concerns raised by the reviewers. Furthermore, the lack of and also superficial address of the ethical concerns raised by the reviewers as well as ethics reviewers strongly suggests that the authors need to substantially revise the manuscript along both technical and ethical aspects. The paper is thus recommended to be rejected.",
        "reviews": [
            "Reviewer 1: \nSummary: This work addresses the large-scale pre-training in the open-domain Text-to-Video Generation. The major challenge to this task is the lack of large text-video paired datasets available and the weak relevance between them. In this paper, the authors propose a 9B-parameter transformer model CogVideo which is trained by inheriting the learned spatial semantics from a pre-trained text-to-image model (CogView2 in this paper).\nThey claim that the key difference between the text-to-video generation and the text-to-image generation is that the former needs huge of paired data to infer both spatial and temporal correlation between two modalities while the latter only requires the learning of spatial correlation. Therefore, they propose a dual-attention channel that adds an additional attention layer based on original structure of CogView2 to address the learning of temporal correlation (as illustrated in Figure 3). During training, it only optimizes the parameters of newly added temporal attention layer while keep all the parameters of CogView2 frozen.\nTo address the weak alignment of text and variable-length video (the example in Line 32-36 gives a good illustration of this issue), they propose multi-frame-rate hierarchical training. Concretely, it involves a two-stage generation process. In stage 1, they propose to add a frame-rate token to the text to generate the image frames at low frame rate. Then in stage 2, they introduce another frame interpolation transformer to generate the immediate transition frames between the generated frames of the first transformer model in stage 1.\nThe proposed hierarchical generation framework looks promising on long videos given a text input. The idea of interpolation transformer model that can utilize bidirectional frame context to finish the interpolation of current frame also make sense. However, there are some critical weaknesses and questions listed below.\nStrengths And Weaknesses: Strengths:\n\nThe proposed multi-frame-rate hierarchical training has the potential on the text-to-video generation, especially the idea of frame interpolation transformer model that can utilize the bidirectional frame context to generate immediate frame. It indeed looks a promising solution to handle long video generation given a text input.\nThe proposed CogVideo inherits the parameters of a pre-trained text-to-image models and avoid the expensive pre-training from scratch. \nIn addition, the authors claim that they will open-source the proposed large-scale text-to-video generation model. This is another contribution to the community.\n\nWeaknesses:\n\nIn the main experiment results in Table 1, it seems that CogVideo obviously underperforms TATS-base [9] on UCF-101 dataset and TriVD-GAN-FP [16] on Kinetics-600. This conflicts with the claim in abstract. Is that due to the issue of metric itself or other reasons? Could you explain more about results in Table 1 since I cannot find related information in the main text?\nIt is not clear how much the temporal attention channel contributes to the performance gains of CogVideo. In the ablation study, it does not include the comparison of with/without temporal attention layer, i.e., compare the performance gap of directly fine-tuning CogView2\u2019s weights and keeping CogView2\u2019s weights frozen while tuning the temporal attention layer.\nThe qualitative evaluation only includes one case analysis, it would be more convincing to provide more visualized comparison between different variants. Since the visualization samples are much more intuitive than evaluation metrics to directly judge the real performance of the model.\nQuestions: Questions for the authors:\n\nWhy are there no detailed analysis about main experimental results in Table 1 in the main text of the paper?\nIt seems there are only an ablation study on Kinetics-600. Why not including the ablation study on UCF-101 datasets in Section 5.3? It would be more convincing to cover the comparison results on UCF-101.\nIn Figure 7, it looks there is no obvious performance gap between (a) and (e). Thus, what\u2019s the advantage of hierarchical generation from the perspective of visualization results, not just in human evaluation results. Could you provide more visualized case analysis in appendix later to justify the superior performance of your proposed method?\nIn Section 3.2, Is the restricted receptive field formulation in Eq. 4 like the 3D nearby attention mechanism in NUWA [36]? If yes, what\u2019s the difference between two?\nHow many seconds do the longest videos that your method generate can last? In my understanding, this is the key advantage of the hierarchical generation framework.\nHow to understand the recursive process of hierarchical generation? Do you mean that immediate interpolated (generated) frames at each iteration will be used to generate new immediate frames between previous ones? Why not directly generating all immediate frames at once?\n\nMinor issues:\n\nCould you please add a citation or hyperlink for DeepSpeed in the paper later? Since it is a great work in the community, you should mention it at least.\nGrammar error in Line 287, \u201csamples generated hierarchically performs\u2026\u201d => \u201csamples \u2026 perform \u2026\u201d.\nLimitations: The major limitation is that how long the generated videos by the proposed CogVideo can last. The submitted demos show that the generated videos can only last several seconds. It would be more exciting that CogVideo can generate longer videos for given text input.\nEthics Flag: Yes\nEthics Review Area: Discrimination / Bias / Fairness Concerns\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper is the first work to propose an open-source pretrained transformer to solve the text-to-video task. The authors propose a two-stage framework CogVideo by finetuning a text-to-image model and avoid pretraining from scratch to reduce the training cost. The idea of multi-frame-rate ensures the flexibility and accuracy of the generated video. Experiments and visualized samples show the effectiveness of the method on video generating.\nStrengths And Weaknesses: \uff081\uff09Strengths\uff1a\nThe paper proposes the pretrained two-stage Sequential Generation and Recursive Interpolation pipeline and better reconstruct the alignment relation in a video. And the two-stage method does help the model converge better and faster, which is proved by the line chart of training loss shown in the ablation studies. I think the CogVideo pipeline has its value in real-world application scenarios. Also, the paper is well writing.\n\uff082\uff09Weaknesses:\n-First, the paper is not the first attempting to investigate hierarchical transformer structure in text-to-video challenge. For example, [1] also exploits autoregressive and interpolation transformers and gain better performance on UCF-101. However, the authors do not explain the difference or innovation compared with [1].\n-The authors have claimed that the CogVideo pipeline can solve the text-to-video generation in the general domain, but the experiment results in tab.1 are all attained on human action video datasets( UCF-101 and Kinetics-600), which maybe somewhat weak to prove the above conclusion. I guess maybe general domain represents the motions in the text have some temporal relation. If the concept of general domain can be defined in the paper, it will be much better.\n[1] S. Ge, T. Hayes, H. Yang, X. Yin, G. Pang, D. Jacobs, J.-B. Huang, and D. Parikh. Long video generation with time-agnostic vqgan and time-sensitive transformer. arXiv preprint arXiv:2204.03638, 2022\nQuestions: 1)Is the fps a learnable parameter or a hyper-parameter? And how to use the fps token concretely in the transformer?\n2)Compared with other training method, does CogVideo accelerate the training process? What environment and how much time does the training process need?\n3)Compared with the 1-Stage finetuned CogVideo model, how does the full model deal with the problem that one generated frame in the sequential generation stage collapses and influences the later frames? I do not have any idea that the two stage pipeline can solve this problem.\nLimitations: No.\nAnd I do not see any serious concerns.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: In this paper, the authors propose a large-scale pre-training model for text-to-video generation, called CogVideo, which is trained by inheriting a pre-trained text-to-image model CogView2. A multi-frame-rate hierarchical training strategy is designed to better align text and video clips. The proposed method is validated on standard benchmarks such as UCF-101 and Kinetics-600.\nStrengths And Weaknesses: Strengths:\n1.This work explores an important topic - text-conditional video generation, and presents an effective method for it.\n2.A multi-frame-rate hierarchical training strategy is proposed to improve the generation quality and control the intensity of changes during generation.\n3.The authors verified the proposed model through both quantitative experiments and qualitative analyses.\nWeaknesses:\n1.The novelty and technical contributions of this work are quite limited. It simply assembles several existing algorithms, such as CogView2 [6] and Swin Transformer [14].\n2.The performance of the proposed CogVideo is not as strong as the authors claimed. As shown in Tab. 1, the metrics of CogVideo (IS and FVD) fall behind previous methods. It is not acceptable to only compare with publicly available models.\n3.The authors trained the CogVideo on a large dataset of 5.4 million captioned videos, but did not give any detailed information regarding this dataset. What are the sources of the videos and captions? How are they collected? Will the dataset be released? \n4.The authors claimed that they greatly enhance parallelism and accelerate inference, but no results about inference speed of the CogVideo model are provided.\n5.In Sec. 5.1, the authors \"fine-tune CogVideo on the whole dataset (UCF-101) for 10,000 iterations\". Is it appropriate in this field?\nQuestions: 1.The authors should explain the novelty and contributions of the proposed CogVideo.\n2.The performance of CogVideo is not as competitive as claimed. The authors should give more discussions and analyses.\n3.More details about the dataset with 5.4 million captioned videos are expected.\nLimitations: Yes, the authors adequately addressed the limitations and potential negative societal impact of the work.\nEthics Flag: No\nEthics Review Area: I don\u2019t know\nSoundness: 2 fair\nPresentation: 2 fair\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper proposed a large-scale pretrained text-to-video model and multi-frame-rate hierarchical training strategy to better align text and video clips.\nStrengths And Weaknesses: The strengths of this paper are as follows:\n\nThis paper is well written and easy to follow.\nThe proposed model is the largest and the first open-source pre-trained transformer for text-to-video generation in the general domain.\nThe experimental results show that the proposed methods can outperform a number of existing baselines.\n\nThe weaknesses of this paper are as follows:\n\nThe main limitation of the work is the huge consumption of GPU memory, but the related information (type and number of GPU) is not provided. I hope this information can be given.\n\nI am not an expert in this field and do not tap into DALL-E and CogView, I will adjust the final score with other reviewers' comments and the response from the author.\nQuestions: \nIs there a gap between the generated video and the ground truth, so ground truth is not placed in human evaluation for comparison?\n\nI wonder whether the mixture factor /alpha will finally converge to 0 or 1, making the dual-channel attention block useless.\nLimitations: None\nEthics Flag: Yes\nEthics Review Area: Discrimination / Bias / Fairness Concerns, Privacy and Security (e.g., consent)\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This work addresses the large-scale pre-training in the open-domain Text-to-Video Generation. The major challenge to this task is the lack of large text-video paired datasets available and the weak relevance between them. In this paper, the authors propose a 9B-parameter transformer model CogVideo which is trained by inheriting the learned spatial semantics from a pre-trained text-to-image model (CogView2 in this paper).\nThey claim that the key difference between the text-to-video generation and the text-to-image generation is that the former needs huge of paired data to infer both spatial and temporal correlation between two modalities while the latter only requires the learning of spatial correlation. Therefore, they propose a dual-attention channel that adds an additional attention layer based on original structure of CogView2 to address the learning of temporal correlation (as illustrated in Figure 3). During training, it only optimizes the parameters of newly added temporal attention layer while keep all the parameters of CogView2 frozen.\nTo address the weak alignment of text and variable-length video (the example in Line 32-36 gives a good illustration of this issue), they propose multi-frame-rate hierarchical training. Concretely, it involves a two-stage generation process. In stage 1, they propose to add a frame-rate token to the text to generate the image frames at low frame rate. Then in stage 2, they introduce another frame interpolation transformer to generate the immediate transition frames between the generated frames of the first transformer model in stage 1.\nThe proposed hierarchical generation framework looks promising on long videos given a text input. The idea of interpolation transformer model that can utilize bidirectional frame context to finish the interpolation of current frame also make sense. However, there are some critical weaknesses and questions listed below.",
                "Strengths And Weaknesses": "Strengths:\n\nThe proposed multi-frame-rate hierarchical training has the potential on the text-to-video generation, especially the idea of frame interpolation transformer model that can utilize the bidirectional frame context to generate immediate frame. It indeed looks a promising solution to handle long video generation given a text input.\nThe proposed CogVideo inherits the parameters of a pre-trained text-to-image models and avoid the expensive pre-training from scratch. \nIn addition, the authors claim that they will open-source the proposed large-scale text-to-video generation model. This is another contribution to the community.\n\nWeaknesses:\n\nIn the main experiment results in Table 1, it seems that CogVideo obviously underperforms TATS-base [9] on UCF-101 dataset and TriVD-GAN-FP [16] on Kinetics-600. This conflicts with the claim in abstract. Is that due to the issue of metric itself or other reasons? Could you explain more about results in Table 1 since I cannot find related information in the main text?\nIt is not clear how much the temporal attention channel contributes to the performance gains of CogVideo. In the ablation study, it does not include the comparison of with/without temporal attention layer, i.e., compare the performance gap of directly fine-tuning CogView2\u2019s weights and keeping CogView2\u2019s weights frozen while tuning the temporal attention layer.\nThe qualitative evaluation only includes one case analysis, it would be more convincing to provide more visualized comparison between different variants. Since the visualization samples are much more intuitive than evaluation metrics to directly judge the real performance of the model.",
                "Questions": "Questions for the authors:\n\nWhy are there no detailed analysis about main experimental results in Table 1 in the main text of the paper?\nIt seems there are only an ablation study on Kinetics-600. Why not including the ablation study on UCF-101 datasets in Section 5.3? It would be more convincing to cover the comparison results on UCF-101.\nIn Figure 7, it looks there is no obvious performance gap between (a) and (e). Thus, what\u2019s the advantage of hierarchical generation from the perspective of visualization results, not just in human evaluation results. Could you provide more visualized case analysis in appendix later to justify the superior performance of your proposed method?\nIn Section 3.2, Is the restricted receptive field formulation in Eq. 4 like the 3D nearby attention mechanism in NUWA [36]? If yes, what\u2019s the difference between two?\nHow many seconds do the longest videos that your method generate can last? In my understanding, this is the key advantage of the hierarchical generation framework.\nHow to understand the recursive process of hierarchical generation? Do you mean that immediate interpolated (generated) frames at each iteration will be used to generate new immediate frames between previous ones? Why not directly generating all immediate frames at once?\n\nMinor issues:\n\nCould you please add a citation or hyperlink for DeepSpeed in the paper later? Since it is a great work in the community, you should mention it at least.\nGrammar error in Line 287, \u201csamples generated hierarchically performs\u2026\u201d => \u201csamples \u2026 perform \u2026\u201d.",
                "Limitations": "The major limitation is that how long the generated videos by the proposed CogVideo can last. The submitted demos show that the generated videos can only last several seconds. It would be more exciting that CogVideo can generate longer videos for given text input.",
                "Ethics Flag": "Yes",
                "Ethics Review Area": "Discrimination / Bias / Fairness Concerns",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper is the first work to propose an open-source pretrained transformer to solve the text-to-video task. The authors propose a two-stage framework CogVideo by finetuning a text-to-image model and avoid pretraining from scratch to reduce the training cost. The idea of multi-frame-rate ensures the flexibility and accuracy of the generated video. Experiments and visualized samples show the effectiveness of the method on video generating.",
                "Strengths And Weaknesses": "\uff081\uff09Strengths\uff1a\nThe paper proposes the pretrained two-stage Sequential Generation and Recursive Interpolation pipeline and better reconstruct the alignment relation in a video. And the two-stage method does help the model converge better and faster, which is proved by the line chart of training loss shown in the ablation studies. I think the CogVideo pipeline has its value in real-world application scenarios. Also, the paper is well writing.\n\uff082\uff09Weaknesses:\n-First, the paper is not the first attempting to investigate hierarchical transformer structure in text-to-video challenge. For example, [1] also exploits autoregressive and interpolation transformers and gain better performance on UCF-101. However, the authors do not explain the difference or innovation compared with [1].\n-The authors have claimed that the CogVideo pipeline can solve the text-to-video generation in the general domain, but the experiment results in tab.1 are all attained on human action video datasets( UCF-101 and Kinetics-600), which maybe somewhat weak to prove the above conclusion. I guess maybe general domain represents the motions in the text have some temporal relation. If the concept of general domain can be defined in the paper, it will be much better.\n[1] S. Ge, T. Hayes, H. Yang, X. Yin, G. Pang, D. Jacobs, J.-B. Huang, and D. Parikh. Long video generation with time-agnostic vqgan and time-sensitive transformer. arXiv preprint arXiv:2204.03638, 2022",
                "Questions": "1)Is the fps a learnable parameter or a hyper-parameter? And how to use the fps token concretely in the transformer?\n2)Compared with other training method, does CogVideo accelerate the training process? What environment and how much time does the training process need?\n3)Compared with the 1-Stage finetuned CogVideo model, how does the full model deal with the problem that one generated frame in the sequential generation stage collapses and influences the later frames? I do not have any idea that the two stage pipeline can solve this problem.",
                "Limitations": "No.\nAnd I do not see any serious concerns.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "In this paper, the authors propose a large-scale pre-training model for text-to-video generation, called CogVideo, which is trained by inheriting a pre-trained text-to-image model CogView2. A multi-frame-rate hierarchical training strategy is designed to better align text and video clips. The proposed method is validated on standard benchmarks such as UCF-101 and Kinetics-600.",
                "Strengths And Weaknesses": "Strengths:\n1.This work explores an important topic - text-conditional video generation, and presents an effective method for it.\n2.A multi-frame-rate hierarchical training strategy is proposed to improve the generation quality and control the intensity of changes during generation.\n3.The authors verified the proposed model through both quantitative experiments and qualitative analyses.\nWeaknesses:\n1.The novelty and technical contributions of this work are quite limited. It simply assembles several existing algorithms, such as CogView2 [6] and Swin Transformer [14].\n2.The performance of the proposed CogVideo is not as strong as the authors claimed. As shown in Tab. 1, the metrics of CogVideo (IS and FVD) fall behind previous methods. It is not acceptable to only compare with publicly available models.\n3.The authors trained the CogVideo on a large dataset of 5.4 million captioned videos, but did not give any detailed information regarding this dataset. What are the sources of the videos and captions? How are they collected? Will the dataset be released? \n4.The authors claimed that they greatly enhance parallelism and accelerate inference, but no results about inference speed of the CogVideo model are provided.\n5.In Sec. 5.1, the authors \"fine-tune CogVideo on the whole dataset (UCF-101) for 10,000 iterations\". Is it appropriate in this field?",
                "Questions": "1.The authors should explain the novelty and contributions of the proposed CogVideo.\n2.The performance of CogVideo is not as competitive as claimed. The authors should give more discussions and analyses.\n3.More details about the dataset with 5.4 million captioned videos are expected.",
                "Limitations": "Yes, the authors adequately addressed the limitations and potential negative societal impact of the work.",
                "Ethics Flag": "No",
                "Ethics Review Area": "I don\u2019t know",
                "Soundness": "2 fair",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposed a large-scale pretrained text-to-video model and multi-frame-rate hierarchical training strategy to better align text and video clips.",
                "Strengths And Weaknesses": "The strengths of this paper are as follows:\n\nThis paper is well written and easy to follow.\nThe proposed model is the largest and the first open-source pre-trained transformer for text-to-video generation in the general domain.\nThe experimental results show that the proposed methods can outperform a number of existing baselines.\n\nThe weaknesses of this paper are as follows:\n\nThe main limitation of the work is the huge consumption of GPU memory, but the related information (type and number of GPU) is not provided. I hope this information can be given.\n\nI am not an expert in this field and do not tap into DALL-E and CogView, I will adjust the final score with other reviewers' comments and the response from the author.",
                "Questions": "Is there a gap between the generated video and the ground truth, so ground truth is not placed in human evaluation for comparison?\n\nI wonder whether the mixture factor /alpha will finally converge to 0 or 1, making the dual-channel attention block useless.",
                "Limitations": "None",
                "Ethics Flag": "Yes",
                "Ethics Review Area": "Discrimination / Bias / Fairness Concerns, Privacy and Security (e.g., consent)",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "soundness_avg": 2.5,
        "presentation_avg": 2.5,
        "contribution_avg": 2.5,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, the paper proposes a large-scale pre-training model called CogVideo for text-to-video generation. The proposed multi-frame-rate hierarchical training strategy and the use of a dual-attention channel show promise in addressing the challenges of aligning text and video clips. The paper has strengths in its potential impact, the use of pre-trained models, and the plan to open-source the proposed model. However, there are weaknesses in the performance comparison with existing methods, the lack of detailed analysis of experimental results, and the limited novelty of the proposed approach. The reviewers have raised valid questions and concerns regarding the experimental results, the comparison with related work, the dataset used, and the training process. Overall, while the paper has technical flaws and limitations, it is considered to be technically solid with moderate-to-high impact. Therefore, I recommend accepting the paper."
    },
    "Computational_Doob_h-transforms_for_Online_Filtering_of_Discretely_Observed_Diffusions": {
        "link": "https://openreview.net//forum?id=7yvu4qOKtn1",
        "pub_url": "https://openreview.net/forum?id=7yvu4qOKtn1",
        "pdf_link": "https://openreview.net//pdf?id=7yvu4qOKtn1",
        "paper_id": "7yvu4qOKtn1",
        "title": "Computational_Doob_h-transforms_for_Online_Filtering_of_Discretely_Observed_Diffusions",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Less certain\nThis is an interesting paper, but it also requires some additional work. The paper received mixed responses from the reviewers, but the main concerns were sorted out during the rebuttal and discussion. In the end, the reviewers ended up (weakly) recommending acceptance after the authors promised an extensive number of changes to the paper in the camera-ready stage. However, the promised changes appear very extensive and beyond what would be expected for a typical NeurIPS paper (list below). The authors have provided links to plots in the discussion, but have not revised the paper in OpenReview. Sorting out the issues counts as a 'major revision' and the conference review process does not recognise such a concept.\nList of changes (based on rebuttals):\n\nEmpirical comparison (& discussion) to GIRF instead of only bootstrap particle filter\nAdding a discussion section to the end of the paper\nWriting a more thorough Related work section\nA study on the impact of growing dimensionality (OU process)\nPlots and discussion on the learned dynamics (control)\nPlots and discussion on training loss\nA more intuitive explanation of the Doob's h-transform in the Background section\nExpanded Introduction to discuss applications (with references)\nComputational cost discussion (promised to add to the appendix)\nFigures illustrating Doob\u2019s h-transform trajectories\nDiscussion on how fine discretization is needed\nDiscussion on parameter inference and the smoothing problem\nDiscussion on irregular observation intervals",
        "reviews": [
            "Reviewer 1: \nSummary: Disclaimer: I am not expert in SDE theory so my review will focus on the high level and clarity.\nThe authors are interested in the filtering problem in SDEs, i.e. computing the conditional distributions x_t|y<t, with x the latent process and y the observations.\nThe focus is on particule filtering, where the filtering distribution is approximated via discrete particules.\nIn particule filtering, a guiding function q or proposal is used to propagate the values of the particules in time.\nA convenient guide is the 'Fully Adapted Auxiliary Particle Filter' which samples from the conditional p(x_t+1|y_t+1, x_t).\nDoob's theorem happens to give an expression for the SDE corresponding to this conditional p(x_t+1|y_t+1, x_t), which shares the same\ndiffusion as the a priori SDE and whose drift function is equal to the prior drift function plus an offest, or control function. \nSampling from this SDE for starting point x_t would give the desired sample of p(x_t+1|y_t+1, x_t) for the purpose of particule filtering\nThe authors propose an algorithm to find learn this control function c, without having to have to first solve a PDE first.\nThis function and the prior density is parameterized by neural network.\nAn objective is proposed to learn the control function.\nAn algorithm is proposed to optimize this objective.\nThe algorithm is evaluated to check the validity of the learned control in toy settings and in Particle filtering scenarios.\nStrengths And Weaknesses: I find the proposed manuscript is well motivated.\nThe background on particule filtering is clear.\nMy SDE theory is less developed but I don't understand section 2.5,\nnot even at a high level. As a result I m not sure I trust the content of section 3.1 (the loss and algorithm)\nI m possibly not the best reviewer (hence the low confidence) \nbut I also think clarity could be greatly improved (see below).\nQuestions: Some comments / questions:\ntwo related comments first\n\neta_x should depend on the conditioning end observation. \nIf you drop this dependency, you are not sampling from the conditioned SDE. \nIn your experiment (L252), you drop this dependency. Is this a typo, a design choice, an approximation?\n\nL159: \"In practice, we will let the three sources of randomness be independent of each other.\"\nWhat is lost with that approximation (is it an approximation)? If you choose T large, then the process reverts to the prior (independent of Y), stationary distribution of the uncontrolled SDE.\nIs it what you do?\n\nThe result section, shows that the learned control matches the exact control on a linear SDE scenario.\nMany details are missing, an appendix with those would be great. \nas a reader, I don't want to have to fill all the gaps. Even less as a reviewer.\nFor example, for OU, you could give the exact expression for h, and v.\n\nThe proposed objective seems to contain the control on both side of the square loss, the V_T and the log g(..).\nI do not really understand or see why the optimal control is a minimizer of objective.\nIt also feels like hitting a moving target.\n\nIt would be good to have a discussion of this optimization problem.\nFor example, how do the dynamics of learning look like?\n\nCould you be more precise on which variables you are taking expectations over and why?\nThis is important for the loss.\n\nAlso could you give a justification for the 'stop gradient' comment?\nYou have a loss that has multiple dependence on c and you decide to only propagate through one part.\n\nCDT algorithm, it would help to have a more detailed pseudo code for the algorithm.\n\nDoob's transform: I suggest you either give more details or remove the sketch from the main paper. As is it is not useful.\n\nWhere is the conclusion? It is good to end a paper with the conclusion summarizing the method and results.\nLimitations: None\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper addresses the task of online filtering for discretely observed nonlinear diffusion approaches. The paper proposes a method based on the fully adapted auxiliary particle filter (FA-APF). The paper discusses how a control function can be used to construct a controlled diffusion that takes into account a future observation. The desired control function is related to Doob\u2019s h-transform and can be obtained by solving the backward Kolmogorov equations. This is computationally intractable, so the proposed strategy is to work with the value function (the negative log of h). The optimal control can then be expressed in terms of the value function and approximated with neural networks. These networks can be trained by simulating the controlled diffusion trajectories. After training, the online filtering can be performed using the approximately optimal control. \nThe paper presents numerical results for three models: an Ornstein-Uhlenbeck model, a logistic diffusion model, and a cell model. The results are compared to a bootstrap particle filter. For the Ornstein-Uhlenbeck model, which is analytically tractable, there is also comparison with the exact APF. There superiority of the proposed method is clear in all three examples.\nStrengths And Weaknesses: Strengths\n1.\tThe paper addresses the important problem of online inference for diffusion processes (although it doesn\u2019t make a compelling case as to why this problem is important) and provides an elegant algorithm for performing the filtering. To the best of my knowledge, this represents a novel approach to solving this problem and I would rate it as a highly original approach. I think the work could have a significant impact on research addressing online inference for diffusion processes.  \n\n   The paper is very well written. The material is relatively dense, but the authors do an excellent job of providing a clear description of the algorithm. It is developed step-by-step in an intuitive manner.\n\nWeaknesses\n1.\tRelated work and performance comparison: there is very little discussion of existing methods for filtering partially observed diffusions. Multiple methods are acknowledged (and dismissed) with the single sentence \u201cSpecialized methodologies have been developed to circumvent or mitigate these issues.\u201d Other methods like [R1] are ignored. \nEven if some of the methods are more limited in their applicability, there should have been an effort to compare with them experimentally for examples where they are applicable. Some discussion of the limitations of existing work should be included in the paper. \n\n   Motivation: The paper does not provide a compelling motivation for the analyzed problem. There are very general claims about the ubiquity of diffusion processes in the first few sentences but no citations to any literature to support these claims. There are no citations of work providing more practical examples of where the proposed filtering problem would prove beneficial. The studied examples, while providing a good illustration of the benefits of the technique, do not provide compelling evidence of the practical utility. The cell model and the logistic diffusion model for population size dynamics do not seem suited to a meaningful, practical filtering task.\n\n   Experimental analysis: There is no performance comparison to any methods except for the basic bootstrap particle filter. There have been multiple approaches to address the filtering task, so there should either be a clear explanation as to why existing approaches are inapplicable or other methods should be included. I could not find the details of exactly how many particles are used in the simulations (apart from the specification that it increases linearly with K). This seems to be an important design choice and there should be an explanation as to how the value was selected. Preferably there should be an analysis of how performance changes with varying K. There is no reporting of computational requirements. It is not clear if the proposed filter and the BPF have the same (or very similar) computations. Presumably there are additional neural network evaluations for the proposed scheme, but these may be negligible compared to other computational overhead. If they are non-negligible, then a fairer comparison would use more particles for the BPF.\n\n\n[R1] Jasra, A., Law, K. J., & Yu, F. (2020). Unbiased filtering of a class of partially observed diffusions. Advances in Applied Probability, 1-27.\nQuestions: \n   How many particles were used in the experiments (or what was the scaling factor with K)? Why was this value chosen? What is the sensitivity to this choice? Is it possible to achieve improved performance with more particles or is the computational burden already considerable, i.e. if I were trying to implement a real-time system with a reasonably powerful computer, with a reasonable time between observations, how many particles could I use?\n\n   What is the computational overhead? How does the computation of the proposed method compare to the BPF? What are the key contributors to the computational burden? \n\n   What are the state-of-the-art competing techniques? Why are these not considered in a quantitative performance comparison? Are methods like [R1] inapplicable for the studied settings?\nLimitations: Yes.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The paper presents a novel method for online filtering where the latent process has a higher frequency than the observations. The authors define an algorithm, Computational Doob\u2019s h-Transform, for iteratively learning a control function over the latent space and an observation to drive a stochastic process to a specific point at time T. The learned control function is then later applied in online filtering, where no further learning is required but the controlled dynamics can be applied to compute the particle filtering weights and to propagate the particles. CDT is applied to low-dimensional settings in the experiments section, where it is compared to bootstrap particle filtering for nonlinear dynamics, and to the exact analytical solution when available.\nStrengths And Weaknesses: Strengths\n\nAn original method for learning a control function for particle filtering using a Doob\u2019s h-transform\nSeparation of learning the control and the filtering itself is an attractive idea for improving efficiency \nThe work is reproducible (the code was provided and I was able to run it)\n\nWeaknesses\n\nLimitations and related work were not discussed enough, the paper would have benefited from a well-structured Conclusions/Discussion \n  section at the end instead of scattered remarks. It was not clear to me how the method presented compares to earlier work. \nWhile I agree that covering the theory in detail is well justified, having three pages of background section would have been more \n  comfortable to read if there was more text motivating why the topics covered are important or intuitive/heuristic explanations. \nThe convergence properties of the iterative scheme were not studied empirically or theoretically, I was not able to develop an intuition \ninto how the control behaves at iteration 1 versus iteration N.\nLow dimensional experiments, only comparisons to a simple baseline method (bootstrap particle filter) and not to more recent work\nThe figures were focused on presenting error metrics, the behaviour of the learned control or the filtering distribution were hardly \n  visualized\nQuestions: Questions\n\nOn the iterative method: how many iterations of the iterative method were required until satisfactory results/convergence? Can you \n   point to any theoretical results or give heuristics on the behaviour of the learned control through the iterative method? \nOn dimensionality: How does the method scale when the dimensionality of the problem is changed? I\u2019m concerned of the learning of \nthe control function, and how representative is the sampling scheme for observations during training when the problem is high- \n   dimensional\nOn experiments; Do they present a fair comparison? Is there some more recent work than bootstrap filters you could compare to in the \nexperiment settings where no analytical solution is available?\nOn training of neural networks; Did training the initial value and control networks simultaneously present any issues? \t\nOn the loss function: the loss function considers only the final state of the value function. Was no regularization needed on the \ndynamics? Why, and are there some cases where it would be beneficial?\nOn the observations: There is a comment in the experiments section (Line 242) that the results are not sensitive to choice of T as long \n as the discretization has a small enough step size. What is small enough? A heuristic explanation/plot showing how long it takes the \ncontrol to steer to the observation would have been informative.\nOn clarity of text: (minor) some parts of the text had, to my knowledge, a number of typos and issues with grammar and notation. In \n addition, there was some vague phrasing. Please consider going through the following lines\n\nLines to check:\nLine 13-14: applications listed, but no references provided\nLine 21: \u201cis collected\u201d while referring to multiple observations\nLine 29-30: \u201cthe goal of the article is\u2026\u201d This sentence felt too vague on my initial read\nLine 33: \u201cthese quantities\u201d which quantities are you referring to here? Only the control function has been referred to so far \nLine 37: Efficient in what sense? \nLine 44: \u201can homogenous\u201d should be \u201ca\u201d?\nLine 68: comma before while\nEquation 4: why p_T? It is confusing to the reader in the case k> 1. The notation makes sense after reading 88-90, but this equation is before that\nLine 136: \u201cIto lemma\u201d should be \u201cIto\u2019s lemma\u201d\nLine 143: Period missing from the last sentence of the paragraph.\nEquation 15: t is used as time on the left-hand size, but it is the integrated variable on the right-hand side\nLine 217: why is the control evaluated at t-t_k?\nLine 238: odd to say that all experiments had 10 observations, when nearly all experiments vary K?\nLine 248: why was it required to grow the number of samples when the number of observations grows? Does this mean that when K=1000, there were 100k samples (since there were 1k samples for K=10)\nLine 255: \u201cAnalytically tractability\u201d \nFigure 1: the figure text was quite vague, I didn\u2019t get what I should be concluding based on the plots? I can see that they somewhat match, but was there some additional insight I\u2019m missing here?\nFigure 2: The y-axis labels slightly overlap with the subplot borders\nLimitations: \nSocietal impact of the work was not discussed. As the paper is presenting theoretical work, it does not require a deeper investigation into such matters. \nScalability to higher dimensional problems and convergence of the iterative method were not sufficiently discussed or empirically tested, even though scalability to high-dimensional problems was explicitly stated as a motivating factor for not using standard numerical methods for solving PDEs (Line 126-128)\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper develops an approximation to the locally optimal particle filter in discretely observed diffusion processes under the assumption of a constant measurement rate.\nStrengths And Weaknesses: S1 - The method compares favourably to baseline solutions. \nW1 - Experiments are not entirely convincing. More specifically, only low-dimensional examples re considered (d <= 2), which undermines the rationale for their method in that we are not in a high-dimensional regime where numerical  solutions of PDEs become infeasible (paragraph 1 of sec 2.5). \nW2 - The method relies on fixed SDE dynamics so is not applicable to parameter inference. \nW3 - The method relies on constant sample rate, which is many times infeasible in practice due to e.g. missing measurements.\nQuestions: Q1 - The difference between CDT static scheme and bootstrap proposals needs to be elucidated. Choosing c = 0 yield the original SDE dynamics, i.e. bootstrap proposals, no?\nLimitations: Its fine.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "Disclaimer: I am not expert in SDE theory so my review will focus on the high level and clarity.\nThe authors are interested in the filtering problem in SDEs, i.e. computing the conditional distributions x_t|y<t, with x the latent process and y the observations.\nThe focus is on particule filtering, where the filtering distribution is approximated via discrete particules.\nIn particule filtering, a guiding function q or proposal is used to propagate the values of the particules in time.\nA convenient guide is the 'Fully Adapted Auxiliary Particle Filter' which samples from the conditional p(x_t+1|y_t+1, x_t).\nDoob's theorem happens to give an expression for the SDE corresponding to this conditional p(x_t+1|y_t+1, x_t), which shares the same\ndiffusion as the a priori SDE and whose drift function is equal to the prior drift function plus an offest, or control function. \nSampling from this SDE for starting point x_t would give the desired sample of p(x_t+1|y_t+1, x_t) for the purpose of particule filtering\nThe authors propose an algorithm to find learn this control function c, without having to have to first solve a PDE first.\nThis function and the prior density is parameterized by neural network.\nAn objective is proposed to learn the control function.\nAn algorithm is proposed to optimize this objective.\nThe algorithm is evaluated to check the validity of the learned control in toy settings and in Particle filtering scenarios.",
                "Strengths And Weaknesses": "I find the proposed manuscript is well motivated.\nThe background on particule filtering is clear.\nMy SDE theory is less developed but I don't understand section 2.5,\nnot even at a high level. As a result I m not sure I trust the content of section 3.1 (the loss and algorithm)\nI m possibly not the best reviewer (hence the low confidence) \nbut I also think clarity could be greatly improved (see below).",
                "Questions": "Some comments / questions:\ntwo related comments first\n\neta_x should depend on the conditioning end observation. \nIf you drop this dependency, you are not sampling from the conditioned SDE. \nIn your experiment (L252), you drop this dependency. Is this a typo, a design choice, an approximation?\n\nL159: \"In practice, we will let the three sources of randomness be independent of each other.\"\nWhat is lost with that approximation (is it an approximation)? If you choose T large, then the process reverts to the prior (independent of Y), stationary distribution of the uncontrolled SDE.\nIs it what you do?\n\nThe result section, shows that the learned control matches the exact control on a linear SDE scenario.\nMany details are missing, an appendix with those would be great. \nas a reader, I don't want to have to fill all the gaps. Even less as a reviewer.\nFor example, for OU, you could give the exact expression for h, and v.\n\nThe proposed objective seems to contain the control on both side of the square loss, the V_T and the log g(..).\nI do not really understand or see why the optimal control is a minimizer of objective.\nIt also feels like hitting a moving target.\n\nIt would be good to have a discussion of this optimization problem.\nFor example, how do the dynamics of learning look like?\n\nCould you be more precise on which variables you are taking expectations over and why?\nThis is important for the loss.\n\nAlso could you give a justification for the 'stop gradient' comment?\nYou have a loss that has multiple dependence on c and you decide to only propagate through one part.\n\nCDT algorithm, it would help to have a more detailed pseudo code for the algorithm.\n\nDoob's transform: I suggest you either give more details or remove the sketch from the main paper. As is it is not useful.\n\nWhere is the conclusion? It is good to end a paper with the conclusion summarizing the method and results.",
                "Limitations": "None",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper addresses the task of online filtering for discretely observed nonlinear diffusion approaches. The paper proposes a method based on the fully adapted auxiliary particle filter (FA-APF). The paper discusses how a control function can be used to construct a controlled diffusion that takes into account a future observation. The desired control function is related to Doob\u2019s h-transform and can be obtained by solving the backward Kolmogorov equations. This is computationally intractable, so the proposed strategy is to work with the value function (the negative log of h). The optimal control can then be expressed in terms of the value function and approximated with neural networks. These networks can be trained by simulating the controlled diffusion trajectories. After training, the online filtering can be performed using the approximately optimal control. \nThe paper presents numerical results for three models: an Ornstein-Uhlenbeck model, a logistic diffusion model, and a cell model. The results are compared to a bootstrap particle filter. For the Ornstein-Uhlenbeck model, which is analytically tractable, there is also comparison with the exact APF. There superiority of the proposed method is clear in all three examples.",
                "Strengths And Weaknesses": "Strengths\n1.\tThe paper addresses the important problem of online inference for diffusion processes (although it doesn\u2019t make a compelling case as to why this problem is important) and provides an elegant algorithm for performing the filtering. To the best of my knowledge, this represents a novel approach to solving this problem and I would rate it as a highly original approach. I think the work could have a significant impact on research addressing online inference for diffusion processes.  \n\n   The paper is very well written. The material is relatively dense, but the authors do an excellent job of providing a clear description of the algorithm. It is developed step-by-step in an intuitive manner.\n\nWeaknesses\n1.\tRelated work and performance comparison: there is very little discussion of existing methods for filtering partially observed diffusions. Multiple methods are acknowledged (and dismissed) with the single sentence \u201cSpecialized methodologies have been developed to circumvent or mitigate these issues.\u201d Other methods like [R1] are ignored. \nEven if some of the methods are more limited in their applicability, there should have been an effort to compare with them experimentally for examples where they are applicable. Some discussion of the limitations of existing work should be included in the paper. \n\n   Motivation: The paper does not provide a compelling motivation for the analyzed problem. There are very general claims about the ubiquity of diffusion processes in the first few sentences but no citations to any literature to support these claims. There are no citations of work providing more practical examples of where the proposed filtering problem would prove beneficial. The studied examples, while providing a good illustration of the benefits of the technique, do not provide compelling evidence of the practical utility. The cell model and the logistic diffusion model for population size dynamics do not seem suited to a meaningful, practical filtering task.\n\n   Experimental analysis: There is no performance comparison to any methods except for the basic bootstrap particle filter. There have been multiple approaches to address the filtering task, so there should either be a clear explanation as to why existing approaches are inapplicable or other methods should be included. I could not find the details of exactly how many particles are used in the simulations (apart from the specification that it increases linearly with K). This seems to be an important design choice and there should be an explanation as to how the value was selected. Preferably there should be an analysis of how performance changes with varying K. There is no reporting of computational requirements. It is not clear if the proposed filter and the BPF have the same (or very similar) computations. Presumably there are additional neural network evaluations for the proposed scheme, but these may be negligible compared to other computational overhead. If they are non-negligible, then a fairer comparison would use more particles for the BPF.\n\n\n[R1] Jasra, A., Law, K. J., & Yu, F. (2020). Unbiased filtering of a class of partially observed diffusions. Advances in Applied Probability, 1-27.",
                "Questions": "How many particles were used in the experiments (or what was the scaling factor with K)? Why was this value chosen? What is the sensitivity to this choice? Is it possible to achieve improved performance with more particles or is the computational burden already considerable, i.e. if I were trying to implement a real-time system with a reasonably powerful computer, with a reasonable time between observations, how many particles could I use?\n\n   What is the computational overhead? How does the computation of the proposed method compare to the BPF? What are the key contributors to the computational burden? \n\n   What are the state-of-the-art competing techniques? Why are these not considered in a quantitative performance comparison? Are methods like [R1] inapplicable for the studied settings?",
                "Limitations": "Yes.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper presents a novel method for online filtering where the latent process has a higher frequency than the observations. The authors define an algorithm, Computational Doob\u2019s h-Transform, for iteratively learning a control function over the latent space and an observation to drive a stochastic process to a specific point at time T. The learned control function is then later applied in online filtering, where no further learning is required but the controlled dynamics can be applied to compute the particle filtering weights and to propagate the particles. CDT is applied to low-dimensional settings in the experiments section, where it is compared to bootstrap particle filtering for nonlinear dynamics, and to the exact analytical solution when available.",
                "Strengths And Weaknesses": "Strengths\n\nAn original method for learning a control function for particle filtering using a Doob\u2019s h-transform\nSeparation of learning the control and the filtering itself is an attractive idea for improving efficiency \nThe work is reproducible (the code was provided and I was able to run it)\n\nWeaknesses\n\nLimitations and related work were not discussed enough, the paper would have benefited from a well-structured Conclusions/Discussion \n  section at the end instead of scattered remarks. It was not clear to me how the method presented compares to earlier work. \nWhile I agree that covering the theory in detail is well justified, having three pages of background section would have been more \n  comfortable to read if there was more text motivating why the topics covered are important or intuitive/heuristic explanations. \nThe convergence properties of the iterative scheme were not studied empirically or theoretically, I was not able to develop an intuition \ninto how the control behaves at iteration 1 versus iteration N.\nLow dimensional experiments, only comparisons to a simple baseline method (bootstrap particle filter) and not to more recent work\nThe figures were focused on presenting error metrics, the behaviour of the learned control or the filtering distribution were hardly \n  visualized",
                "Questions": "Questions\n\nOn the iterative method: how many iterations of the iterative method were required until satisfactory results/convergence? Can you \n   point to any theoretical results or give heuristics on the behaviour of the learned control through the iterative method? \nOn dimensionality: How does the method scale when the dimensionality of the problem is changed? I\u2019m concerned of the learning of \nthe control function, and how representative is the sampling scheme for observations during training when the problem is high- \n   dimensional\nOn experiments; Do they present a fair comparison? Is there some more recent work than bootstrap filters you could compare to in the \nexperiment settings where no analytical solution is available?\nOn training of neural networks; Did training the initial value and control networks simultaneously present any issues? \t\nOn the loss function: the loss function considers only the final state of the value function. Was no regularization needed on the \ndynamics? Why, and are there some cases where it would be beneficial?\nOn the observations: There is a comment in the experiments section (Line 242) that the results are not sensitive to choice of T as long \n as the discretization has a small enough step size. What is small enough? A heuristic explanation/plot showing how long it takes the \ncontrol to steer to the observation would have been informative.\nOn clarity of text: (minor) some parts of the text had, to my knowledge, a number of typos and issues with grammar and notation. In \n addition, there was some vague phrasing. Please consider going through the following lines\n\nLines to check:\nLine 13-14: applications listed, but no references provided\nLine 21: \u201cis collected\u201d while referring to multiple observations\nLine 29-30: \u201cthe goal of the article is\u2026\u201d This sentence felt too vague on my initial read\nLine 33: \u201cthese quantities\u201d which quantities are you referring to here? Only the control function has been referred to so far \nLine 37: Efficient in what sense? \nLine 44: \u201can homogenous\u201d should be \u201ca\u201d?\nLine 68: comma before while\nEquation 4: why p_T? It is confusing to the reader in the case k> 1. The notation makes sense after reading 88-90, but this equation is before that\nLine 136: \u201cIto lemma\u201d should be \u201cIto\u2019s lemma\u201d\nLine 143: Period missing from the last sentence of the paragraph.\nEquation 15: t is used as time on the left-hand size, but it is the integrated variable on the right-hand side\nLine 217: why is the control evaluated at t-t_k?\nLine 238: odd to say that all experiments had 10 observations, when nearly all experiments vary K?\nLine 248: why was it required to grow the number of samples when the number of observations grows? Does this mean that when K=1000, there were 100k samples (since there were 1k samples for K=10)\nLine 255: \u201cAnalytically tractability\u201d \nFigure 1: the figure text was quite vague, I didn\u2019t get what I should be concluding based on the plots? I can see that they somewhat match, but was there some additional insight I\u2019m missing here?\nFigure 2: The y-axis labels slightly overlap with the subplot borders",
                "Limitations": "Societal impact of the work was not discussed. As the paper is presenting theoretical work, it does not require a deeper investigation into such matters. \nScalability to higher dimensional problems and convergence of the iterative method were not sufficiently discussed or empirically tested, even though scalability to high-dimensional problems was explicitly stated as a motivating factor for not using standard numerical methods for solving PDEs (Line 126-128)",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper develops an approximation to the locally optimal particle filter in discretely observed diffusion processes under the assumption of a constant measurement rate.",
                "Strengths And Weaknesses": "S1 - The method compares favourably to baseline solutions. \nW1 - Experiments are not entirely convincing. More specifically, only low-dimensional examples re considered (d <= 2), which undermines the rationale for their method in that we are not in a high-dimensional regime where numerical  solutions of PDEs become infeasible (paragraph 1 of sec 2.5). \nW2 - The method relies on fixed SDE dynamics so is not applicable to parameter inference. \nW3 - The method relies on constant sample rate, which is many times infeasible in practice due to e.g. missing measurements.",
                "Questions": "Q1 - The difference between CDT static scheme and bootstrap proposals needs to be elucidated. Choosing c = 0 yield the original SDE dynamics, i.e. bootstrap proposals, no?",
                "Limitations": "Its fine.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "soundness_avg": 3.0,
        "presentation_avg": 2.75,
        "contribution_avg": 2.75,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is clear that the proposed method in this paper is technically solid and has the potential for moderate-to-high impact. The authors have addressed an important problem in online filtering for diffusion processes and have provided an elegant algorithm for performing the filtering. The method compares favorably to baseline solutions and the experiments demonstrate its effectiveness.\n\nHowever, there are some limitations and weaknesses that should be addressed. The paper would benefit from a more thorough discussion of related work and a clearer motivation for the problem being addressed. The experiments are limited to low-dimensional examples, which undermines the rationale for the method in high-dimensional regimes. The method also relies on fixed SDE dynamics and a constant sample rate, which may not be feasible in practical scenarios.\n\nOverall, the strengths of the paper outweigh the weaknesses, and the proposed method has the potential to make a significant impact in the field. Therefore, I recommend accepting the paper."
    },
    "Fairness_for_Workers_Who_Pull_the_Arms:_An_Index_Based_Policy_for_Allocation_of_Restless_Bandit_Tasks": {
        "link": "https://openreview.net//forum?id=uCXNOeL0TG",
        "pub_url": "https://openreview.net/forum?id=uCXNOeL0TG",
        "pdf_link": "https://openreview.net//pdf?id=uCXNOeL0TG",
        "paper_id": "uCXNOeL0TG",
        "title": "Fairness_for_Workers_Who_Pull_the_Arms:_An_Index_Based_Policy_for_Allocation_of_Restless_Bandit_Tasks",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nThis paper looks at the restless MAB (RMAB) problem through the lens of fairness, an increasingly-active area over the last few years.  This works generalizations to fairness (over the arms that are pulled) but spread out across multiple workers who are pulling the arms.  This is a well-motivated setting, and one that might see application in various mobile-health-related scenarios that are popular in this space, and where the ML community has a presence.  Still, reviewers raised many questions about theoretical bounds for cases under the purview of the settings investigated.  We would appreciate a stronger rebuttal and/or stronger edits to a camera-ready or next submission for this work.",
        "reviews": [
            "Reviewer 1: \nSummary: The authors study the problem of multi-worker restless bandits, that extends the standard restless bandits having different costs and fairness constraints on different actions. The authors propose a scheme that at first decouples the problem and than, using the decoupled solutions, introduce the interaction with other workers. Finally, some experiments comparing the proposed algorithm to the ones present in the literature (which do not include the fairness constraint) are provided.\nStrengths And Weaknesses: The paper is well structured and the definition of the steps taken to get to the solution is helping the reader to understand the idea behind the paper. There are a few ortographic mistakes. The topic is interesting and the solution is well motivated empirically.\nI have some doubts about the real formulation of some of the results and the strenght of the theoretical results provided.\nMinor:\nLine 99: \"M=1\" I got the idea, but i think that the more formal statement would be c_ij = c_ih=1 \\forall j,h \\in [M]\nLine 130: It is not clear the statement. Is it \"by relying on the work by qian et al.\"? Or is it a derivation from the previous work?\nLine 283: Please provide the rationale behind the choice of B)18.\nLine 297: The -> the\nFigure 4: I suggest to rearrange the subplots and the table, to better explain the results therein.\nQuestions: It is not clear to me if the solution you provided is solving the original problem or if it is an approximate solution. In the former case, I would like to have a formal statement about that, in the latter case a study on the approximation gap.\nIs Theorem 3 only predicating on those instances having that all the workers are of the same type? I would like to understand if in this theorem we are restricting to a specific case or not.\nLimitations: I do not foresee limitations and potential negative societal impacts. The paper is focused on the idea to make the work allocation task fair, therefore at the moment i only see positive impacts on society.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper considers a multi-worker version of the restless multi-armed bandit problem where the intervention on a particular arm can be carried out by one of M possible workers. The workers have possibly different costs for intervening on different arms and the goal is to design an optimal allocation policy that satisfies budget constraint for each worker and also fair. \u2028\nThe authors devise a heuristic balanced allocation rule for the problem. The main idea behind the algorithm is to decompose the original problem into several related subproblems. The experiments show that the proposed heuristic scales with the number of agents without compromising too much on the objective.\nStrengths And Weaknesses: Strengths:\n\nI think the multi-worker extension of the restless multi-armed bandit problem is an interesting direction and certainly more practical.\nThe empirical section is interesting as the authors could show that the proposed approximation algorithm runs fast for a large number of agents (N is of the order of hundreds) and the performance doesn't deteriorate much.\n\nWeaknesses:\n\nThe main weakness of the paper is the lack of proper theoretical guarantees. First, it is not clear if you can decompose the original problem~(2) into N\u00d7M subproblems because of the additional fairness constraint. Second, the main result also shows that the proposed algorithm works only for homogeneous workers (theorem 3) and it's not clear if the balanced allocation works when the costs are heterogeneous.\nEven if I assume that the problem is decomposable the authors don't bound fairness violation of the final solution. Note that fairness is a global constraint and the individual subproblems don't have this constraint. So it is not trivial to combine the solutions of these subproblems and ensure a desired level of fairness. \nFor the adjusted index algorithm it is not clear what is the right choice of the variables \u03bb\u2212j for each j. The authors justified that choosing \u03bb\u2212j=0 is not optimal, and chose these values based on Whittle indices. But I am not sure that should be optimal either because of heterogeneous costs and global constraints. Maybe you can solve for a fixed point of this system and use the fixed point as the adjusted indices?\n\nSome other comments:\n\nGive definition of indexability of arms.\nAt the end of section 3, the authors highlight two challenges for MWRMAB model. It might be a good idea to illustrate these challenges with an example.\nQuestions: \nThe original optimization problem (1 and 2) has the fairness constraint. However, this constraint is absent in the subproblem (3). How do you guarantee that solving each subproblem will automatically generate a fair solution?\n\nAlso I am not sure when solving each subproblem is sufficient to solve the original problem~(2). Do you have any result showing that you can obtain a solution of the original problem by solving the N\u00d7M subproblems?\n\nI don't understand why theorem 1 is useful. It seems to me this theorem is only used to derive Corollary 1 for the case of identical cost and probability transition function. But doesn't that directly follow from the nature of the optimization problem (3) by substituting identical cost and probability transition function?\n\nTheorem 3 states that the algorithm balanced allocation works only when the workers are homogeneous. But I thought the whole point of introducing the general framework was to handle workers with heterogeneous costs. Do you have any results for the setting with heterogeneous costs?\n\nThe balanced allocation takes fairness threshold \u03f5 as input. But as far as I can understand, the algorithm never explicitly uses this argument. It would be nice if you could clarify which step of the algorithm uses this parameter? Also regarding this, do you have any guarantee for the fairness guarantee obtained by the balanced allocation algorithm?\nLimitations: This paper doesn't have any negative societal impact.\nEthics Flag: No\nSoundness: 1 poor\nPresentation: 2 fair\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper considers constrained resource allocation tasks framed as restless bandit problems. In contrast to prior work in this space which assumes that all of the resources (i.e., healthcare workers, mechanics, etc.) to be allocated are interchangeable, the authors: (a) consider heterogeneous workers with individual/varied costs, budgets, and intervention effects; and (b) strive to optimally allocate arms to workers while ensuring the disparity in costs incurred by any two workers does not exceed a given threshold, \u03f5. To do this, the authors define an augmented action space, such that each worker is represented as a possible active action, with a corresponding worker-arm-specific cost function and transition matrix. They then decompose the problem and compute Whittle indices for each worker-arm combination. They use these Whittle indices to compute an adjusted index that reflects the minimum charge required to make the agent indifferent between an active action provided by worker j and one provided by any other worker j\u2032. They use the adjusted indices to inform budget- and fairness-constraint satisfying round-robin allocation of arms to workers.\nStrengths And Weaknesses: Strengths:\n\nThe paper is well-written and the extension to the RMAB setting that the authors propose (i.e., actions with arm-specific heterogenous costs and effectiveness) is well-motivated by many practical domains, such as healthcare, manufacturing, and wildlife conservation. The technical work required to extend the problem setting in this way is significant since one must now account for how workers with different (arm/state-specific) expertise may interact (and influence arms' transitions) over time.\n\nWeaknesses:\n\nArms' states and worker-specific transition matrices are assumed to be observable. While it is conventional to assume each arm's (worker-agnostic) transition matrix is known by the decision-maker in the planning setting, the assumption that this additional level of information is available should be explicitly stated and justified by the availability/\"learnability\" of this type of information within the domain(s) of interest. This will be particularly important in settings where there is heteroskedastic uncertainty about workers' intervention effects.\nQuestions: \nHow is fair allocation defined/operationalized in the empirical results?\nCould the knapsack portion of the Hawkins approach be modified to encode the type of cost-disparity threshold fairness considered here?\nLimitations: The authors acknowledge that incorporating fairness among workers (i.e., with respect to the number of arms each worker is allocated) will, in general, reduce expected total reward relative to a fairness-agnostic (but otherwise equivalent) approach. An additional limitation is that worker-specific transition matrices are assumed to be known by the agent.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The authors study the problem of multi-worker restless bandits, that extends the standard restless bandits having different costs and fairness constraints on different actions. The authors propose a scheme that at first decouples the problem and than, using the decoupled solutions, introduce the interaction with other workers. Finally, some experiments comparing the proposed algorithm to the ones present in the literature (which do not include the fairness constraint) are provided.",
                "Strengths And Weaknesses": "The paper is well structured and the definition of the steps taken to get to the solution is helping the reader to understand the idea behind the paper. There are a few ortographic mistakes. The topic is interesting and the solution is well motivated empirically.\nI have some doubts about the real formulation of some of the results and the strenght of the theoretical results provided.\nMinor:\nLine 99: \"M=1\" I got the idea, but i think that the more formal statement would be c_ij = c_ih=1 \\forall j,h \\in [M]\nLine 130: It is not clear the statement. Is it \"by relying on the work by qian et al.\"? Or is it a derivation from the previous work?\nLine 283: Please provide the rationale behind the choice of B)18.\nLine 297: The -> the\nFigure 4: I suggest to rearrange the subplots and the table, to better explain the results therein.",
                "Questions": "It is not clear to me if the solution you provided is solving the original problem or if it is an approximate solution. In the former case, I would like to have a formal statement about that, in the latter case a study on the approximation gap.\nIs Theorem 3 only predicating on those instances having that all the workers are of the same type? I would like to understand if in this theorem we are restricting to a specific case or not.",
                "Limitations": "I do not foresee limitations and potential negative societal impacts. The paper is focused on the idea to make the work allocation task fair, therefore at the moment i only see positive impacts on society.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper considers a multi-worker version of the restless multi-armed bandit problem where the intervention on a particular arm can be carried out by one of M possible workers. The workers have possibly different costs for intervening on different arms and the goal is to design an optimal allocation policy that satisfies budget constraint for each worker and also fair. \u2028\nThe authors devise a heuristic balanced allocation rule for the problem. The main idea behind the algorithm is to decompose the original problem into several related subproblems. The experiments show that the proposed heuristic scales with the number of agents without compromising too much on the objective.",
                "Strengths And Weaknesses": "Strengths:\n\nI think the multi-worker extension of the restless multi-armed bandit problem is an interesting direction and certainly more practical.\nThe empirical section is interesting as the authors could show that the proposed approximation algorithm runs fast for a large number of agents (N is of the order of hundreds) and the performance doesn't deteriorate much.\n\nWeaknesses:\n\nThe main weakness of the paper is the lack of proper theoretical guarantees. First, it is not clear if you can decompose the original problem~(2) into N\u00d7M subproblems because of the additional fairness constraint. Second, the main result also shows that the proposed algorithm works only for homogeneous workers (theorem 3) and it's not clear if the balanced allocation works when the costs are heterogeneous.\nEven if I assume that the problem is decomposable the authors don't bound fairness violation of the final solution. Note that fairness is a global constraint and the individual subproblems don't have this constraint. So it is not trivial to combine the solutions of these subproblems and ensure a desired level of fairness. \nFor the adjusted index algorithm it is not clear what is the right choice of the variables \u03bb\u2212j for each j. The authors justified that choosing \u03bb\u2212j=0 is not optimal, and chose these values based on Whittle indices. But I am not sure that should be optimal either because of heterogeneous costs and global constraints. Maybe you can solve for a fixed point of this system and use the fixed point as the adjusted indices?\n\nSome other comments:\n\nGive definition of indexability of arms.\nAt the end of section 3, the authors highlight two challenges for MWRMAB model. It might be a good idea to illustrate these challenges with an example.",
                "Questions": "The original optimization problem (1 and 2) has the fairness constraint. However, this constraint is absent in the subproblem (3). How do you guarantee that solving each subproblem will automatically generate a fair solution?\n\nAlso I am not sure when solving each subproblem is sufficient to solve the original problem~(2). Do you have any result showing that you can obtain a solution of the original problem by solving the N\u00d7M subproblems?\n\nI don't understand why theorem 1 is useful. It seems to me this theorem is only used to derive Corollary 1 for the case of identical cost and probability transition function. But doesn't that directly follow from the nature of the optimization problem (3) by substituting identical cost and probability transition function?\n\nTheorem 3 states that the algorithm balanced allocation works only when the workers are homogeneous. But I thought the whole point of introducing the general framework was to handle workers with heterogeneous costs. Do you have any results for the setting with heterogeneous costs?\n\nThe balanced allocation takes fairness threshold \u03f5 as input. But as far as I can understand, the algorithm never explicitly uses this argument. It would be nice if you could clarify which step of the algorithm uses this parameter? Also regarding this, do you have any guarantee for the fairness guarantee obtained by the balanced allocation algorithm?",
                "Limitations": "This paper doesn't have any negative societal impact.",
                "Ethics Flag": "No",
                "Soundness": "1 poor",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper considers constrained resource allocation tasks framed as restless bandit problems. In contrast to prior work in this space which assumes that all of the resources (i.e., healthcare workers, mechanics, etc.) to be allocated are interchangeable, the authors: (a) consider heterogeneous workers with individual/varied costs, budgets, and intervention effects; and (b) strive to optimally allocate arms to workers while ensuring the disparity in costs incurred by any two workers does not exceed a given threshold, \u03f5. To do this, the authors define an augmented action space, such that each worker is represented as a possible active action, with a corresponding worker-arm-specific cost function and transition matrix. They then decompose the problem and compute Whittle indices for each worker-arm combination. They use these Whittle indices to compute an adjusted index that reflects the minimum charge required to make the agent indifferent between an active action provided by worker j and one provided by any other worker j\u2032. They use the adjusted indices to inform budget- and fairness-constraint satisfying round-robin allocation of arms to workers.",
                "Strengths And Weaknesses": "Strengths:\n\nThe paper is well-written and the extension to the RMAB setting that the authors propose (i.e., actions with arm-specific heterogenous costs and effectiveness) is well-motivated by many practical domains, such as healthcare, manufacturing, and wildlife conservation. The technical work required to extend the problem setting in this way is significant since one must now account for how workers with different (arm/state-specific) expertise may interact (and influence arms' transitions) over time.\n\nWeaknesses:\n\nArms' states and worker-specific transition matrices are assumed to be observable. While it is conventional to assume each arm's (worker-agnostic) transition matrix is known by the decision-maker in the planning setting, the assumption that this additional level of information is available should be explicitly stated and justified by the availability/\"learnability\" of this type of information within the domain(s) of interest. This will be particularly important in settings where there is heteroskedastic uncertainty about workers' intervention effects.",
                "Questions": "How is fair allocation defined/operationalized in the empirical results?\nCould the knapsack portion of the Hawkins approach be modified to encode the type of cost-disparity threshold fairness considered here?",
                "Limitations": "The authors acknowledge that incorporating fairness among workers (i.e., with respect to the number of arms each worker is allocated) will, in general, reduce expected total reward relative to a fairness-agnostic (but otherwise equivalent) approach. An additional limitation is that worker-specific transition matrices are assumed to be known by the agent.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.333,
        "confidence_avg": 3.667,
        "soundness_avg": 2.0,
        "presentation_avg": 2.667,
        "contribution_avg": 2.333,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the paper addresses an interesting and practical problem of multi-worker restless bandits with fairness constraints. The paper is well-structured and the proposed solution is well-motivated empirically. However, there are some concerns raised by the reviewers regarding the theoretical guarantees and the handling of heterogeneous costs.\n\nReviewer 1 raises doubts about the formulation of some results and the strength of the theoretical results provided. They also request clarification on whether the solution is solving the original problem or if it is an approximate solution. Additionally, they question if Theorem 3 is restricted to a specific case or not.\n\nReviewer 2 points out the lack of proper theoretical guarantees and the challenge of combining the solutions of the subproblems to ensure fairness. They also question the choice of variables in the adjusted index algorithm and the usefulness of Theorem 1. Furthermore, they highlight the need for results in the setting with heterogeneous costs and request clarification on the fairness guarantee obtained by the balanced allocation algorithm.\n\nReviewer 3 acknowledges the well-written paper and the significance of extending the problem setting to account for heterogeneous workers. However, they raise concerns about the assumption of observable arm states and worker-specific transition matrices. They also inquire about the operationalization of fair allocation in the empirical results and suggest modifying the knapsack portion of the Hawkins approach to encode the cost-disparity threshold fairness.\n\nTaking into consideration the strengths and weaknesses identified by the reviewers, it is clear that the paper makes a technically solid contribution with high impact in the area of multi-worker restless bandits. While there are some concerns regarding the theoretical guarantees and the handling of heterogeneous costs, the empirical results and the motivation behind the proposed solution are strong. Therefore, I recommend accepting the paper."
    },
    "Models_of_human_preference_for_learning_reward_functions": {
        "link": "https://openreview.net//forum?id=6UtOXn1LwNE",
        "pub_url": "https://openreview.net/forum?id=6UtOXn1LwNE",
        "pdf_link": "https://openreview.net//pdf?id=6UtOXn1LwNE",
        "paper_id": "6UtOXn1LwNE",
        "title": "Models_of_human_preference_for_learning_reward_functions",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Less certain\nThe submitted paper was reviewed by 4 knowledgable reviewers and the reviewers and authors enganged in intense discussions. The authors clarified many details in these discussion but could not convince the reviewers in all regards (there are still open concerns regardings the proofs and the update proofs came in rather late so that there was insufficient time for the reviewers to further interact; there concerns regarding experiments although I discounted most of those regarding to scalability as I agree with the authors in that regard to some extent; etc.). Moreover, looking at the discussions and the authors' responses, the paper would benefit from making several points more clear/improving their presentation, likely by including parts which came up in the discussions in the paper. Considering all this, I think this paper should go through another round of reviews before it should be accepted and I am recommending rejection of the paper. Please note that it was not easy to come to this decision - there are some important insights and experiments in the paper which should be made available to the community asap. Thus I would honestly encourage the authors to improve their paper considering the reviewers' comments and take-aways from the discussion and submit a revised version of the paper at one of the upcoming conferences. I am already looking forward to seeing an improved version of the paper being published.",
        "reviews": [
            "Reviewer 1: \nSummary: The paper deals with the problem of modeling human preferences in a setting where they are presented with two segments and choose to compare the two. Importantly, the authors propose that people compare the segments in terms of their values (measured by a notion of regret) instead of the total reward achieved by each segment. A regret notion---the sum of the negative advantage function value of the segment---is used to summarize the value of a segment. The advantage function is defined under an optimal policy pi^* (optimal wrt the true reward r) and the reward of interest \\tilde{r}.\nStrengths And Weaknesses: Strength: The paper provides a key insight that preferences are not just a function of the (instantaneous) reward of the segment of interest. Given that humans may care about the goal of a task, their preference towards different segments will necessarily be influenced by their long-term value, i.e., how these segments perform in terms of achieving the goal. The identification results presented in Section 3 nicely summarized the proposed insight. \nWeakness: The biggest weakness to me is how one can utilize this insight in practice. In particular, calculating the regret requires one to know the optimal policy under the true reward r (or at least the value and q-value function of that optimal policy under any reward \\tilde{r}). In general, even if one provides an optimal policy \\pi^*, the planning problem (and possibly learning problem when the transition matrix is unknown) will make the estimation of the regret very hard. As a related note, in the general framework, the regret definition under a particular optimal policy and L150 (\"And regret(\\sigma|r) > 0 if and only if \\sigma is suboptimal\") in the proof seem to only hold if one assumes there is one single optimal policy \\pi^*. What if there is a set of optimal policies under the true reward r? How should one adjust the regret notion for that?\nQuestions: Could the authors elaborate more on the setting when there are multiple optimal policies, how one should define regret in such cases, and how the results in Section 3 look like when one chooses different optimal policies to define ther regret?\n\nL63: typo in the mathematical expression\nLimitations: Yes, the authors have discussed the limitations and societal impact of their work in Appendix A. (When writing the above reviews, I have not read Appendix A of their paper yet.)\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper studies the issues of reward functions. It considers alignment on the pairs of trajectory segments from human-generated preferences. The paper finds that it is flawed that human preferences are assumed to be informed by partial return. Previous works consider the sum of rewards over a segment. The paper provides an alternative preference model based on the regret of each segment.\nStrengths And Weaknesses: The paper addresses an interesting problem about human preferences. It shows that the partial return preference model can prefer suboptimal actions with lucky outcomes.\nThe paper also provides a method based on the regret of each segment, which is equivalent to the negated sum of an optimal policy\u2019s advantage of each transition in the segment.\nThe paper also provides theoretical comparisons.\nThe main weakness is that the experimental results seem not to be enough. The proposed method does not provide comparison with previous methods from [9-16].\nThe environments are also limited. \nIt would be better to provide more results.\nAnother weakness is that the code is not opened. It would be difficult to reproduce the results by others.\nQuestions: What is the segment\u2019s desirability? \nFigure 1 is a little confusing.  In Figure 1, the right segment should have a higher sum of reward according to humans\u2019 preference.\nHow to define a start state of a segment? And how to define an end state of a segment?\nRegret is computed based on a segment. The segment is also partial. \nWhat is the advantage of using regret? \nThe motivation of using desirability is not clear.\nLimitations: It would be better to provide more results and more details about experiments.\nThe paper needs to compare with other baselines, such as methods using (2).\nEthics Flag: No\nEthics Review Area: I don\u2019t know\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper studies the problem of learning from human preferences. A new preference model is proposed which compares the advantage on the optimal policy between two trajectory segments. Some theoretical results are given that show the method is consistent under some assumptions and that a popular alternative is potentially not consistent. An algorithm is proposed to make use of this model. A new dataset is collected for a simulated delivery problem where workers provided preference labels for segments given to them. The proposed algorithm and model were compared with a partial return model on both a synthetic dataset and the collected dataset.\nStrengths And Weaknesses: Strengths\n\nThe proposed preference model seems new to my knowledge and makes sense algorithmically.\nThe theory could be interesting although I have some reservations about correctness and the significance of one of the results.\nThe algorithm seems to perform significantly better than the partial return baseline in empirical evaluations.\n\nWeaknesses\n\nThe presentation could be improved. Generally speaking, there are many seemingly out of place paragraphs and sections that do not seem to advance the content of the paper. For example, Section 3 is about theoretical comparisons of the learning objectives but then Section 4 abruptly is about an experimental model, but we do not even know what the algorithm looks like or how we will use the models from Section 3 at this point. This is only explained in Section 6.\nThe description of the algorithm is very confusing and way too informal to the point where I am still unclear on what it is actually being done.  \nWhat are the input rewards and policies? Why can they be empty sometimes?\nWhy would line 4 already estimate those? What procedure is being done to estimate these?\nHow many feature functions are necessary?\nFor the partial return algorithm, was the same framework used but the model just swapped out? How does this compare with past algorithms that use partial return? This seems important for the experimental comparison.\n\n\nThe discussion of related work is quite sparse and it is difficult to place this work in the literature as a result.\nTheorem 3.1 (and Definition 3.1) is dubious. Implicitly there is an assumption that the dataset covers every \u03c31 and \u03c32 pair and infinite data for each one. Not just that it contains infinite data for some distribution over certain segments, which is what Definition 3.1 is ambiguous about. This only becomes apparent in the proof where this unstated fact is used. \nI am also not convinced that Theorem 3.2 is all that significant. The setting is different from the preliminaries of the paper: to assume noiseless labels is to say that P(\u22c5|r) is actually not in the class of models from Section 2.2 since the softmax cannot realize this model for finite rewards. The problem is therefore misspecified, and it\u2019s not surprising that there is an identifiability issue, considering that the KL divergence cannot even be driven to zero if the true reward function is plugged in! Note that Theorem 3.1 crucially made use of the fact that the model is realizable to prove the positive result, so I feel that this is an unfair comparison.\nThe computational burden of solving potentially many MDPs to optimize the proposed preference model seems difficult to overcome.\nQuestions: \nCan the authors clarify what assumption is being made over the covariates in the dataset D\u2265 in Definition 3.1?\nIn Section 4, it mentions that data was collected via two different methodologies. In the end, was data from only the second used to present the results in the end or was it a mix?\nCan the authors provide more details about how the actual segments that were presented to the labelers were generated? In the appendix it just says that certain trajectories were favored, but it\u2019s unclear to me what that means. Were these generated by demonstrations or an algorithm? Were they generated specifically to have good coverage over the state space?\nLimitations: See above discussion.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 1 poor\nContribution: 3 good\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: The paper aims to learn the reward function from preferences between pairs of trajectory segments by introducing a new notion of the segment's regret that is based on the advantage function. Notable, they argue that the existing approach using the partial returns in the literature is flawed due to the lack of an identifiability property: the ability to recover the reward function underlying the preference dataset. As a result, the importance of using the segment's regret in learning the reward function from preference datasets is highlighted.\nStrengths And Weaknesses: The main contribution of the paper is to introduce a new preference model based on the advantage function. The derivation of the segment's regret as the advantage function is sound and reasonable.\nHowever, there are several weaknesses in the paper.\n1, if I am not mistaken, the proposed regret model is limited to the case of deterministic policies. How is it extended to stochastic policies?\n2, compared with existing approaches that use partial returns, computing the advantage function in the segment's regret is computationally expensive (as mentioned in Appendix A1). While the paper shows an approximation to reduce the computation in Section 6.1, it only works for the linear reward function. Hence, a more detailed discussion on the time complexity of the proposed regret vs. that of the partial returns is necessary, and the work needs to illustrate whether the proposed method is scalable to more practical problems, e.g., by including experiments with neural networks and larger state/action spaces.\n3, if I am not missing anything, Theorem 3.1 and 3.2 are not comparable. While both partial returns and the segment's regret use the logistic function (Equation 2 and Equation 5), there is a difference in the two theorems: in Theorem 3.1, if regret(\u03c31|r~)<regret(\u03c32|r~), Pregret(\u03c31>\u03c32|r~)>0.5, in Theorem 3.2, if \u03a3\u03c31r~>\u03a3\u03c32r~, P\u03a3r(\u03c31>\u03c32|r~)=1.\nWhich existing works assume/imply the latter assumption?\nFurthermore, it raises the question of whether P\u03a3r is indeed nonidentifiable if Theorem 3.2 has the same premise as Theorem 3.1.\n4, there is no comparison with IRL methods (which often rely on the value function or the Q function instead of partial returns): intuitively how they are different, and empirically how they are different (e.g., by experimental results).\n5, existing works (e.g., [9,10]), the reward function is define as a function of the state and the action or the state only (i.e., r(s,a), r(s)). Do these reward formulations affect the result in the paper?\n6, there is only a toy grid world experiment (a very small state and action space, and linear reward functions) which is quite limited.\nQuestions: Please address the weakenesses mentioned above.\nLimitations: The scalability of the proposed method to a more realistic environment is not demonstrated.\nEthics Flag: No\nEthics Review Area: I don\u2019t know\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The paper deals with the problem of modeling human preferences in a setting where they are presented with two segments and choose to compare the two. Importantly, the authors propose that people compare the segments in terms of their values (measured by a notion of regret) instead of the total reward achieved by each segment. A regret notion---the sum of the negative advantage function value of the segment---is used to summarize the value of a segment. The advantage function is defined under an optimal policy pi^* (optimal wrt the true reward r) and the reward of interest \\tilde{r}.",
                "Strengths And Weaknesses": "Strength: The paper provides a key insight that preferences are not just a function of the (instantaneous) reward of the segment of interest. Given that humans may care about the goal of a task, their preference towards different segments will necessarily be influenced by their long-term value, i.e., how these segments perform in terms of achieving the goal. The identification results presented in Section 3 nicely summarized the proposed insight. \nWeakness: The biggest weakness to me is how one can utilize this insight in practice. In particular, calculating the regret requires one to know the optimal policy under the true reward r (or at least the value and q-value function of that optimal policy under any reward \\tilde{r}). In general, even if one provides an optimal policy \\pi^*, the planning problem (and possibly learning problem when the transition matrix is unknown) will make the estimation of the regret very hard. As a related note, in the general framework, the regret definition under a particular optimal policy and L150 (\"And regret(\\sigma|r) > 0 if and only if \\sigma is suboptimal\") in the proof seem to only hold if one assumes there is one single optimal policy \\pi^*. What if there is a set of optimal policies under the true reward r? How should one adjust the regret notion for that?",
                "Questions": "Could the authors elaborate more on the setting when there are multiple optimal policies, how one should define regret in such cases, and how the results in Section 3 look like when one chooses different optimal policies to define ther regret?\n\nL63: typo in the mathematical expression",
                "Limitations": "Yes, the authors have discussed the limitations and societal impact of their work in Appendix A. (When writing the above reviews, I have not read Appendix A of their paper yet.)",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper studies the issues of reward functions. It considers alignment on the pairs of trajectory segments from human-generated preferences. The paper finds that it is flawed that human preferences are assumed to be informed by partial return. Previous works consider the sum of rewards over a segment. The paper provides an alternative preference model based on the regret of each segment.",
                "Strengths And Weaknesses": "The paper addresses an interesting problem about human preferences. It shows that the partial return preference model can prefer suboptimal actions with lucky outcomes.\nThe paper also provides a method based on the regret of each segment, which is equivalent to the negated sum of an optimal policy\u2019s advantage of each transition in the segment.\nThe paper also provides theoretical comparisons.\nThe main weakness is that the experimental results seem not to be enough. The proposed method does not provide comparison with previous methods from [9-16].\nThe environments are also limited. \nIt would be better to provide more results.\nAnother weakness is that the code is not opened. It would be difficult to reproduce the results by others.",
                "Questions": "What is the segment\u2019s desirability? \nFigure 1 is a little confusing.  In Figure 1, the right segment should have a higher sum of reward according to humans\u2019 preference.\nHow to define a start state of a segment? And how to define an end state of a segment?\nRegret is computed based on a segment. The segment is also partial. \nWhat is the advantage of using regret? \nThe motivation of using desirability is not clear.",
                "Limitations": "It would be better to provide more results and more details about experiments.\nThe paper needs to compare with other baselines, such as methods using (2).",
                "Ethics Flag": "No",
                "Ethics Review Area": "I don\u2019t know",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper studies the problem of learning from human preferences. A new preference model is proposed which compares the advantage on the optimal policy between two trajectory segments. Some theoretical results are given that show the method is consistent under some assumptions and that a popular alternative is potentially not consistent. An algorithm is proposed to make use of this model. A new dataset is collected for a simulated delivery problem where workers provided preference labels for segments given to them. The proposed algorithm and model were compared with a partial return model on both a synthetic dataset and the collected dataset.",
                "Strengths And Weaknesses": "Strengths\n\nThe proposed preference model seems new to my knowledge and makes sense algorithmically.\nThe theory could be interesting although I have some reservations about correctness and the significance of one of the results.\nThe algorithm seems to perform significantly better than the partial return baseline in empirical evaluations.\n\nWeaknesses\n\nThe presentation could be improved. Generally speaking, there are many seemingly out of place paragraphs and sections that do not seem to advance the content of the paper. For example, Section 3 is about theoretical comparisons of the learning objectives but then Section 4 abruptly is about an experimental model, but we do not even know what the algorithm looks like or how we will use the models from Section 3 at this point. This is only explained in Section 6.\nThe description of the algorithm is very confusing and way too informal to the point where I am still unclear on what it is actually being done.  \nWhat are the input rewards and policies? Why can they be empty sometimes?\nWhy would line 4 already estimate those? What procedure is being done to estimate these?\nHow many feature functions are necessary?\nFor the partial return algorithm, was the same framework used but the model just swapped out? How does this compare with past algorithms that use partial return? This seems important for the experimental comparison.\n\n\nThe discussion of related work is quite sparse and it is difficult to place this work in the literature as a result.\nTheorem 3.1 (and Definition 3.1) is dubious. Implicitly there is an assumption that the dataset covers every \u03c31 and \u03c32 pair and infinite data for each one. Not just that it contains infinite data for some distribution over certain segments, which is what Definition 3.1 is ambiguous about. This only becomes apparent in the proof where this unstated fact is used. \nI am also not convinced that Theorem 3.2 is all that significant. The setting is different from the preliminaries of the paper: to assume noiseless labels is to say that P(\u22c5|r) is actually not in the class of models from Section 2.2 since the softmax cannot realize this model for finite rewards. The problem is therefore misspecified, and it\u2019s not surprising that there is an identifiability issue, considering that the KL divergence cannot even be driven to zero if the true reward function is plugged in! Note that Theorem 3.1 crucially made use of the fact that the model is realizable to prove the positive result, so I feel that this is an unfair comparison.\nThe computational burden of solving potentially many MDPs to optimize the proposed preference model seems difficult to overcome.",
                "Questions": "Can the authors clarify what assumption is being made over the covariates in the dataset D\u2265 in Definition 3.1?\nIn Section 4, it mentions that data was collected via two different methodologies. In the end, was data from only the second used to present the results in the end or was it a mix?\nCan the authors provide more details about how the actual segments that were presented to the labelers were generated? In the appendix it just says that certain trajectories were favored, but it\u2019s unclear to me what that means. Were these generated by demonstrations or an algorithm? Were they generated specifically to have good coverage over the state space?",
                "Limitations": "See above discussion.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "1 poor",
                "Contribution": "3 good",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper aims to learn the reward function from preferences between pairs of trajectory segments by introducing a new notion of the segment's regret that is based on the advantage function. Notable, they argue that the existing approach using the partial returns in the literature is flawed due to the lack of an identifiability property: the ability to recover the reward function underlying the preference dataset. As a result, the importance of using the segment's regret in learning the reward function from preference datasets is highlighted.",
                "Strengths And Weaknesses": "The main contribution of the paper is to introduce a new preference model based on the advantage function. The derivation of the segment's regret as the advantage function is sound and reasonable.\nHowever, there are several weaknesses in the paper.\n1, if I am not mistaken, the proposed regret model is limited to the case of deterministic policies. How is it extended to stochastic policies?\n2, compared with existing approaches that use partial returns, computing the advantage function in the segment's regret is computationally expensive (as mentioned in Appendix A1). While the paper shows an approximation to reduce the computation in Section 6.1, it only works for the linear reward function. Hence, a more detailed discussion on the time complexity of the proposed regret vs. that of the partial returns is necessary, and the work needs to illustrate whether the proposed method is scalable to more practical problems, e.g., by including experiments with neural networks and larger state/action spaces.\n3, if I am not missing anything, Theorem 3.1 and 3.2 are not comparable. While both partial returns and the segment's regret use the logistic function (Equation 2 and Equation 5), there is a difference in the two theorems: in Theorem 3.1, if regret(\u03c31|r~)<regret(\u03c32|r~), Pregret(\u03c31>\u03c32|r~)>0.5, in Theorem 3.2, if \u03a3\u03c31r~>\u03a3\u03c32r~, P\u03a3r(\u03c31>\u03c32|r~)=1.\nWhich existing works assume/imply the latter assumption?\nFurthermore, it raises the question of whether P\u03a3r is indeed nonidentifiable if Theorem 3.2 has the same premise as Theorem 3.1.\n4, there is no comparison with IRL methods (which often rely on the value function or the Q function instead of partial returns): intuitively how they are different, and empirically how they are different (e.g., by experimental results).\n5, existing works (e.g., [9,10]), the reward function is define as a function of the state and the action or the state only (i.e., r(s,a), r(s)). Do these reward formulations affect the result in the paper?\n6, there is only a toy grid world experiment (a very small state and action space, and linear reward functions) which is quite limited.",
                "Questions": "Please address the weakenesses mentioned above.",
                "Limitations": "The scalability of the proposed method to a more realistic environment is not demonstrated.",
                "Ethics Flag": "No",
                "Ethics Review Area": "I don\u2019t know",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 4.5,
        "confidence_avg": 3.25,
        "soundness_avg": 2.5,
        "presentation_avg": 2.5,
        "contribution_avg": 2.5,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the paper addresses an interesting problem and provides a new preference model based on the regret of each segment. The paper also presents theoretical comparisons and empirical evaluations that show the proposed method outperforms the existing approach using partial returns. \n\nWhile there are some weaknesses pointed out by the reviewers, such as the limited experimental results and the lack of comparison with other baselines, these weaknesses do not outweigh the strengths of the paper. The proposed insight about the influence of long-term value on human preferences is valuable and the theoretical results provide a solid foundation for the proposed method.\n\nTherefore, I recommend accepting the paper."
    },
    "Estimating_individual_treatment_effects_under_unobserved_confounding_using_binary_instruments": {
        "link": "https://openreview.net//forum?id=BlF6CWzWKT7",
        "pub_url": "https://openreview.net/forum?id=BlF6CWzWKT7",
        "pdf_link": "https://openreview.net//pdf?id=BlF6CWzWKT7",
        "paper_id": "BlF6CWzWKT7",
        "title": "Estimating_individual_treatment_effects_under_unobserved_confounding_using_binary_instruments",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nThe authors offer a methodologically novel and very interesting approach to an important problem of CATE (or conditional LATE) with binary instrument/treatment. The paper should be published at a good ML venue.\nUnfortunately, I need to recommend rejection primarily because the key proofs supporting their main theorems were missing from the original supplementary material and were only submitted after the rebuttal. Given that these were crucial elements supporting their main results and that they were submitted post the original submission deadline it seems unfair (even if it was most probably an honest mistake of the authors). \nAnother issue that came up in the discussion phase that seems crucial to revise before a resubmission is that the authors main estimation rate result relies on a main theorem of the unpublished work of Kennedy 2020, which has since been revised and the new theorem in Kennedy 2020, is technically very different and requires different assumptions. Hence the authors need to revise their main estimation rate result accordingly. \nHowever, I acknowledge that this is not the main contribution of this work and a simple invocation of past work, but rather the main contribution is to formulate a loss for CATE using the idea of Want and Tchetgen-Tchetgen. So this wouldn't most probably be a reason for rejection.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper studies a multiply-robust estimate of the conditional average treatment effect (CATE), \u03c4(x)=E[Y(1)\u2212Y(0)\u2223X=x] using a binary instrumental variable (IV) for identification. The approach is to construct a transformed outcome, Y^0 such that E[Y^0\u2223X=x]=\u03c4(x), and then use a machine learning regression model to estimate the mean of Y^0 using X. The paper shows that such an approach can improve convergence rates over naive approaches such as plug-in estimates typically used for IVs.\nStrengths And Weaknesses: The paper is reasonably well written. While it focuses a lot of attention on the convergence rates, which require following a lot of subtlety that makes it difficult for the reader to fully understand the main message, it is reasonably high quality and appropriate for publication on the topics of clarity and quality.\nUnfortunately, the authors seem to have missed a key paper on this topic. Their abstract says \"[t]o the best of our knowledge, our MRIV is the first multiple robust machine learning framework tailored to estimating ITEs in the binary IV setting.\" This is strange, as they cite  Syrgkanis et al., 2019 [29 in the paper], who provide almost an identical method for inference (up to some algebra and mild re-parameterization), show that it is multiply robust, and provide convergence rates under certain conditions, similarly emphasizing the dependence on the nuisance parameter convergence rates.\nEdit: it appears that \"multiple\" (meaning more than double) robustness is the key innovation here, and that there is a nontrivial practical difference between it and double robustness. See the conversation in the reviews for more details. While the transformed outcomes are very similar, and have the same conditional mean, suggesting some way of transforming from one to the next, the differences are nontrivial, and allow for construction of different nuisance parameter estimates that allow for improved performance. The authors have clarified this in their updated version, and therefore, I believe the paper is appropriate for publication.\nQuestions: How is this work different from DRIV method of Syrgkanis et al., 2019?\nLimitations: N/A\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The authors propose an algorithm for estimating ITE for binary instrument and binary treatment. The procedure has three steps.\n-implement some initial estimator of ITE\n-construct pseudo-outcome as sum of the initial estimator and a term combining several nuisances\n-regress the pseudo-outcome on covariates\nFor this algorithm, the authors prove excess risk that scales as the sum of an oracle rate and several product rates.\nStrengths And Weaknesses: Originality\nI will raise the score if the authors improve the framing of the contribution in the context of previous work.\n\nThe pseudo-outcome technique is relatively popular in causal inference; see e.g. Kennedy et al.\u2019s work on dose response (2019) which Semenova and Chernozhukov (2021) extend to ITE. This paper extends those techniques, so I would like them to be cited.\n\nThe main theoretical result extends an analogous result by Kennedy (2020), which somehow doesn\u2019t get mentioned until Section 4.2. Moreover, citations for ITE without unobserved confounding could be more generous; it is a vast literature.\n\nTo distinguish the originality of this paper relative to Syrgkanis et al (2019), I would like to see a discussion that compares the estimation procedures and their guarantees. If I understand correctly, the Syrgkanis et al (2019) estimator proposes a Neyman orthogonal loss while this work used the pseudo-outcome technique, yet both provide excess risk rates that involve products of nuisance rates. \n\nEstimation that uses the efficient influence function to study ITE in the IV setting has been proposed by Ogburn et al (2015). Estimation that combines the efficient influence function with sample splitting and machine learning has been analyzed in the semiparametric IV setting, e.g. Singh and Sun (2019). This paper goes further than these previous works in proposing an ML estimator for ITE. I would like these previous works to be cited as well.\n\n\nQuality\n\nI will raise the score if the experiments are made to align more closely with the theory.\n\n-line 284. Is there any sense in which the proposed nuisance estimators would satisfy Assumption 3?\n-line 294. I would like to see the experiments with sample splitting since that is the proposal in the theory section\n-line 313. The comparisons are hard to understand. The various estimators have different estimands. For example, DeepIV estimates a function that is not the ITE. So what is being reported here? These comparison estimators also involve sample splitting in some cases, to align with their theory, while the proposed estimator is not implemented with sample splitting (though its theory requires it)\n\nI would like more discussion in the case study. In line 386, at what values are these variables fixed? Simply fixing values means that the quantity visualized in Figure 1 is not the ITE. Nor is it the ITE conditional on some subset of covariates. Please interpret what is being displayed.\n\nThe theoretical result, stated in Section 4.2 and explained in Section 4.3, is well written and interesting. I would like to see the additional assumptions of Theorem 2 stated in the main text, rather than pointing to another paper. Then the reader can assess whether they are \u201cmild\u201d or not.\n\n\nClarity\n\nThere were several instances in which the authors made statements that were either unclear or untrue as written. I will increase the score when these are addressed.\n\n-line 25. The definition of unconfoundedness is incorrect. The given definition is an example of when unconfoundedness holds.\n-line 92. Exclusion is not unrestrictive.\n-line 107. The descriptions in Assumption 2 are misleading. The assumptions state that U can essentially be differenced out. It is an additive equi-confounding.  \n-line 117 (footnote). The definition of compliers is incorrect. It is the subpopulation for whom A(1)>A(0).\n-line 142. This statement is misleading. Arguably this paper requires a type of additive separability of confounding as well; see the comment above.\n-line 223. This is a misleading citation. Cross-fitting is a type of sample splitting that has the same theoretical analysis. It is not a practical shortcut. The cited paper does not advocate fitting all nuisances on the same data set; that approach is only valid when the function spaces have limited complexity.\n\nPlease provide some intuition for the first term in equation 3. It helps to group \\hat{\\tau}_{init} and look at what residual is being extracted from Y before being reweighted.\n\nSignificance\nMy assessment of significance will hinge upon the authors\u2019 improvements described above. There are currently too many issues for this paper to be a significant contribution, but I am optimistic that these issues can be addressed in the revision.\nQuestions: Please address the items in Originality, Quality, and Clarity and I will increase the score\nLimitations: N/A\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper presents a two-stage regression method: In stage 1, they estimates nuisance components \u03c0(x),\u03bc0Y,\u03bc0A,\u03b4A(x); In stage 2, given an arbitrary initial ITE estimator \u03c4init\u00a0(x) and  nuisance estimates \u03c0(x),\u03bc0Y,\u03bc0A,\u03b4A(x)  (obtained from stage 1), they define a pseudo outcome for ITE estimation.  Theoretically, the framework proposed in this paper yields multiple robust convergence rates. \n\nI thank the authors for addressing my comments. I increase my score to 6.\nStrengths And Weaknesses: This paper builds upon the theoretical results and propose a deep neural network architecture called MRIV-Net for ITE estimation. However, the proof of the theory and Appendices A-G are missing, which I cannot find in the supplemental material. This makes me doubt the solidity of the method and results. I will adjust my score according to the authors\u2019 responses to my comments.\nStrengths\n\nThis paper considers a very important and interesting problem in Treatment Effect and proposes a novel estimator using binary instruments. \nThe paper is very well written and provides extensive evaluation and discussion/comparison of past work. \nTheoretically, I believe that Theorem 1 is correct, and MRIV has Multiple robustness properties. But I think it's necessary to give a brief description or simply express the process with an example:\n\n(1) Assuming \u03bc^0Y=\u03bc0Y,\u03bc^0A=\u03bc0A,\u03b4^A=\u03b4A,\u03c0^=0.5,\u03c4^=0: \nY^0\u2190(Z\u2212(1\u2212Z)\u03b4A(X))(Y\u2212\u03bc0Y(X));\n(2) Assuming \u03bc^0Y=0,\u03bc^0A=0,\u03b4^A=\u03b4A,\u03c0^=\u03c0,and\u00a0\u03c4^=0: \nY^0\u2190(Z\u2212(1\u2212Z)\u03b4A(X))(YZ\u03c0(X)+(1\u2212Z)(1\u2212\u03c0(X)));\n(3) Assuming \u03bc^0Y=0,\u03bc^0A=0, \u03b4^A=1,\u03c0^=\u03c0,and\u00a0\u03c4^=\u03c4: \nY^0\u2190(Z\u2212(1\u2212Z))(Y\u2212A\u03c4Z\u03c0(X)+(1\u2212Z)(1\u2212\u03c0(X)))+\u03c4. \nE[Y^0\u2223X=x]=\u03c4. \nWeaknesses\n\nFor Eq. (3), at least two models need to be correctly specified to guarantee robust learning, which is a stronger condition than robust learning. The latter only requires either the propensity model or the potential outcome estimation model to be specified accurately. \nThe proof of the theory and Appendices A-G are missing, which I cannot find in the supplemental material. This makes me doubt the solidity of the method and results. \nThis paper should introduce the concept of multiple robust in the Introduction Section, and roughly explain that the original problem is simplified to 5 nuisance estimators \u2014\u2014 the solution is still robust even if some models are misspecified.\nQuestions: In Figure 1, is it necessary to assume that X and U are independent? \nLines 79-82: Does this article focus on observational data or experiments data? \nY^0 is usually used to denote E[Y|T=0] instead of ITE \u03c4, which is confusing. \nTypos: Line 157: \u201cWe then derive we derive \u2026\u201d\nMaybe the author can give a brief conclusion and future exploration.\nLimitations: I do not foresee any major limitations and/or societal impacts.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper studies a multiply-robust estimate of the conditional average treatment effect (CATE), \u03c4(x)=E[Y(1)\u2212Y(0)\u2223X=x] using a binary instrumental variable (IV) for identification. The approach is to construct a transformed outcome, Y^0 such that E[Y^0\u2223X=x]=\u03c4(x), and then use a machine learning regression model to estimate the mean of Y^0 using X. The paper shows that such an approach can improve convergence rates over naive approaches such as plug-in estimates typically used for IVs.",
                "Strengths And Weaknesses": "The paper is reasonably well written. While it focuses a lot of attention on the convergence rates, which require following a lot of subtlety that makes it difficult for the reader to fully understand the main message, it is reasonably high quality and appropriate for publication on the topics of clarity and quality.\nUnfortunately, the authors seem to have missed a key paper on this topic. Their abstract says \"[t]o the best of our knowledge, our MRIV is the first multiple robust machine learning framework tailored to estimating ITEs in the binary IV setting.\" This is strange, as they cite  Syrgkanis et al., 2019 [29 in the paper], who provide almost an identical method for inference (up to some algebra and mild re-parameterization), show that it is multiply robust, and provide convergence rates under certain conditions, similarly emphasizing the dependence on the nuisance parameter convergence rates.\nEdit: it appears that \"multiple\" (meaning more than double) robustness is the key innovation here, and that there is a nontrivial practical difference between it and double robustness. See the conversation in the reviews for more details. While the transformed outcomes are very similar, and have the same conditional mean, suggesting some way of transforming from one to the next, the differences are nontrivial, and allow for construction of different nuisance parameter estimates that allow for improved performance. The authors have clarified this in their updated version, and therefore, I believe the paper is appropriate for publication.",
                "Questions": "How is this work different from DRIV method of Syrgkanis et al., 2019?",
                "Limitations": "N/A",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors propose an algorithm for estimating ITE for binary instrument and binary treatment. The procedure has three steps.\n-implement some initial estimator of ITE\n-construct pseudo-outcome as sum of the initial estimator and a term combining several nuisances\n-regress the pseudo-outcome on covariates\nFor this algorithm, the authors prove excess risk that scales as the sum of an oracle rate and several product rates.",
                "Strengths And Weaknesses": "Originality\nI will raise the score if the authors improve the framing of the contribution in the context of previous work.\n\nThe pseudo-outcome technique is relatively popular in causal inference; see e.g. Kennedy et al.\u2019s work on dose response (2019) which Semenova and Chernozhukov (2021) extend to ITE. This paper extends those techniques, so I would like them to be cited.\n\nThe main theoretical result extends an analogous result by Kennedy (2020), which somehow doesn\u2019t get mentioned until Section 4.2. Moreover, citations for ITE without unobserved confounding could be more generous; it is a vast literature.\n\nTo distinguish the originality of this paper relative to Syrgkanis et al (2019), I would like to see a discussion that compares the estimation procedures and their guarantees. If I understand correctly, the Syrgkanis et al (2019) estimator proposes a Neyman orthogonal loss while this work used the pseudo-outcome technique, yet both provide excess risk rates that involve products of nuisance rates. \n\nEstimation that uses the efficient influence function to study ITE in the IV setting has been proposed by Ogburn et al (2015). Estimation that combines the efficient influence function with sample splitting and machine learning has been analyzed in the semiparametric IV setting, e.g. Singh and Sun (2019). This paper goes further than these previous works in proposing an ML estimator for ITE. I would like these previous works to be cited as well.\n\n\nQuality\n\nI will raise the score if the experiments are made to align more closely with the theory.\n\n-line 284. Is there any sense in which the proposed nuisance estimators would satisfy Assumption 3?\n-line 294. I would like to see the experiments with sample splitting since that is the proposal in the theory section\n-line 313. The comparisons are hard to understand. The various estimators have different estimands. For example, DeepIV estimates a function that is not the ITE. So what is being reported here? These comparison estimators also involve sample splitting in some cases, to align with their theory, while the proposed estimator is not implemented with sample splitting (though its theory requires it)\n\nI would like more discussion in the case study. In line 386, at what values are these variables fixed? Simply fixing values means that the quantity visualized in Figure 1 is not the ITE. Nor is it the ITE conditional on some subset of covariates. Please interpret what is being displayed.\n\nThe theoretical result, stated in Section 4.2 and explained in Section 4.3, is well written and interesting. I would like to see the additional assumptions of Theorem 2 stated in the main text, rather than pointing to another paper. Then the reader can assess whether they are \u201cmild\u201d or not.\n\n\nClarity\n\nThere were several instances in which the authors made statements that were either unclear or untrue as written. I will increase the score when these are addressed.\n\n-line 25. The definition of unconfoundedness is incorrect. The given definition is an example of when unconfoundedness holds.\n-line 92. Exclusion is not unrestrictive.\n-line 107. The descriptions in Assumption 2 are misleading. The assumptions state that U can essentially be differenced out. It is an additive equi-confounding.  \n-line 117 (footnote). The definition of compliers is incorrect. It is the subpopulation for whom A(1)>A(0).\n-line 142. This statement is misleading. Arguably this paper requires a type of additive separability of confounding as well; see the comment above.\n-line 223. This is a misleading citation. Cross-fitting is a type of sample splitting that has the same theoretical analysis. It is not a practical shortcut. The cited paper does not advocate fitting all nuisances on the same data set; that approach is only valid when the function spaces have limited complexity.\n\nPlease provide some intuition for the first term in equation 3. It helps to group \\hat{\\tau}_{init} and look at what residual is being extracted from Y before being reweighted.\n\nSignificance\nMy assessment of significance will hinge upon the authors\u2019 improvements described above. There are currently too many issues for this paper to be a significant contribution, but I am optimistic that these issues can be addressed in the revision.",
                "Questions": "Please address the items in Originality, Quality, and Clarity and I will increase the score",
                "Limitations": "N/A",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper presents a two-stage regression method: In stage 1, they estimates nuisance components \u03c0(x),\u03bc0Y,\u03bc0A,\u03b4A(x); In stage 2, given an arbitrary initial ITE estimator \u03c4init\u00a0(x) and  nuisance estimates \u03c0(x),\u03bc0Y,\u03bc0A,\u03b4A(x)  (obtained from stage 1), they define a pseudo outcome for ITE estimation.  Theoretically, the framework proposed in this paper yields multiple robust convergence rates. \n\nI thank the authors for addressing my comments. I increase my score to 6.",
                "Strengths And Weaknesses": "This paper builds upon the theoretical results and propose a deep neural network architecture called MRIV-Net for ITE estimation. However, the proof of the theory and Appendices A-G are missing, which I cannot find in the supplemental material. This makes me doubt the solidity of the method and results. I will adjust my score according to the authors\u2019 responses to my comments.\nStrengths\n\nThis paper considers a very important and interesting problem in Treatment Effect and proposes a novel estimator using binary instruments. \nThe paper is very well written and provides extensive evaluation and discussion/comparison of past work. \nTheoretically, I believe that Theorem 1 is correct, and MRIV has Multiple robustness properties. But I think it's necessary to give a brief description or simply express the process with an example:\n\n(1) Assuming \u03bc^0Y=\u03bc0Y,\u03bc^0A=\u03bc0A,\u03b4^A=\u03b4A,\u03c0^=0.5,\u03c4^=0: \nY^0\u2190(Z\u2212(1\u2212Z)\u03b4A(X))(Y\u2212\u03bc0Y(X));\n(2) Assuming \u03bc^0Y=0,\u03bc^0A=0,\u03b4^A=\u03b4A,\u03c0^=\u03c0,and\u00a0\u03c4^=0: \nY^0\u2190(Z\u2212(1\u2212Z)\u03b4A(X))(YZ\u03c0(X)+(1\u2212Z)(1\u2212\u03c0(X)));\n(3) Assuming \u03bc^0Y=0,\u03bc^0A=0, \u03b4^A=1,\u03c0^=\u03c0,and\u00a0\u03c4^=\u03c4: \nY^0\u2190(Z\u2212(1\u2212Z))(Y\u2212A\u03c4Z\u03c0(X)+(1\u2212Z)(1\u2212\u03c0(X)))+\u03c4. \nE[Y^0\u2223X=x]=\u03c4. \nWeaknesses\n\nFor Eq. (3), at least two models need to be correctly specified to guarantee robust learning, which is a stronger condition than robust learning. The latter only requires either the propensity model or the potential outcome estimation model to be specified accurately. \nThe proof of the theory and Appendices A-G are missing, which I cannot find in the supplemental material. This makes me doubt the solidity of the method and results. \nThis paper should introduce the concept of multiple robust in the Introduction Section, and roughly explain that the original problem is simplified to 5 nuisance estimators \u2014\u2014 the solution is still robust even if some models are misspecified.",
                "Questions": "In Figure 1, is it necessary to assume that X and U are independent? \nLines 79-82: Does this article focus on observational data or experiments data? \nY^0 is usually used to denote E[Y|T=0] instead of ITE \u03c4, which is confusing. \nTypos: Line 157: \u201cWe then derive we derive \u2026\u201d\nMaybe the author can give a brief conclusion and future exploration.",
                "Limitations": "I do not foresee any major limitations and/or societal impacts.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.333,
        "confidence_avg": 3.0,
        "soundness_avg": 3.0,
        "presentation_avg": 3.333,
        "contribution_avg": 3.0,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that this paper presents a technically solid and original contribution to the field of estimating the conditional average treatment effect (CATE) using a binary instrumental variable (IV). The paper is well-written and provides extensive evaluation and discussion of related work. While there were some concerns raised by the reviewers regarding the framing of the contribution, clarity of certain statements, and missing proofs, the authors have addressed these concerns in their responses. The theoretical results and the proposed MRIV-Net architecture for ITE estimation are promising. Overall, this paper has the potential for moderate-to-high impact in the field."
    },
    "Controlling_Confusion_via_Generalisation_Bounds": {
        "link": "https://openreview.net//forum?id=1BJUwgi3ed",
        "pub_url": "https://openreview.net/forum?id=1BJUwgi3ed",
        "pdf_link": "https://openreview.net//pdf?id=1BJUwgi3ed",
        "paper_id": "1BJUwgi3ed",
        "title": "Controlling_Confusion_via_Generalisation_Bounds",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nThe consensus was that the reviewers were not convinced that the results were significant, and did not see significant fundamental novelty in the analysis.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper sets out to extend the PAC-Bayes framework to establish new generalization bounds for multi-class classification with M classes of errors extending the 0-1 risk. The main results appear to be Theorem 3 and Corollary 7, which generalize previously known results in this space, and can recover those existing results. My biggest concern about this paper is that I don't find the problem setup inspiring. In particular, the only worked out examples are in Section 4. The novel and interesting piece seems to be the definition of kl^-1, but I find the study to be thin. To sum everything up, I think the derived results appear to be correct; there is some novelty in proofs; but the setup of the problem is not well motivated and it is not clear how these results may be used to derive intuition or practical algorithms.\nStrengths And Weaknesses: Strengths \n\nThe paper is clearly written and the theoretical derivations are clearly discussed\n\nTheorem 3 extends the existing results in the literature, and the proof requires some nice extension of existing results including Lemma 5.\n\nCorollary 7 is also a nice extension of the existing results. While I did not follow its proof closely, the form of the result appears to be meaningful.\n\nThe new results motivate some new study, including a new definition of kl^-1 that seems to be interesting.\n\n\nWeaknesses:\n\nThe setup of the problem is not well motivated, and the study has not resulted in deriving new intuitions.\n\nThe new definition of kl^-1 is not well motivated and the details around it are thin.\nQuestions: \nAs one example I can think of: can you say anything about balancing false positive rate and false negative rate in a binary classification? \n\nIn particular, can you probably make any connections with the fairness literature where the goal might be to equalize false positive rate and false negative rate?\nLimitations: As it currently stands, the impact of the paper is not well quantifiable.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper studies the PAC-Bayes generalization bound, which is an important topic and has been successfully applied to produce non-vacuous generalization bounds for neural network. The authors extend the existing results to the multiclass setting by introducing the discretized error types, which is a disjoint partition of the assembly of model prediction and ground truth labels. Based on the results, the authors further provide an abstract implementation of the method which can be applied to the real tasks.\nStrengths And Weaknesses: Strength:\n1.The derived theorems hold for multiclass problem and soft labels, which has a wide range of applications to the real learning tasks. Such results in the PAC-Bayes literature have not been well-studied yet.\n2.Although there are no empirical studies to validate the results, the authors provide abstract implementation of the algorithm for better understanding the applications of the theorems.\n3.The paper is well presented and easy to understand. Detailed proofs are provided in the paper and supplementary material. \nWeakness:\n1.The technical contribution is somewhat weak in my view. The authors leverage the discretized error types to incorporate the entire confusion matrix, but many steps of the proofs mainly follow existing results.\n2.For the minor problems, there are some flaws in the paper, e.g., incorrect citations in L13 in the paper.\nQuestions: Although the discretized error types can be arbitrary in the theorem, are there any suggestions to set this parameter in the real tasks?\nCan you make more detailed discussion about your results that whether they are vacuous or not?\nLimitations: N/A\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The paper deals with multi-class classification with a vector of M possible error types. The paper establishes a PAC-Bayes bound for the convergence of the empirical error vector to the expected one,  under some convex distance measure (Thm. 3), and gives a more explicit bound for the kl-measure between the Multininomial distributions parametrized by those two corresponding vectors (Cor. 7). Finally, the paper discusses how the result of Cor.7 can yield a bound for the individual error types, and how to derive a gradient-based algorithm that minimizes the bound.\nStrengths And Weaknesses: Strengths\n\nThe problem of multi-class generalization bounds for the confusion matrix is interesting.\nThe main results (Thm. 3, Cor. 7) seem elegant and non-trivial to derive.\n\nWeaknesses\n\nThe writing can be improved - for example - paragraph 38-48 is hard to follow, The structure of the paper can be improved, currently, the main contributions are hard to discern from smaller details.\n\nClassical PAC-Bayes bounds (e.g. Maurer \u201804) can account for non-zero-one losses.  An alternative route to deriving bounds on the divergence of the empirical confusion matrix from the expected one, under some matrix norm, can be using those classical bounds for each error type and then using the union bound. How does this simple approach compares to the results in the paper?  I think the paper lacks comparisons to possible simpler approaches.\n\nIn the introduction, the authors describe a problem where each error type is associated with a different loss value \u2113j\u2208[0,\u221e). However, if am not mistaken, the bound presented in Thm 3. and Cor. 7 seem to only deal with \u2113j\u22080,1.\n\nThere are also no explicit results for the convergence of the confusion matrix under some matrix norms.\nI may have not understood correctly the results, in that case, I suggest the authors improve the clarity of these issues, by emphasizing the corresponding formulations and results. \n\nThere is no experimental validation for the suggested algorithm and for the bounds.\nQuestions: 1. \nLine 170 -  I didn\u2019t understand the comment about m\u2032. How is the formulation with \u03b2 more general?\nLimitations: No further limitations\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 2 fair\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper sets out to extend the PAC-Bayes framework to establish new generalization bounds for multi-class classification with M classes of errors extending the 0-1 risk. The main results appear to be Theorem 3 and Corollary 7, which generalize previously known results in this space, and can recover those existing results. My biggest concern about this paper is that I don't find the problem setup inspiring. In particular, the only worked out examples are in Section 4. The novel and interesting piece seems to be the definition of kl^-1, but I find the study to be thin. To sum everything up, I think the derived results appear to be correct; there is some novelty in proofs; but the setup of the problem is not well motivated and it is not clear how these results may be used to derive intuition or practical algorithms.",
                "Strengths And Weaknesses": "Strengths \n\nThe paper is clearly written and the theoretical derivations are clearly discussed\n\nTheorem 3 extends the existing results in the literature, and the proof requires some nice extension of existing results including Lemma 5.\n\nCorollary 7 is also a nice extension of the existing results. While I did not follow its proof closely, the form of the result appears to be meaningful.\n\nThe new results motivate some new study, including a new definition of kl^-1 that seems to be interesting.\n\n\nWeaknesses:\n\nThe setup of the problem is not well motivated, and the study has not resulted in deriving new intuitions.\n\nThe new definition of kl^-1 is not well motivated and the details around it are thin.",
                "Questions": "As one example I can think of: can you say anything about balancing false positive rate and false negative rate in a binary classification? \n\nIn particular, can you probably make any connections with the fairness literature where the goal might be to equalize false positive rate and false negative rate?",
                "Limitations": "As it currently stands, the impact of the paper is not well quantifiable.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper studies the PAC-Bayes generalization bound, which is an important topic and has been successfully applied to produce non-vacuous generalization bounds for neural network. The authors extend the existing results to the multiclass setting by introducing the discretized error types, which is a disjoint partition of the assembly of model prediction and ground truth labels. Based on the results, the authors further provide an abstract implementation of the method which can be applied to the real tasks.",
                "Strengths And Weaknesses": "Strength:\n1.The derived theorems hold for multiclass problem and soft labels, which has a wide range of applications to the real learning tasks. Such results in the PAC-Bayes literature have not been well-studied yet.\n2.Although there are no empirical studies to validate the results, the authors provide abstract implementation of the algorithm for better understanding the applications of the theorems.\n3.The paper is well presented and easy to understand. Detailed proofs are provided in the paper and supplementary material. \nWeakness:\n1.The technical contribution is somewhat weak in my view. The authors leverage the discretized error types to incorporate the entire confusion matrix, but many steps of the proofs mainly follow existing results.\n2.For the minor problems, there are some flaws in the paper, e.g., incorrect citations in L13 in the paper.",
                "Questions": "Although the discretized error types can be arbitrary in the theorem, are there any suggestions to set this parameter in the real tasks?\nCan you make more detailed discussion about your results that whether they are vacuous or not?",
                "Limitations": "N/A",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper deals with multi-class classification with a vector of M possible error types. The paper establishes a PAC-Bayes bound for the convergence of the empirical error vector to the expected one,  under some convex distance measure (Thm. 3), and gives a more explicit bound for the kl-measure between the Multininomial distributions parametrized by those two corresponding vectors (Cor. 7). Finally, the paper discusses how the result of Cor.7 can yield a bound for the individual error types, and how to derive a gradient-based algorithm that minimizes the bound.",
                "Strengths And Weaknesses": "Strengths\n\nThe problem of multi-class generalization bounds for the confusion matrix is interesting.\nThe main results (Thm. 3, Cor. 7) seem elegant and non-trivial to derive.\n\nWeaknesses\n\nThe writing can be improved - for example - paragraph 38-48 is hard to follow, The structure of the paper can be improved, currently, the main contributions are hard to discern from smaller details.\n\nClassical PAC-Bayes bounds (e.g. Maurer \u201804) can account for non-zero-one losses.  An alternative route to deriving bounds on the divergence of the empirical confusion matrix from the expected one, under some matrix norm, can be using those classical bounds for each error type and then using the union bound. How does this simple approach compares to the results in the paper?  I think the paper lacks comparisons to possible simpler approaches.\n\nIn the introduction, the authors describe a problem where each error type is associated with a different loss value \u2113j\u2208[0,\u221e). However, if am not mistaken, the bound presented in Thm 3. and Cor. 7 seem to only deal with \u2113j\u22080,1.\n\nThere are also no explicit results for the convergence of the confusion matrix under some matrix norms.\nI may have not understood correctly the results, in that case, I suggest the authors improve the clarity of these issues, by emphasizing the corresponding formulations and results. \n\nThere is no experimental validation for the suggested algorithm and for the bounds.",
                "Questions": "1. \nLine 170 -  I didn\u2019t understand the comment about m\u2032. How is the formulation with \u03b2 more general?",
                "Limitations": "No further limitations",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.667,
        "confidence_avg": 3.0,
        "soundness_avg": 3.333,
        "presentation_avg": 2.667,
        "contribution_avg": 2.667,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that this paper makes significant contributions to the PAC-Bayes framework for multi-class classification. The main results, Theorem 3 and Corollary 7, are seen as novel and non-trivial extensions of existing results in the literature. The paper is well-written and the theoretical derivations are clearly discussed. \n\nWhile there are some weaknesses pointed out by the reviewers, such as the lack of motivation for the problem setup and the thin details around the new definition of kl^-1, these weaknesses do not outweigh the strengths of the paper. The reviewers also raise some questions and limitations, but these can be addressed in future work.\n\nOverall, the paper is technically solid and has the potential to have a high impact on the field. Therefore, I recommend accepting this paper."
    },
    "Augmented_Deep_Unrolling_Networks_for_Snapshot_Compressive_Hyperspectral_Imaging": {
        "link": "https://openreview.net//forum?id=xOqqlH_E5k0",
        "pub_url": "https://openreview.net/forum?id=xOqqlH_E5k0",
        "pdf_link": "https://openreview.net//pdf?id=xOqqlH_E5k0",
        "paper_id": "xOqqlH_E5k0",
        "title": "Augmented_Deep_Unrolling_Networks_for_Snapshot_Compressive_Hyperspectral_Imaging",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Less certain\nThe paper received mixed reviews with two weak accepts and two borderline rejects, making it a borderline case. Based on the reviews and the rebuttal and on their own reading of the paper, the area chair would like to make a few remarks:\n\nthe paper achieves good empirical results in terms of PSNR for the task of compressive HSI. This is the main strenght of the paper.\nthe code for reproducing the experiments is not provided. Even though this is not a critical requirement, this would definitely help assessing the quality of the experiments, given that the contribution is mostly methodological.\nthe method consists of modifying several components of classical deep unrolling networks. Some of them are related to existing work, such as the idea to use lstms to exploit past gradients, as discussed in the rebuttal. Such discussions should be included in the paper, even though this idea was not investigated for HSI in this prior work. More generally, the modifications of the DUN method seem quite generic and not specific to compressive HSI. Evaluating their effect on other HSI tasks would be helpful to get a better understanding of the importance of these modifications: are they effective beyond compressive HSI, beyond HSI. If not, why?\nThe rebuttal was useful. Numerous additional experiments were conducted. Yet, it would have been good to include them in a revised version of the pdf.\n\nAt this point, it seems that the method is promising, but that a major revision of the paper is required, leading to a reject decision for NeurIPS this year.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper is on spectral reconstruction from snapshot CASSI. It is based on the linear inverse model, and solved by merging model-based and learning-based methods in the framework of deep unrolling network. Compared with existing methods, memory-assistant descent blocks and cross-stage attentive proximal subnetworks are proposed, together with a new loss term. Experiments show that it outperforms exiting unrolling based methods and end-to-end methods.\nStrengths And Weaknesses: Strong points: \n1.\tTo use deep unrolling for image/video restoration receives attention in recent years, and the authors proposed new add-ons to improve DUN for CASSI based spectral reconstruction. \n2.\tExperiment results have shown that the proposed method achieves favorable results than existing iterative methods, as well as the latest end-to-end learning based methods. \nWeak points: \n1.\tInitialization of the algorithm and its effect on convergence is not mentioned/discussed. \n2.\tModel/algorithm complexity and running time is not mentioned, especially the advantages/disadvantages when compared with end-to-end methods.\n3.\tMany results are directly quoted from other papers. Is there any reason for that? At least ,there are some randomness for data augmentation. To quote results from elsewhere tends to be improper. \n4.\tNo quantitative comparison is conducted on real data. Maybe a real dataset with GT should be prepared first.\n5.\tPersonally, the reviewer has severe concern about the real meaningfulness of trying to reconstruct spectra from CASSI. Given the spectral accuracy in Fig.2 and Fig4, most high-frequency details can not be recovered. To use several mosaiced filters can reach same level accuracy, yet has much better spatial resolution/details. Given this level of spectral details, reconstructed spectral curves are not meaningful for practical applications. One might directly use CASSI raw images for segmentation/recognition directly, without reconstruction.\nQuestions: Please refer to the weakpoints.\nLimitations: No potential negative social impact.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper presents a method for reconstruction a hyperspectral image from its snapshot measurements.\nStrengths And Weaknesses: This paper requires further improvements on paper organization. The technical contributions of the proposed approach and theoretical background to support the proposed algorithm are not clear enough from the paper. There are many places where the explanation is unclear.\nQuestions: Introduction should discuss the novelty and technical contributions of the proposed approach over previously proposed approaches.\nTheoretical background to support the proposed algorithms should be clearly described.\nLimitations: The technical contribution of the proposed approach and theoretical background to support the proposed algorithm are not clear enough from the paper.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 1 poor\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The paper proposes a new unrolled neural network architecture for the problem of snapshot compressive hyperspectral imaging.\nThe architecture is inspired from proximal gradient descent, where both the gradient update and the proximal mapping steps are replaced by two recurrent modules.\nThe former (Memory-Assistant Descent) is based on ConvLSTM, and the latter (Cross-stage Attentive Proximal sub-network) uses a combination of convolutions, self-attention and triplet attention.\nThe authors compare against multiple recent approaches on several datasets.\nStrengths And Weaknesses: Strengths\n\nThe method achieves very good performances on noise-free data\nThe performances are compared against several recent methods\nSeveral datasets are used to show the superior performances of the proposed method\nAblation studies are provided for multiple parts of the method, allowing to validate the overall significance of the main contributions\n\nWeaknesses\n\nAll quantitative results shown are valid on noise-free measurements only.\nNo quantitative results are provided for noisy measurements, although the image formation model described in the introduction explicitly mentions the presence of noise on measurements. \nThis is even more dissonant as the model is fine-tuned on synthetic noisy data (shot noise) before applying it to real data for visual assessment, which indicates that the noise-free setting is not very realistic.\n\n\nThe authors claim that the visual results on real data is sufficient evidence of the good generalization of the method on real measurement data (i.e. with noise). This is not a convincing argument as it is very difficult to see any improvement of the proposed method over its competitors on real data.\nAll quantitative results are provided without error bars.\nNo visual comparison is provided against the most competitive methods (HDNet, MST-L) on real data.\nQuestions: \nRegarding generalization to real data:\nAs previously stated, visual comparison on real data is not provided against the most performant methods (HDNet, MST-L). This would help assessing the performance of the method.\nA convincing argument would be to provide quantitative results on synthetic data with noisy measurements, similar to table 2 of the paper TSA-Net, where the authors argue that shot noise is realistic in this setting.\n\n\nThere is no evidence that the unrolled architecture is beneficial with this method. An ablation study with a few different number of iterations/stages would be more convincing (including the limit case of a single iteration).\nSince both the Gradient Update and the Proximal Mapping modules benefits from using information across several stages/iterations, what is the justification for using different recurrent architectures (ConvLSTM and \"Cross-stage self-attention\") for tasks which are so similar in spirit ? If the authors disagree with this last statement, please explain why.\nThe use of triplet attention for the CAP module is mentioned, but it would be helpful to develop a bit more why it is used here.\nIt should be made clearer that the results presented in table 1 and table 2 are for noise-free synthetic data.\nWhat is the batch size used ?\nMinor:\nThe same notation is used to denote convolutions (eq. 10-13 and 15) and matrix multiplication (eq. 14). It would be clearer to denote the convolution operation with a dedicated symbol (see for example the ConvLSTM paper), and more coherent as the Hadamard operator has its own explicit symbol.\nIn eq 16, the symbol used for concatenation is ambiguous.\nl. 202: it is unclear what the authors refer to as \"padding number\". Another formulation would be clearer.\nl. 79: supposed to be (I guess)\neq. 10-11: missing term with C^(k-1)\nl. 201: please provide citation for PyTorch\nTable 1: \nthe table is difficult to read. It would benefit from enhancing the separation between methods (spacing or horizontal lines).\nthe number of parameters of DNU should be in bold\n\n\nfig. 2-3 of main paper and fig. 3 of supplemental: DGMP -> DGMSP ?\non visual comparison, it would be helpful to know which spectral channel are shown.\non visual comparison on real data, it would be helpful to display the zoomed region on the reference and snapshot, as it is done with the results\nl. 149: decent -> descent\nLimitations: \nThe broader impact section is not included in the 9 pages limit. Instead it is addressed in the supplemental material.\nThe authors do not address the fact that their quantitative experiments are only valid on noise-free measurements only.\nThe authors adequately mention the limitations of the supervised framework, i.e. its dependency on the amount of data available.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper proposes a proximal gradient descent (PGD) based deep unrolling network for snapshot compressive hyperspectral imaging, which employs a memory assistant descent module for gradient descent and a sub-network with cross-stage self-attention for proximal mapping. The experimental results show that the proposed method outperforms the compared methods.\nStrengths And Weaknesses: Strength\n\nDeep unrolling network is an important technique for snapshot compressive sensing.\nModeling correlation between different iteration stages in deep unrolling network is a good idea to improve the performance.\nWeakness\n\n\nNovelty. Memory assistant deep unrolling network has been proposed in previous work, such as [1]. The relationship and the difference should be discussed. Besides, the comparison between these two methods is also necessary.\nInterpretability. Deep unrolling network is famous for its interpretability, compared with conventional deep network. However, adding the connection between different iteration stages weaken the interpretability. Moreover, in this paper, employing ConvLSTM to model the correlation between gradient descent in different iteration stages, which does not follow the PGD iteration. Besides, for hyperspectral snapshot compressive sensing, employing other optimization methods, e.g, ADMM, always have a fast close-form solver for data-fidelity. Thus, gradient descent and further memory-assistant module may be unnecessary.\nExperiment. PSNR and SSIM only evaluate the spatial fidelity between reconstructed HSI and groudtruth. Spectral fidelity evaluation metrics, e.g., SAM and ERGAS, are also necessary, especially the proposed method proposes a spectral loss.\nWriting. The citation of RMSProp and Adam is lacking in line 61. There lacks blank between 0 and otherwise in line 195. Please checking the typos of this manuscript.\nQuestions: Please see strength and weakness\nLimitations: Yes\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 2 fair\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper is on spectral reconstruction from snapshot CASSI. It is based on the linear inverse model, and solved by merging model-based and learning-based methods in the framework of deep unrolling network. Compared with existing methods, memory-assistant descent blocks and cross-stage attentive proximal subnetworks are proposed, together with a new loss term. Experiments show that it outperforms exiting unrolling based methods and end-to-end methods.",
                "Strengths And Weaknesses": "Strong points: \n1.\tTo use deep unrolling for image/video restoration receives attention in recent years, and the authors proposed new add-ons to improve DUN for CASSI based spectral reconstruction. \n2.\tExperiment results have shown that the proposed method achieves favorable results than existing iterative methods, as well as the latest end-to-end learning based methods. \nWeak points: \n1.\tInitialization of the algorithm and its effect on convergence is not mentioned/discussed. \n2.\tModel/algorithm complexity and running time is not mentioned, especially the advantages/disadvantages when compared with end-to-end methods.\n3.\tMany results are directly quoted from other papers. Is there any reason for that? At least ,there are some randomness for data augmentation. To quote results from elsewhere tends to be improper. \n4.\tNo quantitative comparison is conducted on real data. Maybe a real dataset with GT should be prepared first.\n5.\tPersonally, the reviewer has severe concern about the real meaningfulness of trying to reconstruct spectra from CASSI. Given the spectral accuracy in Fig.2 and Fig4, most high-frequency details can not be recovered. To use several mosaiced filters can reach same level accuracy, yet has much better spatial resolution/details. Given this level of spectral details, reconstructed spectral curves are not meaningful for practical applications. One might directly use CASSI raw images for segmentation/recognition directly, without reconstruction.",
                "Questions": "Please refer to the weakpoints.",
                "Limitations": "No potential negative social impact.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper presents a method for reconstruction a hyperspectral image from its snapshot measurements.",
                "Strengths And Weaknesses": "This paper requires further improvements on paper organization. The technical contributions of the proposed approach and theoretical background to support the proposed algorithm are not clear enough from the paper. There are many places where the explanation is unclear.",
                "Questions": "Introduction should discuss the novelty and technical contributions of the proposed approach over previously proposed approaches.\nTheoretical background to support the proposed algorithms should be clearly described.",
                "Limitations": "The technical contribution of the proposed approach and theoretical background to support the proposed algorithm are not clear enough from the paper.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "1 poor",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper proposes a new unrolled neural network architecture for the problem of snapshot compressive hyperspectral imaging.\nThe architecture is inspired from proximal gradient descent, where both the gradient update and the proximal mapping steps are replaced by two recurrent modules.\nThe former (Memory-Assistant Descent) is based on ConvLSTM, and the latter (Cross-stage Attentive Proximal sub-network) uses a combination of convolutions, self-attention and triplet attention.\nThe authors compare against multiple recent approaches on several datasets.",
                "Strengths And Weaknesses": "Strengths\n\nThe method achieves very good performances on noise-free data\nThe performances are compared against several recent methods\nSeveral datasets are used to show the superior performances of the proposed method\nAblation studies are provided for multiple parts of the method, allowing to validate the overall significance of the main contributions\n\nWeaknesses\n\nAll quantitative results shown are valid on noise-free measurements only.\nNo quantitative results are provided for noisy measurements, although the image formation model described in the introduction explicitly mentions the presence of noise on measurements. \nThis is even more dissonant as the model is fine-tuned on synthetic noisy data (shot noise) before applying it to real data for visual assessment, which indicates that the noise-free setting is not very realistic.\n\n\nThe authors claim that the visual results on real data is sufficient evidence of the good generalization of the method on real measurement data (i.e. with noise). This is not a convincing argument as it is very difficult to see any improvement of the proposed method over its competitors on real data.\nAll quantitative results are provided without error bars.\nNo visual comparison is provided against the most competitive methods (HDNet, MST-L) on real data.",
                "Questions": "Regarding generalization to real data:\nAs previously stated, visual comparison on real data is not provided against the most performant methods (HDNet, MST-L). This would help assessing the performance of the method.\nA convincing argument would be to provide quantitative results on synthetic data with noisy measurements, similar to table 2 of the paper TSA-Net, where the authors argue that shot noise is realistic in this setting.\n\n\nThere is no evidence that the unrolled architecture is beneficial with this method. An ablation study with a few different number of iterations/stages would be more convincing (including the limit case of a single iteration).\nSince both the Gradient Update and the Proximal Mapping modules benefits from using information across several stages/iterations, what is the justification for using different recurrent architectures (ConvLSTM and \"Cross-stage self-attention\") for tasks which are so similar in spirit ? If the authors disagree with this last statement, please explain why.\nThe use of triplet attention for the CAP module is mentioned, but it would be helpful to develop a bit more why it is used here.\nIt should be made clearer that the results presented in table 1 and table 2 are for noise-free synthetic data.\nWhat is the batch size used ?\nMinor:\nThe same notation is used to denote convolutions (eq. 10-13 and 15) and matrix multiplication (eq. 14). It would be clearer to denote the convolution operation with a dedicated symbol (see for example the ConvLSTM paper), and more coherent as the Hadamard operator has its own explicit symbol.\nIn eq 16, the symbol used for concatenation is ambiguous.\nl. 202: it is unclear what the authors refer to as \"padding number\". Another formulation would be clearer.\nl. 79: supposed to be (I guess)\neq. 10-11: missing term with C^(k-1)\nl. 201: please provide citation for PyTorch\nTable 1: \nthe table is difficult to read. It would benefit from enhancing the separation between methods (spacing or horizontal lines).\nthe number of parameters of DNU should be in bold\n\n\nfig. 2-3 of main paper and fig. 3 of supplemental: DGMP -> DGMSP ?\non visual comparison, it would be helpful to know which spectral channel are shown.\non visual comparison on real data, it would be helpful to display the zoomed region on the reference and snapshot, as it is done with the results\nl. 149: decent -> descent",
                "Limitations": "The broader impact section is not included in the 9 pages limit. Instead it is addressed in the supplemental material.\nThe authors do not address the fact that their quantitative experiments are only valid on noise-free measurements only.\nThe authors adequately mention the limitations of the supervised framework, i.e. its dependency on the amount of data available.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposes a proximal gradient descent (PGD) based deep unrolling network for snapshot compressive hyperspectral imaging, which employs a memory assistant descent module for gradient descent and a sub-network with cross-stage self-attention for proximal mapping. The experimental results show that the proposed method outperforms the compared methods.",
                "Strengths And Weaknesses": "Strength\n\nDeep unrolling network is an important technique for snapshot compressive sensing.\nModeling correlation between different iteration stages in deep unrolling network is a good idea to improve the performance.\nWeakness\n\n\nNovelty. Memory assistant deep unrolling network has been proposed in previous work, such as [1]. The relationship and the difference should be discussed. Besides, the comparison between these two methods is also necessary.\nInterpretability. Deep unrolling network is famous for its interpretability, compared with conventional deep network. However, adding the connection between different iteration stages weaken the interpretability. Moreover, in this paper, employing ConvLSTM to model the correlation between gradient descent in different iteration stages, which does not follow the PGD iteration. Besides, for hyperspectral snapshot compressive sensing, employing other optimization methods, e.g, ADMM, always have a fast close-form solver for data-fidelity. Thus, gradient descent and further memory-assistant module may be unnecessary.\nExperiment. PSNR and SSIM only evaluate the spatial fidelity between reconstructed HSI and groudtruth. Spectral fidelity evaluation metrics, e.g., SAM and ERGAS, are also necessary, especially the proposed method proposes a spectral loss.\nWriting. The citation of RMSProp and Adam is lacking in line 61. There lacks blank between 0 and otherwise in line 195. Please checking the typos of this manuscript.",
                "Questions": "Please see strength and weakness",
                "Limitations": "Yes",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "soundness_avg": 2.5,
        "presentation_avg": 2.0,
        "contribution_avg": 2.5,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the proposed method in this paper has several strengths. Reviewer 1 highlights the attention received by deep unrolling for image/video restoration and the improvements made by the authors in the context of CASSI-based spectral reconstruction. The experimental results also show that the proposed method outperforms existing iterative methods and end-to-end learning-based methods. Reviewer 3 also emphasizes the good performances achieved by the method on noise-free data, the comparison against recent methods, and the validation of the main contributions through ablation studies.\n\nHowever, there are also some weaknesses pointed out by the reviewers. Reviewer 1 mentions the lack of discussion on the initialization of the algorithm and its effect on convergence, as well as the absence of a quantitative comparison on real data. Reviewer 2 raises concerns about the clarity of the technical contributions and theoretical background, suggesting the need for further improvements in paper organization. Reviewer 3 points out the absence of quantitative results for noisy measurements and the lack of visual comparison against the most competitive methods on real data.\n\nConsidering the strengths and weaknesses mentioned by the reviewers, it is clear that the proposed method has potential and makes contributions to the field of snapshot compressive hyperspectral imaging. While there are some limitations and areas for improvement, the overall technical solidity and moderate-to-high impact of the paper justify its acceptance. Therefore, I recommend accepting this paper for publication."
    },
    "Unbiased_Estimates_for_Multilabel_Reductions_of_Extreme_Classification_with_Missing_Labels": {
        "link": "https://openreview.net//forum?id=9zWlrwlT9-j",
        "pub_url": "https://openreview.net/forum?id=9zWlrwlT9-j",
        "pdf_link": "https://openreview.net//pdf?id=9zWlrwlT9-j",
        "paper_id": "9zWlrwlT9-j",
        "title": "Unbiased_Estimates_for_Multilabel_Reductions_of_Extreme_Classification_with_Missing_Labels",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Less certain\nThis is a borderline paper. The reviewers lean towards acceptance but do have reservation about the paper. I have also read the paper in order to make an informed recommendation. In the end I've decided to recommend against acceptance at this point for the reasons I'll describe below. I do understand, and sympathize with the authors' frustration at my decision, but I truly believe that the paper can be significantly improved with some additional work.\nThe authors tackle an interesting and important problem in the area of extreme classification (and multi-label classification in general): the problem of missing labels due to various biases in how the data is annotated. This is a well recognized and important problem both in the extreme classification literature, and also in the benchmark creation literature, especially for computer vision tasks. (I recommend the authors look at the work on Imagenet 2.0 and similar papers where due to the shortcoming of the annotation protocol relevant labels are missing).  The paper makes an interesting theoretical contribution on how to obtain unbiased loss estimates in this case, identifies an issue with the high variance of these estimates, and proposed a lower-variance upper-bound that could be used as a surrogate loss. \nThe main drawback of the paper, as originally submitted is the very limited experimental evaluation. The authors explain the lack of empirical results by the fact that there are no datasets that have accurate propensity scores available, so even evaluating on such datasets would be meaningless. While it is true that existing datasets do have this problem, it is incumbent on the authors to find an application where their work would be applicable. Otherwise, if there is no application that can benefit from this work, what is it useful for?  One suggestion I can make to do the following evaluation: take a (sub-sample) of the instances  that method M assigned label L to and, using human labelers, determine how many of those documents should truly be assigned label L and how many should not have label L. Do this for multiple labels L.  While I admit that this would be a tedious endeavor, it would be possible to achieve with current crowdsourcing technology, and it would significantly improve the paper.  \nDuring the author response period, the authors have submitted additional results on some real datasets. These results do look pretty strong, but, because they have been rushed and not really integrated in the paper, I fear is difficult for the reviewers to truly scrutinize their validity, and to draw the correct conclusions from them.  The paper would benefit from having the authors integrate the results in the paper and fully analyze them. \nI do believe this is interesting work, and I encourage the authors to revise and resubmit their paper at a future conference. But as it is, the paper is not yet ready for publication.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper tackles the missing label problem in the Extreme Classification setting. In particular -\n\nIt provides unbiased estimation of all kind of losses (decomposable or non decomposable over labels) under the missing label setting. Previous papers mostly focused on decomposable losses.\nShows that if propensities are low then these losses can have very high variance and may lead to ill-posed optimization problems.\nProposes to use convex upper bounds of these losses which significantly reduces the variance at cost of slight increase in bias.\nStrengths And Weaknesses: Originality: While the issue of high variance with inverse propensity models has been explored previously such as in [1], this paper studies it in the extreme classification setting where it hasn't been explored much. \nQuality: In terms of experimental results I feel like the paper is a bit weak. It would have been good to see some comparison of the proposed technique with other popular variance reduction methods such as one proposed in [1]\n[1] Swaminathan, Adith, and Thorsten Joachims. \"Counterfactual risk minimization: Learning from logged bandit feedback.\" International Conference on Machine Learning. PMLR, 2015\nQuestions: It would have been nice to see if the proposed convex upper bound framework actually improves the performance on standard tasks/datasets. I believe for a lot of public datasets the propensity scores have been provided [1] so it should be pretty simple to try them out and compare against methods which do not take variance reduction into account.\n[1] The Extreme Classification Repository: Multi-label Datasets & Code: http://manikvarma.org/downloads/XC/XMLRepository.html\nLimitations: Yes\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: In this paper, the authors address the problem of unbiased estimates for multi-label reductions of extreme classification with missing labels. Specifically, the unbiased estimates for four cases of multi-label reductions are discussed. The authors first show the unbiased estimates for general multi-label losses capable for pick-all-labels and normalized reductions, and then prove the upper-bounds for two reductions, which trade-off bias and variance. The empirical experiments demonstrate the influence of missing labels, as well as unbiased estimates. The results also indicate that although unbiased loss functions work well with sufficient training data, normalized reductions can still be starving. Besides, the authors also show that generic multi-label losses with achievable unbiasedness could not be suitable for optimization while the presented trade-off method works well for handling training with fewer data.\nStrengths And Weaknesses: Strengths\n\nComprehensive coverage on different types and cases reductions.\nTheorems and proofs for both unbiased estimates and convex upper-bounds.\nEmpirical studies and practical conclusions that emphasize the contributions\n\nWeaknesses\n\nLack of discussions on the relations to tree-based XMC methods, which are one of the most popular conventional methods for tackling XMC problems.\nLack of discussions of different types of noises.\nQuestions: \nMost of the existing state-of-the-art methods for XMC problems are tree-based methods. In each layer, not all of the labels will participate in optimization and loss calculations. Moreover, the predictions and inference also usually are based on beam search. I wonder if the conclusions and guidelines can be also applied to those methods.\n\nThe authors model missing-label setting by treating them as independent noises, but real-world noises can be more complicated with many different distributions and correlations among labels. I wonder if the methods can be further extended to more different types of noises (or distributions of missing labels).\nLimitations: The authors did not address any limitations and potential negative societal impact.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper discusses the problem of  missing labels in extreme multi-label classification (XMC). First a framework for defining the loss function is defined, which can be applied to various one-vs-all (OVA) and pick-all-labels reduction methods. Next, unbiased estimators for the loss functions based on propensity  are discussed, and it is shown that such estimators have high variance. Next, convex upper-bounds for the loss functions are discussed, in order to obtain efficient solvers. Numerical results on two datasets are presented to illustrate the various aspects of missing labels in XMC problems.\nStrengths And Weaknesses: The strengths of the paper  are:\n\nAn important problem in XMC, that of missing labels is discussed.\nUnbiased loss functions and their convex upper bounds are discussed.\nThe framework is general and addressed a range of XMC methods that can be written as OvA or PAL.\n\nThe weaknesses of the paper  are:\n\nSignificance of the results are not clear.\nNumerical results seem limited.\nScalability issues are not addressed.\nQuestions: Missing labels is an important problem in XMC literature. The paper might be presenting an interesting framework for solving XMC problems with missing labels. \nHowever, the current version of the paper has the following shortcomings:  \n\nSignificance: Unbiased loss functions for XMC with missing labels have been proposed before, see [1],[2]. It is not clear how the proposed estimators in this paper differ from the existing ones and what are the significance of the proposed estimators. Also, certain aspects are  not clear, eg., why the upper bounds would have reduced variance and how the bias looks like in these cases.\n\nNumerical results: The experiment results seem limited. Only two datasets are considered. Many aspects of the framework are not studied, e.g., whether the considers loss functions solve the original XMC problem efficiently, what type of XMC algorithms perform best (OvA or PAL), also, comparison to [1],[2] would be helpful to better understand the advantages of the popped framework. \n\nScalibity: Since in XMC set up, the number of instances and labels can be very large (in millions), it is not clear if OvA or PAL is scalable. There are many other reduction methods (label reduction or tree based methods) that are scalable. So, it is not clear if studying OvA type methods is useful in XMC settings.\n\nMinor comment:\ni. In Theorem 2, under the conditions of Theorem 2 --> under the conditions of Proposition 2?\n\n\nReferences:\n[1] Schultheis, Erik, and Rohit Babbar. \"Unbiased Loss Functions for Multilabel Classification with Missing Labels.\" arXiv preprint arXiv:2109.11282 (2021).\n[2] Schultheis, Erik, et al. \"Unbiased Loss Functions for Extreme Classification With Missing Labels.\" arXiv preprint arXiv:2007.00237 (2020).\nLimitations: Yes, the paper addresses these.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: The paper studies the problem of extreme multi-label learning with missing labels. To solve the problem, the paper considers reducing the multi-label problem into a serious binary or multi-class problems. To deal with missing labels, the paper proposes unbiased estimates for multi-label reduction loss functions. To reduce the variance of estimates, the paper proposes convex upper-bound for the OVA and PAL-reduction.\nStrengths And Weaknesses: Strength\n1.The paper proposes a framework for dealing with missing labels in extreme multi-label setting. In the proposed framework, the unbiased estimates in terms of decomposable reduction and non-decomposable losses under missing-label setting are derived.\n2.To deal with issue of increased variance, the paper proposes convex upper bounds for normalized PAL reduction, which provides trade-off between bias and variance.\nWeakness\n1.The experiments are weak. The paper only conducts a toy experiment and an experiment on a real-world dataset. Furthermore, the proposed method does not compare with other counterpart methods. The experimental results on the current submission are insufficient to validate the effectiveness of the proposed method.\n2.The paper is not well written. Many important details are missed or placed on the appendix, which make the paper hard to understand. For example, Eq.(4) is difficult to understand without any detailed introduction (in appendix). This makes this paper become difficult to follow. The organization of this paper should be improved. For example, the figures in experiments are too large with limited information.\n3.The paper fails to sufficiently discuss its pioneering works. Many related works are missed. For example, authors do not discuss the relevant works in extreme multi-label classification that are very relevant to this work. The very relevant works about multi-label noise are also missed.\nQuestions: In experiments, why use BCE for OVA reduction and CCE for PAL reduction? \nIn Related Work, authors claim that \u201clearning with missing labels is a specific\u201d instance of learning with class-conditional noise. Why? Is it there any reference?\nLimitations: The experiments are weak due to the lack of comparison with counterpart methods. The results on real-world scenarios are also insufficient.\nEthics Flag: No\nEthics Review Area: I don\u2019t know\nSoundness: 3 good\nPresentation: 1 poor\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper tackles the missing label problem in the Extreme Classification setting. In particular -\n\nIt provides unbiased estimation of all kind of losses (decomposable or non decomposable over labels) under the missing label setting. Previous papers mostly focused on decomposable losses.\nShows that if propensities are low then these losses can have very high variance and may lead to ill-posed optimization problems.\nProposes to use convex upper bounds of these losses which significantly reduces the variance at cost of slight increase in bias.",
                "Strengths And Weaknesses": "Originality: While the issue of high variance with inverse propensity models has been explored previously such as in [1], this paper studies it in the extreme classification setting where it hasn't been explored much. \nQuality: In terms of experimental results I feel like the paper is a bit weak. It would have been good to see some comparison of the proposed technique with other popular variance reduction methods such as one proposed in [1]\n[1] Swaminathan, Adith, and Thorsten Joachims. \"Counterfactual risk minimization: Learning from logged bandit feedback.\" International Conference on Machine Learning. PMLR, 2015",
                "Questions": "It would have been nice to see if the proposed convex upper bound framework actually improves the performance on standard tasks/datasets. I believe for a lot of public datasets the propensity scores have been provided [1] so it should be pretty simple to try them out and compare against methods which do not take variance reduction into account.\n[1] The Extreme Classification Repository: Multi-label Datasets & Code: http://manikvarma.org/downloads/XC/XMLRepository.html",
                "Limitations": "Yes",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "In this paper, the authors address the problem of unbiased estimates for multi-label reductions of extreme classification with missing labels. Specifically, the unbiased estimates for four cases of multi-label reductions are discussed. The authors first show the unbiased estimates for general multi-label losses capable for pick-all-labels and normalized reductions, and then prove the upper-bounds for two reductions, which trade-off bias and variance. The empirical experiments demonstrate the influence of missing labels, as well as unbiased estimates. The results also indicate that although unbiased loss functions work well with sufficient training data, normalized reductions can still be starving. Besides, the authors also show that generic multi-label losses with achievable unbiasedness could not be suitable for optimization while the presented trade-off method works well for handling training with fewer data.",
                "Strengths And Weaknesses": "Strengths\n\nComprehensive coverage on different types and cases reductions.\nTheorems and proofs for both unbiased estimates and convex upper-bounds.\nEmpirical studies and practical conclusions that emphasize the contributions\n\nWeaknesses\n\nLack of discussions on the relations to tree-based XMC methods, which are one of the most popular conventional methods for tackling XMC problems.\nLack of discussions of different types of noises.",
                "Questions": "Most of the existing state-of-the-art methods for XMC problems are tree-based methods. In each layer, not all of the labels will participate in optimization and loss calculations. Moreover, the predictions and inference also usually are based on beam search. I wonder if the conclusions and guidelines can be also applied to those methods.\n\nThe authors model missing-label setting by treating them as independent noises, but real-world noises can be more complicated with many different distributions and correlations among labels. I wonder if the methods can be further extended to more different types of noises (or distributions of missing labels).",
                "Limitations": "The authors did not address any limitations and potential negative societal impact.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper discusses the problem of  missing labels in extreme multi-label classification (XMC). First a framework for defining the loss function is defined, which can be applied to various one-vs-all (OVA) and pick-all-labels reduction methods. Next, unbiased estimators for the loss functions based on propensity  are discussed, and it is shown that such estimators have high variance. Next, convex upper-bounds for the loss functions are discussed, in order to obtain efficient solvers. Numerical results on two datasets are presented to illustrate the various aspects of missing labels in XMC problems.",
                "Strengths And Weaknesses": "The strengths of the paper  are:\n\nAn important problem in XMC, that of missing labels is discussed.\nUnbiased loss functions and their convex upper bounds are discussed.\nThe framework is general and addressed a range of XMC methods that can be written as OvA or PAL.\n\nThe weaknesses of the paper  are:\n\nSignificance of the results are not clear.\nNumerical results seem limited.\nScalability issues are not addressed.",
                "Questions": "Missing labels is an important problem in XMC literature. The paper might be presenting an interesting framework for solving XMC problems with missing labels. \nHowever, the current version of the paper has the following shortcomings:  \n\nSignificance: Unbiased loss functions for XMC with missing labels have been proposed before, see [1],[2]. It is not clear how the proposed estimators in this paper differ from the existing ones and what are the significance of the proposed estimators. Also, certain aspects are  not clear, eg., why the upper bounds would have reduced variance and how the bias looks like in these cases.\n\nNumerical results: The experiment results seem limited. Only two datasets are considered. Many aspects of the framework are not studied, e.g., whether the considers loss functions solve the original XMC problem efficiently, what type of XMC algorithms perform best (OvA or PAL), also, comparison to [1],[2] would be helpful to better understand the advantages of the popped framework. \n\nScalibity: Since in XMC set up, the number of instances and labels can be very large (in millions), it is not clear if OvA or PAL is scalable. There are many other reduction methods (label reduction or tree based methods) that are scalable. So, it is not clear if studying OvA type methods is useful in XMC settings.\n\nMinor comment:\ni. In Theorem 2, under the conditions of Theorem 2 --> under the conditions of Proposition 2?\n\n\nReferences:\n[1] Schultheis, Erik, and Rohit Babbar. \"Unbiased Loss Functions for Multilabel Classification with Missing Labels.\" arXiv preprint arXiv:2109.11282 (2021).\n[2] Schultheis, Erik, et al. \"Unbiased Loss Functions for Extreme Classification With Missing Labels.\" arXiv preprint arXiv:2007.00237 (2020).",
                "Limitations": "Yes, the paper addresses these.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper studies the problem of extreme multi-label learning with missing labels. To solve the problem, the paper considers reducing the multi-label problem into a serious binary or multi-class problems. To deal with missing labels, the paper proposes unbiased estimates for multi-label reduction loss functions. To reduce the variance of estimates, the paper proposes convex upper-bound for the OVA and PAL-reduction.",
                "Strengths And Weaknesses": "Strength\n1.The paper proposes a framework for dealing with missing labels in extreme multi-label setting. In the proposed framework, the unbiased estimates in terms of decomposable reduction and non-decomposable losses under missing-label setting are derived.\n2.To deal with issue of increased variance, the paper proposes convex upper bounds for normalized PAL reduction, which provides trade-off between bias and variance.\nWeakness\n1.The experiments are weak. The paper only conducts a toy experiment and an experiment on a real-world dataset. Furthermore, the proposed method does not compare with other counterpart methods. The experimental results on the current submission are insufficient to validate the effectiveness of the proposed method.\n2.The paper is not well written. Many important details are missed or placed on the appendix, which make the paper hard to understand. For example, Eq.(4) is difficult to understand without any detailed introduction (in appendix). This makes this paper become difficult to follow. The organization of this paper should be improved. For example, the figures in experiments are too large with limited information.\n3.The paper fails to sufficiently discuss its pioneering works. Many related works are missed. For example, authors do not discuss the relevant works in extreme multi-label classification that are very relevant to this work. The very relevant works about multi-label noise are also missed.",
                "Questions": "In experiments, why use BCE for OVA reduction and CCE for PAL reduction? \nIn Related Work, authors claim that \u201clearning with missing labels is a specific\u201d instance of learning with class-conditional noise. Why? Is it there any reference?",
                "Limitations": "The experiments are weak due to the lack of comparison with counterpart methods. The results on real-world scenarios are also insufficient.",
                "Ethics Flag": "No",
                "Ethics Review Area": "I don\u2019t know",
                "Soundness": "3 good",
                "Presentation": "1 poor",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "soundness_avg": 3.0,
        "presentation_avg": 2.25,
        "contribution_avg": 2.75,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that this paper addresses an important problem in extreme multi-label classification (XMC) - the problem of missing labels. The paper proposes a framework for defining loss functions and discusses unbiased estimators and convex upper-bounds for these loss functions. The strengths of the paper include its comprehensive coverage of different types and cases of reductions, theorems and proofs for unbiased estimates and convex upper-bounds, and empirical studies that demonstrate the influence of missing labels and the effectiveness of the proposed methods.\n\nWhile there are some weaknesses pointed out by the reviewers, such as the limited experimental results and the lack of discussions on tree-based XMC methods and different types of noises, these weaknesses do not outweigh the strengths of the paper. The reviewers also have some questions and suggestions for improvement, but these do not raise major concerns about the validity or significance of the proposed methods.\n\nOverall, this paper is technically solid and has moderate-to-high impact. It provides valuable contributions to the field of XMC with missing labels. Therefore, I recommend accepting this paper."
    },
    "Highly_Parallel_Deep_Ensemble_Learning": {
        "link": "https://openreview.net//forum?id=IZXIfq0CuTa",
        "pub_url": "https://openreview.net/forum?id=IZXIfq0CuTa",
        "pdf_link": "https://openreview.net//pdf?id=IZXIfq0CuTa",
        "paper_id": "IZXIfq0CuTa",
        "title": "Highly_Parallel_Deep_Ensemble_Learning",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nReviewers generally agreed that the parallelization idea described in the manuscript is interesting, but for the most part felt that it is not well positioned within existing literature (making it difficult to gauge the exact novelty), and that empirical results are not sufficiently convincing.  I encourage the authors to address these two critiques and submit their work to a future venue.",
        "reviews": [
            "Reviewer 1: \nSummary: This work proposes a tensorial representation of data, and linear transformation and split into multiple spectral subsets. An independent neural network is trained on each of these subsets at training and combined through an ensembling approach. This reduces the computational complexity due to smaller data size per network and the parallel training of each subnetwork.\nStrengths And Weaknesses: Strengths\n\nAble to train an ensemble of subnetworks on a subset of data in a highly parallel fashion is an efficient way to learn generalizable and efficient neural network model.\nThis can lead to a paradigm shift in the way models are learned and can enable the scaling of approach to larger data and network sizes\n\nWeaknesses\nThe (novel) contribution of the paper and contrast with literature is not clear. The tensor layer idea seems to be already proposed in the literature. If the parallel implementation and ensembling the network outputs is the contribution, it should be made clear\nQuestions: \nIn related works, it would be helpful if the proposed approach is contrasted against other ensembling techniques that learn sparse subnetworks [1, 2]. Also, discussion on other data subsetting approaches []  will provide a good context.\n\nFor the fully connected spectral tensor layer, is it possible to set Q < 3n? if so, has the sensitivity to this been evaluated? Similarly, is the effect of the choice of B for the convolutional spectral tensor layer evaluated?\n\nIt is mentioned that the performance metrics of Compression ratio, Parallel Speedup, Convergence, and Accuracy are considered, but these metrics are not explicitly shown in table 3 and 4\n\nHow are the neural network hyperparmeters chosen for MNIST and CIFAR-10 FC-tensor method?\n\nThe performance of tNN and FC-tensor seems to be poor in CIFAR-10 compared to a vanilla FC, why is this?\n\nWhy not use a convolutional spectral tensor layer for CIFAR10.\n\nIs the O(Q) and O(B) speedup seen during training? \n\nA discussion on the limitations of the approach will be helpful. Can this be applied for residual networks?\n\nMinor typos in multiple places \n\nStrucred linear layers (pg 1)\nCIAFR-10 used multiple times (pg 8)\nLimitations: the limitations and potential negative societal impact of this work is not provided\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 4 excellent\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The authors proposed a spectral tensor decomposition of a DNN into independent, parallel and computationally cheaper subnets that process corresponding spectrally decomposed data, resulting in speedup in training; ensembling of these subnets yielded reasonable generalization performance.\nStrengths And Weaknesses: [+] Novel idea\n[-] Inadequate supporting experiments\nQuestions: \nThough a recurrent spectral tensor layer was derived, it was not demonstrated with experiments.  \nThe example DNNs experimented are not representative or practically relevant. \nDo spectral tensor transformers exist?  \nIt seems decomposition of data with orthogonal bases is not unique.  Nor is the number of components and the grouping thereof.  How does one choose optimal or reasonable decomposition?  \nWith a certain data decomposition, task-relevant information in different components naturally vary.  Corresponding subnet experts might need to have different capacities to realize maximal efficiency?  Or how does one equalize component importance, or do spectral pruning?\nFig. 2, why was the FC training numerically unstable, with a non-monotonic training loss curve?\nLimitations: See above.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 1 poor\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper introduces a parallelization of DNN from a tensor perspective. The data is split into their spectral subsets and is passed into parallel subnetworks and finally, the results are based on an ensemble of the subnetworks. Specifically, the author provides detailed spectral counterparts for fully connected layer, convolution layer and recurrent layers. The tensorized structure naturally enables network compression at the same time.\nStrengths And Weaknesses: The overall idea is interesting and novel to some extent. By separating data into spectral subsets, the compression limit is extended as well as the level of parallelization. The experimental supports the claim that applying the technic speeds up the training and the inference.\nThe overall structure is well-organized. However, there may be space for improvement in conveying the motivation, ideas, and justifications.\nIn the introduction part, the author mentions that the proposed method has no communication cost. It may be better if the author could support such claims by comparing them with other parallelization ideas which have such costs. \nFor the main idea, the author mentions the independence of each subset and the orthogonality among each subset. However, how to obtain such subsets and a principal way to select the desired dimension (Q) is not very clear and well-justified. \nMy main concern with the work, besides the justification, is how significant and general it is. \nIn the experiment session, the author compares performance and runtime on FC, tNN, AlexNet and CycleMLP, but no state-of-the-art architectures on the benchmarks. \nAlso there is a lack of runtime comparison on other parallel DNN baselines. \nAs for the recurrent settings, the attention mechanism also achieves a certain level of parallelization, which may be worth comparing as well.\nQuestions: \nhow to make sure that the divided subsets are independent and orthogonal to each other.\n\nWhat is the performance (accuracy, runtime, compression) compared to the sota architectures in the benchmark in the experiment session.\n\nIs there any way to demonstrate or analyze the generalization ability of proposed structures compared to original structures?\nLimitations: Limitations not discussed.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: The paper introduces a method to train DNN models using parallel ensemble learning. The key idea is to build networks with parallel branches and update each branch independently using split, independent data sets. The evaluation shows that such a method can lead to reduced computation and model size on MNIST, CIFAR-10, and ImageNet.\nStrengths And Weaknesses: Strengths:\n\nInteresting idea to combine parallel ensemble learning and compression. \nThe paper obtains preliminary promising results on training speedups and model sizes.\n\nWeaknesses:\n\nThe proposed method in this paper is highly related to parallel training and compression but appears to miss a lot of related work in both areas. On the training side, there are many existing works on reducing the memory consumption of DNN training, such as [1-3]. On the compression side, the proposed method looks closely related to mixture-of-experts (MoE) where a model has multiple parallel expert branches and each branch is sparsely activated during training, but it misses citing any MoE related papers such as MoE[4], Gshard[5], SwitchTransformer[6]. Overall, parallel ensemble learning is an interesting idea and could lead to something quite impactful. However, given its current status of not positioning it well with many existing works on parallel training and sparse training, it is hard to evaluate the significance and novelty of the proposed method.\n\nThere are some mismatched statements. For example, in line 27, the paper says modern DNNs have billions of parameters, but then the examples given are AlexNet, which has only 60 million parameters and is one the earliest network far from representing billion-scale models. \n[1] Rajbandari et al. \"ZeRO: Memory Optimizations Toward Training Trillion Parameter Models\",  https://arxiv.org/pdf/1910.02054.pdf\n[2] Shoeybi et al. \"Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism\", https://arxiv.org/abs/1909.08053\n[3] Huang et al. \"GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism\", https://arxiv.org/abs/1811.06965\n[4] Shazeer et al. \"Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer\"\n[5] Lepikhin et al. \"GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding\"\n[6] Fedus et al. \"Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity\"\nQuestions: Please describe the relationship between the proposed method with respect to existing parallelism strategies for model training and MoE models.\nWhy choose AlexNet for the evaluation? It would strengthen the work a lot if it is performed on more standard MLPerf benchmarks, such as ResNet or BERT models.\nLimitations: No, there is almost no discussion on the limitations of the proposed method. It would be better if the authors could discuss the rationale behind the chosen workloads and also the generalizability of the proposed method.\nEthics Flag: No\nEthics Review Area: I don\u2019t know\nSoundness: 3 good\nPresentation: 1 poor\nContribution: 3 good\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This work proposes a tensorial representation of data, and linear transformation and split into multiple spectral subsets. An independent neural network is trained on each of these subsets at training and combined through an ensembling approach. This reduces the computational complexity due to smaller data size per network and the parallel training of each subnetwork.",
                "Strengths And Weaknesses": "Strengths\n\nAble to train an ensemble of subnetworks on a subset of data in a highly parallel fashion is an efficient way to learn generalizable and efficient neural network model.\nThis can lead to a paradigm shift in the way models are learned and can enable the scaling of approach to larger data and network sizes\n\nWeaknesses\nThe (novel) contribution of the paper and contrast with literature is not clear. The tensor layer idea seems to be already proposed in the literature. If the parallel implementation and ensembling the network outputs is the contribution, it should be made clear",
                "Questions": "In related works, it would be helpful if the proposed approach is contrasted against other ensembling techniques that learn sparse subnetworks [1, 2]. Also, discussion on other data subsetting approaches []  will provide a good context.\n\nFor the fully connected spectral tensor layer, is it possible to set Q < 3n? if so, has the sensitivity to this been evaluated? Similarly, is the effect of the choice of B for the convolutional spectral tensor layer evaluated?\n\nIt is mentioned that the performance metrics of Compression ratio, Parallel Speedup, Convergence, and Accuracy are considered, but these metrics are not explicitly shown in table 3 and 4\n\nHow are the neural network hyperparmeters chosen for MNIST and CIFAR-10 FC-tensor method?\n\nThe performance of tNN and FC-tensor seems to be poor in CIFAR-10 compared to a vanilla FC, why is this?\n\nWhy not use a convolutional spectral tensor layer for CIFAR10.\n\nIs the O(Q) and O(B) speedup seen during training? \n\nA discussion on the limitations of the approach will be helpful. Can this be applied for residual networks?\n\nMinor typos in multiple places \n\nStrucred linear layers (pg 1)\nCIAFR-10 used multiple times (pg 8)",
                "Limitations": "the limitations and potential negative societal impact of this work is not provided",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "4 excellent",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors proposed a spectral tensor decomposition of a DNN into independent, parallel and computationally cheaper subnets that process corresponding spectrally decomposed data, resulting in speedup in training; ensembling of these subnets yielded reasonable generalization performance.",
                "Strengths And Weaknesses": "[+] Novel idea\n[-] Inadequate supporting experiments",
                "Questions": "Though a recurrent spectral tensor layer was derived, it was not demonstrated with experiments.  \nThe example DNNs experimented are not representative or practically relevant. \nDo spectral tensor transformers exist?  \nIt seems decomposition of data with orthogonal bases is not unique.  Nor is the number of components and the grouping thereof.  How does one choose optimal or reasonable decomposition?  \nWith a certain data decomposition, task-relevant information in different components naturally vary.  Corresponding subnet experts might need to have different capacities to realize maximal efficiency?  Or how does one equalize component importance, or do spectral pruning?\nFig. 2, why was the FC training numerically unstable, with a non-monotonic training loss curve?",
                "Limitations": "See above.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "1 poor",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper introduces a parallelization of DNN from a tensor perspective. The data is split into their spectral subsets and is passed into parallel subnetworks and finally, the results are based on an ensemble of the subnetworks. Specifically, the author provides detailed spectral counterparts for fully connected layer, convolution layer and recurrent layers. The tensorized structure naturally enables network compression at the same time.",
                "Strengths And Weaknesses": "The overall idea is interesting and novel to some extent. By separating data into spectral subsets, the compression limit is extended as well as the level of parallelization. The experimental supports the claim that applying the technic speeds up the training and the inference.\nThe overall structure is well-organized. However, there may be space for improvement in conveying the motivation, ideas, and justifications.\nIn the introduction part, the author mentions that the proposed method has no communication cost. It may be better if the author could support such claims by comparing them with other parallelization ideas which have such costs. \nFor the main idea, the author mentions the independence of each subset and the orthogonality among each subset. However, how to obtain such subsets and a principal way to select the desired dimension (Q) is not very clear and well-justified. \nMy main concern with the work, besides the justification, is how significant and general it is. \nIn the experiment session, the author compares performance and runtime on FC, tNN, AlexNet and CycleMLP, but no state-of-the-art architectures on the benchmarks. \nAlso there is a lack of runtime comparison on other parallel DNN baselines. \nAs for the recurrent settings, the attention mechanism also achieves a certain level of parallelization, which may be worth comparing as well.",
                "Questions": "how to make sure that the divided subsets are independent and orthogonal to each other.\n\nWhat is the performance (accuracy, runtime, compression) compared to the sota architectures in the benchmark in the experiment session.\n\nIs there any way to demonstrate or analyze the generalization ability of proposed structures compared to original structures?",
                "Limitations": "Limitations not discussed.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper introduces a method to train DNN models using parallel ensemble learning. The key idea is to build networks with parallel branches and update each branch independently using split, independent data sets. The evaluation shows that such a method can lead to reduced computation and model size on MNIST, CIFAR-10, and ImageNet.",
                "Strengths And Weaknesses": "Strengths:\n\nInteresting idea to combine parallel ensemble learning and compression. \nThe paper obtains preliminary promising results on training speedups and model sizes.\n\nWeaknesses:\n\nThe proposed method in this paper is highly related to parallel training and compression but appears to miss a lot of related work in both areas. On the training side, there are many existing works on reducing the memory consumption of DNN training, such as [1-3]. On the compression side, the proposed method looks closely related to mixture-of-experts (MoE) where a model has multiple parallel expert branches and each branch is sparsely activated during training, but it misses citing any MoE related papers such as MoE[4], Gshard[5], SwitchTransformer[6]. Overall, parallel ensemble learning is an interesting idea and could lead to something quite impactful. However, given its current status of not positioning it well with many existing works on parallel training and sparse training, it is hard to evaluate the significance and novelty of the proposed method.\n\nThere are some mismatched statements. For example, in line 27, the paper says modern DNNs have billions of parameters, but then the examples given are AlexNet, which has only 60 million parameters and is one the earliest network far from representing billion-scale models. \n[1] Rajbandari et al. \"ZeRO: Memory Optimizations Toward Training Trillion Parameter Models\",  https://arxiv.org/pdf/1910.02054.pdf\n[2] Shoeybi et al. \"Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism\", https://arxiv.org/abs/1909.08053\n[3] Huang et al. \"GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism\", https://arxiv.org/abs/1811.06965\n[4] Shazeer et al. \"Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer\"\n[5] Lepikhin et al. \"GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding\"\n[6] Fedus et al. \"Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity\"",
                "Questions": "Please describe the relationship between the proposed method with respect to existing parallelism strategies for model training and MoE models.\nWhy choose AlexNet for the evaluation? It would strengthen the work a lot if it is performed on more standard MLPerf benchmarks, such as ResNet or BERT models.",
                "Limitations": "No, there is almost no discussion on the limitations of the proposed method. It would be better if the authors could discuss the rationale behind the chosen workloads and also the generalizability of the proposed method.",
                "Ethics Flag": "No",
                "Ethics Review Area": "I don\u2019t know",
                "Soundness": "3 good",
                "Presentation": "1 poor",
                "Contribution": "3 good",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 4.5,
        "confidence_avg": 3.25,
        "soundness_avg": 2.75,
        "presentation_avg": 1.75,
        "contribution_avg": 2.75,
        "ai_sum_meta": "Recommendation: Reject\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that the paper has some strengths, such as the novel idea of training an ensemble of subnetworks in a highly parallel fashion. However, there are also several weaknesses pointed out by the reviewers. The contribution of the paper and its contrast with existing literature is not clear, and there are concerns about the lack of supporting experiments and inadequate evaluation. Additionally, there are questions raised about the choice of architectures for evaluation and the lack of discussion on the limitations of the proposed method. Overall, while the idea is interesting, the paper falls short in terms of significance, novelty, and evaluation. Therefore, I recommend rejecting the paper."
    },
    "Prompt_Injection:_Parameterization_of_Fixed_Inputs": {
        "link": "https://openreview.net//forum?id=FjqBs4XKe87",
        "pub_url": "https://openreview.net/forum?id=FjqBs4XKe87",
        "pdf_link": "https://openreview.net//pdf?id=FjqBs4XKe87",
        "paper_id": "FjqBs4XKe87",
        "title": "Prompt_Injection:_Parameterization_of_Fixed_Inputs",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Less certain\nThe paper proposes a method for distilling prompts into the parameters of a model. Reviewers liked that the method can improve the efficiency of inference by avoiding having to attend over prompts, and the evaluation on the PersonaChat dataset is a good use case for this approach. However, several important concerns were raised. As pointed out by reviewer y47p, similar ideas have been explored in previous work, and claims of novelty need to be toned down. As acknowledged in the author response, most of the experiments are on tasks with short inputs, so gain little benefit from the approach. The difficulty in finding suitable tasks where the approach has a clear benefit might suggest the method has limited applicability. The additional experiment on MSC is a nice addition in the author response, although results here are a bit underwhelming. Overall, this is borderline, leaning reject.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper addresses the problem in prompt learning that prompts are always included in the input text, which can cause computational and memory overhead.\nTo this end, this paper proposes prompt injection, a method that injects the prompt into the parameters of a pre-trained language model (PLM).\nThey show that the prompt injection method can be 280 times more efficient compared with previous approaches.\nStrengths And Weaknesses: Strength:\n\nThis paper proposes an interesting question that many conditional text generation tasks usually include an instance-specific prompt for each data, for example the persona profile for persona dialogue generation.\nHowever, such prompt can cause computational costs and make it difficult for models to capture the key information during inference, in particular when the prompt is very long.\nTherefore, this paper proposes a new method call Prompt Inject (PI) to store the prompts in the PLM instead of concating it to the input.\nTo my knowledge, the idea is very novel and interesting.\n\nThe experiments are solid.\nThis paper conducts experiments on persona dialogue generation, Text-2-SQL and zero-shot task generalization.\nThe experiments show that the PI can speed up the inference time and improve the lower bound of the models.\n\nThis paper is well written with proper citation and clarification\n\n\nWeakness:\nA minor note would be that the prompt in this paper is different from the prompt in most sense in other NLP paper, such prefix tuning, prompt tuning, etc.\nSo I  would suggest that the authors could give a more clear explanation on this issue in the introduction.\nQuestions: NA\nLimitations: NA\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper is about prompt injection, which aims to be an efficient alternative to attaching fixed prompts to the input. Prompt injection is sample efficient and worth it when there are long prompts. This can be useful if there is a detailed description of a personalized chatbot, for example.\nUpdate after response.\nWith the additional experiment, I've increased my score to 5.\nStrengths And Weaknesses: Originality: Paper tackles the problem of using fixed prompts many times for different examples.\nQuality: Experiments done in the paper are OK but not particularly stunning. One way to improve the experiments could have been to pick a setting where it was crucial for long contexts (like summarization, or long dialogues), and show that with this method it was possible to use longer contexts which lead to substantially better performance. Or show that it works over a broad range of settings.\nClarity: The paper is relatively clear.\nSignificance: The paper proposes a method for prepending fixed prompts in a computationally efficient manner. \nWhile the paper is a nice start, I think it still leaves a lot to be desired. There is enough substance to warrant an ACL short paper, but I am not sure about a NeurIPS paper. Some examples of how I think the paper could be stronger:\n\nEmpirical results showing that PING works across a very wide range of tasks with good performance. \nComparison with other methods that try to do similar things.\nShow for tasks that require long inputs and long prompts, PING enables substantial performance improvements. \nOverall, experiments on settings where fast inference is crucial might make it more clear to the reader why it is important to trade off this complexity from using PING for faster inference.\n\nMinor note: Line 22 should be Sanh et al, not Raffel et al., right?\nSome further related work might have been missed, such as context distillation (https://arxiv.org/pdf/2112.00861.pdf)\nQuestions: How does the proposed method compare with other baselines such as context distillation? (Askell et al, https://arxiv.org/pdf/2112.00861.pdf)\nAre there other approaches where this approach might be especially useful? As the main benefit is inference-time efficiency, one might imagine that the WSC, RTE, COPA, and SPIDER tasks are not the prime candidates for this approach. The dialogue eval is good but it only uses one dataset.\nLimitations: Seems fine to me\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper proposes a (self-proclaimed) novel approach called prompt injection, which injects the declarative knowledge of a prompt into the language model parameters by distilling a teacher model with the prompt into a student teacher without prompt on automatically generated inputs. The papers show that the injection is successful across a wide & diverse range of tasks and the approach saves inference time compute.\nStrengths And Weaknesses: Strength:\n\nThis paper elaborates on the impactful idea of \"prompt-injection\", and show that this is broadly useful for a wide range of tasks. \nThis paper also sets up a reasonable evaluation framework that could be used to test future methods.\nThis paper is generally well-written.\n\nWeakness:\n\nThe idea of prompt-injection is not novel, and various previous works have explored this idea. For example, [1] and \"context distillation\" in [2]. Please tune down the claim on novelty in the presentation. That said, I would still vote for acceptance of this paper since the other paper did not focus on the framing of prompt-injection, and this paper could be useful for the community to cite. \nI wished that there were more experiments and ablations, given that the contribution of this paper is more about \"studying an existing algorithm (PING) and figure out its basic property\", rather than \"proposing a drastically novel algorithm\".\n\n[1] Towards Zero-Label Language Learning\n[2] A General Language Assistant as a Laboratory for Alignment\nQuestions: \nHow many pseudo inputs did the paper distill on? I would imagine that the gap between the student and teacher should drastically decrease when you increase the number of pseudo inputs. \nHow does the gap between student & teacher change w.r.t. model size? Should we expect future larger models to become better at this? \nCan you show some qualitative examples where you claimed that \"the low quality of the pseudo generated inputs lead to lower performance\"? How about the diversity of the pseudo inputs?\nLimitations: Yes.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper addresses the problem in prompt learning that prompts are always included in the input text, which can cause computational and memory overhead.\nTo this end, this paper proposes prompt injection, a method that injects the prompt into the parameters of a pre-trained language model (PLM).\nThey show that the prompt injection method can be 280 times more efficient compared with previous approaches.",
                "Strengths And Weaknesses": "Strength:\n\nThis paper proposes an interesting question that many conditional text generation tasks usually include an instance-specific prompt for each data, for example the persona profile for persona dialogue generation.\nHowever, such prompt can cause computational costs and make it difficult for models to capture the key information during inference, in particular when the prompt is very long.\nTherefore, this paper proposes a new method call Prompt Inject (PI) to store the prompts in the PLM instead of concating it to the input.\nTo my knowledge, the idea is very novel and interesting.\n\nThe experiments are solid.\nThis paper conducts experiments on persona dialogue generation, Text-2-SQL and zero-shot task generalization.\nThe experiments show that the PI can speed up the inference time and improve the lower bound of the models.\n\nThis paper is well written with proper citation and clarification\n\n\nWeakness:\nA minor note would be that the prompt in this paper is different from the prompt in most sense in other NLP paper, such prefix tuning, prompt tuning, etc.\nSo I  would suggest that the authors could give a more clear explanation on this issue in the introduction.",
                "Questions": "NA",
                "Limitations": "NA",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper is about prompt injection, which aims to be an efficient alternative to attaching fixed prompts to the input. Prompt injection is sample efficient and worth it when there are long prompts. This can be useful if there is a detailed description of a personalized chatbot, for example.\nUpdate after response.\nWith the additional experiment, I've increased my score to 5.",
                "Strengths And Weaknesses": "Originality: Paper tackles the problem of using fixed prompts many times for different examples.\nQuality: Experiments done in the paper are OK but not particularly stunning. One way to improve the experiments could have been to pick a setting where it was crucial for long contexts (like summarization, or long dialogues), and show that with this method it was possible to use longer contexts which lead to substantially better performance. Or show that it works over a broad range of settings.\nClarity: The paper is relatively clear.\nSignificance: The paper proposes a method for prepending fixed prompts in a computationally efficient manner. \nWhile the paper is a nice start, I think it still leaves a lot to be desired. There is enough substance to warrant an ACL short paper, but I am not sure about a NeurIPS paper. Some examples of how I think the paper could be stronger:\n\nEmpirical results showing that PING works across a very wide range of tasks with good performance. \nComparison with other methods that try to do similar things.\nShow for tasks that require long inputs and long prompts, PING enables substantial performance improvements. \nOverall, experiments on settings where fast inference is crucial might make it more clear to the reader why it is important to trade off this complexity from using PING for faster inference.\n\nMinor note: Line 22 should be Sanh et al, not Raffel et al., right?\nSome further related work might have been missed, such as context distillation (https://arxiv.org/pdf/2112.00861.pdf)",
                "Questions": "How does the proposed method compare with other baselines such as context distillation? (Askell et al, https://arxiv.org/pdf/2112.00861.pdf)\nAre there other approaches where this approach might be especially useful? As the main benefit is inference-time efficiency, one might imagine that the WSC, RTE, COPA, and SPIDER tasks are not the prime candidates for this approach. The dialogue eval is good but it only uses one dataset.",
                "Limitations": "Seems fine to me",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposes a (self-proclaimed) novel approach called prompt injection, which injects the declarative knowledge of a prompt into the language model parameters by distilling a teacher model with the prompt into a student teacher without prompt on automatically generated inputs. The papers show that the injection is successful across a wide & diverse range of tasks and the approach saves inference time compute.",
                "Strengths And Weaknesses": "Strength:\n\nThis paper elaborates on the impactful idea of \"prompt-injection\", and show that this is broadly useful for a wide range of tasks. \nThis paper also sets up a reasonable evaluation framework that could be used to test future methods.\nThis paper is generally well-written.\n\nWeakness:\n\nThe idea of prompt-injection is not novel, and various previous works have explored this idea. For example, [1] and \"context distillation\" in [2]. Please tune down the claim on novelty in the presentation. That said, I would still vote for acceptance of this paper since the other paper did not focus on the framing of prompt-injection, and this paper could be useful for the community to cite. \nI wished that there were more experiments and ablations, given that the contribution of this paper is more about \"studying an existing algorithm (PING) and figure out its basic property\", rather than \"proposing a drastically novel algorithm\".\n\n[1] Towards Zero-Label Language Learning\n[2] A General Language Assistant as a Laboratory for Alignment",
                "Questions": "How many pseudo inputs did the paper distill on? I would imagine that the gap between the student and teacher should drastically decrease when you increase the number of pseudo inputs. \nHow does the gap between student & teacher change w.r.t. model size? Should we expect future larger models to become better at this? \nCan you show some qualitative examples where you claimed that \"the low quality of the pseudo generated inputs lead to lower performance\"? How about the diversity of the pseudo inputs?",
                "Limitations": "Yes.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.333,
        "confidence_avg": 3.333,
        "soundness_avg": 3.333,
        "presentation_avg": 3.667,
        "contribution_avg": 2.667,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the paper proposes an interesting and novel approach called prompt injection, which addresses the problem of computational and memory overhead caused by including prompts in the input text. The experiments conducted in the paper demonstrate the effectiveness of the prompt injection method in improving inference time and model performance. \n\nWhile there are some suggestions for improvement, such as providing a clearer explanation of the prompt injection method and conducting more experiments and ablations, the overall consensus is that the paper is technically solid and has a high impact on the field. The reviewers also acknowledge the contribution of the paper in studying an existing algorithm and providing a reasonable evaluation framework for future methods.\n\nTherefore, based on the positive feedback and the lack of any unaddressed ethical considerations, I recommend accepting the paper."
    },
    "Implicitly_regularized_interaction_between_SGD_and_the_loss_landscape_geometry": {
        "link": "https://openreview.net//forum?id=KHoV9zn1jLE",
        "pub_url": "https://openreview.net/forum?id=KHoV9zn1jLE",
        "pdf_link": "https://openreview.net//pdf?id=KHoV9zn1jLE",
        "paper_id": "KHoV9zn1jLE",
        "title": "Implicitly_regularized_interaction_between_SGD_and_the_loss_landscape_geometry",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nWhile this paper presents a series of interesting observation, e.g., self regularization around the edge of stability and learning rate scaling, in my view it fails to communicate the scientific value of the work in a coherent way. For example, I find it puzzling that the main result of the paper \"implicitly regularized interaction\" is stated as a definition (Def. 4) instead of a theorem, proposition, or a hypothesis. During the discussion, I realized that the authors use the word \"regularization\" in a slightly non-standard way. My questions to the authors are: (1) what does it mean to regularize the interaction? and (2) how does it relate to generalization?",
        "reviews": [
            "Reviewer 1: \nSummary: The paper studies the instability in SGD optimization dynamics (edge of stability) and how that impacts generalization. In particular, the authors propose the idea of interaction-aware sharpness, which I believe is original. Based on a definition of implicit interaction regularization, the authors propose the linear and saturation learning rate scaling rule (LSSR). Most of the findings are supported by empirical evidences but theoretical support is at an intuitive level.\nStrengths And Weaknesses: Strengths:\n\nThe idea of interaction-aware sharpness seems to be original.\nEmpirical evidence to support the self-regulation of interaction-aware sharpness around the edge of stability.\nIntuituive argument for learning rate scaling.\n\nWeaknesses:\n\nLearning rate scaling only supported by a vague argument and empirical evidence.\nWeak connection between the concepts proposed in the paper and generalization.\nNothing in the theory related to neural networks.\nQuestions: \nMy feeling is that the current theoretical setup may explain the gap between batch optimization and minibatch optimization but that is not the same as explaining generalization because generalization depends on the model class size. Can you agree or disagre?\nMore specifically, do I understand correctly that the theoretical setup does not assume anywhere that the model is a neural network? Then why are all the experiments on neural networks?\nCan we motivate the linear and saturation scaling rule better? I am not sure why keeping the right-hand side of Eq. (11) constant leads to optimal scaling.\nLimitations: N/A\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The authors explore the notion of edge of stability for SGD dynamics, they introduce some quantities and explain / illustrate why they make sense for the understanding of the dynamics. They then propose a novel \"linear and saturation scaline rule\" and provide experimental support.\nStrengths And Weaknesses: Overall I believe there are some interesting ideas and observations. For example Figure 5 (right) (which illustrates the linear and saturation scaling rule) is rather convincing. Some quantities which are introduction seem to make sense. However the paper and the claims are not at all convincing enough. The abstract and introduction are very superficial and it is not even clear what the authors want to prove / show. The related work is neglected. \nI am also bothered by some very vague and imprecise claims and sentences. The title to start with: \"Implicitly regularized interaction between SGD and the loss landscape geometry\". I don't understand what this means: what is a \"regularised interaction\" ? \nThen in the text: \"we find that SGD induces an implicit regularization on the interaction between the gradient distribution and the loss landscape geometry.\", \"we find that SGD implicitly regularizes the interaction-aware sharpness\". I do not manage to understand these sentences, they are very vague and the meaning is not clear at all. \nThe fact that the paper is not well written with very unprecise statements and claims makes me heavily doubt on the sanity and significance of the presented results. In the following questions I give a few examples to support my opinion.\nQuestions: \neq (3): over what are you taking the expectation ? if it is the full expectation then you should also have E[Lt], I guess you are taking the conditional expectation but this is not clear. \nline 96: a bit weird to name a set a \"regime\". It would also be clearer to keep the \u03b8 index in H: H\u03b8, to make clear that the hessian depends on \u03b8.\nunclear experiments in fig 1: what is the precise setting ? what dataset ?\nl110: \" This result implies that the training loss L(\u03b8) is approximately locally quadratic, i.e., \u03b5 \u2248 0, in the early phase.\" Why and what does this mean ? isn't any twice differentiable function approximately locally quadratic ?\n\"We hypothesise that due to this non-quadraticity of the training loss, the iterate is discouraged from staying within the unstable regime.\" I don't see why this is due to non-quadraticity. If you want to optimise f(x,y)=|y|x2 for example, which is always \"locally quadratic\": then for a large step-size, the iterates are \"discouraged from staying within the unstable regime\" too.\nFigure 3: what is \u0394L ?\nFigure 4: very hard to read labels, especially in fig (d)\nequation 12: \"if b is small\", \"if b is large\": how small ? how large ?\nLimitations: N/A\nEthics Flag: No\nSoundness: 1 poor\nPresentation: 1 poor\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper makes several contributions:\n\nThe authors propose a new characterization of 'edge of stability' which is said to improve over the original characterization from Cohen et al. (2021) in that it (1) fits full-batch GD better, and (2) generalizes to SGD.  Specifically, whereas the original characterization is that the sharpness (maximum Hessian eigenvalue) hovers just above the value 2/\u03b7, the authors propose characterizing the EoS as a regime in which the expected loss difference that is predicted by a quadratic taylor approximation hovers around the value zero (here, the expectation is wrt randomness in minibatch sampling).  For SGD, this condition comes out to tr(HSb)|g|2\u22482\u03b7, where g is the (full-batch) gradient, H is the Hessian, and Sb is the second moment matrix of minibatch gradients.  For full-batch GD, the condition reduces to gTHg|g|2\u22482\u03b7.  In the case of full-batch GD, the authors argue that their condition gTHg|g|2\u22482\u03b7 improves over the original condition |H|2\u2a862/\u03b7 in that  gTHg|g|2 empirically hovers right around 2/\u03b7 (Figure 4), whereas there is usually a gap between |H|2 and  2/\u03b7.  More importantly, it is currently an open question how the 'edge of stability' phenomenon generalizes to SGD, and the authors argue that their condition tr(HSb)|g|2\u22482\u03b7 holds during SGD. \n\nThe authors investigate the behavior of gradient descent at the EoS (Figures 1-3).   They find, essentially, that gradient descent is leaping back and forth across an asymmetric valley (https://arxiv.org/abs/1902.00744).  At every iteration where  gTHg|g|2 is above 2/\u03b7, it dips below 2/\u03b7 on the next step.  At every iteration where gTHg|g|2 is below 2/\u03b7, it rises above 2/\u03b7 on the next step.  Note that a similar point has been made (with no experiments) in the contemporaneous work of Chen & Bruna (https://arxiv.org/abs/2206.04172).\n\nThe authors propose a new scaling rule that describes how the linear rate ought to be scaled with the batch size in order to preserve the same implicit regularization.  Namely, the authors suggest that two training runs have the same implicit regularization whenever tr(Sb)/[\u03b7|g|2] is the same, and they present evidence (Figure 5) in support of their hypothesis.  Their scaling rule reduces to the well-known linear scaling rule in the limit of small batches, and reduces to \"no scaling\" in the limit of large batches.\nStrengths And Weaknesses: In what follows, I will reference the contributions I listed above by their numbers.\n\nWeakness of contribution #1: I could be wrong, but I don't think the new EoS characterization will generalize to momentum gradient descent (either with Polyak-style or Nesterov-style momentum).  In the Cohen et al EoS paper, it is intuitively clear why the sharpness should hover just above 2/\u03b7: if the training objective is modeled by its quadratic Taylor approximation, we see that gradient descent cannot linger for long in any region where the sharpness exceeds 2/\u03b7, because it will oscillate with exponentially growing magnitude in a certain direction until it leaves the region.  The extensions in that paper to Nesterov and Polyak momentum are based on the same reasoning.  By contrast, the underlying logic behind the new proposed EoS characterization (which is based on the idea that the loss is always non-monotonic) is less clear to me, and one consequence is that I don't see how it can be generalized to momentum.\n\nStrength of contribution #1: the proposed extension of EoS to SGD is interesting (note that it's basically a quadratic Taylor approximation version of the phenomenon reported in Cohen et al (2021) appendix H).  Nothing has been published in the literature addressing the question of how EoS might generalize to SGD, so any experimental result that seems to hold consistently across a wide range of networks is valuable.\n\nStrength of contribution #2: I think that these experiments will be useful for people interested in how gradient descent manages to remain semi-stable at the EoS.\n\nWeakness of contribution #3: both tr(Sb) and |g|2 will vary over the course of training, and I don't see any reason why their ratio should remain constant.  Thus, the scaling rule is not even well-defined.\nQuestions: \nIn Figure 5, where does the yellow dotted line come from? \n\nThe plots of ||H|| in Figure 31 look weird to me -- typically, the sharpness along the optimization trajectory is smaller when the batch size is smaller.  Could there be an error here?\nLimitations: Yes\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The paper studies the instability in SGD optimization dynamics (edge of stability) and how that impacts generalization. In particular, the authors propose the idea of interaction-aware sharpness, which I believe is original. Based on a definition of implicit interaction regularization, the authors propose the linear and saturation learning rate scaling rule (LSSR). Most of the findings are supported by empirical evidences but theoretical support is at an intuitive level.",
                "Strengths And Weaknesses": "Strengths:\n\nThe idea of interaction-aware sharpness seems to be original.\nEmpirical evidence to support the self-regulation of interaction-aware sharpness around the edge of stability.\nIntuituive argument for learning rate scaling.\n\nWeaknesses:\n\nLearning rate scaling only supported by a vague argument and empirical evidence.\nWeak connection between the concepts proposed in the paper and generalization.\nNothing in the theory related to neural networks.",
                "Questions": "My feeling is that the current theoretical setup may explain the gap between batch optimization and minibatch optimization but that is not the same as explaining generalization because generalization depends on the model class size. Can you agree or disagre?\nMore specifically, do I understand correctly that the theoretical setup does not assume anywhere that the model is a neural network? Then why are all the experiments on neural networks?\nCan we motivate the linear and saturation scaling rule better? I am not sure why keeping the right-hand side of Eq. (11) constant leads to optimal scaling.",
                "Limitations": "N/A",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors explore the notion of edge of stability for SGD dynamics, they introduce some quantities and explain / illustrate why they make sense for the understanding of the dynamics. They then propose a novel \"linear and saturation scaline rule\" and provide experimental support.",
                "Strengths And Weaknesses": "Overall I believe there are some interesting ideas and observations. For example Figure 5 (right) (which illustrates the linear and saturation scaling rule) is rather convincing. Some quantities which are introduction seem to make sense. However the paper and the claims are not at all convincing enough. The abstract and introduction are very superficial and it is not even clear what the authors want to prove / show. The related work is neglected. \nI am also bothered by some very vague and imprecise claims and sentences. The title to start with: \"Implicitly regularized interaction between SGD and the loss landscape geometry\". I don't understand what this means: what is a \"regularised interaction\" ? \nThen in the text: \"we find that SGD induces an implicit regularization on the interaction between the gradient distribution and the loss landscape geometry.\", \"we find that SGD implicitly regularizes the interaction-aware sharpness\". I do not manage to understand these sentences, they are very vague and the meaning is not clear at all. \nThe fact that the paper is not well written with very unprecise statements and claims makes me heavily doubt on the sanity and significance of the presented results. In the following questions I give a few examples to support my opinion.",
                "Questions": "eq (3): over what are you taking the expectation ? if it is the full expectation then you should also have E[Lt], I guess you are taking the conditional expectation but this is not clear. \nline 96: a bit weird to name a set a \"regime\". It would also be clearer to keep the \u03b8 index in H: H\u03b8, to make clear that the hessian depends on \u03b8.\nunclear experiments in fig 1: what is the precise setting ? what dataset ?\nl110: \" This result implies that the training loss L(\u03b8) is approximately locally quadratic, i.e., \u03b5 \u2248 0, in the early phase.\" Why and what does this mean ? isn't any twice differentiable function approximately locally quadratic ?\n\"We hypothesise that due to this non-quadraticity of the training loss, the iterate is discouraged from staying within the unstable regime.\" I don't see why this is due to non-quadraticity. If you want to optimise f(x,y)=|y|x2 for example, which is always \"locally quadratic\": then for a large step-size, the iterates are \"discouraged from staying within the unstable regime\" too.\nFigure 3: what is \u0394L ?\nFigure 4: very hard to read labels, especially in fig (d)\nequation 12: \"if b is small\", \"if b is large\": how small ? how large ?",
                "Limitations": "N/A",
                "Ethics Flag": "No",
                "Soundness": "1 poor",
                "Presentation": "1 poor",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper makes several contributions:\n\nThe authors propose a new characterization of 'edge of stability' which is said to improve over the original characterization from Cohen et al. (2021) in that it (1) fits full-batch GD better, and (2) generalizes to SGD.  Specifically, whereas the original characterization is that the sharpness (maximum Hessian eigenvalue) hovers just above the value 2/\u03b7, the authors propose characterizing the EoS as a regime in which the expected loss difference that is predicted by a quadratic taylor approximation hovers around the value zero (here, the expectation is wrt randomness in minibatch sampling).  For SGD, this condition comes out to tr(HSb)|g|2\u22482\u03b7, where g is the (full-batch) gradient, H is the Hessian, and Sb is the second moment matrix of minibatch gradients.  For full-batch GD, the condition reduces to gTHg|g|2\u22482\u03b7.  In the case of full-batch GD, the authors argue that their condition gTHg|g|2\u22482\u03b7 improves over the original condition |H|2\u2a862/\u03b7 in that  gTHg|g|2 empirically hovers right around 2/\u03b7 (Figure 4), whereas there is usually a gap between |H|2 and  2/\u03b7.  More importantly, it is currently an open question how the 'edge of stability' phenomenon generalizes to SGD, and the authors argue that their condition tr(HSb)|g|2\u22482\u03b7 holds during SGD. \n\nThe authors investigate the behavior of gradient descent at the EoS (Figures 1-3).   They find, essentially, that gradient descent is leaping back and forth across an asymmetric valley (https://arxiv.org/abs/1902.00744).  At every iteration where  gTHg|g|2 is above 2/\u03b7, it dips below 2/\u03b7 on the next step.  At every iteration where gTHg|g|2 is below 2/\u03b7, it rises above 2/\u03b7 on the next step.  Note that a similar point has been made (with no experiments) in the contemporaneous work of Chen & Bruna (https://arxiv.org/abs/2206.04172).\n\nThe authors propose a new scaling rule that describes how the linear rate ought to be scaled with the batch size in order to preserve the same implicit regularization.  Namely, the authors suggest that two training runs have the same implicit regularization whenever tr(Sb)/[\u03b7|g|2] is the same, and they present evidence (Figure 5) in support of their hypothesis.  Their scaling rule reduces to the well-known linear scaling rule in the limit of small batches, and reduces to \"no scaling\" in the limit of large batches.",
                "Strengths And Weaknesses": "In what follows, I will reference the contributions I listed above by their numbers.\n\nWeakness of contribution #1: I could be wrong, but I don't think the new EoS characterization will generalize to momentum gradient descent (either with Polyak-style or Nesterov-style momentum).  In the Cohen et al EoS paper, it is intuitively clear why the sharpness should hover just above 2/\u03b7: if the training objective is modeled by its quadratic Taylor approximation, we see that gradient descent cannot linger for long in any region where the sharpness exceeds 2/\u03b7, because it will oscillate with exponentially growing magnitude in a certain direction until it leaves the region.  The extensions in that paper to Nesterov and Polyak momentum are based on the same reasoning.  By contrast, the underlying logic behind the new proposed EoS characterization (which is based on the idea that the loss is always non-monotonic) is less clear to me, and one consequence is that I don't see how it can be generalized to momentum.\n\nStrength of contribution #1: the proposed extension of EoS to SGD is interesting (note that it's basically a quadratic Taylor approximation version of the phenomenon reported in Cohen et al (2021) appendix H).  Nothing has been published in the literature addressing the question of how EoS might generalize to SGD, so any experimental result that seems to hold consistently across a wide range of networks is valuable.\n\nStrength of contribution #2: I think that these experiments will be useful for people interested in how gradient descent manages to remain semi-stable at the EoS.\n\nWeakness of contribution #3: both tr(Sb) and |g|2 will vary over the course of training, and I don't see any reason why their ratio should remain constant.  Thus, the scaling rule is not even well-defined.",
                "Questions": "In Figure 5, where does the yellow dotted line come from? \n\nThe plots of ||H|| in Figure 31 look weird to me -- typically, the sharpness along the optimization trajectory is smaller when the batch size is smaller.  Could there be an error here?",
                "Limitations": "Yes",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 4.333,
        "confidence_avg": 4.0,
        "soundness_avg": 2.333,
        "presentation_avg": 2.333,
        "contribution_avg": 2.333,
        "ai_sum_meta": "Recommendation: Reject\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that there are several weaknesses in this paper. Reviewer 1 points out that the learning rate scaling is only supported by a vague argument and empirical evidence, and there is a weak connection between the proposed concepts and generalization. Reviewer 2 raises concerns about the imprecise claims and statements in the paper, as well as the lack of clarity in the abstract and introduction. Reviewer 3 questions the generalizability of the proposed edge of stability characterization to momentum gradient descent and the well-definedness of the scaling rule. \n\nWhile there are some strengths in the paper, such as the original idea of interaction-aware sharpness and the experimental support for the proposed linear and saturation scaling rule, the weaknesses and concerns raised by the reviewers outweigh these strengths. Therefore, I recommend rejecting this paper."
    },
    "Mathematically_Modeling_the_Lexicon_Entropy_of_Emergent_Language": {
        "link": "https://openreview.net//forum?id=IKcdgKKA_cs",
        "pub_url": "https://openreview.net/forum?id=IKcdgKKA_cs",
        "pdf_link": "https://openreview.net//pdf?id=IKcdgKKA_cs",
        "paper_id": "IKcdgKKA_cs",
        "title": "Mathematically_Modeling_the_Lexicon_Entropy_of_Emergent_Language",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nThis paper proposes FiLex -- a mathematical model to capture lexicon entropy in emergent language systems. The paper tackles an important and interesting problem in a field (emergent language) where relatively less theory currently exists. However, the reviewers find the experiments not convincing enough (e.g. they do not evaluate actual emergent language and instead use human languages) and lacking in scale. I do think the paper has some merits and can be strengthened further by addressing the reviewer comments, but the current version unfortunately seems below bar for acceptance.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper proposes a stochastic process, FILEX, to abstract out the essence of deep learning based emergent language systems. FILEX follows the intuition that the more a word is used, the more it will be used in the future. On four experimental settings, the authors show that the correlation between parameters of FILEX and the lexicon entropy is similar to the correlation between hyper parameters of neural networks and the lexicon entropy.\nStrengths And Weaknesses: strength \n\nThis work attempts to construct a simple enough theory for understanding emergent language. Such attempt is generally valuable for the overall community as the filed of emergent language itself is, emerging.\nThe proposed method is simple enough to mimic the model behavior thus providing a level of abstraction/ simplification for understanding. Additionally, I believe similar observation is also discussed in the previous VAE literature, just for the authors information[1].\nThis work is inspiring to me and I believe such work should also be inspiring to future work. Though I am not fully convinced with the existing experiments (see below), I am happy to see either future work may reinforce its conclusion or turn them over.\n\nweakness \n\nThe proposed methods is too simple to miss important details of many aspects of neural networks. When the authors link the parameters to of FILEX to the neural network hyper parameters, their reasons are more about intuition rather than rigorously mathematically discussions.\nThe experimental settings are too simple and may be hard to generalize to more complicated setting. One direct generalization is whether the conclusion will hold if the vocabulary size is large (say 10K) and compositional (say a sentence of length 10).\n\n[1] Alemi et. al. ICML 2018. Fixing a Broken ELBO\nQuestions: How would the conclusion generalize to setting when the vocabulary is large and when the setting is compositional?\nLimitations: The authors have properly discussed the limitations\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper proposes a stochastic process FILEX developed from the Chinese restaurant process, to mathematically model the lexicon entropy of emergent language between multiple agents (the speaker and the listener) in ELS (emergent language system) environments. The authors make correspondences between the FILEX and ELS to evaluate FILEX in real ELS environments. Experimental results on four ELS environments show that FILEX can correctly predict the correlation between hyperparameters and the lexicon entropy of well-trained emergent language in real ELS systems.\nStrengths And Weaknesses: In this paper, the authors propose a mathematical model of lexicon entropy of emergent language between agents. Moreover, the authors conduct extensive experiments to verify the model, and the results show its effectiveness.\nStrengths:\n1.\tThe paper provides an inspiring idea of mathematically modeling the properties of the emergent language without training in real environments. Besides, the mathematical description is more precise and testable than natural language.\n2.\tThe experimental results demonstrate the effectiveness of the proposed FILEX, which verifies the feasibility of the idea.\nWeaknesses:\n\nThe mathematical model may be not rigorous enough.\n----a) The proposed FILEX is based on the assumption that word use is reinforced in emergent language in sec 3.1. However, the paper only provides evidence in human language but not emergent language between agents. The paper does not prove the assumption fits all ELS environments either.\n----b) The correspondences of hyperparameters between FILEX and ELS in line 193 are based on analogy, thus the relationships between FILEX and ELS maybe not strong enough to support the alignments. Besides, beta in FILEX is corresponding to both buffer size and temperature in ELS, which may break the independence of the two hyperparameters despite the reason given in the paper.\nThe experiments seem to be not well-organized and insufficient somewhat.\n----a) In sec 3.4, the meaning of the hyperparameter-entropy correlation and the reason why it can be used to evaluate whether FILEX matches ELS is not given.\n----b) It is better to add the experimental evidence of the self-reinforcing assumption of emergent language in the four ELS environments, which is the basic assumption of the proposed FILEX.\n----c) In line 173, as a testable mathematical model, FILEX is expected to provide more precise information, thus the equality of sign of correlation as the metric seems a little too weak. It would be better if the authors add some stronger metrics.\nThe organization and presentation of the paper could be improved.\n----a) The introduction section misses necessary background introductions to the key concept \u201cemergent language\u201d and \u201clexicon entropy\u201d, which may confuse readers from a broad domain.\n----b) The paper lacks a formal definition of the problem or task. Besides, it is better to give the input, output, and goal of FILEX before the technical details in sec 3.1.\n----c) In sec 3.4, it is better to provide more explanations about the obscure hyperparameter-entropy correlation, which may be unfamiliar to many readers.\n----d) The paper may be not well-organized. For example, the environments in sec 3.2 and result analysis in sec 5.1 should be included in the experimental parts.\n----e) There are some typos and small mistakes in the paper. For example, line 9 in Algorithm 1 is not correctly initialized and used elsewhere; \u201cSection 3.3\u201d -> \u201cin Section 3.3\u201d in line 102.\nQuestions: \nDoes the self-reinforcing assumption of emergent language in line 79 make sense in all ELS environments? Are there any evidences in the literature or experimental results?\nWhat\u2019s the idea or intuitions behind the hyperparameter-entropy correlation in line 162? Why can it be used to evaluate whether FILEX matches the real ELS system?\nLimitations: According to the authors, there are weaknesses in this work that have not been addressed. Details are as above.\nThis paper does not have any potential negative societal impact.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 2 fair\nContribution: 3 good\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper fits into the Emergent Language literation and argues that prior work has been insufficiently rigorous when presenting their hypotheses. This work is presented as a starting point for mathematical methodology in developing and testing models of emergent language. \nTheir main contribution is an approach \"FiLex\" to understanding models of emergent language influenced by the Chinese Restaurant process (CRP). The relation here is to describe words as having a similar property to the tables in the CRP in that their usage is self-reinforcing. This approach is detailed in Section 3.1 with Algorithm 1 and the Formulation on page 3.\nTheir hypothesis, presented in Section 3.4, is that hyperparameters in FiLex correlate with hyperparameters commonly found in emergent language setups: time steps, lexicon size, learning rate, buffer size, and temperature. Their specific statement is that the sign of the correlation between those hyperparameters and entropy will be the same for FiLex as it is for the ELS setups. \nThey experimentally test this hypothesis by comparing FiLex against 4 ELS setups in Table 2 and Figure 1 and then make claims in Sec 5 (discussion) that this model lets practitioners more rigorously understand confounding factors.\nStrengths And Weaknesses: Originality:\nThis paper is original. It's taking a well-known idea (CRP) and applying it to a domain (emergent language) where the procedure is potentially beneficial for attaining understanding. It's unclear to me that this is actually the right approach for this domain and that's something that warrants greater discussion in the paper, but it's still an interesting direction that has merit.\nQuality:\nI don't think that this approach makes sense to do in ELS. I love the motivation to have better mathematical foundations in the space, but I disagree that this approach, or at least as presented, is the right path.\nFirst, why should it be the case that methods with same sign correlations in individual hyperparameters are actually indicative of each other? This is much too weak of a statement to be predictive as we could manufacture this artificially without much issue. The argument given at the end of section 3 that then qualitatively associates the variables doesn't fix this issue; changing just the algorithm used from PPO to something else that doesn't have a buffer size shows how fragile that is. \nThe explanation in 3.4 (L173-L180) points to this as well, suggesting that there are too many factors unaccounted for (due to FiLex's simplicity) to do much else besides this. But that's exactly what the paper set out to do at the beginning after discussing how prior work skipped out on this important step. Perhaps they did so for this same reason?\nSec 5, the evaluation, talks about making predictions (\"[... FiLex] makes the correct prediction 20 out of 20 times.\") and how that wouldn't happen if it wasn't predictive. But then the graphs (and the discussion) shows how tenuous that is. It's not very helpful for my research to run this method a bunch of times and hope that the correlation remains positive versus just varying a hyperparameter in my actual model and seeing what that does. Perhaps the authors are thinking that I cannot run my actual model that much because, say, it's a real robot. Okay that's fair, but I have no idea if this method would actually work in that setting and little belief that my model in totality would really be correlated given that a handful of hyperparameters are.\nClarity:\nThe paper is clear enough. The one area which would have been more helpful is to coalesce Table 2 and Figure 1 to be more apparently connected. It takes longer than I would have liked to understand what was going on in them (which are the results) and the stories they told.\nSignificance:\nThis paper is only significant in the world where the simple model is predictive of much bigger and more interesting models. The ones examined are not that, nor is it even assessed as predictive of anything in those settings.\nFor it to get to a place where we can confidently say that this is interesting for real-world settings, it would need to be aligned with actual (emergent) language learning. That is unfair to evaluate wrt learning new words in this setting (as neither FiLex nor most ELS systems are doing that), but it is fair to ask whether the learned language distributions are the same. Is that true? Is FiLex learning similar word distributions to the ELS models? More to the point, because FiLex's learned distribution won't ever be different given its simplicity, is it Zipfian? We expect that to if it's ever going to be able to model a full language.\nQuestions: \nIt's not clear in this paper whether we are asking whether the mathematical model that this process produces can answer questions of current ELS systems or are we asking whether it can help us illuminate where these systems are weak. Which one is it? The second is much more significant imo.\n\nWhy should the sign of the per-hyperparameter entropy correlation be predictive about what my approach will do? Is there some foundation for that in other literature?\n\nWhat is the resulting word distribution of the CRP at steady state?\n\nMy suggestion is to return to the models you've made (the 4 methods NoDyn Recon Sig and Nav) and try and see what, if anything, is invariant and unit-independent amongst these. I think that will bear more interesting fruit than this approach starting w CRP.\nLimitations: Societally, this is fine. Wrt limitations, see the above S&W section.\nEthics Flag: No\nSoundness: 1 poor\nPresentation: 3 good\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper proposes a stochastic process, FILEX, to abstract out the essence of deep learning based emergent language systems. FILEX follows the intuition that the more a word is used, the more it will be used in the future. On four experimental settings, the authors show that the correlation between parameters of FILEX and the lexicon entropy is similar to the correlation between hyper parameters of neural networks and the lexicon entropy.",
                "Strengths And Weaknesses": "strength \n\nThis work attempts to construct a simple enough theory for understanding emergent language. Such attempt is generally valuable for the overall community as the filed of emergent language itself is, emerging.\nThe proposed method is simple enough to mimic the model behavior thus providing a level of abstraction/ simplification for understanding. Additionally, I believe similar observation is also discussed in the previous VAE literature, just for the authors information[1].\nThis work is inspiring to me and I believe such work should also be inspiring to future work. Though I am not fully convinced with the existing experiments (see below), I am happy to see either future work may reinforce its conclusion or turn them over.\n\nweakness \n\nThe proposed methods is too simple to miss important details of many aspects of neural networks. When the authors link the parameters to of FILEX to the neural network hyper parameters, their reasons are more about intuition rather than rigorously mathematically discussions.\nThe experimental settings are too simple and may be hard to generalize to more complicated setting. One direct generalization is whether the conclusion will hold if the vocabulary size is large (say 10K) and compositional (say a sentence of length 10).\n\n[1] Alemi et. al. ICML 2018. Fixing a Broken ELBO",
                "Questions": "How would the conclusion generalize to setting when the vocabulary is large and when the setting is compositional?",
                "Limitations": "The authors have properly discussed the limitations",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper proposes a stochastic process FILEX developed from the Chinese restaurant process, to mathematically model the lexicon entropy of emergent language between multiple agents (the speaker and the listener) in ELS (emergent language system) environments. The authors make correspondences between the FILEX and ELS to evaluate FILEX in real ELS environments. Experimental results on four ELS environments show that FILEX can correctly predict the correlation between hyperparameters and the lexicon entropy of well-trained emergent language in real ELS systems.",
                "Strengths And Weaknesses": "In this paper, the authors propose a mathematical model of lexicon entropy of emergent language between agents. Moreover, the authors conduct extensive experiments to verify the model, and the results show its effectiveness.\nStrengths:\n1.\tThe paper provides an inspiring idea of mathematically modeling the properties of the emergent language without training in real environments. Besides, the mathematical description is more precise and testable than natural language.\n2.\tThe experimental results demonstrate the effectiveness of the proposed FILEX, which verifies the feasibility of the idea.\nWeaknesses:\n\nThe mathematical model may be not rigorous enough.\n----a) The proposed FILEX is based on the assumption that word use is reinforced in emergent language in sec 3.1. However, the paper only provides evidence in human language but not emergent language between agents. The paper does not prove the assumption fits all ELS environments either.\n----b) The correspondences of hyperparameters between FILEX and ELS in line 193 are based on analogy, thus the relationships between FILEX and ELS maybe not strong enough to support the alignments. Besides, beta in FILEX is corresponding to both buffer size and temperature in ELS, which may break the independence of the two hyperparameters despite the reason given in the paper.\nThe experiments seem to be not well-organized and insufficient somewhat.\n----a) In sec 3.4, the meaning of the hyperparameter-entropy correlation and the reason why it can be used to evaluate whether FILEX matches ELS is not given.\n----b) It is better to add the experimental evidence of the self-reinforcing assumption of emergent language in the four ELS environments, which is the basic assumption of the proposed FILEX.\n----c) In line 173, as a testable mathematical model, FILEX is expected to provide more precise information, thus the equality of sign of correlation as the metric seems a little too weak. It would be better if the authors add some stronger metrics.\nThe organization and presentation of the paper could be improved.\n----a) The introduction section misses necessary background introductions to the key concept \u201cemergent language\u201d and \u201clexicon entropy\u201d, which may confuse readers from a broad domain.\n----b) The paper lacks a formal definition of the problem or task. Besides, it is better to give the input, output, and goal of FILEX before the technical details in sec 3.1.\n----c) In sec 3.4, it is better to provide more explanations about the obscure hyperparameter-entropy correlation, which may be unfamiliar to many readers.\n----d) The paper may be not well-organized. For example, the environments in sec 3.2 and result analysis in sec 5.1 should be included in the experimental parts.\n----e) There are some typos and small mistakes in the paper. For example, line 9 in Algorithm 1 is not correctly initialized and used elsewhere; \u201cSection 3.3\u201d -> \u201cin Section 3.3\u201d in line 102.",
                "Questions": "Does the self-reinforcing assumption of emergent language in line 79 make sense in all ELS environments? Are there any evidences in the literature or experimental results?\nWhat\u2019s the idea or intuitions behind the hyperparameter-entropy correlation in line 162? Why can it be used to evaluate whether FILEX matches the real ELS system?",
                "Limitations": "According to the authors, there are weaknesses in this work that have not been addressed. Details are as above.\nThis paper does not have any potential negative societal impact.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper fits into the Emergent Language literation and argues that prior work has been insufficiently rigorous when presenting their hypotheses. This work is presented as a starting point for mathematical methodology in developing and testing models of emergent language. \nTheir main contribution is an approach \"FiLex\" to understanding models of emergent language influenced by the Chinese Restaurant process (CRP). The relation here is to describe words as having a similar property to the tables in the CRP in that their usage is self-reinforcing. This approach is detailed in Section 3.1 with Algorithm 1 and the Formulation on page 3.\nTheir hypothesis, presented in Section 3.4, is that hyperparameters in FiLex correlate with hyperparameters commonly found in emergent language setups: time steps, lexicon size, learning rate, buffer size, and temperature. Their specific statement is that the sign of the correlation between those hyperparameters and entropy will be the same for FiLex as it is for the ELS setups. \nThey experimentally test this hypothesis by comparing FiLex against 4 ELS setups in Table 2 and Figure 1 and then make claims in Sec 5 (discussion) that this model lets practitioners more rigorously understand confounding factors.",
                "Strengths And Weaknesses": "Originality:\nThis paper is original. It's taking a well-known idea (CRP) and applying it to a domain (emergent language) where the procedure is potentially beneficial for attaining understanding. It's unclear to me that this is actually the right approach for this domain and that's something that warrants greater discussion in the paper, but it's still an interesting direction that has merit.\nQuality:\nI don't think that this approach makes sense to do in ELS. I love the motivation to have better mathematical foundations in the space, but I disagree that this approach, or at least as presented, is the right path.\nFirst, why should it be the case that methods with same sign correlations in individual hyperparameters are actually indicative of each other? This is much too weak of a statement to be predictive as we could manufacture this artificially without much issue. The argument given at the end of section 3 that then qualitatively associates the variables doesn't fix this issue; changing just the algorithm used from PPO to something else that doesn't have a buffer size shows how fragile that is. \nThe explanation in 3.4 (L173-L180) points to this as well, suggesting that there are too many factors unaccounted for (due to FiLex's simplicity) to do much else besides this. But that's exactly what the paper set out to do at the beginning after discussing how prior work skipped out on this important step. Perhaps they did so for this same reason?\nSec 5, the evaluation, talks about making predictions (\"[... FiLex] makes the correct prediction 20 out of 20 times.\") and how that wouldn't happen if it wasn't predictive. But then the graphs (and the discussion) shows how tenuous that is. It's not very helpful for my research to run this method a bunch of times and hope that the correlation remains positive versus just varying a hyperparameter in my actual model and seeing what that does. Perhaps the authors are thinking that I cannot run my actual model that much because, say, it's a real robot. Okay that's fair, but I have no idea if this method would actually work in that setting and little belief that my model in totality would really be correlated given that a handful of hyperparameters are.\nClarity:\nThe paper is clear enough. The one area which would have been more helpful is to coalesce Table 2 and Figure 1 to be more apparently connected. It takes longer than I would have liked to understand what was going on in them (which are the results) and the stories they told.\nSignificance:\nThis paper is only significant in the world where the simple model is predictive of much bigger and more interesting models. The ones examined are not that, nor is it even assessed as predictive of anything in those settings.\nFor it to get to a place where we can confidently say that this is interesting for real-world settings, it would need to be aligned with actual (emergent) language learning. That is unfair to evaluate wrt learning new words in this setting (as neither FiLex nor most ELS systems are doing that), but it is fair to ask whether the learned language distributions are the same. Is that true? Is FiLex learning similar word distributions to the ELS models? More to the point, because FiLex's learned distribution won't ever be different given its simplicity, is it Zipfian? We expect that to if it's ever going to be able to model a full language.",
                "Questions": "It's not clear in this paper whether we are asking whether the mathematical model that this process produces can answer questions of current ELS systems or are we asking whether it can help us illuminate where these systems are weak. Which one is it? The second is much more significant imo.\n\nWhy should the sign of the per-hyperparameter entropy correlation be predictive about what my approach will do? Is there some foundation for that in other literature?\n\nWhat is the resulting word distribution of the CRP at steady state?\n\nMy suggestion is to return to the models you've made (the 4 methods NoDyn Recon Sig and Nav) and try and see what, if anything, is invariant and unit-independent amongst these. I think that will bear more interesting fruit than this approach starting w CRP.",
                "Limitations": "Societally, this is fine. Wrt limitations, see the above S&W section.",
                "Ethics Flag": "No",
                "Soundness": "1 poor",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 4.0,
        "confidence_avg": 3.667,
        "soundness_avg": 2.0,
        "presentation_avg": 2.667,
        "contribution_avg": 2.667,
        "ai_sum_meta": "Recommendation: Reject\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that there are several weaknesses in this paper. Reviewer 1 acknowledges the value of the work but raises concerns about the simplicity of the proposed method and the limited scope of the experimental settings. Reviewer 2 points out flaws in the mathematical model and the organization and presentation of the paper. Reviewer 3 questions the validity of the approach and its relevance to real-world settings. Overall, the weaknesses highlighted by the reviewers outweigh the strengths of the paper. Therefore, I recommend rejecting this paper."
    },
    "A_hybrid_approach_to_seismic_deblending:_when_physics_meets_self-supervision": {
        "link": "https://openreview.net//forum?id=TfMeY_L_l6t",
        "pub_url": "https://openreview.net/forum?id=TfMeY_L_l6t",
        "pdf_link": "https://openreview.net//pdf?id=TfMeY_L_l6t",
        "paper_id": "TfMeY_L_l6t",
        "title": "A_hybrid_approach_to_seismic_deblending:_when_physics_meets_self-supervision",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Less certain\nThe paper studies a seismic deblending problem. This is a problem in reflection seismology, in which multiple excitations are applied simultaneously, and then an underdetermined inverse problem is solved to recover the underlying composition of the earth. Existing approaches to this problem are mostly based on regularization \u2014 e.g., frequency domain sparsity. The paper proposes an alternative method based on plug-and-play-ADMM, with a self-supervised regularizer. The regularizer here is a \u201cblind spot\u201d network, which tries to predict a pixel based on its surroundings. In simulation studies (based on synthetic blending of real seismic data), the proposed algorithm outperforms the regularization approach. \n\u2028Reviews of the paper were mixed: reviewers all recognized careful, pedagogical manner in which the paper lays out its problem of interest. At the same time, several reviewers raised concerns that the exposition was overly focused on background material, at the expense of explaining the paper\u2019s technical contributions. Exposition aside, much of the discussion in the reviews and authors\u2019 response centers on the novelty and depth of the paper\u2019s technical contributions. The reviewers note that the application of self-supervised denoising within a plug-n-play framework is not a novelty of the paper (nor is it argued as one). Rather the technical contribution lies in a combination of existing ideas (self-supervised denoising ala struct BS, plug-n-play) which is well suited to the reflection seismology application. Reviewers generally felt that the paper would be stronger if it focused more on this methodology and on the technical justification of the approach. While the paper introduces a method that has value for reflection seismology, it is current form, the concerns are significant enough to place it below the bar for acceptance.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper tackles the inverse problem of \"seismic deblending\" by using the well known \"Plug-And-Play\" (PnP) framework together with a recently proposed self-supervised denoiser, which is adapted to follow the noise structure of the particular problem at hand. Experiments on a real dataset artificially blended by the authors show that the approach outperforms a state-of-the-art method based on a Fourier sparsity prior, and an ablation study show that the proposed combination of PnP with a carefully trained self-supervised denoiser is efficient.\nStrengths And Weaknesses: Strengths\n\nThe paper is generally very didactic. Quite unusually, 5 out of 9 pages are devoted to the introduction, background and related work sections. In that sense, the paper can almost be regarded as a \"tutorial\" paper, giving a subsequent overview of the field of seismic deblending and of recently proposed self-supervised denoising techniques to non-expert readers.\nThe proposed approach is sound and seem to outperform a more conventional technique on a real dataset\n\nWeaknesses\n\nWhile 5 pages are devoted to introductory materials, only half a page is devoted to presenting the methodology. On the one hand this seems short, on the other hand, this can be explained by the fact that the proposed methodological contribution is very incremental: two relatively well-known existing techniques are straight-forwardly combined and applied to a known problem in the field.\nThe experiments are relatively limited, eventhough this may be justified by the lack of available real data for this problem. Still, more detailed quantitative results could have been provided.\nNo detail is given on the key \"StructBS\" step of the method (the self-supervised denoising), not the paper nor in the supplementary material. The reader is entirely referred to the recent reference [47] for this (in fact, the reference to [47] is implicit, and the acronym StructBS is never made explicit). This makes the methodological part of paper not self-contained, which is not good for research reproducibility and transmission.\nA lot of important implementation details are scattered across the experimental section or in the appendix, which would make the proposed method very hard to reimplement\nIn the ablation study, not using the PnP iterations and using only self-supervised denoising seem to be equivalent to what is done in [47], but this is not explicitly stated by the authors. More details should be given on these results than a single number, since according to the authors themselves, [47] is the closest work to what they propose.\nQuestions: The main question I have is: Is the proposed method without the PnP steps the same as [47] ? If so, this should be made very explicit in the method section and in the experimental results.\nI noted the following minor typos:\n\nL136 : \"to to\"\nL172 a image -> an image\nLimitations: The limitations and societal impact of the work are adequately addressed by the authors in section 6.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 2 fair\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper introduces the problem of seismic deblending and provide a state-of-the art result in this problem using denoising network in the PnP setup. Denoising model is learned as a part of PnP.\nStrengths And Weaknesses: [strengths]\n\nIntroduces Seismic Deblending to ML community. Seismic problems are generally less explored in ML community and this paper introduces a good problem. \nGood results with learned denoiser.\n\n[weaknesses]\n\nWriting : The paper devotes very less space to the main algorithm. PnP + denoiser. Also, for people who are not familiar with the ADMM algorithm like me, the section 4 reads very difficult with a lot of terms introduced but not explained like y_k , x-update, y-update, LSQR, StuctBS, theta. These details are provided partially in the supplementary. However more discussion space should be provided to the algorithmic part.\n\nNovelty: I am not sure if paper provides enough novelty for this conference. It uses denoiser architecture in a seismic setting and shows good results. However, it is not clear what the contributions are apart from applying existing denoiser in seismic PnP.\n\nExperimental validation is limited. The experiments are performed on a single dataset. More empirical validation is needed.\nQuestions: \nPlease consider weaknesses above as questions.\nLimitations: Limitations are adequately addressed.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 1 poor\nContribution: 1 poor\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper combines a self-supervised deep image denoising method and PnP framework to improve seismic deblending. The problem is interesting and significant. However, the rationale of the proposed algorithm is unclear. It seems like a combination of existing techniques and the technical contribution seems limited.\nStrengths And Weaknesses: Strength:\n\nThis paper aims to improve the performance of seismic deblending, which is a significant problem and can benefit geophysical studies.\nThe authors explore to improve the conventional deblending problem with deep image denoising technology.\nThe proposed method can outperform a conventional method according to the experiment.\n\nWeakness:\n\nThis paper is poorly organized and the meanings of many symbols in formulas and figures are not well introduced (see Questions for detail). This makes it difficult to understand the background and the problem formulation. The reader needs to spend a long time reading this paper before understanding the problem.\nThe authors introduced their algorithm very briefly in \u201cMethod\u201d. The motivation of the proposed algorithm is unclear because the authors only provide the resulting update rules instead of showing the original optimization problem and the regularization term. Especially, the biggest modification to the algorithm in this paper seems to be using a self-supervised denoiser for y-update. However, the rationale behind it is confusing. I wonder how this update rule is derived. Indeed, too much essential information has been omitted. \nPartly because the authors did not give any theoretical illustrations for their algorithm, the technical contribution seems limited. According to the paper, the authors (1) follow the conventional optimization problem formulation of seismic blending/denoising; (2) use PnP framework to solve this optimization problem; (3) change a term for y-update (without properly explaining the rationale) based on the self-supervised image denoiser. Then, this paper seems like a combination of existing techniques. The inspiration it can bring to the community is limited.\nThe experiments are not sound. The authors have mentioned in the related work that there are other seismic deblending/denoising methods. However, only one conventional method is used as the baseline. The authors should report their performance to better demonstrate the effectiveness of the proposed algorithm in comparison to SOTA. Otherwise, the authors should explain why the other methods are not applicable.\nQuestions: \nHow is the blending operator decided? Why does it have the property of B^TB=I? Maybe a proper citation is needed here for the reader to better understand the background.\nWhat do t(s), x_R(m), and \\bar{\\bar{x}}_R(m) mean in Figure 1 b)? Also, why does the y-axis x_s(m) instead of x_R(m) in Figure 1 c)? What does m represent here?\nAccording to Figure 1 b), the input seems like an image. However, it is confusing how it is generated. What are the white curves and the horizontal dash line mean?\nWhat is the regularization term in the proposed optimization problem? How is y-update derived as StructBS(x+u)\uff1f\nHow will the model perform if only adopting PnP framework but does not use the self-supervised denoiser?\nLimitations: The authors have adequately addressed the limitations and social impact of their work.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper proposed a plug-and-play (PnP) algorithm for reflection seismology (RS). The key concept of PnP is to leverage an image denoiser as an implicit regularizer to impose prior within an iterative optimization algorithm. By using deep image denoisers, PnP combines the physical constraints and trainable priors. Proposed algorithm in this paper combines PnP with self-supervised deep image denoisers to solve the RS problem.\nStrengths And Weaknesses: Strength:\n\nNew application of PnP to reflection seismology (RS).\n\nWeakness:\n\nThe proposed method is not novel. The claimed novelty is the inclusion of self-supervised image denoiser in the PnP framework. However, this has been done in [1] for medical imaging.\nThe presentation of the work is not well organized. The introduction and background is too long while the method section is too short.\n\n[1] RARE: Image Reconstruction using Deep Priors Learned without Ground Truth\nQuestions: \nBesides the apparent benefits of self-supervised deep image denoiser, that is, no use of ground-truth data, what else motivates you to use such image denoiser? Why this is denoiser is necessary.\n\nApart from the deep image denoiser, what else can be considered as contributions of the work?\nLimitations: Not applicable.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 2 fair\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper tackles the inverse problem of \"seismic deblending\" by using the well known \"Plug-And-Play\" (PnP) framework together with a recently proposed self-supervised denoiser, which is adapted to follow the noise structure of the particular problem at hand. Experiments on a real dataset artificially blended by the authors show that the approach outperforms a state-of-the-art method based on a Fourier sparsity prior, and an ablation study show that the proposed combination of PnP with a carefully trained self-supervised denoiser is efficient.",
                "Strengths And Weaknesses": "Strengths\n\nThe paper is generally very didactic. Quite unusually, 5 out of 9 pages are devoted to the introduction, background and related work sections. In that sense, the paper can almost be regarded as a \"tutorial\" paper, giving a subsequent overview of the field of seismic deblending and of recently proposed self-supervised denoising techniques to non-expert readers.\nThe proposed approach is sound and seem to outperform a more conventional technique on a real dataset\n\nWeaknesses\n\nWhile 5 pages are devoted to introductory materials, only half a page is devoted to presenting the methodology. On the one hand this seems short, on the other hand, this can be explained by the fact that the proposed methodological contribution is very incremental: two relatively well-known existing techniques are straight-forwardly combined and applied to a known problem in the field.\nThe experiments are relatively limited, eventhough this may be justified by the lack of available real data for this problem. Still, more detailed quantitative results could have been provided.\nNo detail is given on the key \"StructBS\" step of the method (the self-supervised denoising), not the paper nor in the supplementary material. The reader is entirely referred to the recent reference [47] for this (in fact, the reference to [47] is implicit, and the acronym StructBS is never made explicit). This makes the methodological part of paper not self-contained, which is not good for research reproducibility and transmission.\nA lot of important implementation details are scattered across the experimental section or in the appendix, which would make the proposed method very hard to reimplement\nIn the ablation study, not using the PnP iterations and using only self-supervised denoising seem to be equivalent to what is done in [47], but this is not explicitly stated by the authors. More details should be given on these results than a single number, since according to the authors themselves, [47] is the closest work to what they propose.",
                "Questions": "The main question I have is: Is the proposed method without the PnP steps the same as [47] ? If so, this should be made very explicit in the method section and in the experimental results.\nI noted the following minor typos:\n\nL136 : \"to to\"\nL172 a image -> an image",
                "Limitations": "The limitations and societal impact of the work are adequately addressed by the authors in section 6.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "2 fair",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper introduces the problem of seismic deblending and provide a state-of-the art result in this problem using denoising network in the PnP setup. Denoising model is learned as a part of PnP.",
                "Strengths And Weaknesses": "[strengths]\n\nIntroduces Seismic Deblending to ML community. Seismic problems are generally less explored in ML community and this paper introduces a good problem. \nGood results with learned denoiser.\n\n[weaknesses]\n\nWriting : The paper devotes very less space to the main algorithm. PnP + denoiser. Also, for people who are not familiar with the ADMM algorithm like me, the section 4 reads very difficult with a lot of terms introduced but not explained like y_k , x-update, y-update, LSQR, StuctBS, theta. These details are provided partially in the supplementary. However more discussion space should be provided to the algorithmic part.\n\nNovelty: I am not sure if paper provides enough novelty for this conference. It uses denoiser architecture in a seismic setting and shows good results. However, it is not clear what the contributions are apart from applying existing denoiser in seismic PnP.\n\nExperimental validation is limited. The experiments are performed on a single dataset. More empirical validation is needed.",
                "Questions": "Please consider weaknesses above as questions.",
                "Limitations": "Limitations are adequately addressed.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "1 poor",
                "Contribution": "1 poor",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper combines a self-supervised deep image denoising method and PnP framework to improve seismic deblending. The problem is interesting and significant. However, the rationale of the proposed algorithm is unclear. It seems like a combination of existing techniques and the technical contribution seems limited.",
                "Strengths And Weaknesses": "Strength:\n\nThis paper aims to improve the performance of seismic deblending, which is a significant problem and can benefit geophysical studies.\nThe authors explore to improve the conventional deblending problem with deep image denoising technology.\nThe proposed method can outperform a conventional method according to the experiment.\n\nWeakness:\n\nThis paper is poorly organized and the meanings of many symbols in formulas and figures are not well introduced (see Questions for detail). This makes it difficult to understand the background and the problem formulation. The reader needs to spend a long time reading this paper before understanding the problem.\nThe authors introduced their algorithm very briefly in \u201cMethod\u201d. The motivation of the proposed algorithm is unclear because the authors only provide the resulting update rules instead of showing the original optimization problem and the regularization term. Especially, the biggest modification to the algorithm in this paper seems to be using a self-supervised denoiser for y-update. However, the rationale behind it is confusing. I wonder how this update rule is derived. Indeed, too much essential information has been omitted. \nPartly because the authors did not give any theoretical illustrations for their algorithm, the technical contribution seems limited. According to the paper, the authors (1) follow the conventional optimization problem formulation of seismic blending/denoising; (2) use PnP framework to solve this optimization problem; (3) change a term for y-update (without properly explaining the rationale) based on the self-supervised image denoiser. Then, this paper seems like a combination of existing techniques. The inspiration it can bring to the community is limited.\nThe experiments are not sound. The authors have mentioned in the related work that there are other seismic deblending/denoising methods. However, only one conventional method is used as the baseline. The authors should report their performance to better demonstrate the effectiveness of the proposed algorithm in comparison to SOTA. Otherwise, the authors should explain why the other methods are not applicable.",
                "Questions": "How is the blending operator decided? Why does it have the property of B^TB=I? Maybe a proper citation is needed here for the reader to better understand the background.\nWhat do t(s), x_R(m), and \\bar{\\bar{x}}_R(m) mean in Figure 1 b)? Also, why does the y-axis x_s(m) instead of x_R(m) in Figure 1 c)? What does m represent here?\nAccording to Figure 1 b), the input seems like an image. However, it is confusing how it is generated. What are the white curves and the horizontal dash line mean?\nWhat is the regularization term in the proposed optimization problem? How is y-update derived as StructBS(x+u)\uff1f\nHow will the model perform if only adopting PnP framework but does not use the self-supervised denoiser?",
                "Limitations": "The authors have adequately addressed the limitations and social impact of their work.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposed a plug-and-play (PnP) algorithm for reflection seismology (RS). The key concept of PnP is to leverage an image denoiser as an implicit regularizer to impose prior within an iterative optimization algorithm. By using deep image denoisers, PnP combines the physical constraints and trainable priors. Proposed algorithm in this paper combines PnP with self-supervised deep image denoisers to solve the RS problem.",
                "Strengths And Weaknesses": "Strength:\n\nNew application of PnP to reflection seismology (RS).\n\nWeakness:\n\nThe proposed method is not novel. The claimed novelty is the inclusion of self-supervised image denoiser in the PnP framework. However, this has been done in [1] for medical imaging.\nThe presentation of the work is not well organized. The introduction and background is too long while the method section is too short.\n\n[1] RARE: Image Reconstruction using Deep Priors Learned without Ground Truth",
                "Questions": "Besides the apparent benefits of self-supervised deep image denoiser, that is, no use of ground-truth data, what else motivates you to use such image denoiser? Why this is denoiser is necessary.\n\nApart from the deep image denoiser, what else can be considered as contributions of the work?",
                "Limitations": "Not applicable.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 4.5,
        "confidence_avg": 3.25,
        "soundness_avg": 3.0,
        "presentation_avg": 2.25,
        "contribution_avg": 1.75,
        "ai_sum_meta": "Recommendation: Reject\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is clear that the paper has some significant weaknesses that outweigh its strengths. Reviewer 1 points out that the methodology is not well explained and lacks important implementation details, making it difficult to reproduce the proposed method. Reviewer 2 also mentions that the writing is poor and the main algorithm is not adequately discussed. Reviewer 3 raises concerns about the limited technical contribution and the lack of theoretical illustrations for the algorithm. Reviewer 4 questions the novelty of the proposed method, as similar approaches have been used in other domains.\n\nConsidering these weaknesses, it is recommended to reject the paper. The confidence in this decision is certain, as the concerns raised by the reviewers are substantial and indicate that the paper does not meet the standards of the conference."
    },
    "Revisiting_Populations_in_Multi-Agent_Communication": {
        "link": "https://openreview.net//forum?id=HH3GHN_Q1Ba",
        "pub_url": "https://openreview.net/forum?id=HH3GHN_Q1Ba",
        "pdf_link": "https://openreview.net//pdf?id=HH3GHN_Q1Ba",
        "paper_id": "HH3GHN_Q1Ba",
        "title": "Revisiting_Populations_in_Multi-Agent_Communication",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nThe paper investigates the effectiveness of population-level training of multi-agent communication strategies. Based on the finding that agents that interact with one another co-adapt, the paper proposes an alternative training process that \"partitions\" the population by constructing specific sender-receiver pairs in a manner that reduces co-adaptation. The paper shoes that this partition-based strategy gives rise to a new optimization objective that encourages alignment across the population. Experiments demonstrate the emergence of mutual understanding between agents that have never communicated, and that partition-based training results in language that is more compositional compared to alternative strategies.\nThe paper was reviewed by three researchers who discussed the merits of the paper with the AC. There is general agreement that the paper provides an interesting discussion of and important insights into the effect of population-based optimization for emergent communication. Based on these insights, the authors propose a novel training procedure that experiments show is effective. Several reviewers commented that the paper is very well written and was enjoyable to read. The reviewers raised several concerns/questions that the authors made a concerted effort to address. However, a notable limitation of the current version of the paper is the lack of qualitative and quantitative comparisons to previous work. While the proposal to update the related work discussion is helpful, the paper should also provide experimental evaluations that compare to existing work, without which the significance of this particular training procedure is unclear.",
        "reviews": [
            "Reviewer 1: \nSummary: The authors propose a modified training procedure for population-based training for emergent communication in which specific speaker-listener pairs are constructed, and replace the \"free for all\" mixing of pairs present in traditional methods.  Constraining the mixing in this way limits co-adaptation, and thus improves generalization and topographical similarity.  In addition, this solution also solves some more long-standing issues, like why scaling to larger populations in traditional training methods has not typically met with significant improvements in emergent structure or task accuracy, and the authors demonstrate how this originates in the loss of the standard training algorithm.\nStrengths And Weaknesses: Strengths:\nOverall I really enjoyed this paper.  It's very well written, and the way the authors narrow their focus to this one specific issue helps the argument structure come across very clearly.  I thought their argument was convincing, especially when the scope and argument applies to training dynamics in toy scenarios.  The paper contributes important theoretical understanding to population-based optimization for EC, and the effects of controlling population size, a co-adaptation \"factor\", and mutual intelligibilty.\nWeaknesses:\nI don't have any major criticism of the work within the scope the authors layout.  However, working against this paper is that the authors make only a passing effort to connect their work to previous related work, some of which may have very similar interpretations.  Two strands of work that I think should be discussed in much more detail and direct comparison are are neural iterated learning and cultural transmission models.  Both approaches are mentioned in the related work, but no direct comparison is made, despite that both approaches apply similar constraints to the population, essentially limiting who is talking to who, and likely reducing co-adaptation.  Considering the improved performance on communicating with novel partners, one would think some comparison to iterated learning, or the Easy-of-teaching (Li 2019) would have been warranted here.\nI think by the phrasing of the last paragraph of the related work (L332/333) the authors are trying to position themselves outside of this work, but I don't find it a convincing excuse.  The motivations are similar, the solutions are quite similar, and it would be appropriate to connect to this research, both in discussion and in experimentation.  Ideally I would like to see existing work as baselines in direct comparison to this work, exploring the role of different partitioning patterns have.\nBecause in the end, I'm unsure of what these results would mean in terms of pushing the field forward.  If iterated learning is more effective on all of the proposed benchmarks, is this just a footnote in the progression of EC research or only relevant to those who are for some reason unwilling to consider known approaches to training that work better than the standard population-based training scheme?  If the authors more explicitly compared their partitioning approach to other population-based approaches, it would be clearer what the impact of the research would mean in a more practical sense.\nIntuitively, to me, the other approaches seem more a bit more plausible from a sociolinguistic point-of-view.  Of course there is no need for the partitionings to exist in this circular pattern, but I'm not sure how these results relate to existing work when more realistic communication cliques are used.  Some discussion of partitioning as it relates to a plausible force in shaping human language development would be appreciated.\nMy review score reflects that I believe this paper has a lot of merit, but comes up short in connecting to existing research and acknowledging extent and similarities of those contributions to a sufficient extent.\nQuestions: Questions are mostly implied by 'weaknesses', but to be clear: how does your proposed method relate to neural iterated learning, cultural transmission, and ease-of-teaching based approaches which study similar dynamics and reach similar conclusions -- typically higher task accuracy and topographic similarity?\nLimitations: I did not see any explicit discussion of limitations or societal impact, but it is hard to imagine such small scale experiments in this topic having important negative societal impact.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 3 good\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper proposes a partitioned way of training communication in receiver-sender games in a network of receiver-sender agents. A theoretical analysis is carried and the optimality of popoulation training is discussed. The results show that a partitioned approach performs better when compared to a standard fully connected communication approach. In addiiton, the quality of the language learned by the agents is analysed.\nStrengths And Weaknesses: Despite some grammar mistakes/misspelings (I document some below) this paper reads well.\nStrengths:\nThe paper analyses theoretically a sender receiver system where there is exchange of messages and builds up to achieve the proposed partitioned setup. In addition, an interesting analysis of components such as language similarity/topographic similarity is carried.\nWeaknesses:\n\nin line 74: \u201csampled from p\u201d; p should be a distribution (or the input space X in this case); according to line 61, p is a probability value. Same problem in most equations throughout the paper, when writing for example \u201cEx\u223cp\u201d.\nin the objective of the sender in equation before line 111, why is \u03c0 conditioned on m in the second expectation Em\u223c\u03c0\u03b8i\u2217(.|m)? In all the previous definitions \u03c0i is always conditioned in the input, i.e., x.\nin line 138, the same derivation from section 2.2 is assumed to be valid to the partitioned setting. While I understand the logic for the standard setting (fully connected) I have concerns about whether the derivations still hold for the partitioned setting. I believe this requires some deeper explanation instead of simply stating it. For instance, in section 2 the objective of the sender is given as the average of the objectives of the neighbour senders of the sender i. But according to Fig 1, in the partitioned setting only the receivers have neighbour senders since the senders are only connected to receivers. Same question for receivers, since the neighbours of receivers are all senders according to Fig 1. I believe this should be made more clear.\nin line 104, from my understanding it is stated that the policy of the receiver is equal to the average policy of all the neighbour senders. It is unclear to me how this equality holds even when the receiver has enough capacity. At the optimal level I agree that the policy of the receiver could indeed be some mix of the policies of the neighbour senders but it is unclear to me why this mix is the average. Is this an assumption?\n\nGenerally, I have some concerns that I have outlined in this section and some questions below.\nQuestions: \naccording to line 246, the high standard deviations are due to the fact that different behaviour may show up between agents that are far away in the population. Does it mean that agents are then limited to communicate with their neighbours if they would be placed in a new setting? Based on the results with the distances between pairs (Fig 3) I would say that the distance does not seem to be a big problem.\nin section 6.4 and Figure 5c, the values remain stable until very low values of beta and only drop when mutual intelligibility is almost non-existent, raising questions regarding the importance of a lot of mutual intelligibility. It seems true that the existence of mutual intelligibility is needed for better compositionality, but why is there almost no difference from 0.1 to 0.5? \nin line 197, if for every sampled pair both objectives for sender and receiver i are calculated, from my understanding then it means that the neighbour senders of receiver i will also be updated (because it receives the message from the other receiver as in Fig 1) without updating their tied receiver. Will this have an impact on the language if many times only the sender of the pair will be updated, as it was initially mentioned to be a problem in line 190?\nLimitations: In the results, the compositionality demonstration could be improved; although the plots in Fig 5a give an idea of the argument, it would be interesting to visualise in some way the learned languages to a more clear perception of the compositionality. \nSome minor mistakes/misspelings:\n\nin line 66, blank space at the end, seems that something is missing.\nline 294: \u201cFigure 5c\u201d -> \u201cFigure 5b\u201d\nline 79: \u201can\u201d -> \u201ca\u201d\nline 94: \u201canalyses\u201d -> \u201canalysis\u201d.\nline 65: C is defined as a set of length |C| including x; thus \u201ccontaining x and |C| distractors\u201d is incorrect since the number of distractors should be |C|-1.\nline 192: \u201cneighbor\u201d -> \u201cneighbors\u201d\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The research reevaluates the standard training procedure, highlights its shortcomings, and studied the communication of multi-agents at the population level. \nThe primary contributions: the paper propose an alternative training procedure that partitions sender-receiver pairs, restricts co-adaptation of receiver agents, and explicitly promotes mutual understanding between various agents. Moreover, the article discovers that languages created in partitioned populations are more compositional, and that population size has an effect, with bigger populations developing more structured languages.\nStrengths And Weaknesses: Strengths:\nIn this study, multi-agent communication is examined from the viewpoint of the population. the idea is relatively creative, Moreover, population-level communication in sender-receiver Lewis games is analyzed, and a novel protocol is proposed, experiments also demonstrate the efficacy of the proposed protocol. \nWeaknesses: The analysis of 6.3 may be unclear. It would not be able to understand it without reading the supplementary materials, but in 6.3 it does not say that supplementary materials are needed.\nQuestions: Can you make your code public?\nLimitations: Yes.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 2 fair\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The authors propose a modified training procedure for population-based training for emergent communication in which specific speaker-listener pairs are constructed, and replace the \"free for all\" mixing of pairs present in traditional methods.  Constraining the mixing in this way limits co-adaptation, and thus improves generalization and topographical similarity.  In addition, this solution also solves some more long-standing issues, like why scaling to larger populations in traditional training methods has not typically met with significant improvements in emergent structure or task accuracy, and the authors demonstrate how this originates in the loss of the standard training algorithm.",
                "Strengths And Weaknesses": "Strengths:\nOverall I really enjoyed this paper.  It's very well written, and the way the authors narrow their focus to this one specific issue helps the argument structure come across very clearly.  I thought their argument was convincing, especially when the scope and argument applies to training dynamics in toy scenarios.  The paper contributes important theoretical understanding to population-based optimization for EC, and the effects of controlling population size, a co-adaptation \"factor\", and mutual intelligibilty.\nWeaknesses:\nI don't have any major criticism of the work within the scope the authors layout.  However, working against this paper is that the authors make only a passing effort to connect their work to previous related work, some of which may have very similar interpretations.  Two strands of work that I think should be discussed in much more detail and direct comparison are are neural iterated learning and cultural transmission models.  Both approaches are mentioned in the related work, but no direct comparison is made, despite that both approaches apply similar constraints to the population, essentially limiting who is talking to who, and likely reducing co-adaptation.  Considering the improved performance on communicating with novel partners, one would think some comparison to iterated learning, or the Easy-of-teaching (Li 2019) would have been warranted here.\nI think by the phrasing of the last paragraph of the related work (L332/333) the authors are trying to position themselves outside of this work, but I don't find it a convincing excuse.  The motivations are similar, the solutions are quite similar, and it would be appropriate to connect to this research, both in discussion and in experimentation.  Ideally I would like to see existing work as baselines in direct comparison to this work, exploring the role of different partitioning patterns have.\nBecause in the end, I'm unsure of what these results would mean in terms of pushing the field forward.  If iterated learning is more effective on all of the proposed benchmarks, is this just a footnote in the progression of EC research or only relevant to those who are for some reason unwilling to consider known approaches to training that work better than the standard population-based training scheme?  If the authors more explicitly compared their partitioning approach to other population-based approaches, it would be clearer what the impact of the research would mean in a more practical sense.\nIntuitively, to me, the other approaches seem more a bit more plausible from a sociolinguistic point-of-view.  Of course there is no need for the partitionings to exist in this circular pattern, but I'm not sure how these results relate to existing work when more realistic communication cliques are used.  Some discussion of partitioning as it relates to a plausible force in shaping human language development would be appreciated.\nMy review score reflects that I believe this paper has a lot of merit, but comes up short in connecting to existing research and acknowledging extent and similarities of those contributions to a sufficient extent.",
                "Questions": "Questions are mostly implied by 'weaknesses', but to be clear: how does your proposed method relate to neural iterated learning, cultural transmission, and ease-of-teaching based approaches which study similar dynamics and reach similar conclusions -- typically higher task accuracy and topographic similarity?",
                "Limitations": "I did not see any explicit discussion of limitations or societal impact, but it is hard to imagine such small scale experiments in this topic having important negative societal impact.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposes a partitioned way of training communication in receiver-sender games in a network of receiver-sender agents. A theoretical analysis is carried and the optimality of popoulation training is discussed. The results show that a partitioned approach performs better when compared to a standard fully connected communication approach. In addiiton, the quality of the language learned by the agents is analysed.",
                "Strengths And Weaknesses": "Despite some grammar mistakes/misspelings (I document some below) this paper reads well.\nStrengths:\nThe paper analyses theoretically a sender receiver system where there is exchange of messages and builds up to achieve the proposed partitioned setup. In addition, an interesting analysis of components such as language similarity/topographic similarity is carried.\nWeaknesses:\n\nin line 74: \u201csampled from p\u201d; p should be a distribution (or the input space X in this case); according to line 61, p is a probability value. Same problem in most equations throughout the paper, when writing for example \u201cEx\u223cp\u201d.\nin the objective of the sender in equation before line 111, why is \u03c0 conditioned on m in the second expectation Em\u223c\u03c0\u03b8i\u2217(.|m)? In all the previous definitions \u03c0i is always conditioned in the input, i.e., x.\nin line 138, the same derivation from section 2.2 is assumed to be valid to the partitioned setting. While I understand the logic for the standard setting (fully connected) I have concerns about whether the derivations still hold for the partitioned setting. I believe this requires some deeper explanation instead of simply stating it. For instance, in section 2 the objective of the sender is given as the average of the objectives of the neighbour senders of the sender i. But according to Fig 1, in the partitioned setting only the receivers have neighbour senders since the senders are only connected to receivers. Same question for receivers, since the neighbours of receivers are all senders according to Fig 1. I believe this should be made more clear.\nin line 104, from my understanding it is stated that the policy of the receiver is equal to the average policy of all the neighbour senders. It is unclear to me how this equality holds even when the receiver has enough capacity. At the optimal level I agree that the policy of the receiver could indeed be some mix of the policies of the neighbour senders but it is unclear to me why this mix is the average. Is this an assumption?\n\nGenerally, I have some concerns that I have outlined in this section and some questions below.",
                "Questions": "according to line 246, the high standard deviations are due to the fact that different behaviour may show up between agents that are far away in the population. Does it mean that agents are then limited to communicate with their neighbours if they would be placed in a new setting? Based on the results with the distances between pairs (Fig 3) I would say that the distance does not seem to be a big problem.\nin section 6.4 and Figure 5c, the values remain stable until very low values of beta and only drop when mutual intelligibility is almost non-existent, raising questions regarding the importance of a lot of mutual intelligibility. It seems true that the existence of mutual intelligibility is needed for better compositionality, but why is there almost no difference from 0.1 to 0.5? \nin line 197, if for every sampled pair both objectives for sender and receiver i are calculated, from my understanding then it means that the neighbour senders of receiver i will also be updated (because it receives the message from the other receiver as in Fig 1) without updating their tied receiver. Will this have an impact on the language if many times only the sender of the pair will be updated, as it was initially mentioned to be a problem in line 190?",
                "Limitations": "In the results, the compositionality demonstration could be improved; although the plots in Fig 5a give an idea of the argument, it would be interesting to visualise in some way the learned languages to a more clear perception of the compositionality. \nSome minor mistakes/misspelings:\n\nin line 66, blank space at the end, seems that something is missing.\nline 294: \u201cFigure 5c\u201d -> \u201cFigure 5b\u201d\nline 79: \u201can\u201d -> \u201ca\u201d\nline 94: \u201canalyses\u201d -> \u201canalysis\u201d.\nline 65: C is defined as a set of length |C| including x; thus \u201ccontaining x and |C| distractors\u201d is incorrect since the number of distractors should be |C|-1.\nline 192: \u201cneighbor\u201d -> \u201cneighbors\u201d",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The research reevaluates the standard training procedure, highlights its shortcomings, and studied the communication of multi-agents at the population level. \nThe primary contributions: the paper propose an alternative training procedure that partitions sender-receiver pairs, restricts co-adaptation of receiver agents, and explicitly promotes mutual understanding between various agents. Moreover, the article discovers that languages created in partitioned populations are more compositional, and that population size has an effect, with bigger populations developing more structured languages.",
                "Strengths And Weaknesses": "Strengths:\nIn this study, multi-agent communication is examined from the viewpoint of the population. the idea is relatively creative, Moreover, population-level communication in sender-receiver Lewis games is analyzed, and a novel protocol is proposed, experiments also demonstrate the efficacy of the proposed protocol. \nWeaknesses: The analysis of 6.3 may be unclear. It would not be able to understand it without reading the supplementary materials, but in 6.3 it does not say that supplementary materials are needed.",
                "Questions": "Can you make your code public?",
                "Limitations": "Yes.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.0,
        "confidence_avg": 3.667,
        "soundness_avg": 3.0,
        "presentation_avg": 3.0,
        "contribution_avg": 2.333,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that this paper has significant strengths. Reviewer 1 commends the authors for their clear argument structure and convincing analysis of the proposed method. However, Reviewer 1 also points out the lack of comparison to existing work, such as neural iterated learning and cultural transmission models, which could provide valuable insights and baselines for evaluation. Reviewer 2 raises some concerns about the derivations and assumptions made in the paper, particularly in the partitioned setting. Additionally, Reviewer 2 questions the impact of distance between agents and the importance of mutual intelligibility. Reviewer 3 highlights the creative idea of examining multi-agent communication from a population perspective and praises the efficacy of the proposed protocol.\n\nOverall, the strengths of this paper outweigh the weaknesses. The proposed method shows promise in improving generalization and topographical similarity in emergent communication. While there are some concerns and areas for improvement, the contributions of this paper are significant and have moderate-to-high impact. Therefore, I recommend accepting this paper for publication."
    },
    "Coincidence_Detection_Is_All_You_Need": {
        "link": "https://openreview.net//forum?id=xT5rDp5VqKO",
        "pub_url": "https://openreview.net/forum?id=xT5rDp5VqKO",
        "pdf_link": "https://openreview.net//pdf?id=xT5rDp5VqKO",
        "paper_id": "xT5rDp5VqKO",
        "title": "Coincidence_Detection_Is_All_You_Need",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nThe authors use a simple coincidence detection algorithm on pathogenic bacteria data set and increase performance by 0.5% with respect to a ResNet-26 that was published previously.\nThe manuscript is quite thought provoking showing that a simple algorithm can potentially outperform a complex deep neural network. However, all reviewers agreed that the study should be extended in order to be publishable at NeurIPS. In particular, they raised the following points.\n\nRelevance with respect to existing methods is not discussed. Related to that, the model seems similar to a perceptron with some normalization as preprocessing. This relation should be discussed.\nThe method is tested only on a single data set. More evaluation would be needed in order to assess the generality of the method. Also, a clean statistical analysis is missing.\nAn analysis for why method performs well on this (and potentially also other) data set is missing.",
        "reviews": [
            "Reviewer 1: \nSummary: Authors present an empirical study on exploiting a classical coincidence detection based method for classification. Experiments on classifying pathogenic bacteria from Raman spectroscopy data is performed, showing a 0.5% increase in classification accuracy in comparison to using a deep learning approach with a ResNet-26 as performed in [Ho et al., 2019].\nStrengths And Weaknesses: Paper is written as a very short report on an empirical observation. No details on the relevance of the approach to existing methods are present. A clear narrative on the methodological contribution is lacking. It is not really suitable for publication at NeurIPS in its current form.\nQuestions: There is an interesting empirical observation here, yet the narrative is too shallow and clarity of the paper is weak. Generally, it is still not clear in text how the proposed \"coincidence detection\" application is applied without checking the implementation (lack of a thorough Methods section). There is also no relationship drawn with any existing neuromorphic processing algorithms that exploit temporal information encoding (lack of a thorough Related Work section). Perhaps the authors may consider extending their findings with a clear methodological contribution in a complete manuscript.\nLimitations: No discussions regarding potential societal impact or limitations.\nEthics Flag: No\nSoundness: 1 poor\nPresentation: 1 poor\nContribution: 2 fair\nRating: 2: Strong Reject: For instance, a paper with major technical flaws, and/or poor evaluation, limited impact, poor reproducibility and mostly unaddressed ethical considerations.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The authors draw inspiration from Rosenblatt\u2019s perceptrons to investigate if coincidence detection can be an important element for neuromorphic signal processing. To illustrate their approach, the authors apply a perceptron to a bacteria identification problem, showing that it outperforms a recent deep neural network approach.\nStrengths And Weaknesses: Strengths:\n\nThe paper is thought-provoking, drawing attention to how early works on neural networks focused on neural temporal dynamics that are now making a come-back in the SNN domain.\nCoincidence detection as a basis for analog pattern recognition (as explained by Hopfield, [7] in the paper) is highly interesting.\n\nWeaknesses:\n\nArriving at equation 1 was a desillusion for me, as I very much liked the text leading to it. In this equation, coincidence detection is approximated with a linear multiplication (and a max function for picking the most probable class). This takes away the main idea of coincidence detection, which requires temporal delays.\nThe simple \"coincidence\" detector gives very good results compared with a deep net. Although this could be demonstrating an advantage of coincidence detection, it may also be that the classification problem is actually not that difficult. Paper [10] seems to only apply a deep net to the problem. The authors only apply a linear function. What do other functions do? k-nearest  neighbors, SVMs, ...? \nThe paper is very short and fails to delve into the details of why the proposed method works so well. It seems logical that it has to be applied to other tasks as well to get more insight.\nQuestions: \nIs there no more suitable implementation of coincidence detection, e.g., within a spiking net?\nIs your model in eq 1 not simply a perceptron? (With normalized inputs and a max on the outputs)\nCan you report on other methods on the task of ref [10]?\nCan you show similarly good performance on other tasks?\nLimitations: N/A\nEthics Flag: No\nSoundness: 1 poor\nPresentation: 2 fair\nContribution: 1 poor\nRating: 1: Very Strong Reject: For instance, a paper with trivial results or unaddressed ethical considerations\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The authors make an argument for revisiting the use of neural circuits for pattern recognition problems citing the existence of similar neural circuits in animal brains. In that direction, the authors refer to the experiments in [10], which uses deep learning to classify pathogenic bacteria. \nWith motivation from coincidence detection theory, the authors propose a multinomial logistic regression model to solve the problem. The dataset is preprocessed with a specific standardization and smoothening that allows the model to demonstrate the translation and scale-invariance of coincidence detection. The results show higher accuracy than the residual neural network used in [10] at isolate-level classification.\nStrengths And Weaknesses: The authors show a higher accuracy compared to a deep learning algorithm which helps show the potential of framing classification problems with the coincidence detection approach. However, the authors show the accuracy for one single train/validation split whereas the reference [10] shows a statistical mean of 82.2 +- 0.3% over 5 runs. For a fair comparison the authors should rerun the experiment and generate statistical mean/variance results for random train/validation split to remove any bias due to specific train/validation split selection. Additional details about the baseline model (ResNet-26) e.g., network architecture/training time/training accuracy would be helpful to get an all-round comparison. \nFurther, the authors provide no explanation as to why their model fares better than the deep learning model for the specific problem being addressed. The paper lacks any detailed analysis on the contribution of the standardization and smoothening steps which could be generated by selectively applying these preprocessing steps. \nLastly, the authors have added a few figures to their supplementary material which would have been valuable additions to the main paper. A discussion on these figures to help understand their results and how it compares to the baseline results would be helpful. For instance, the baseline has a higher antibiotic treatment classification accuracy than the proposed model, but this isn\u2019t discussed and no justification is provided for the same.\nQuestions: Authors should consider generating more stats on their accuracy % and provide a more thorough comparison with the baseline (ResNet-26). \nFurther, authors should share additional experiments breaking down the contribution of standardization and smoothing steps. Lastly, explaining why their model fares better than the deep learning model for this problem will be helpful to understand the kind of problems this model can help solve.\nLimitations: The authors do not discuss the limitations of their work, kindly refer to Questions section for suggestions on how to improve this work.\nEthics Flag: No\nSoundness: 1 poor\nPresentation: 1 poor\nContribution: 2 fair\nRating: 2: Strong Reject: For instance, a paper with major technical flaws, and/or poor evaluation, limited impact, poor reproducibility and mostly unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "Authors present an empirical study on exploiting a classical coincidence detection based method for classification. Experiments on classifying pathogenic bacteria from Raman spectroscopy data is performed, showing a 0.5% increase in classification accuracy in comparison to using a deep learning approach with a ResNet-26 as performed in [Ho et al., 2019].",
                "Strengths And Weaknesses": "Paper is written as a very short report on an empirical observation. No details on the relevance of the approach to existing methods are present. A clear narrative on the methodological contribution is lacking. It is not really suitable for publication at NeurIPS in its current form.",
                "Questions": "There is an interesting empirical observation here, yet the narrative is too shallow and clarity of the paper is weak. Generally, it is still not clear in text how the proposed \"coincidence detection\" application is applied without checking the implementation (lack of a thorough Methods section). There is also no relationship drawn with any existing neuromorphic processing algorithms that exploit temporal information encoding (lack of a thorough Related Work section). Perhaps the authors may consider extending their findings with a clear methodological contribution in a complete manuscript.",
                "Limitations": "No discussions regarding potential societal impact or limitations.",
                "Ethics Flag": "No",
                "Soundness": "1 poor",
                "Presentation": "1 poor",
                "Contribution": "2 fair",
                "Rating": "2: Strong Reject: For instance, a paper with major technical flaws, and/or poor evaluation, limited impact, poor reproducibility and mostly unaddressed ethical considerations.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors draw inspiration from Rosenblatt\u2019s perceptrons to investigate if coincidence detection can be an important element for neuromorphic signal processing. To illustrate their approach, the authors apply a perceptron to a bacteria identification problem, showing that it outperforms a recent deep neural network approach.",
                "Strengths And Weaknesses": "Strengths:\n\nThe paper is thought-provoking, drawing attention to how early works on neural networks focused on neural temporal dynamics that are now making a come-back in the SNN domain.\nCoincidence detection as a basis for analog pattern recognition (as explained by Hopfield, [7] in the paper) is highly interesting.\n\nWeaknesses:\n\nArriving at equation 1 was a desillusion for me, as I very much liked the text leading to it. In this equation, coincidence detection is approximated with a linear multiplication (and a max function for picking the most probable class). This takes away the main idea of coincidence detection, which requires temporal delays.\nThe simple \"coincidence\" detector gives very good results compared with a deep net. Although this could be demonstrating an advantage of coincidence detection, it may also be that the classification problem is actually not that difficult. Paper [10] seems to only apply a deep net to the problem. The authors only apply a linear function. What do other functions do? k-nearest  neighbors, SVMs, ...? \nThe paper is very short and fails to delve into the details of why the proposed method works so well. It seems logical that it has to be applied to other tasks as well to get more insight.",
                "Questions": "Is there no more suitable implementation of coincidence detection, e.g., within a spiking net?\nIs your model in eq 1 not simply a perceptron? (With normalized inputs and a max on the outputs)\nCan you report on other methods on the task of ref [10]?\nCan you show similarly good performance on other tasks?",
                "Limitations": "N/A",
                "Ethics Flag": "No",
                "Soundness": "1 poor",
                "Presentation": "2 fair",
                "Contribution": "1 poor",
                "Rating": "1: Very Strong Reject: For instance, a paper with trivial results or unaddressed ethical considerations",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors make an argument for revisiting the use of neural circuits for pattern recognition problems citing the existence of similar neural circuits in animal brains. In that direction, the authors refer to the experiments in [10], which uses deep learning to classify pathogenic bacteria. \nWith motivation from coincidence detection theory, the authors propose a multinomial logistic regression model to solve the problem. The dataset is preprocessed with a specific standardization and smoothening that allows the model to demonstrate the translation and scale-invariance of coincidence detection. The results show higher accuracy than the residual neural network used in [10] at isolate-level classification.",
                "Strengths And Weaknesses": "The authors show a higher accuracy compared to a deep learning algorithm which helps show the potential of framing classification problems with the coincidence detection approach. However, the authors show the accuracy for one single train/validation split whereas the reference [10] shows a statistical mean of 82.2 +- 0.3% over 5 runs. For a fair comparison the authors should rerun the experiment and generate statistical mean/variance results for random train/validation split to remove any bias due to specific train/validation split selection. Additional details about the baseline model (ResNet-26) e.g., network architecture/training time/training accuracy would be helpful to get an all-round comparison. \nFurther, the authors provide no explanation as to why their model fares better than the deep learning model for the specific problem being addressed. The paper lacks any detailed analysis on the contribution of the standardization and smoothening steps which could be generated by selectively applying these preprocessing steps. \nLastly, the authors have added a few figures to their supplementary material which would have been valuable additions to the main paper. A discussion on these figures to help understand their results and how it compares to the baseline results would be helpful. For instance, the baseline has a higher antibiotic treatment classification accuracy than the proposed model, but this isn\u2019t discussed and no justification is provided for the same.",
                "Questions": "Authors should consider generating more stats on their accuracy % and provide a more thorough comparison with the baseline (ResNet-26). \nFurther, authors should share additional experiments breaking down the contribution of standardization and smoothing steps. Lastly, explaining why their model fares better than the deep learning model for this problem will be helpful to understand the kind of problems this model can help solve.",
                "Limitations": "The authors do not discuss the limitations of their work, kindly refer to Questions section for suggestions on how to improve this work.",
                "Ethics Flag": "No",
                "Soundness": "1 poor",
                "Presentation": "1 poor",
                "Contribution": "2 fair",
                "Rating": "2: Strong Reject: For instance, a paper with major technical flaws, and/or poor evaluation, limited impact, poor reproducibility and mostly unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 1.667,
        "confidence_avg": 4.333,
        "soundness_avg": 1.0,
        "presentation_avg": 1.333,
        "contribution_avg": 1.667,
        "ai_sum_meta": "Recommendation: Reject\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that the paper lacks clarity, thoroughness, and detailed analysis. Reviewer 1 points out that the paper is written as a very short report with no clear narrative on the methodological contribution. Reviewer 2 raises concerns about the approximation of coincidence detection and the lack of comparison with other methods. Reviewer 3 highlights the need for statistical mean/variance results and a more thorough comparison with the baseline model. Additionally, the paper lacks discussion on the contribution of preprocessing steps and fails to justify why their model performs better than the deep learning model. Considering these shortcomings, it is recommended to reject the paper."
    },
    "Meta-sketch:_A_Neural_Data_Structure_for_Estimating_Item_Frequencies_of_Data_Streams": {
        "link": "https://openreview.net//forum?id=-kS21GWVJU",
        "pub_url": "https://openreview.net/forum?id=-kS21GWVJU",
        "pdf_link": "https://openreview.net//pdf?id=-kS21GWVJU",
        "paper_id": "-kS21GWVJU",
        "title": "Meta-sketch:_A_Neural_Data_Structure_for_Estimating_Item_Frequencies_of_Data_Streams",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nThe paper had mixed reviews in terms of scores but if we put the strengths and the weakness together the weakness appears stronger. \nStrengths: People liked the neural only method and good experimental results on two datasets.\nWeakness:  Evaluations may not make sense in data stream settings, only two datasets, no theoretical motivation etc. Paper do not cite and compare recent literature on learned/adaptive learned sketches\nThe AC went through the paper and did find that there are certain major arguments that needs to be made before the paper is accepted.\n\nThe paper is about learned sketches that typically works in a bursty environment and with a lot of distribution changes all the time. No wonder all the learning augmented method still use sketches to provide worst case guarantees and control over the estimation errors. This is more or less required if at all any learning based method claims to replace sketches. As a result, the purely neural approach which treats this as a learning problem without any theoretical understanding requires more justification and case study of real scenarios.\nThe paper did not cite and compare with several recent learned/adaptive learned sketches in the literature (including recent papers in NeurIPS/ICML)\nLooking at supplementary martial and meta-task generation, it seems that there is a very strong assumption that distribution of frequency does not change over intervals. For instance, one of the typical use case of frequency estimation is to recover frequency in any interval of time (See papers on sketches over time or adaptive sketches) and dyadic interval tricks to extend sketches to do that. A purely learning based approach is unlikely to achieve much there.",
        "reviews": [
            "Reviewer 1: \nSummary: The paper proposed a neural model to estimate item frequencies of data streams, which is using the thought of meta-learning. And they called the model meta-sketch. It\u2019s said that they are the first to try to solve this problem with neural data structure and gain good performances on real datasets.\nStrengths And Weaknesses: Strengths:\nThe paper is well structured and the explanation is easy to understand.\nWeakness:\n1.\tIn my view, training data and evaluation data should be isolated completely. That is, there should be a certain mount streams and items haven\u2019t happened in the meta-tasks. Therefore, sampling training set and evaluating set from the same pool is not sufficient enough to prove the generalization.\n2.\tThe references and baselines are out of date, more researches of recent years should be covered. And it is easy to get a lot of results if you search items like \u201cItem Frequencies of Data Streams\u201d.\n3.\tOne advantage of meta-learning is that it could find better params of network faster and more efficiently. So I believe the efficiency is also a good sight of this model and it should be contained in the experiment.\nQuestions: Apart from the above, I have question about the update rule for M, M=M+z_i a_i. Is this adding process derived by some objective? Could the authors give this rule out directly. Please explain that it is representable for all items and streams.\nLimitations: None\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper introduces a sketching method where neural networks are used for specific components of the sketching. In particular, a neural network is used to encode stream/query items into an internal representation used to update/retrieve frequency values of items, which is followed by another neural network that decodes this information into actual frequency values. A meta-training procedure is also introduced, whose goal is to train the neural networks to handle the task at hand on a meta level, that is, not tied to a specific dataset. The method and its multiple aspects are experimentally evaluated, showing how its internal mechanisms behave under differing circumstances and improved performance over baseline methods built on Count sketch and Count-min sketch.\nStrengths And Weaknesses: Overall, I find this to be a strong submission. The paper is properly motivated, well-organized, and clearly written. The introduced methodology is quite original for sketching, leveraging neural networks and increasing the robustness to changes in distribution significantly, compared to existing approaches, without additional training.\nI was also pleased with the experimental evaluation, as it not only compares accuracy in frequency estimates under varied conditions, but also evaluates the different components that comprise the approach. In my view, this helps justifying why certain parts are a positive contributor to the overall performance of the method, shedding also some light on when they might fail. One weakness, however pointed out by the authors, is that the proposed method needs to be extended to other sketching tasks supported by traditional sketches.\nQuestions: There are two major points where I would appreciate an answer from the authors:\n\nHow is the method's robustness to the meta-training step? That is, how much variance is expected in the results under repeated experiments with different initial seeds?\nAre there any theoretical results that can be leveraged from existing literature on sketches? It seems to me the proposed method is lacking on the theoretical side.\n\nMinor points:\n\nl. 97: what is meant by \"length\"? Perhaps lr elements has less ambiguous meanings (cf. length vs. norm)\nFootnote 2 (p. 3): does that mean ai\u22a4\u2208Rd2\u00d7d1\u00d71? Please write explicitly the space where ai\u22a4 comes from to avoid confusion\nl. 271: \u03d5 does not seem to be defined\nLimitations: I believe the authors have sufficiently addressed the limitations of their method by analyzing its multiple components and how they behave under different circumstances.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 4 excellent\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The work considers the problem of estimating item frequencies in data streams. Sketches are probabilistic data structures that solve this problem approximately; e.g., a classical count-min (CM) sketch increments counts resulting from several hash functions for each query (exactly like a Bloom filter, only with integer counts) and outputs the minimal value of these counts as the result; this is a biased estimator that can overestimate but not underestimate. Machine learning models can be used in sketches to exploit the properties of underlying data distributions. For example, it would be better to assign heavy hitters separate buckets in a CM-sketch to avoid collisions, and a machine learning model can be used to identify these heavy hitters when they appear.\nThe work presents Meta-Sketch, a neural data structure that emulates a sketch in a neural network. The Meta-Sketch is a neural network with an encoder that produces embeddings zi and refined embeddings ri of incoming items, a sparse addressing unit that converts ri into an address ai in the storage matrix (this is the neural version of hash functions), a compressed storage matrix M that stores embedding vectors, and a decoder that produces the frequency from a reading from the storage matrix, embedding vector zi, and the total number of stored items N. The network supports two kinds of operations: \"Store\" that additively writes zi to M and \"Query\" that estimates the frequency via the decoder.\nThe entire network is both pretrained and fine-tuned (adapted) on a series of meta-tasks; each meta-task is a set of store and query operations; during pretraining, the meta-tasks are synthetic problems generated based on the Zipf distribution (the result is called a basic meta-sketch), and during adaption the network is fine-tuned on real data records (advanced meta-sketch). The idea here is to pretrain the architecture to operate as a sketch while preserving the ability to quickly adapt to a given data distribution.\nThe authors evaluate on two real datasets, a stream of search queries (several words each) and an IP trace where packets are identified with source/destination IP addresses. They report improved performance over classical sketches and also over previous attempts of adding ML to sketches: learned CM-sketch and learned C-sketch. The paper also presents an analysis section that studies how different units of the architecture perform.\nStrengths And Weaknesses: Strengths:\n\nnovel neural data structure with a clear use case\nanalysis section supporting that the components operate as intended\nconvincing experimental evaluation\n\nWeaknesses (see also questions):\n\nlack of discussion of the architectural choices for the neural networks\nonly two real datasets with no motivation for this choice and no discussion of their differences\nQuestions: \nThere is an ablation study in the supplement but I think the paper would benefit from a discussion of neural network architecture choices. For example, are there gains to be achieved from more involved encoder/decoder architectures?\n\nIt appears that the authors simply picked the same real datasets that were used in previous work (references [15, 21]). Are there other use-cases and available datasets for evaluation? Are there differences in the data distributions between these two (it appears there should be: IP traces are generally more heavy-tailed) and does it make any difference to Meta-Sketch results?\nLimitations: Limitations of the work and possible extensions have been adequately discussed in the conclusion. The societal impact question is not applicable in this case.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The paper proposed a neural model to estimate item frequencies of data streams, which is using the thought of meta-learning. And they called the model meta-sketch. It\u2019s said that they are the first to try to solve this problem with neural data structure and gain good performances on real datasets.",
                "Strengths And Weaknesses": "Strengths:\nThe paper is well structured and the explanation is easy to understand.\nWeakness:\n1.\tIn my view, training data and evaluation data should be isolated completely. That is, there should be a certain mount streams and items haven\u2019t happened in the meta-tasks. Therefore, sampling training set and evaluating set from the same pool is not sufficient enough to prove the generalization.\n2.\tThe references and baselines are out of date, more researches of recent years should be covered. And it is easy to get a lot of results if you search items like \u201cItem Frequencies of Data Streams\u201d.\n3.\tOne advantage of meta-learning is that it could find better params of network faster and more efficiently. So I believe the efficiency is also a good sight of this model and it should be contained in the experiment.",
                "Questions": "Apart from the above, I have question about the update rule for M, M=M+z_i a_i. Is this adding process derived by some objective? Could the authors give this rule out directly. Please explain that it is representable for all items and streams.",
                "Limitations": "None",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper introduces a sketching method where neural networks are used for specific components of the sketching. In particular, a neural network is used to encode stream/query items into an internal representation used to update/retrieve frequency values of items, which is followed by another neural network that decodes this information into actual frequency values. A meta-training procedure is also introduced, whose goal is to train the neural networks to handle the task at hand on a meta level, that is, not tied to a specific dataset. The method and its multiple aspects are experimentally evaluated, showing how its internal mechanisms behave under differing circumstances and improved performance over baseline methods built on Count sketch and Count-min sketch.",
                "Strengths And Weaknesses": "Overall, I find this to be a strong submission. The paper is properly motivated, well-organized, and clearly written. The introduced methodology is quite original for sketching, leveraging neural networks and increasing the robustness to changes in distribution significantly, compared to existing approaches, without additional training.\nI was also pleased with the experimental evaluation, as it not only compares accuracy in frequency estimates under varied conditions, but also evaluates the different components that comprise the approach. In my view, this helps justifying why certain parts are a positive contributor to the overall performance of the method, shedding also some light on when they might fail. One weakness, however pointed out by the authors, is that the proposed method needs to be extended to other sketching tasks supported by traditional sketches.",
                "Questions": "There are two major points where I would appreciate an answer from the authors:\n\nHow is the method's robustness to the meta-training step? That is, how much variance is expected in the results under repeated experiments with different initial seeds?\nAre there any theoretical results that can be leveraged from existing literature on sketches? It seems to me the proposed method is lacking on the theoretical side.\n\nMinor points:\n\nl. 97: what is meant by \"length\"? Perhaps lr elements has less ambiguous meanings (cf. length vs. norm)\nFootnote 2 (p. 3): does that mean ai\u22a4\u2208Rd2\u00d7d1\u00d71? Please write explicitly the space where ai\u22a4 comes from to avoid confusion\nl. 271: \u03d5 does not seem to be defined",
                "Limitations": "I believe the authors have sufficiently addressed the limitations of their method by analyzing its multiple components and how they behave under different circumstances.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "4 excellent",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The work considers the problem of estimating item frequencies in data streams. Sketches are probabilistic data structures that solve this problem approximately; e.g., a classical count-min (CM) sketch increments counts resulting from several hash functions for each query (exactly like a Bloom filter, only with integer counts) and outputs the minimal value of these counts as the result; this is a biased estimator that can overestimate but not underestimate. Machine learning models can be used in sketches to exploit the properties of underlying data distributions. For example, it would be better to assign heavy hitters separate buckets in a CM-sketch to avoid collisions, and a machine learning model can be used to identify these heavy hitters when they appear.\nThe work presents Meta-Sketch, a neural data structure that emulates a sketch in a neural network. The Meta-Sketch is a neural network with an encoder that produces embeddings zi and refined embeddings ri of incoming items, a sparse addressing unit that converts ri into an address ai in the storage matrix (this is the neural version of hash functions), a compressed storage matrix M that stores embedding vectors, and a decoder that produces the frequency from a reading from the storage matrix, embedding vector zi, and the total number of stored items N. The network supports two kinds of operations: \"Store\" that additively writes zi to M and \"Query\" that estimates the frequency via the decoder.\nThe entire network is both pretrained and fine-tuned (adapted) on a series of meta-tasks; each meta-task is a set of store and query operations; during pretraining, the meta-tasks are synthetic problems generated based on the Zipf distribution (the result is called a basic meta-sketch), and during adaption the network is fine-tuned on real data records (advanced meta-sketch). The idea here is to pretrain the architecture to operate as a sketch while preserving the ability to quickly adapt to a given data distribution.\nThe authors evaluate on two real datasets, a stream of search queries (several words each) and an IP trace where packets are identified with source/destination IP addresses. They report improved performance over classical sketches and also over previous attempts of adding ML to sketches: learned CM-sketch and learned C-sketch. The paper also presents an analysis section that studies how different units of the architecture perform.",
                "Strengths And Weaknesses": "Strengths:\n\nnovel neural data structure with a clear use case\nanalysis section supporting that the components operate as intended\nconvincing experimental evaluation\n\nWeaknesses (see also questions):\n\nlack of discussion of the architectural choices for the neural networks\nonly two real datasets with no motivation for this choice and no discussion of their differences",
                "Questions": "There is an ablation study in the supplement but I think the paper would benefit from a discussion of neural network architecture choices. For example, are there gains to be achieved from more involved encoder/decoder architectures?\n\nIt appears that the authors simply picked the same real datasets that were used in previous work (references [15, 21]). Are there other use-cases and available datasets for evaluation? Are there differences in the data distributions between these two (it appears there should be: IP traces are generally more heavy-tailed) and does it make any difference to Meta-Sketch results?",
                "Limitations": "Limitations of the work and possible extensions have been adequately discussed in the conclusion. The societal impact question is not applicable in this case.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "soundness_avg": 3.333,
        "presentation_avg": 3.333,
        "contribution_avg": 3.0,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that this paper presents a novel neural data structure, called Meta-Sketch, for estimating item frequencies in data streams. The paper is well-structured and clearly explains the methodology. The experimental evaluation demonstrates improved performance over classical sketches and previous attempts at adding machine learning to sketches. The analysis section provides insights into the performance of different components of the architecture.\n\nWhile there are some minor weaknesses pointed out by the reviewers, such as the lack of discussion on architectural choices and the limited number of real datasets used for evaluation, these limitations have been adequately addressed in the conclusion.\n\nOverall, this is a technically solid paper with high impact on the area of sketching. The evaluation is good-to-excellent, and there are no unaddressed ethical considerations. Therefore, I recommend accepting this paper with a high level of confidence."
    },
    "Differentiable_Rendering_with_Reparameterized_Volume_Sampling": {
        "link": "https://openreview.net//forum?id=pZtdVOQuA3",
        "pub_url": "https://openreview.net/forum?id=pZtdVOQuA3",
        "pdf_link": "https://openreview.net//pdf?id=pZtdVOQuA3",
        "paper_id": "pZtdVOQuA3",
        "title": "Differentiable_Rendering_with_Reparameterized_Volume_Sampling",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nReviewers noted that the paper contains some useful ideas for acceleration of neural rendering pipelines.  However, the paper as initially presented was rather preliminary with very limited evaluation.  The authors present considerably more material in the rebuttal, but as noted by the reviewers post-rebuttal, this extra material fails to demonstrate the computational advantage which is a primary contribution of this method.   It is hoped that the authors can continue this line of work, following the reviewers' suggestions, and demonstrate the method's value.   It may be that these ideas have other advantages, or that the advantage is ultimately less significant, in which case a more specific venue such as 3DV may be appropriate.\nAlthough 2v6p did not provide a post-rebuttal comment, their initial review  was closely consistent with the others (albeit marginally more positive), so the post-rebuttal analysis of the reviewers and AC remains valid.",
        "reviews": [
            "Reviewer 1: \nSummary: This submission proposes a differentiable importance sampling to estimate the rendering equation used in NeRF based methods. The method is derived using the re-parameterization method. The gradient descent is derived based on the re-parameterization method. Compared with the previous sampling method used in NeRF based methods, the proposed method leads to much lower sampling variance under the same computational cost.\nStrengths And Weaknesses: Strength\n+The proposed importance sampling for Monte-Carlo (MC) estimate is technically sound by being based on the re-parameterization method. \n+The author also shows how to make the importance sampling along the ray differentiable by taking advantage of the re-parameterization. As a result, the new sampling method can be plugged into the neural rendering pipeline and make the implicit function trainable end-to-end.\n+The proposed differentiable sampling method has much lower sampling variance as compared to the existing sampling method used in the NeRF-based methods.\n+The density field is approximated by splines in closed form. This makes the integration along the ray for getting the light attenuation more efficient to compute, as compared to the previous methods where another integration is performed along the ray.\nWeakness\n-Although the proposed sampling method and its corresponding backpropagation process is sound and promising, the paper lacks the experiments to validate its effectiveness:\n1.The method is only evaluated on a single scene (Lego)\n2.The method is only compared to the base NeRF. There are works on speeding up NeRF without sacrificing performance during both training and rendering (eg. Plenoxel NeRF). How does this method compare those methods? And more importantly, can the method be plugged into those methods for further speed-up? Without the corresponding experiment, those questions can hardly be answered.\n3.Key experiment missing for trade-off between speed and reconstruction quality: How is reconstruction quality degrades with the decrease # of samples (ie. speed-up) by using the proposed method?\n4.Related to the missing speed-quality trade-off: From Tab.2, the estimation time per iteration  increases with the number of points in the splines and exceeds the baseline at around 16 points. So the question is how does the reconstruction quality compare with the baseline at around 16 sampling points. The paper does not include the quality comparison .\n5.Comparison to other SOTA method missing: How is the proposed method compared to the SOTA NeRF methods in terms of reconstruction quality and computational and memory consumption \n-Paper needs more refinement: There are multiple question marks in the paper due to error in reference.\nQuestions: For spline construction (L128-L130), what if the underlying density field is not piecewise linear, or have sharp spikes along a ray (eg. thin structure)? Will the spline approximation still be accurate enough to get opacity estimation?\nL131-133: how to get the sampled grid t_0<...<t_m in the first place? Are they predefined? If so, how to guarantee that they don\u2019t miss any non-empty space across different views and across different scenes?\nLimitations: Experiment is performed on only one scene. So it\u2019s unknown whether this method is finetuned for that scene or more general.\nFrom L131-133, the sampling grid t_0<...<t_m cannot be guaranteed to cover the non-empty space.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 1 poor\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper proposes a reparametrization of volume sampling for faster rendering of neural radiance fields. The key idea is that, when the density value (i.e., \\sigma) is known at a few sparse points, volume rendering can be reparametrized for importance sampling, which reduces the variance and thereby accelerates the rendering of the neural radiance field. The paper provides the demonstration of lower variance (compared to uniform sampling), ablation study, and novel-view synthesis with a different number of samples both qualitatively and quantitatively.\nStrengths And Weaknesses: While this paper tackles an interesting and important problem in neural rendering, which is an acceleration of NeRF rendering, it needs to be much improved in terms of presentation and evaluation.\n\nThe proposed method is not evaluated properly. The key contribution of this paper is importance sampling that can accelerate NeRF rendering, but the provided evaluation does not demonstrate this contribution. Figure 2 shows the variance compared to uniform sampling, but the baseline should be the importance sampling used in the original NeRF. Any importance sampling should provide better results than uniform sampling, and this experiment cannot show any meaningful demonstration as the proposed method has an additional cost of density sampling in the previous step for the reparametrization. Also, in Section 5.2, the proposed method modified the original NeRF to reduce the computational cost of density sampling (by changing the density network from eight layers to three layers), which will reduce the quality of the density field and make the resultant comparison NOT apple-to-apple. Moreover, the evaluations are conducted only on a single scene (i.e., lego) and the improvement over the baseline is marginal even in the current evaluation.\nThe presentation can be much improved. There are a number of typos and the notation is not consistent throughout the paper, which severely reduces the clarity of the paper considering the fact that the main contribution is in the reparametrization of equations. To list a few:\nLine 47: R^3 \u2192 \\mathbb{R}^3\nLine 48: directionn \u2192 direction\nLine 48: location x \u2192 \\mathbf{x}, direction d \u2192 \\mathbf{d}\nLine 53: ray r \u2192 ray \\mathbf{r}\nLine 58: fauithfull \u2192 faithful\nLine 75: c(o + Td, d) \u2192 c and d should be bold\nLine 82: \\sigma_r \u2192 both \\sigma and r should be bold\nNotation for Equations are not consistent; there are Eq n, Eq. n, n, Eq. eq. (n).\nLines 110, 123: Eqs. eqs\nLine 130: r = o + td \u2192 r, o, d, should be bold\nLine 208: Eq. ??\nLine 224: Fig. ??\nLine 225: ren dering \u2192 rendering\n\n\nThe paper is based on Equation (2), which is the Riemann sum for the integral of volume rendering. However, it is not directly equivalent to the discrete volume rendering used in the original NeRF paper (Equation (3) in the original NeRF paper that is based on [Max 1995]) because of the small difference in the derivation (e.g., density is locally uniform between the samples). The difference in the equation should be clarified for a better comparison to the original NeRF.\nQuestions: Why is the proposed method efficient compared to the hierarchical volume sampling of the original NeRF paper? There is no clear demonstration of this. Both require the coarse sampling stage, which is the same additional cost compared to the naive sampling strategy. If the proposed method modifies the network structure to reduce this additional computational burden, the original NeRF can also benefit from this modification. The main baseline should be the original NeRF paper, and the comparison should be stated much more clearly and fairly in the experiment.\nLimitations: The checklist says the limitations are described in Section 1, but Section 1 does not include any description of the limitation.\nEthics Flag: No\nSoundness: 1 poor\nPresentation: 1 poor\nContribution: 1 poor\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: A Monte Carlo sampling strategy is proposed for rendering NeRF-based density field representation. The method works by firstly densely querying the density field to compute an inverse CDF, which is later used to reduce the number of subsequent samples of colour network.\nThe method is compared to the NeRF baseline and achieved faster speeds (20%) but at the cost of slightly worse image quality (0.7dB reduction in PSNR).\nStrengths And Weaknesses: The paper does address an important problem, that is to improve the efficiency of NeRF rendering. The proposed method is well motivated and indeed effective in that it does significantly reduce the sampling rate of colour network (8 to 32 samples per ray compared to 128 samples per ray in NeRF). However, on the other hand, it still requires a dense sampling of density network in the first stage, and as such the overall rendering efficiency is only slightly, if at all, improved without sacrificing performance. \nMany related papers are missing from related work section and should be cited and compared to, these include faster NeRFs:\n\nDavid B Lindell, Julien NP Martel, and Gordon Wetzstein. 2021. Autoint: Automatic integration for fast neural volume rendering\nDaniel Rebain, Wei Jiang, Soroosh Yazdani, Ke Li, Kwang Moo Yi, and Andrea Tagliasacchi. 2021. Derf: Decomposed radiance fields.\nStephan J. Garbin, Marek Kowalski, Matthew Johnson, Jamie Shotton, and Julien Valentin. 2021. FastNeRF: High-Fidelity Neural Rendering at 200FPS\nAlex Yu, Ruilong Li, Matthew Tancik, Hao Li, Ren Ng, and Angjoo Kanazawa. 2021. Plenoctrees for real-time rendering of neural radiance fields.\nChristian Reiser, Songyou Peng, Yiyi Liao, and Andreas Geiger. 2021. KiloNeRF: Speeding up Neural Radiance Fields with Thousands of Tiny MLPs.\n\nThere are several papers on implicit surface volumetric sampling, that may be worth citing as well:\n\nPeng Wang, Lingjie Liu, Yuan Liu, Christian Theobalt, Taku Komura, and Wenping Wang. 2021. NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction.\nMichael Oechsle, Songyou Peng, Andreas Geiger. 2021. UNISURF: Unifying Neural Implicit Surfaces and Radiance Fields for Multi-View Reconstruction.\n\nExperiments are too limited. There is only one case being the lego scene. Table 1 only includes two training sampling rates, what are the results for 1,2,8,16 samples per ray?\nSome typos need to be corrected, e.g.:\nline 71: propose a propose a\nline 208, 224: broken ref\nQuestions: I would suggest the authors to include missing references, and expand the experiment section.\nTo me the main drawback of proposed method is that dense sampling of density network still takes significant time. As such the speed gain is rather limited compared to vanilla NeRF. I wonder whether using a smaller density network can help in this regard.\nLimitations: I would suggest discussing the limitations in detail in section 6.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This submission proposes a differentiable importance sampling to estimate the rendering equation used in NeRF based methods. The method is derived using the re-parameterization method. The gradient descent is derived based on the re-parameterization method. Compared with the previous sampling method used in NeRF based methods, the proposed method leads to much lower sampling variance under the same computational cost.",
                "Strengths And Weaknesses": "Strength\n+The proposed importance sampling for Monte-Carlo (MC) estimate is technically sound by being based on the re-parameterization method. \n+The author also shows how to make the importance sampling along the ray differentiable by taking advantage of the re-parameterization. As a result, the new sampling method can be plugged into the neural rendering pipeline and make the implicit function trainable end-to-end.\n+The proposed differentiable sampling method has much lower sampling variance as compared to the existing sampling method used in the NeRF-based methods.\n+The density field is approximated by splines in closed form. This makes the integration along the ray for getting the light attenuation more efficient to compute, as compared to the previous methods where another integration is performed along the ray.\nWeakness\n-Although the proposed sampling method and its corresponding backpropagation process is sound and promising, the paper lacks the experiments to validate its effectiveness:\n1.The method is only evaluated on a single scene (Lego)\n2.The method is only compared to the base NeRF. There are works on speeding up NeRF without sacrificing performance during both training and rendering (eg. Plenoxel NeRF). How does this method compare those methods? And more importantly, can the method be plugged into those methods for further speed-up? Without the corresponding experiment, those questions can hardly be answered.\n3.Key experiment missing for trade-off between speed and reconstruction quality: How is reconstruction quality degrades with the decrease # of samples (ie. speed-up) by using the proposed method?\n4.Related to the missing speed-quality trade-off: From Tab.2, the estimation time per iteration  increases with the number of points in the splines and exceeds the baseline at around 16 points. So the question is how does the reconstruction quality compare with the baseline at around 16 sampling points. The paper does not include the quality comparison .\n5.Comparison to other SOTA method missing: How is the proposed method compared to the SOTA NeRF methods in terms of reconstruction quality and computational and memory consumption \n-Paper needs more refinement: There are multiple question marks in the paper due to error in reference.",
                "Questions": "For spline construction (L128-L130), what if the underlying density field is not piecewise linear, or have sharp spikes along a ray (eg. thin structure)? Will the spline approximation still be accurate enough to get opacity estimation?\nL131-133: how to get the sampled grid t_0<...<t_m in the first place? Are they predefined? If so, how to guarantee that they don\u2019t miss any non-empty space across different views and across different scenes?",
                "Limitations": "Experiment is performed on only one scene. So it\u2019s unknown whether this method is finetuned for that scene or more general.\nFrom L131-133, the sampling grid t_0<...<t_m cannot be guaranteed to cover the non-empty space.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "1 poor",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper proposes a reparametrization of volume sampling for faster rendering of neural radiance fields. The key idea is that, when the density value (i.e., \\sigma) is known at a few sparse points, volume rendering can be reparametrized for importance sampling, which reduces the variance and thereby accelerates the rendering of the neural radiance field. The paper provides the demonstration of lower variance (compared to uniform sampling), ablation study, and novel-view synthesis with a different number of samples both qualitatively and quantitatively.",
                "Strengths And Weaknesses": "While this paper tackles an interesting and important problem in neural rendering, which is an acceleration of NeRF rendering, it needs to be much improved in terms of presentation and evaluation.\n\nThe proposed method is not evaluated properly. The key contribution of this paper is importance sampling that can accelerate NeRF rendering, but the provided evaluation does not demonstrate this contribution. Figure 2 shows the variance compared to uniform sampling, but the baseline should be the importance sampling used in the original NeRF. Any importance sampling should provide better results than uniform sampling, and this experiment cannot show any meaningful demonstration as the proposed method has an additional cost of density sampling in the previous step for the reparametrization. Also, in Section 5.2, the proposed method modified the original NeRF to reduce the computational cost of density sampling (by changing the density network from eight layers to three layers), which will reduce the quality of the density field and make the resultant comparison NOT apple-to-apple. Moreover, the evaluations are conducted only on a single scene (i.e., lego) and the improvement over the baseline is marginal even in the current evaluation.\nThe presentation can be much improved. There are a number of typos and the notation is not consistent throughout the paper, which severely reduces the clarity of the paper considering the fact that the main contribution is in the reparametrization of equations. To list a few:\nLine 47: R^3 \u2192 \\mathbb{R}^3\nLine 48: directionn \u2192 direction\nLine 48: location x \u2192 \\mathbf{x}, direction d \u2192 \\mathbf{d}\nLine 53: ray r \u2192 ray \\mathbf{r}\nLine 58: fauithfull \u2192 faithful\nLine 75: c(o + Td, d) \u2192 c and d should be bold\nLine 82: \\sigma_r \u2192 both \\sigma and r should be bold\nNotation for Equations are not consistent; there are Eq n, Eq. n, n, Eq. eq. (n).\nLines 110, 123: Eqs. eqs\nLine 130: r = o + td \u2192 r, o, d, should be bold\nLine 208: Eq. ??\nLine 224: Fig. ??\nLine 225: ren dering \u2192 rendering\n\n\nThe paper is based on Equation (2), which is the Riemann sum for the integral of volume rendering. However, it is not directly equivalent to the discrete volume rendering used in the original NeRF paper (Equation (3) in the original NeRF paper that is based on [Max 1995]) because of the small difference in the derivation (e.g., density is locally uniform between the samples). The difference in the equation should be clarified for a better comparison to the original NeRF.",
                "Questions": "Why is the proposed method efficient compared to the hierarchical volume sampling of the original NeRF paper? There is no clear demonstration of this. Both require the coarse sampling stage, which is the same additional cost compared to the naive sampling strategy. If the proposed method modifies the network structure to reduce this additional computational burden, the original NeRF can also benefit from this modification. The main baseline should be the original NeRF paper, and the comparison should be stated much more clearly and fairly in the experiment.",
                "Limitations": "The checklist says the limitations are described in Section 1, but Section 1 does not include any description of the limitation.",
                "Ethics Flag": "No",
                "Soundness": "1 poor",
                "Presentation": "1 poor",
                "Contribution": "1 poor",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "A Monte Carlo sampling strategy is proposed for rendering NeRF-based density field representation. The method works by firstly densely querying the density field to compute an inverse CDF, which is later used to reduce the number of subsequent samples of colour network.\nThe method is compared to the NeRF baseline and achieved faster speeds (20%) but at the cost of slightly worse image quality (0.7dB reduction in PSNR).",
                "Strengths And Weaknesses": "The paper does address an important problem, that is to improve the efficiency of NeRF rendering. The proposed method is well motivated and indeed effective in that it does significantly reduce the sampling rate of colour network (8 to 32 samples per ray compared to 128 samples per ray in NeRF). However, on the other hand, it still requires a dense sampling of density network in the first stage, and as such the overall rendering efficiency is only slightly, if at all, improved without sacrificing performance. \nMany related papers are missing from related work section and should be cited and compared to, these include faster NeRFs:\n\nDavid B Lindell, Julien NP Martel, and Gordon Wetzstein. 2021. Autoint: Automatic integration for fast neural volume rendering\nDaniel Rebain, Wei Jiang, Soroosh Yazdani, Ke Li, Kwang Moo Yi, and Andrea Tagliasacchi. 2021. Derf: Decomposed radiance fields.\nStephan J. Garbin, Marek Kowalski, Matthew Johnson, Jamie Shotton, and Julien Valentin. 2021. FastNeRF: High-Fidelity Neural Rendering at 200FPS\nAlex Yu, Ruilong Li, Matthew Tancik, Hao Li, Ren Ng, and Angjoo Kanazawa. 2021. Plenoctrees for real-time rendering of neural radiance fields.\nChristian Reiser, Songyou Peng, Yiyi Liao, and Andreas Geiger. 2021. KiloNeRF: Speeding up Neural Radiance Fields with Thousands of Tiny MLPs.\n\nThere are several papers on implicit surface volumetric sampling, that may be worth citing as well:\n\nPeng Wang, Lingjie Liu, Yuan Liu, Christian Theobalt, Taku Komura, and Wenping Wang. 2021. NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction.\nMichael Oechsle, Songyou Peng, Andreas Geiger. 2021. UNISURF: Unifying Neural Implicit Surfaces and Radiance Fields for Multi-View Reconstruction.\n\nExperiments are too limited. There is only one case being the lego scene. Table 1 only includes two training sampling rates, what are the results for 1,2,8,16 samples per ray?\nSome typos need to be corrected, e.g.:\nline 71: propose a propose a\nline 208, 224: broken ref",
                "Questions": "I would suggest the authors to include missing references, and expand the experiment section.\nTo me the main drawback of proposed method is that dense sampling of density network still takes significant time. As such the speed gain is rather limited compared to vanilla NeRF. I wonder whether using a smaller density network can help in this regard.",
                "Limitations": "I would suggest discussing the limitations in detail in section 6.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 3.333,
        "confidence_avg": 3.667,
        "soundness_avg": 2.333,
        "presentation_avg": 1.667,
        "contribution_avg": 1.667,
        "ai_sum_meta": "Recommendation: Reject\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that the proposed method lacks proper evaluation and comparison with existing methods. The experiments are limited to only one scene and do not provide a comprehensive analysis of the trade-off between speed and reconstruction quality. Additionally, there are several typos and inconsistencies in the presentation of the paper. The missing references and related work also need to be addressed. Overall, while the proposed method addresses an important problem, it falls short in terms of evaluation, presentation, and comparison with existing methods. Therefore, I recommend rejecting the paper."
    },
    "Principle_Components_Analysis_based_frameworks_for_efficient_missing_data_imputation_algorithms": {
        "link": "https://openreview.net//forum?id=eE-S1U5GG94",
        "pub_url": "https://openreview.net/forum?id=eE-S1U5GG94",
        "pdf_link": "https://openreview.net//pdf?id=eE-S1U5GG94",
        "paper_id": "eE-S1U5GG94",
        "title": "Principle_Components_Analysis_based_frameworks_for_efficient_missing_data_imputation_algorithms",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nThis paper proposes a framework based on principle components analysis (PCA) to speed up the missing data imputation. It divides the feature sets into two partitions -- the fully observed one and the one that contains missing values. The proposed method applies PCA to the fully observed partition to do dimensionality reduction, followed by the existing imputation methods. The authors further propose to apply PCA to the imputed data to speed up the downstream classification task.\nThe major weakness is that the methodological contribution is quite limited. Projecting data into lower dimensional spaces to speed up downstream tasks is not new. In particular, the main assumption of random missingness has been considered before 10-20 years ago and the more challenging setting of non-random missingness was not considered. Overall the reviewers mostly agree that the contribution is limited.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper proposes a framework based on principle components analysis (PCA) to speed up the missing data imputation. It divides the feature sets into two partitions -- the fully observed one and the one that contains missing values. The proposed method applies PCA to the fully observed partition to do dimensionality reduction, followed by the existing imputation methods. The authors further propose to apply PCA to the imputed data to speed up the downstream classification task.\nStrengths And Weaknesses: Strengths:\n\nThe paper is overall organized and readers can easily follow.\n\nWeaknesses:\n\nThe major weakness is that the methodological contribution is quite limited. Projecting data into lower dimensional spaces to speed up downstream tasks is not new. In fact, it has been widely regarded as the go-to tool to handle large datasets.\nQuestions: A suggestion for further improvement: the proposed method only applies PCA to the fully observed partition, yet in many important cases, either we have no prior information about which feature is fully observed, or the feature partition with missing value is very large. If the PCA variant to be proposed could directly apply to the partition with missing values, it would much more interesting. Of course, it has to come with theoretical and empirical validations.\nLimitations: Limitations are not discussed in this paper.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 1 poor\nRating: 2: Strong Reject: For instance, a paper with major technical flaws, and/or poor evaluation, limited impact, poor reproducibility and mostly unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The authors presented two novel frameworks, PCAI and PIC, that allow for more efficient handling of missing data. There are two use cases, fashion MNIST (imaging data) and Parkinson (voice recording) dataset.\nStrengths And Weaknesses: Strength: easy to understand and implement. \nWeakness: The main assumption is that introducing random missing is not acceptable without sufficient evidence and justification.\nQuestions: Testing and optimizing imputation is complex and unless one is taking sufficient steps, the results may be biased, and the study will have limited utility and generalizability. \nA comparison of a fashion dataset (in this case imaging data) and a medical dataset (in this case, voice recording) cannot be only about the number of records and number of features. To impute one has to understand the data characteristics, beyond simple statistics. A Deeper discussion of these differences is important if such comparisons are made.\nLimitations: The main assumption is that introducing random missing is not acceptable unless the author can show that such data suffers from random missing. For instance, clinical data has missing that is not completely random. Please see the paper published in nature digital medicine on this topic. https://www.nature.com/articles/s41746-021-00518-0 \nSimilarly, voice recordings and imaging data suffer likely from non at random missingness due to the nature of the data.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 2 fair\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The authors present a PCA based framework for missing data imputation specially efficient for high dimensional data. The experiments indicate that the imputation presents low MSE and, when applied to classification tasks, results in similar or better accuracy values.\nStrengths And Weaknesses: The main motivation is relevant and promising. The related work section indicates a well explored field. Nevertheless, the authors should mention and include in the experimental section at least some of the many PCA based approaches to data imputation. See for instance [1,2,3,4] and the references within. Without those comparisons, it is difficult to state the originality of the work.\nSince the proposed approach relies on classic PCA and can be coupled with any imputation strategy, it seems to be readily available for practitioners. This is a welcomed advantage of the proposal.\nThe writing is mostly sound and the manuscript is well organized. However, some steps of the proposed algorithms are difficult to follow due to the lack of details. I will list them in the next part.\nReferences\n[1] Qu, Li, et al. \"PPCA-based missing data imputation for traffic flow volume: A systematical approach.\" IEEE Transactions on intelligent transportation systems 10.3 (2009): 512-522.\n[2] Folch-Fortuny, Abel, Francisco Arteaga, and Alberto Ferrer. \"PCA model building with missing data: New proposals and a comparative study.\" Chemometrics and Intelligent Laboratory Systems 146 (2015): 77-88.\n[3] Folch\u2010Fortuny, Abel, Francisco Arteaga, and Alberto Ferrer. \"Assessment of maximum likelihood PCA missing data imputation.\" Journal of Chemometrics 30.7 (2016): 386-393.\n[4] D\u2019Enza, Alfonso Iodice, Francesco Palumbo, and Angelos Markos. \"Single Imputation Via Chunk-Wise PCA.\" Data Analysis and Rationality in a Complex World (2021): 75.\nQuestions: Some details of the proposed algorithms and experiments can be improved:\n\nAlthough it is not explicit in the text, I have inferred that the so-called \"partition with missing values\" correspond to features with unknown values (columns of the dataset), instead of samples with unknown feature values (rows of the dataset). Am I correct?\nIn Algorithm 1, how exactly \"R U M\" is handled? Column-wise concatenation?\nHow exactly the missing data was generated? It is not clear if a 20% missing rate is related to 20% instances with a single random missing feature or if it means that 20% of the total features are missing.\nIn the classification experiments, how many data points are used for training and testing? How many independent runs? How hyperparameter selection was performed?\n\nI do not think it is necessary to separate the PCAI and PIC frameworks. It seems to me that PIC is the straightforward application of PCAI on data related to a classification task. Unless I am mistaken, I recommend unifying the presentation of both strategies.\nI list additional comments below:\n\nI believe \"Principal Components Analysis\" is preferred over \"Principle Components Analysis\".\nLine 117: \"We first conduct dimension reduction on the fully observed partition M...\" -> 'F' is the fully observed partition.\nLine 151: The matrix 'W' has not been defined at this point.\nTab. 4 should include the standard result obtained by the SVM classifier, without PCA.\nI recommend always including in the supervised experiments the simple baseline of simply removing the instances with any missing data.\nLimitations: The manuscript states sufficiently its limitations.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: The authors propose we propose a framework based on PCA to speed up the imputation process of many available imputation techniques. The proposed methods are named PCAI and PCA-PIC. Experiments are provided on various datasets.\nStrengths And Weaknesses: Weaknesses:\n\nThe authors only compared PCAI strategy with the traditional strategy.\n\"Principle Component Analysis\" should be \"Principal Component Analysis\"\n\nStrengths:\nThe proposed methods are named PCAI and PCA-PI are novel.\nQuestions: Can the authors explain why the traditional style of imputing on the original missing dataset gives NAs for all missing rates?\nLimitations: The authors addressee adequately the limitaions of  PCAI and PCA-PI.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 2 fair\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper proposes a framework based on principle components analysis (PCA) to speed up the missing data imputation. It divides the feature sets into two partitions -- the fully observed one and the one that contains missing values. The proposed method applies PCA to the fully observed partition to do dimensionality reduction, followed by the existing imputation methods. The authors further propose to apply PCA to the imputed data to speed up the downstream classification task.",
                "Strengths And Weaknesses": "Strengths:\n\nThe paper is overall organized and readers can easily follow.\n\nWeaknesses:\n\nThe major weakness is that the methodological contribution is quite limited. Projecting data into lower dimensional spaces to speed up downstream tasks is not new. In fact, it has been widely regarded as the go-to tool to handle large datasets.",
                "Questions": "A suggestion for further improvement: the proposed method only applies PCA to the fully observed partition, yet in many important cases, either we have no prior information about which feature is fully observed, or the feature partition with missing value is very large. If the PCA variant to be proposed could directly apply to the partition with missing values, it would much more interesting. Of course, it has to come with theoretical and empirical validations.",
                "Limitations": "Limitations are not discussed in this paper.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "1 poor",
                "Rating": "2: Strong Reject: For instance, a paper with major technical flaws, and/or poor evaluation, limited impact, poor reproducibility and mostly unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors presented two novel frameworks, PCAI and PIC, that allow for more efficient handling of missing data. There are two use cases, fashion MNIST (imaging data) and Parkinson (voice recording) dataset.",
                "Strengths And Weaknesses": "Strength: easy to understand and implement. \nWeakness: The main assumption is that introducing random missing is not acceptable without sufficient evidence and justification.",
                "Questions": "Testing and optimizing imputation is complex and unless one is taking sufficient steps, the results may be biased, and the study will have limited utility and generalizability. \nA comparison of a fashion dataset (in this case imaging data) and a medical dataset (in this case, voice recording) cannot be only about the number of records and number of features. To impute one has to understand the data characteristics, beyond simple statistics. A Deeper discussion of these differences is important if such comparisons are made.",
                "Limitations": "The main assumption is that introducing random missing is not acceptable unless the author can show that such data suffers from random missing. For instance, clinical data has missing that is not completely random. Please see the paper published in nature digital medicine on this topic. https://www.nature.com/articles/s41746-021-00518-0 \nSimilarly, voice recordings and imaging data suffer likely from non at random missingness due to the nature of the data.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors present a PCA based framework for missing data imputation specially efficient for high dimensional data. The experiments indicate that the imputation presents low MSE and, when applied to classification tasks, results in similar or better accuracy values.",
                "Strengths And Weaknesses": "The main motivation is relevant and promising. The related work section indicates a well explored field. Nevertheless, the authors should mention and include in the experimental section at least some of the many PCA based approaches to data imputation. See for instance [1,2,3,4] and the references within. Without those comparisons, it is difficult to state the originality of the work.\nSince the proposed approach relies on classic PCA and can be coupled with any imputation strategy, it seems to be readily available for practitioners. This is a welcomed advantage of the proposal.\nThe writing is mostly sound and the manuscript is well organized. However, some steps of the proposed algorithms are difficult to follow due to the lack of details. I will list them in the next part.\nReferences\n[1] Qu, Li, et al. \"PPCA-based missing data imputation for traffic flow volume: A systematical approach.\" IEEE Transactions on intelligent transportation systems 10.3 (2009): 512-522.\n[2] Folch-Fortuny, Abel, Francisco Arteaga, and Alberto Ferrer. \"PCA model building with missing data: New proposals and a comparative study.\" Chemometrics and Intelligent Laboratory Systems 146 (2015): 77-88.\n[3] Folch\u2010Fortuny, Abel, Francisco Arteaga, and Alberto Ferrer. \"Assessment of maximum likelihood PCA missing data imputation.\" Journal of Chemometrics 30.7 (2016): 386-393.\n[4] D\u2019Enza, Alfonso Iodice, Francesco Palumbo, and Angelos Markos. \"Single Imputation Via Chunk-Wise PCA.\" Data Analysis and Rationality in a Complex World (2021): 75.",
                "Questions": "Some details of the proposed algorithms and experiments can be improved:\n\nAlthough it is not explicit in the text, I have inferred that the so-called \"partition with missing values\" correspond to features with unknown values (columns of the dataset), instead of samples with unknown feature values (rows of the dataset). Am I correct?\nIn Algorithm 1, how exactly \"R U M\" is handled? Column-wise concatenation?\nHow exactly the missing data was generated? It is not clear if a 20% missing rate is related to 20% instances with a single random missing feature or if it means that 20% of the total features are missing.\nIn the classification experiments, how many data points are used for training and testing? How many independent runs? How hyperparameter selection was performed?\n\nI do not think it is necessary to separate the PCAI and PIC frameworks. It seems to me that PIC is the straightforward application of PCAI on data related to a classification task. Unless I am mistaken, I recommend unifying the presentation of both strategies.\nI list additional comments below:\n\nI believe \"Principal Components Analysis\" is preferred over \"Principle Components Analysis\".\nLine 117: \"We first conduct dimension reduction on the fully observed partition M...\" -> 'F' is the fully observed partition.\nLine 151: The matrix 'W' has not been defined at this point.\nTab. 4 should include the standard result obtained by the SVM classifier, without PCA.\nI recommend always including in the supervised experiments the simple baseline of simply removing the instances with any missing data.",
                "Limitations": "The manuscript states sufficiently its limitations.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors propose we propose a framework based on PCA to speed up the imputation process of many available imputation techniques. The proposed methods are named PCAI and PCA-PIC. Experiments are provided on various datasets.",
                "Strengths And Weaknesses": "Weaknesses:\n\nThe authors only compared PCAI strategy with the traditional strategy.\n\"Principle Component Analysis\" should be \"Principal Component Analysis\"\n\nStrengths:\nThe proposed methods are named PCAI and PCA-PI are novel.",
                "Questions": "Can the authors explain why the traditional style of imputing on the original missing dataset gives NAs for all missing rates?",
                "Limitations": "The authors addressee adequately the limitaions of  PCAI and PCA-PI.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 3.75,
        "confidence_avg": 3.75,
        "soundness_avg": 2.25,
        "presentation_avg": 2.25,
        "contribution_avg": 2.0,
        "ai_sum_meta": "Recommendation: Reject\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that the proposed framework for missing data imputation using PCA has some limitations and weaknesses. Reviewer 1 points out that the methodological contribution is limited and not novel, as projecting data into lower dimensional spaces for downstream tasks is already a well-established approach. Reviewer 2 raises concerns about the assumption of random missing data and suggests a deeper discussion of the differences between fashion and medical datasets. Reviewer 3 highlights the lack of comparisons with existing PCA-based approaches and suggests unifying the presentation of the proposed frameworks. Reviewer 4 also mentions the lack of comparison with other imputation strategies and points out a typo in the term \"Principal Component Analysis\". Considering these feedback and the strictness level of 0.5, it is recommended to reject the paper."
    },
    "Causal_Discovery_in_Probabilistic_Networks_with_an_Identifiable_Causal_Effect": {
        "link": "https://openreview.net//forum?id=EaRoPGzxRkO",
        "pub_url": "https://openreview.net/forum?id=EaRoPGzxRkO",
        "pdf_link": "https://openreview.net//pdf?id=EaRoPGzxRkO",
        "paper_id": "EaRoPGzxRkO",
        "title": "Causal_Discovery_in_Probabilistic_Networks_with_an_Identifiable_Causal_Effect",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Less certain\nThis paper studies the problem of causal identifiability in probabilistic causal models, where each edge is associated with a probability value that indicate the uncertainty about the existence of edge and whether a given causal effect is identifiable. Two technical problems are considered: 1) finding the most probable graph that renders a desired causal query identifiable, and 2) finding the graph with the highest aggregate probability over its edge-induced subgraphs that renders a desired causal query identifiable.\nA reasonable amount of discussions took place between the authors and the reviewers, and among the reviewers themselves. At the end, we get four confident (4) reviews with ratings 5, 6, 6, and 7: \nThe reviewers appreciate the novel problem setting, interesting complexity results, reasonable algorithms and clear presentation.\nHowever, there is also concern that since the paper solves a surrogate problem than the one it sets out to solve, there needs to be more acknowledgement and up front discussion about this gap in the paper, and discussion on potential ways to bridge this gap. In general, a broader discussion on the practical utility of the work developed here, rather than just the ideal question is expected in the final revision, along with other reviewer feedback.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper addresses problems of probabilistic reasoning about uncertainty in causal diagrams. In particular, given a simple distribution over ADMGs, and a causal effect query, the authors consider 1) finding the most likely graph that is identifiable; and 2) finding the identifiability formula with the greatest probability of being valid. They show that 1) and a relaxation of 2) are equivalent to the edge-ID problem, which they show to be NP-hard (in particular, equivalent to the minimum-cost intervention problem). In view of this, they provide a number of heuristic algorithms to solve the edge-ID problem, demonstrating their efficacy on both simulated graphs and real-world datasets.\nStrengths And Weaknesses: Overall, this is a technically strong and interesting paper which introduces a number of new ideas. The authors introduce the novel problem of evaluating (maximal) probabilities of identifiability under graph uncertainty, and provide both clear formal results on hardness as well as practical heuristic algorithms. \nForm a theoretical perspective, the reductions to and from MCIP (Thm 1 and Thm 2) are quite non-trivial and provide an interesting computational link between the problems of choosing minimal cost interventions and most likely edge-subgraphs for identifiability. The authors study the problem under the restrictive assumption of independent edges, but also introduce a clever extension to distributions with perfect negative correlations. Algorithmically, the backtracking exact algorithm is simple but sensible, while the heuristic algorithms make clever use of the properties of hedge structures.\nThe presentation of the paper has clearly been thought out carefully; in particular, the technical clarity of the main paper and appendix proofs is excellent. However, in terms of telling the story, the paper as written seems to rely on a lot of implicit context to be fully understood, which could perhaps be spelled out more explicitly. To give a few examples, with the aim of providing constructive suggestions for improving readability:\n\nDefinition 4 of a hedge appears to be non-standard, as a specific case of the full definition where G[Y] forms a c-component and the intervention is on all other nodes V\\Y; while I understand the authors\u2019 desire to set up the intuition, it would be helpful to explicitly state this.\nTheorem 1 appears before the MCIP problem is defined or even mentioned; in my opinion, given that the relationship between these two problems is so close as shown in the proofs of Thm 1 and 2, it would be useful to explicitly mention this and give some intuition in the main paper.\nThe MCIP problem formulation is not intuitive (\u201cminimum cost set of interventions\u201d) without the context in [1] about why the stated formulation is consistent; this could be stated explicitly.\n\nMy main criticism of the paper is with regards to the motivation of the edge-ID problem, and as a result the degree to which the paper breaks new ground beyond [1]. In particular, it is not clear why one would want to find the most likely identifiable graph. Unless this probability is very high, it would be unreasonable to rely on identification formulae based on that graph. Finding the identification formula that is most likely to be valid is more compelling, but unfortunately (and understandably from a computational perspective) a rather crude relaxation is used, which could have very different solutions. \nIn this sense, I would have liked to have seen some experiments demonstrating the utility of the edge-ID problem, by putting it in the context of the original problems. In particular, it might be useful to see the raw probabilities associated with the most likely graph/most likely aggregate graphs; or perhaps, in cases where exact computation is feasible, the gap between the probability of the most likely identification formula and the solution to Problem 2. \nNonetheless, this is an extremely solid work overall that provides new understanding of the computational issues regarding probabilistic reasoning about identifiability.\n[1] S. Akbari, J. Etesami, and N. Kiyavash. Minimum cost intervention design for causal effect identification.\nQuestions: \nWhat practical applications can the authors envisage for their methods?\nIn all experiments, the probability of an edge is restricted to lie in [0.51, 1]. Is this because an edge with probability <0.5 would always be removed? If so, do the authors consider this a limitation of their formulation of the problem (in that positive correlations between edges are not possible)?\nLimitations: The authors appropriately acknowledge the limitations of their method (independent edges, approximation made by Problem 2).\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 3 good\nContribution: 2 fair\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper addresses the problem of causal identification under structural uncertainty. In particular the authors assume that the probability of edge existence is given and provide an algorithm to find the most probable configuration for a given causal query of interest. Empirical results show promise.\nStrengths And Weaknesses: Strengths:\n\nNovel and interesting task. Structural uncertainty and misspecification is commonplace, and addressing this for identification is a very important problem area. \nWell described problem setup and the authors provide both exact and heuristic solutions.\n\nWeaknesses:\n\nApproach seems fraught in dense graphs. \nExperimental evidence could be more compelling, would especially like to see a comparison with more naive approaches.\nQuestions: In many practical settings I would imagine that there are a large number of dense graphs that appears (i.e., many non-zero probabilities) do the authors have ideas or guidance on how to reduce the size of the search space?\nLimitations: The authors address limitations of the proposed approach well.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The paper considers a setting where one does not have access to a fully specified causal ADMG but a probabilistic causal graph in which the directed/bidirected edges are assigned probabilities. It studies two questions under this setting:  Given a probabilistic graph and a specific causal effect of interest, (1)  which subgraph has the highest plausibility and (2) which subgraph has the highest aggregate probability over its edge-induced subgraphs for which the causal effect is identifiable? The paper shows that both problems reduce to an NP-hard combinatorial optimization problem, provides several exact and heuristic algorithms, and empirically evaluates the proposed algorithms.\nStrengths And Weaknesses: Originality\nThe paper introduces a new causal inference setting represented by probabilistic causal graphs that capture uncertainties in the existence of edges. The setting relaxes the restrictive requirement that one must have access to a fully specified causal graph in the majority of works on causal effect identification. To the best of my knowledge, this problem setting is novel.\nQuality of work\nThe technical results look sound. The proposed algorithms look reasonable. The empirical evaluation is largely adequate.\nClarity\nThe paper is clearly written. The presentation is excellent.\nSignificance\nThe main weakness of the paper is in its significance. Although the results are of some interest, it looks to me the paper does not really solve the problem it claims to be solving. \n-It looks to me that the results are limited to causal queries of the form Q[Y] instead of arbitrary causal effects PX(Y). Remark 1 appears to address this issue and claims ``They can be applied to general causal queries of the form PX(Y) if the directed edges of G and therefore the set AncG\u2216X(Y) are known.'' It\u2019s not clear what this claim means. Are the results of the paper applicable to general PX(Y) only if all the directed edges are fixed with probability 1?\n-Problem 2 does not solve the problem of deriving an identification formula for a given causal query that holds with the highest probability. Solving Problem 2 finds a lower bound on the plausibility of an identification formula since there may exist other types of graphs with the same identification formula.\nQuestions: Are the results limited to causal queries of the form Q[Y] or applicable to arbitrary causal effects PX(Y)? Please clarify Remark 1.\nIn the experiments, the edge probabilities pe are sampled uniformly between 0.51 and 1.0. Why making pe>0.5? I believe this makes the graph samples biased. In fact, I suspect making all edge probabilities larger than 0.5 might make certain optimization problems easy to solve (just a guess), but any reason keeping pe>0.5?\nLine 111, {z, t} should be {z, x}?\nLimitations: If the results are indeed limited to causal queries of the form Q[Y] instead of arbitrary causal effects PX(Y), then this limitation should be made clear in the abstract/introduction, etc.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: \nGiven uncertainties about the existence of edges in a causal diagram, this paper consider two problems:\n\n\nfinding the most probable graph that renders a desired causal query identifiable.\n\nfinding the graph with the highest aggregate probability over its edge-induced subgraphs that renders a desired causal query identifiable.\n\n\n\nThen, the authors introduce a combinatorial optimization problem which they call the edge ID problem and show that it is NP-hard. Further, they show that the two problems mentioned above are also NP-hard by reducing them to the edge ID problem. \n\nFinally, the authors propose several exact and heuristic algorithms for the aforementioned problems.\nStrengths And Weaknesses: Strengths: \n\nThis paper introduces three new problems and prove that they are NP-hard:\n\n\nfinding the most probable graph that renders a desired causal query identifiable.\nfinding the graph with the highest aggregate probability over its edge-induced subgraphs that renders a desired causal query identifiable.\nfinding the set of edges E with minimum aggregated weight that renders a desired causal query identifiable in the graph resulting from removing E (i.e., the edge ID problem).\n\n\nAs a consequence of their work, the authors also show that if an identification formula is valid w.r.t a causal graph, it is also valid w.r.t all its edge-induced subgraphs. \nFurther, they also establish a bi-directional link between the edge ID problem and the minimum-cost intervention problem. Therefore, the algorithms proposed here could be useful to solve the minimum-cost intervention problem as well.\n\nOriginality:\nThe paper is technically solid and brings a significant originality of ideas. However, I am a little concerned about the importance of the questions considered. See the limitation section below.\nClarity:\nThe paper is mostly well-written. There are certain places where the writing could be improved/made clear. Please see 'Suggestions / typos' below.\nWeakness:\n\nRelevance of the problem setup: As mentioned in the paper, most algorithms proposed to identify causal effect assume access to a correctly specified causal diagram. This assumption includes knowing the presence of every edge in a causal diagram with probability 0 or with probability 1 i.e., pe=0 or pe=1. While this paper does not need to know a binary pe, it still needs to know a continuous valued pe i.e., pe\u2208[0,1] for every edge in a causal diagram. In my opinion, such information is difficult to obtain in most real-world applications. The authors sample pe uniformly between 0.51 and 1.0 in all of their experiments and mention that these uncertainties may reflect the confidence of a particular statistical test. However, how would one obtain such information for bi-directed edges even from statistical tests? I would encourage the authors to think more carefully about this requirement and include real-world scenarios where this requirement would be satisfied. \n\nType of causal queries studied:  In Remark 1, the authors mention that their results are not limited to causal queries of the form Q[Y]. They can be applied to general queries of the form PX(Y) when the directed edges of the causal diagram are known. However, in this case, the authors are inherently eliminating any uncertainties associated with the directed edges of the causal diagram which seems against the spirit of the paper.\nQuestions: Questions:\n\nIn line 52, the authors say 'selecting the most plausible subgraph in which the assumption holds true'. Could they justify or elaborate on why this is the case? In other words, I fail to see the point being made here.\n\nWhat happens when the uncertainties associated with the edges are such that pe=0 or pe=1 instead of pe\u2208[0,1]? It is clear that the weights in Lemma 1 are either 0 or \u221e. Would the recursive algorithm or the heuristic algorithms simplify? Would the solutions of three problems considered in this work simplify? Would the solutions/algorithms map to some existing work?\n\nCould the authors provide more insight regarding Lemma 1? More specifically, is there any intuition behind the weights of the edge ID problem that Problems 1 and 2 map to?\n\nDepending on the number of vertices and edges in the underlying causal diagram, the probability in (1) for any subgraph might be very small. For example, the values for Problem 1 for G1 and G2 are 0.049 and 0.081 respectively. Further, it is also likely that the aggregate probabilities in Problem 2 for two graphs are not very different. In that case, instead of a single identification formula, it might be useful to find a bunch of such formulae. In other words, it might be useful to derive interval bounds for the causal effect than a point estimate. Could the uncertainties about the existence of the edges and/or the problems analyzed in this work be useful towards this?\n\nAs mentioned in lines 148-149, Problem 2 is a surrogate to recovering the identification formula with the highest plausibility. Do the authors have a sense of how far away is this lower bound from the true value?\n\nI understand that the Assumption 1 could be expanded to allow edges with perfect negative or positive correlation as mentioned in lines 158-159. But a perfect correlation between two edges basically makes the probability of one of the two edges irrelevant/useless. I don't have any major concern with Assumption 1 but it may be useful to comment on how relevant this assumption is in practice.\n\n\nSuggestions / typos:\n\nThe authors might want to introduce certain notation before using them e.g., PX(Y) in line 47, PXM(Y) in line 97, ...  \nThe authors introduce the notation [G]Id(PX(Y)) in line 102 as the set of ADMGs in which PX(Y) is identifiable. Is each element of this set an edge-induced subgraph of G? The authors might want to clarify this. \nIn line 111, the authors mention that the set including z and t forms a hedge for Q[x]. Is this correct? Should x not be a part of the hedge for Q[x]? \nThe authors might want to clarify 'the ID algorithm' mentioned on line 192.\nBased on lines 268-276, it seems that there exists a hedge for Q[Ymcip] in ADMG H in Figure 2b. Is this true? Does Ymcip form a district in H[Ymcip]?\nWhat is n on lines 289 and 320?\nIt might be useful to provide more details about the real-world datasets used in this work. Why are the outcome variables in these datasets not fixed? Is there a particular reason why these specific datasets were used?\nLimitations: In its current form, this work has some limitations which are not addressed. For example, see the two points made in the weaknesses above. \nFurther, I am also concerned about the relevance of the Problems studied here. In Problem 1, the authors are interested in finding the most probable causal diagram in which the causal effect is identifiable. In Problem 2, the authors are interested in finding (a lower bond on) the most probable causal effect. These problems makes sense when there exists no way to find the causal effect (under the assumption that only the uncertainties associated with the edges are known).\nWhile most algorithms proposed to identify causal effect assume access to a correctly specified causal diagram, there has been a line of work for identifying causal effect using only an anchor variable when the underlying causal diagram is not known. For example: (1) Entner et al 2013 -- Data-driven covariate selection for nonparametric estimation of causal effects [https://proceedings.mlr.press/v31/entner13a.html], (2) Cheng et al 2020 -- Towards unique and unbiased causal effect estimation from data with hidden variable [https://arxiv.org/pdf/2002.10091.pdf], (3) Shah et al 2021 -- Finding Valid Adjustments under Non-ignorability with Minimal DAG Knowledge [https://arxiv.org/pdf/2106.11560.pdf].\nIn light of these works, I am concerned about the relevance of the two problems studied in this work. First, by requiring uncertainty for every edge in a causal diagram, this paper require global knowledge of the underlying causal diagram which may be too much to ask for as described in first weakness above. In contrast, the aforementioned works require only local knowledge of the underlying causal diagram concerning the anchor variable. Second, and more importantly, consider a scenario where the aforementioned works are able to find a valid identification formula for a causal effect of interest. In that case, no matter what the rest of the causal diagram looks like, the identification formula remains valid. On the other hand, this may not be true for the two problems studied in this work. Consider the example 1 on page 4. If one were to solve Problem 1, they may choose F2 over F1 and if one were to solve Problem 2, they may choose F1 over F2. However, it is certainly possible that the true underlying causal diagram is G in Figure 1a and neither F1 nor F2 are valid identification formulae. To conclude, what is the validity of the causal effect / identification formula returned by the two problems considered in this work? I understand that this may not be apples to apples comparison with the three works mentioned above, my question in the previous sentence stands. How would the outputs of the Problems considered here be used in a real-world application?\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper addresses problems of probabilistic reasoning about uncertainty in causal diagrams. In particular, given a simple distribution over ADMGs, and a causal effect query, the authors consider 1) finding the most likely graph that is identifiable; and 2) finding the identifiability formula with the greatest probability of being valid. They show that 1) and a relaxation of 2) are equivalent to the edge-ID problem, which they show to be NP-hard (in particular, equivalent to the minimum-cost intervention problem). In view of this, they provide a number of heuristic algorithms to solve the edge-ID problem, demonstrating their efficacy on both simulated graphs and real-world datasets.",
                "Strengths And Weaknesses": "Overall, this is a technically strong and interesting paper which introduces a number of new ideas. The authors introduce the novel problem of evaluating (maximal) probabilities of identifiability under graph uncertainty, and provide both clear formal results on hardness as well as practical heuristic algorithms. \nForm a theoretical perspective, the reductions to and from MCIP (Thm 1 and Thm 2) are quite non-trivial and provide an interesting computational link between the problems of choosing minimal cost interventions and most likely edge-subgraphs for identifiability. The authors study the problem under the restrictive assumption of independent edges, but also introduce a clever extension to distributions with perfect negative correlations. Algorithmically, the backtracking exact algorithm is simple but sensible, while the heuristic algorithms make clever use of the properties of hedge structures.\nThe presentation of the paper has clearly been thought out carefully; in particular, the technical clarity of the main paper and appendix proofs is excellent. However, in terms of telling the story, the paper as written seems to rely on a lot of implicit context to be fully understood, which could perhaps be spelled out more explicitly. To give a few examples, with the aim of providing constructive suggestions for improving readability:\n\nDefinition 4 of a hedge appears to be non-standard, as a specific case of the full definition where G[Y] forms a c-component and the intervention is on all other nodes V\\Y; while I understand the authors\u2019 desire to set up the intuition, it would be helpful to explicitly state this.\nTheorem 1 appears before the MCIP problem is defined or even mentioned; in my opinion, given that the relationship between these two problems is so close as shown in the proofs of Thm 1 and 2, it would be useful to explicitly mention this and give some intuition in the main paper.\nThe MCIP problem formulation is not intuitive (\u201cminimum cost set of interventions\u201d) without the context in [1] about why the stated formulation is consistent; this could be stated explicitly.\n\nMy main criticism of the paper is with regards to the motivation of the edge-ID problem, and as a result the degree to which the paper breaks new ground beyond [1]. In particular, it is not clear why one would want to find the most likely identifiable graph. Unless this probability is very high, it would be unreasonable to rely on identification formulae based on that graph. Finding the identification formula that is most likely to be valid is more compelling, but unfortunately (and understandably from a computational perspective) a rather crude relaxation is used, which could have very different solutions. \nIn this sense, I would have liked to have seen some experiments demonstrating the utility of the edge-ID problem, by putting it in the context of the original problems. In particular, it might be useful to see the raw probabilities associated with the most likely graph/most likely aggregate graphs; or perhaps, in cases where exact computation is feasible, the gap between the probability of the most likely identification formula and the solution to Problem 2. \nNonetheless, this is an extremely solid work overall that provides new understanding of the computational issues regarding probabilistic reasoning about identifiability.\n[1] S. Akbari, J. Etesami, and N. Kiyavash. Minimum cost intervention design for causal effect identification.",
                "Questions": "What practical applications can the authors envisage for their methods?\nIn all experiments, the probability of an edge is restricted to lie in [0.51, 1]. Is this because an edge with probability <0.5 would always be removed? If so, do the authors consider this a limitation of their formulation of the problem (in that positive correlations between edges are not possible)?",
                "Limitations": "The authors appropriately acknowledge the limitations of their method (independent edges, approximation made by Problem 2).",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper addresses the problem of causal identification under structural uncertainty. In particular the authors assume that the probability of edge existence is given and provide an algorithm to find the most probable configuration for a given causal query of interest. Empirical results show promise.",
                "Strengths And Weaknesses": "Strengths:\n\nNovel and interesting task. Structural uncertainty and misspecification is commonplace, and addressing this for identification is a very important problem area. \nWell described problem setup and the authors provide both exact and heuristic solutions.\n\nWeaknesses:\n\nApproach seems fraught in dense graphs. \nExperimental evidence could be more compelling, would especially like to see a comparison with more naive approaches.",
                "Questions": "In many practical settings I would imagine that there are a large number of dense graphs that appears (i.e., many non-zero probabilities) do the authors have ideas or guidance on how to reduce the size of the search space?",
                "Limitations": "The authors address limitations of the proposed approach well.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper considers a setting where one does not have access to a fully specified causal ADMG but a probabilistic causal graph in which the directed/bidirected edges are assigned probabilities. It studies two questions under this setting:  Given a probabilistic graph and a specific causal effect of interest, (1)  which subgraph has the highest plausibility and (2) which subgraph has the highest aggregate probability over its edge-induced subgraphs for which the causal effect is identifiable? The paper shows that both problems reduce to an NP-hard combinatorial optimization problem, provides several exact and heuristic algorithms, and empirically evaluates the proposed algorithms.",
                "Strengths And Weaknesses": "Originality\nThe paper introduces a new causal inference setting represented by probabilistic causal graphs that capture uncertainties in the existence of edges. The setting relaxes the restrictive requirement that one must have access to a fully specified causal graph in the majority of works on causal effect identification. To the best of my knowledge, this problem setting is novel.\nQuality of work\nThe technical results look sound. The proposed algorithms look reasonable. The empirical evaluation is largely adequate.\nClarity\nThe paper is clearly written. The presentation is excellent.\nSignificance\nThe main weakness of the paper is in its significance. Although the results are of some interest, it looks to me the paper does not really solve the problem it claims to be solving. \n-It looks to me that the results are limited to causal queries of the form Q[Y] instead of arbitrary causal effects PX(Y). Remark 1 appears to address this issue and claims ``They can be applied to general causal queries of the form PX(Y) if the directed edges of G and therefore the set AncG\u2216X(Y) are known.'' It\u2019s not clear what this claim means. Are the results of the paper applicable to general PX(Y) only if all the directed edges are fixed with probability 1?\n-Problem 2 does not solve the problem of deriving an identification formula for a given causal query that holds with the highest probability. Solving Problem 2 finds a lower bound on the plausibility of an identification formula since there may exist other types of graphs with the same identification formula.",
                "Questions": "Are the results limited to causal queries of the form Q[Y] or applicable to arbitrary causal effects PX(Y)? Please clarify Remark 1.\nIn the experiments, the edge probabilities pe are sampled uniformly between 0.51 and 1.0. Why making pe>0.5? I believe this makes the graph samples biased. In fact, I suspect making all edge probabilities larger than 0.5 might make certain optimization problems easy to solve (just a guess), but any reason keeping pe>0.5?\nLine 111, {z, t} should be {z, x}?",
                "Limitations": "If the results are indeed limited to causal queries of the form Q[Y] instead of arbitrary causal effects PX(Y), then this limitation should be made clear in the abstract/introduction, etc.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "Given uncertainties about the existence of edges in a causal diagram, this paper consider two problems:\n\n\nfinding the most probable graph that renders a desired causal query identifiable.\n\nfinding the graph with the highest aggregate probability over its edge-induced subgraphs that renders a desired causal query identifiable.\n\n\n\nThen, the authors introduce a combinatorial optimization problem which they call the edge ID problem and show that it is NP-hard. Further, they show that the two problems mentioned above are also NP-hard by reducing them to the edge ID problem. \n\nFinally, the authors propose several exact and heuristic algorithms for the aforementioned problems.",
                "Strengths And Weaknesses": "Strengths: \n\nThis paper introduces three new problems and prove that they are NP-hard:\n\n\nfinding the most probable graph that renders a desired causal query identifiable.\nfinding the graph with the highest aggregate probability over its edge-induced subgraphs that renders a desired causal query identifiable.\nfinding the set of edges E with minimum aggregated weight that renders a desired causal query identifiable in the graph resulting from removing E (i.e., the edge ID problem).\n\n\nAs a consequence of their work, the authors also show that if an identification formula is valid w.r.t a causal graph, it is also valid w.r.t all its edge-induced subgraphs. \nFurther, they also establish a bi-directional link between the edge ID problem and the minimum-cost intervention problem. Therefore, the algorithms proposed here could be useful to solve the minimum-cost intervention problem as well.\n\nOriginality:\nThe paper is technically solid and brings a significant originality of ideas. However, I am a little concerned about the importance of the questions considered. See the limitation section below.\nClarity:\nThe paper is mostly well-written. There are certain places where the writing could be improved/made clear. Please see 'Suggestions / typos' below.\nWeakness:\n\nRelevance of the problem setup: As mentioned in the paper, most algorithms proposed to identify causal effect assume access to a correctly specified causal diagram. This assumption includes knowing the presence of every edge in a causal diagram with probability 0 or with probability 1 i.e., pe=0 or pe=1. While this paper does not need to know a binary pe, it still needs to know a continuous valued pe i.e., pe\u2208[0,1] for every edge in a causal diagram. In my opinion, such information is difficult to obtain in most real-world applications. The authors sample pe uniformly between 0.51 and 1.0 in all of their experiments and mention that these uncertainties may reflect the confidence of a particular statistical test. However, how would one obtain such information for bi-directed edges even from statistical tests? I would encourage the authors to think more carefully about this requirement and include real-world scenarios where this requirement would be satisfied. \n\nType of causal queries studied:  In Remark 1, the authors mention that their results are not limited to causal queries of the form Q[Y]. They can be applied to general queries of the form PX(Y) when the directed edges of the causal diagram are known. However, in this case, the authors are inherently eliminating any uncertainties associated with the directed edges of the causal diagram which seems against the spirit of the paper.",
                "Questions": "Questions:\n\nIn line 52, the authors say 'selecting the most plausible subgraph in which the assumption holds true'. Could they justify or elaborate on why this is the case? In other words, I fail to see the point being made here.\n\nWhat happens when the uncertainties associated with the edges are such that pe=0 or pe=1 instead of pe\u2208[0,1]? It is clear that the weights in Lemma 1 are either 0 or \u221e. Would the recursive algorithm or the heuristic algorithms simplify? Would the solutions of three problems considered in this work simplify? Would the solutions/algorithms map to some existing work?\n\nCould the authors provide more insight regarding Lemma 1? More specifically, is there any intuition behind the weights of the edge ID problem that Problems 1 and 2 map to?\n\nDepending on the number of vertices and edges in the underlying causal diagram, the probability in (1) for any subgraph might be very small. For example, the values for Problem 1 for G1 and G2 are 0.049 and 0.081 respectively. Further, it is also likely that the aggregate probabilities in Problem 2 for two graphs are not very different. In that case, instead of a single identification formula, it might be useful to find a bunch of such formulae. In other words, it might be useful to derive interval bounds for the causal effect than a point estimate. Could the uncertainties about the existence of the edges and/or the problems analyzed in this work be useful towards this?\n\nAs mentioned in lines 148-149, Problem 2 is a surrogate to recovering the identification formula with the highest plausibility. Do the authors have a sense of how far away is this lower bound from the true value?\n\nI understand that the Assumption 1 could be expanded to allow edges with perfect negative or positive correlation as mentioned in lines 158-159. But a perfect correlation between two edges basically makes the probability of one of the two edges irrelevant/useless. I don't have any major concern with Assumption 1 but it may be useful to comment on how relevant this assumption is in practice.\n\n\nSuggestions / typos:\n\nThe authors might want to introduce certain notation before using them e.g., PX(Y) in line 47, PXM(Y) in line 97, ...  \nThe authors introduce the notation [G]Id(PX(Y)) in line 102 as the set of ADMGs in which PX(Y) is identifiable. Is each element of this set an edge-induced subgraph of G? The authors might want to clarify this. \nIn line 111, the authors mention that the set including z and t forms a hedge for Q[x]. Is this correct? Should x not be a part of the hedge for Q[x]? \nThe authors might want to clarify 'the ID algorithm' mentioned on line 192.\nBased on lines 268-276, it seems that there exists a hedge for Q[Ymcip] in ADMG H in Figure 2b. Is this true? Does Ymcip form a district in H[Ymcip]?\nWhat is n on lines 289 and 320?\nIt might be useful to provide more details about the real-world datasets used in this work. Why are the outcome variables in these datasets not fixed? Is there a particular reason why these specific datasets were used?",
                "Limitations": "In its current form, this work has some limitations which are not addressed. For example, see the two points made in the weaknesses above. \nFurther, I am also concerned about the relevance of the Problems studied here. In Problem 1, the authors are interested in finding the most probable causal diagram in which the causal effect is identifiable. In Problem 2, the authors are interested in finding (a lower bond on) the most probable causal effect. These problems makes sense when there exists no way to find the causal effect (under the assumption that only the uncertainties associated with the edges are known).\nWhile most algorithms proposed to identify causal effect assume access to a correctly specified causal diagram, there has been a line of work for identifying causal effect using only an anchor variable when the underlying causal diagram is not known. For example: (1) Entner et al 2013 -- Data-driven covariate selection for nonparametric estimation of causal effects [https://proceedings.mlr.press/v31/entner13a.html], (2) Cheng et al 2020 -- Towards unique and unbiased causal effect estimation from data with hidden variable [https://arxiv.org/pdf/2002.10091.pdf], (3) Shah et al 2021 -- Finding Valid Adjustments under Non-ignorability with Minimal DAG Knowledge [https://arxiv.org/pdf/2106.11560.pdf].\nIn light of these works, I am concerned about the relevance of the two problems studied in this work. First, by requiring uncertainty for every edge in a causal diagram, this paper require global knowledge of the underlying causal diagram which may be too much to ask for as described in first weakness above. In contrast, the aforementioned works require only local knowledge of the underlying causal diagram concerning the anchor variable. Second, and more importantly, consider a scenario where the aforementioned works are able to find a valid identification formula for a causal effect of interest. In that case, no matter what the rest of the causal diagram looks like, the identification formula remains valid. On the other hand, this may not be true for the two problems studied in this work. Consider the example 1 on page 4. If one were to solve Problem 1, they may choose F2 over F1 and if one were to solve Problem 2, they may choose F1 over F2. However, it is certainly possible that the true underlying causal diagram is G in Figure 1a and neither F1 nor F2 are valid identification formulae. To conclude, what is the validity of the causal effect / identification formula returned by the two problems considered in this work? I understand that this may not be apples to apples comparison with the three works mentioned above, my question in the previous sentence stands. How would the outputs of the Problems considered here be used in a real-world application?",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "soundness_avg": 3.5,
        "presentation_avg": 3.25,
        "contribution_avg": 2.5,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is clear that this paper is technically strong and addresses an important problem in the field of probabilistic reasoning about uncertainty in causal diagrams. The authors introduce novel problems and provide both theoretical results and practical algorithms to solve them. The paper is well-written and the technical clarity is excellent.\n\nWhile there are some suggestions for improving the readability and motivation of the paper, overall the reviewers have recognized the significance and impact of the work. The limitations of the proposed approach are acknowledged by the authors themselves, but they have provided reasonable justifications for their choices.\n\nTherefore, I recommend accepting this paper. The confidence level is certain as the reviewers have provided positive feedback and there are no major concerns with respect to evaluation, resources, reproducibility, or ethical considerations."
    },
    "Learnable_Graph_Convolutional_Attention_Networks": {
        "link": "https://openreview.net//forum?id=2TdPjch_ogV",
        "pub_url": "https://openreview.net/forum?id=2TdPjch_ogV",
        "pdf_link": "https://openreview.net//pdf?id=2TdPjch_ogV",
        "paper_id": "2TdPjch_ogV",
        "title": "Learnable_Graph_Convolutional_Attention_Networks",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Less certain\nThe paper explores the advantages of both GCN and GAT by proposing a learnable network that can interpolate between GCN, GAT and CAT for each layer automatically. The proposed research idea is novel and discovers an interesting perspective by combining and interpolating between convolution and attention networks. The paper is theoretically sound, and extensive experiments are conducted over 15 datasets with a comprehensive analysis. \nHowever, all the reviewers consistently raise concerns regarding incremental improvement compared with baselines, and another common concern is that the authors do not extend the proposed method with more advanced convolutional and attention networks. The authors argue that their intuition is to design a more robust replacement to GCN/GAT, not a SOTA. However, the author should be aware that L-CAT is able to extend to other networks does not guarantee it will work, and it is possible that the convolution and attention network may conflict during the training. Since the proposed method is a novel and general paradigm, solid experiments are needed to thoroughly evaluate its performance. The motivation is promising, but more experiments should be conducted to sufficiently prove the superiority of the proposed method.",
        "reviews": [
            "Reviewer 1: \nSummary: The work developed by the authors in the paper consists in a design of a novel convolutional operation to achieve learning on graph data. This convolutional operation lies at the crossroad of \"isotropic\" GCN and \"anisotropic\"/ attentional GNN to take the advantages of both operations without increasing the complexity of the operation.\nIn this study, appropriate datasets and baselines are introduced to support the theoretical motivation and the robustness of the proposed operation.\nStrengths And Weaknesses: This work is a novel combination of two well known convolutional operations on unstructured data.  The combination is well motivated / studied methodologically and empirically. It can bring a value for a better understanding of learning on graphs and might give insight for the design of more expressive convolutional operations on graphs. \nThe authors studied theoretically the expressive powers of GCN and GAT while identifying their failures. Based on the latter, their combination is proposed in a straightforward manner while showing a gain in a performance without substantial increase of the complexity of GNN architectures. Moreover, their architecture is less sensitive to noisy data compared to GCN and GAT while being quasi-agnostic to the weights initialization which add significant value to the work. This direction could be interesting to explore further towards invariant architectures w.r.t weight initializations to make the networks more robust and get rid-off careful choice of initialization which is a tedious engineering task. \nThe related work is well studied and the experiments are compared with appropriate GNN models. Moreover, the paper is well structured and easy to follow, including the consistency of math variables. \nI argue that the work is technically correct where the claims are well motivated theoretically and validated empirically with an appropriate experimental protocol. However, l am not sure to find some  mathematical parts developed  in the supplementary necessary to understand the contribution of the paper. Namely line 477 and 519.\nOne may wonder if the proposed framework can be generalized to any convolutional operations on graphs and to what extent it is possible or it is restricted to combining only GAT and GCN.  As a consequence, it's not clear if the proposed combination doesn't interfere with recent convolutional operations, including the seminal works on the design of convolutional operations from dynamical systems, partial differential equations and differential geometry standpoints.\nQuestions: 1/ Is the idea of combining GAT and GCN could be generalized to any pairs of convolutional operations on graphs ? or the proposed framework is restricted to these two convolutional operations\n2/ Can you shed light on the fact that the proposed combination doesn't interfere with any recent convolutional operations design ?\n3/ Could you compare (table 1, table 2) with recent convolutional operations ? it's a good starting that L-CAT outperforms GAT and GCN, however, one may wonder if it the case w.r.t to other convolutional operations.\nLimitations: The limitations are fairly discussed and the work does't have any societal concern.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: In this paper, the authors first investigate the expressiveness of convolutional-based and attention-based GNN architectures under the CSBM setting, and propose graph convolutional attention (CAT) which hinges the attention with convolution. Knowing there is no clear winner between attention and convolution, the authors propose a technique to interpolate in the middle of all the three mechanisms, called L-CAT.\nStrengths And Weaknesses: Strengths:\n\nThe paper is clearly written, well formulated, and easy to follow.\n\nBoth theoretical and empirical analysis on the separate power of attention using CSBM seems interesting, though largely followed from the \u201cGraph Attention Retrospective\u201d paper.\n\nThe ideas of combining and interpolating between convolution and attention are novel proposals and well-motivated.\n\nThe empirical evaluation justifies the theory on CSBM, demonstrates performance on both real data and benchmark, and presents many insightful visualization and ablation studies e.g., the learning curve and distributions of tunable parameters, robustness to initialization and noises.\n\n\nWeaknesses:\n\nThe theoretical analysis is based on toy settings. And the theoretical significance is not claimed very clearly given the \u201cGraph Attention Retrospective\u201d paper. Also the separation power of convolution-based architecture still remains obscure without a formal argument.\n\nThe performance on the benchmark is not as good as expected. GCN and GAT seem to be a special case of L-CAT. However, L-CAT fails to outperform GCN on proteins and mag data. Also, lots of strong baselines are missing.\nQuestions: \nIn \u201cGraph Attention Retrospective\u201d, the authors considered two-class CSBM. Is there any special reason that this paper considers three classes?\n\nCAT computes the attention score based on the neighborhood information of the two nodes. Does this mean CAT actually cheats using second-hop information? And naturally improve the expressiveness? Would it be more fair to compare CAT with two-layer GAT or GCN?\nLimitations: The analysis in this paper is fundamental and provides good insights. However, the major limitation lies in the performance on the benchmark datasets. According to the theoretical results in this paper, L-CAT generalizes GCN and GAT and learns to trade off between these two architectures. However, the final performance on OGB shows even GCN outperforms L-CAT on two datasets. Moreover, current SOTA models faraway outperform GCN and GAT. Trading off between GCN and GAT seems not a key to improve the performance.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The authors propose a new graph neural network by combining existing graph convolution networks: GCNs and GAT. The authors proposed a new learnable convolutional attention layer (L-CAT), which subsumes the graph convolution in GCNs, the graph attention layer in GAT, and a normalized attention layer (CAT).\nStrengths And Weaknesses: \nA new layer that subsumes a couple of popular graph convolution layers has been proposed. Without changing layers in GNNs, by optimizing parameters in the proposed layer, the proposed graph neural network can change its behavior. \nThis paper theoretically discussed the expressive power of GAT and the proposed layer CAT with a contextual stochastic block model (CSBM).\nQuestions: \nThe experiments are somewhat obvious. The proposed method subsumes GCN, GAT, CAT. Then L-CAT must be on par with the models or outperform them.\nIn Table 1, L-CAT and CAT are comparable. The performance gain is marginal compared to GAT. Unless I missed something, both GCN and GAT are baselines of the proposed method.\nIn the literature, more powerful GNNs have been recently studied. Why do the authors compare their method with GCN?\nLimitations: \nThe proposed method is a simple generalized graph neural network that subsumes GCN and GAT layers. The simplicity of the proposed method is great as long as it has practical merits. However, the performance gain by the proposed method is marginal. In addition, the authors did not compare the proposed method with more recent works that exhibit stronger performance.\nThe proposed method is incremental, and the lack of generality of the proposed method makes the impact of this paper questionable.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This submissions has two parts of contribution. \nFirst, it proposes a novel attention mechanism for graph neural networks. The proposed technique first aggregates neighborhood features (as done in GCN) before computing the attention weights. This new method is named CAT. By a theoretical, analysis, the authors show that CAT can be more effective than GAT but their comparison depends on the graph topology. \nSecond, for a given layer, the submission proposes to learn two additional scalar weights that interpolates between GCN , GAT, the newly proposed CAT. The intuition here is that the network can discover the correct network type to use depends on the input data. \nOverall, I think the proposed method is novel and the theoretical analysis provides an interesting perspective. The empirical analysis shows that the proposed methods are more robust to data noise and weight initialization scheme. However, in the standard setting, the proposed method is mostly on-par with GCN (the comparison is not consistent across datasets). To take this empirical weakness into account, I am giving a weak accept.\nStrengths And Weaknesses: Strength\n\nThe proposed method is novel\nThe proposed method is motivated by a theoretical analysis. I appreciate the effort to understand the proposed method.\nOn the empirical side, the proposed method is more robust to data noise and different initialize schemes\nThe writing is very clear\n\nWeakness\n\nFor the standard benchmarks, the proposed method is only on par with GCN, which is a simpler method. \nI provide more requests and suggestions for improving the current draft in the questions section below.\nQuestions: Questions:\n\nAs the authors acknowledged, many new variants of graph neural networks have been proposed. Can the authors include more baselines into comparison to contextualize the results better? I am especially interested in knowing how other baselines would react to the added feature noises. \nCan the theretical analysis  also be applied to L-cat? Similarly, how would L-CAT behave on the synthetic data in Figure 1?\nAnother form of data noise is corruption to the graph adjacency matrix. Does L-CAT also handle this form of corruption better?\nLimitations: I do not see any negative societal impact.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 2 fair\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The work developed by the authors in the paper consists in a design of a novel convolutional operation to achieve learning on graph data. This convolutional operation lies at the crossroad of \"isotropic\" GCN and \"anisotropic\"/ attentional GNN to take the advantages of both operations without increasing the complexity of the operation.\nIn this study, appropriate datasets and baselines are introduced to support the theoretical motivation and the robustness of the proposed operation.",
                "Strengths And Weaknesses": "This work is a novel combination of two well known convolutional operations on unstructured data.  The combination is well motivated / studied methodologically and empirically. It can bring a value for a better understanding of learning on graphs and might give insight for the design of more expressive convolutional operations on graphs. \nThe authors studied theoretically the expressive powers of GCN and GAT while identifying their failures. Based on the latter, their combination is proposed in a straightforward manner while showing a gain in a performance without substantial increase of the complexity of GNN architectures. Moreover, their architecture is less sensitive to noisy data compared to GCN and GAT while being quasi-agnostic to the weights initialization which add significant value to the work. This direction could be interesting to explore further towards invariant architectures w.r.t weight initializations to make the networks more robust and get rid-off careful choice of initialization which is a tedious engineering task. \nThe related work is well studied and the experiments are compared with appropriate GNN models. Moreover, the paper is well structured and easy to follow, including the consistency of math variables. \nI argue that the work is technically correct where the claims are well motivated theoretically and validated empirically with an appropriate experimental protocol. However, l am not sure to find some  mathematical parts developed  in the supplementary necessary to understand the contribution of the paper. Namely line 477 and 519.\nOne may wonder if the proposed framework can be generalized to any convolutional operations on graphs and to what extent it is possible or it is restricted to combining only GAT and GCN.  As a consequence, it's not clear if the proposed combination doesn't interfere with recent convolutional operations, including the seminal works on the design of convolutional operations from dynamical systems, partial differential equations and differential geometry standpoints.",
                "Questions": "1/ Is the idea of combining GAT and GCN could be generalized to any pairs of convolutional operations on graphs ? or the proposed framework is restricted to these two convolutional operations\n2/ Can you shed light on the fact that the proposed combination doesn't interfere with any recent convolutional operations design ?\n3/ Could you compare (table 1, table 2) with recent convolutional operations ? it's a good starting that L-CAT outperforms GAT and GCN, however, one may wonder if it the case w.r.t to other convolutional operations.",
                "Limitations": "The limitations are fairly discussed and the work does't have any societal concern.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "In this paper, the authors first investigate the expressiveness of convolutional-based and attention-based GNN architectures under the CSBM setting, and propose graph convolutional attention (CAT) which hinges the attention with convolution. Knowing there is no clear winner between attention and convolution, the authors propose a technique to interpolate in the middle of all the three mechanisms, called L-CAT.",
                "Strengths And Weaknesses": "Strengths:\n\nThe paper is clearly written, well formulated, and easy to follow.\n\nBoth theoretical and empirical analysis on the separate power of attention using CSBM seems interesting, though largely followed from the \u201cGraph Attention Retrospective\u201d paper.\n\nThe ideas of combining and interpolating between convolution and attention are novel proposals and well-motivated.\n\nThe empirical evaluation justifies the theory on CSBM, demonstrates performance on both real data and benchmark, and presents many insightful visualization and ablation studies e.g., the learning curve and distributions of tunable parameters, robustness to initialization and noises.\n\n\nWeaknesses:\n\nThe theoretical analysis is based on toy settings. And the theoretical significance is not claimed very clearly given the \u201cGraph Attention Retrospective\u201d paper. Also the separation power of convolution-based architecture still remains obscure without a formal argument.\n\nThe performance on the benchmark is not as good as expected. GCN and GAT seem to be a special case of L-CAT. However, L-CAT fails to outperform GCN on proteins and mag data. Also, lots of strong baselines are missing.",
                "Questions": "In \u201cGraph Attention Retrospective\u201d, the authors considered two-class CSBM. Is there any special reason that this paper considers three classes?\n\nCAT computes the attention score based on the neighborhood information of the two nodes. Does this mean CAT actually cheats using second-hop information? And naturally improve the expressiveness? Would it be more fair to compare CAT with two-layer GAT or GCN?",
                "Limitations": "The analysis in this paper is fundamental and provides good insights. However, the major limitation lies in the performance on the benchmark datasets. According to the theoretical results in this paper, L-CAT generalizes GCN and GAT and learns to trade off between these two architectures. However, the final performance on OGB shows even GCN outperforms L-CAT on two datasets. Moreover, current SOTA models faraway outperform GCN and GAT. Trading off between GCN and GAT seems not a key to improve the performance.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors propose a new graph neural network by combining existing graph convolution networks: GCNs and GAT. The authors proposed a new learnable convolutional attention layer (L-CAT), which subsumes the graph convolution in GCNs, the graph attention layer in GAT, and a normalized attention layer (CAT).",
                "Strengths And Weaknesses": "A new layer that subsumes a couple of popular graph convolution layers has been proposed. Without changing layers in GNNs, by optimizing parameters in the proposed layer, the proposed graph neural network can change its behavior. \nThis paper theoretically discussed the expressive power of GAT and the proposed layer CAT with a contextual stochastic block model (CSBM).",
                "Questions": "The experiments are somewhat obvious. The proposed method subsumes GCN, GAT, CAT. Then L-CAT must be on par with the models or outperform them.\nIn Table 1, L-CAT and CAT are comparable. The performance gain is marginal compared to GAT. Unless I missed something, both GCN and GAT are baselines of the proposed method.\nIn the literature, more powerful GNNs have been recently studied. Why do the authors compare their method with GCN?",
                "Limitations": "The proposed method is a simple generalized graph neural network that subsumes GCN and GAT layers. The simplicity of the proposed method is great as long as it has practical merits. However, the performance gain by the proposed method is marginal. In addition, the authors did not compare the proposed method with more recent works that exhibit stronger performance.\nThe proposed method is incremental, and the lack of generality of the proposed method makes the impact of this paper questionable.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This submissions has two parts of contribution. \nFirst, it proposes a novel attention mechanism for graph neural networks. The proposed technique first aggregates neighborhood features (as done in GCN) before computing the attention weights. This new method is named CAT. By a theoretical, analysis, the authors show that CAT can be more effective than GAT but their comparison depends on the graph topology. \nSecond, for a given layer, the submission proposes to learn two additional scalar weights that interpolates between GCN , GAT, the newly proposed CAT. The intuition here is that the network can discover the correct network type to use depends on the input data. \nOverall, I think the proposed method is novel and the theoretical analysis provides an interesting perspective. The empirical analysis shows that the proposed methods are more robust to data noise and weight initialization scheme. However, in the standard setting, the proposed method is mostly on-par with GCN (the comparison is not consistent across datasets). To take this empirical weakness into account, I am giving a weak accept.",
                "Strengths And Weaknesses": "Strength\n\nThe proposed method is novel\nThe proposed method is motivated by a theoretical analysis. I appreciate the effort to understand the proposed method.\nOn the empirical side, the proposed method is more robust to data noise and different initialize schemes\nThe writing is very clear\n\nWeakness\n\nFor the standard benchmarks, the proposed method is only on par with GCN, which is a simpler method. \nI provide more requests and suggestions for improving the current draft in the questions section below.",
                "Questions": "Questions:\n\nAs the authors acknowledged, many new variants of graph neural networks have been proposed. Can the authors include more baselines into comparison to contextualize the results better? I am especially interested in knowing how other baselines would react to the added feature noises. \nCan the theretical analysis  also be applied to L-cat? Similarly, how would L-CAT behave on the synthetic data in Figure 1?\nAnother form of data noise is corruption to the graph adjacency matrix. Does L-CAT also handle this form of corruption better?",
                "Limitations": "I do not see any negative societal impact.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "2 fair",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.0,
        "confidence_avg": 4.25,
        "soundness_avg": 3.25,
        "presentation_avg": 3.75,
        "contribution_avg": 2.5,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the proposed work is technically solid and has the potential for moderate-to-high impact. The combination of the \"isotropic\" GCN and \"anisotropic\"/attentional GNN in the proposed convolutional operation is well motivated and studied both methodologically and empirically. The authors have provided theoretical motivation and empirical validation for their claims, and the experiments are compared with appropriate GNN models. The paper is well structured and easy to follow.\n\nWhile there are some limitations and weaknesses pointed out by the reviewers, such as the performance on benchmark datasets not being as good as expected and the lack of comparison with more recent and powerful GNN models, these concerns do not outweigh the positive aspects of the work. The proposed method is novel and the theoretical analysis provides interesting insights. Additionally, the empirical analysis shows that the proposed method is more robust to data noise and weight initialization schemes.\n\nTherefore, based on the overall positive feedback and the confidence in the assessment, I recommend accepting the paper."
    },
    "Shielding_Federated_Learning:_Aligned_Dual_Gradient_Pruning_Against__Gradient_Leakage": {
        "link": "https://openreview.net//forum?id=Fjw_7Hv-mwB",
        "pub_url": "https://openreview.net/forum?id=Fjw_7Hv-mwB",
        "pdf_link": "https://openreview.net//pdf?id=Fjw_7Hv-mwB",
        "paper_id": "Fjw_7Hv-mwB",
        "title": "Shielding_Federated_Learning:_Aligned_Dual_Gradient_Pruning_Against__Gradient_Leakage",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Less certain\nThis paper proposes a method for defending against gradient inversion attacks.\nA gradient inversion attack attempts to reconstruct the training data from the model and its gradient.\nGradient inversion attacks have been performed in practice, which demonstrates that sharing gradients rather than raw data provides limited privacy protection.\nThe proposed method,\"Aligned Dual Gradient Pruning (ADGP),\" perturbs the gradients by zeroing out a large subset of the coordinates including both small and large values.\nThe key claim is that this prevents reconstruction of the training data.\nThe paper provides both theoretical and experimental results to support this claim.\nHowever, these results rely on implicit assumptions about the form of the gradient inversion attack. Specifically, they assume a vanilla gradient inversion attack that does not compensate for the ADGP defense. In particular, ADGP creates sparse gradients and it is assumed that the attacker attempts to reconstruct an input whose unperturbed gradient is sparse, even if the true unperturbed gradient is not sparse.\nThis assumption is a form of \"security through obscurity.\" We should assume that the attacker is aware of the defense and tailors the reconstruction to the defense. Thus theoretical/empirical evaluation should consider attacks that are designed specifically for ADGP.\nOverall, the key claim of the paper is not adequately supported (and, in my opinion, it seems likely that the proposed defense is not effective). Thus this paper should not be published.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper proposes Aligned Dual Gradient Pruning (ADGP) as a defense against gradient inversion attacks.\nA gradient inversion attack takes the gradient \u2207W(x) (and the model W) and attempts to reconstruct the input data x.\nStandard gradient pruning takes the gradient \u2207W(x) and zeroes out the smallest coordinates. Intuitively, this makes it harder for the attacker as they are not given as much information.\nDual Gradient Pruning (DGP) zeroes out not only the smallest coordinates but also the largest coordinates, leaving only the \"median\" coordinates of the gradient.\nADGP modifies DGP by ensuring that all the participants zero out a similar set of coordinates, rather that independently choosing which coordinates to zero out.\nThe paper provides both experimental and theoretical analysis of ADGP. It give theoretical results that bound the error of a potential attacker. And it also gives experimental results where attacks are run against ADGP. This includes a comparison to other defenses and a utility analysis.\nStrengths And Weaknesses: Strengths:\n\nThis paper studies an important problem.\nIt proposes a simple and novel approach to protecting against gradient inversion.\nBoth theoretical guarantees and empirical evaluation are included.\n\nWeaknesses:\n\nThe theoretical results are somewhat difficult to interpret. E.g. the parameters \u03b31 and \u03b32 from Assumption 1 appear in Theorem 1, but it is not clear what these parameters are and, hence, how to interpret the guarantee.\nThe experimental results do not consider varying the parameters k1 and k2, namely the number of large and small coordinates to zero out. Similarly the other defenses being compared against also have parameters that could be varied.\nSome details about the results are unclear (see below).\nQuestions: I have a question about the theoretical results (Proposition 1) and the experimental results (Figures 1 & 2).\nWhat is the optimization problem that the attacker is solving?\nAbusing notation slightly, I can see two possible ways to do this: First, arg\u2061minx\u2032\u2225\u2207W(x\u2032)\u2212ADGP(\u2207W(x))\u2225 and, second, arg\u2061minx\u2032\u2225ADGP(\u2207W(x\u2032))\u2212ADGP(\u2207W(x))\u2225.\nWhich of these two is being considered in the paper? or is it something else?\nIntuitively, my question is how does the attacker account for the ADGP defense?\nI also have a minor question about Definition 1. There is a nested probability and expectation. What is the source of randomness for each of these?\n\nThe discussion with the authors clarified the question about what optimization the attacker is performing, namely arg\u2061minx\u2032\u2225\u2207W(x\u2032)\u2212ADGP(\u2207W(x))\u2225. \nUnfortunately, this is the wrong way to formulate the problem. Intuitively, this assumes the attacker is not aware of the ADGP defence being used and applies a naive strategy. More precisely, the problem is that this objective is not minimized by x\u2032=x -- i.e., this objective does not lead to successful reconstruction.\nThis issue essentially invalidates the experimental and theoretical results. They assume a naive attacker and tell us nothing about what an attack tailored to this defence would do.\nIn the discussion I presented a simple counterexample to Theorem 1 in the paper. That is, the loss \u2113(w,x)=(x\u2212\u2211iwi)2, where x is a scalar and w is a vector. Given any single coordinate of the gradient and the value of w, it is possible to reconstruct x. ADGP does not protect against this attack.\nThe experimental results attempt \"state-of-the-art\" attacks. The problem is that an attack is tailored to a specific system. A state-of-the-art attack for one system may not be state of the art for another system.\nUnfortunately, given this major flaw, I think the paper cannot be accepted.\nLimitations: Limitations are discussed\nEthics Flag: No\nSoundness: 1 poor\nPresentation: 3 good\nContribution: 3 good\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper considers an important and timely problem in Federated Learning, investigating defense mechanism against model inversion attack in terms of three key metrics: privacy, utility, and communication efficiency. To provide better trade-off among the three key metrics, this paper firstly proposes a simple sparsification technique, named dual gradient pruning (DGP), which removes top-k1 largest values and bottom-k2 smallest values in local model parameters. In the second component, named gradient location bounding, communication cost is further reduced by ensuring that the sparsified region of different users are the same.\nThis paper theoretically shows that proposed scheme guarantees better privacy against model inversion attack. In addition, convergence analysis of the proposed method is provided with IID dataset distribution (i.e., local computation of each user is unbiased to the full gradient) and assumption on DGP.\nStrengths And Weaknesses: Overall, this paper is well structured and written, and hence easy to follow. Intuition behind the motivation of DGP/ADGP is well described in the section 4. While the proposed pruning technique is very simple, it can incur further research investigating privacy and utility trade-off in sparsification/pruning schemes in FL. Especially, combining sparsification and other defense mechanism (DP, secure aggregation, etc) would be very interesting future direction. It also includes extensive experiments with various attack models and defense mechanisms to demonstrate the stronger privacy guarantee and comparable utility of the proposed scheme. \nI have the following concern/comment:\n\nIn theoretical analysis, it seems that this paper relies on strong and unrealistic assumptions. This paper considers IID data distribution (i.e., in assumption 3, local stochastic computation is unbiased to the full gradient), which is not the case in FL. In addition, as the assumption 1 is very important for the analysis of convergence, more justification/explanation is needed. For instance, while k1 is an important parameter which determines the utility (and convergence performance), relationship between \\gamma_2 and k_1 is not presented. \n\nIn section 4, the role of e_i^t is not described. We can know that it is accumulated error of user i at round t in section 5 (after reading the lemma 1, but it is helpful to understand the proposed scheme if explanation will be included in section 4.\nQuestions: \n   How can we represent gamma_1 and gamma_2 with respect to k_1, k_2, and k?\n   In experiments, what is N (number of users), and how the dataset (CIFAR10/100) is distributed over N users?\nLimitations: As this paper considers the privacy in FL, it has no negative societal impact.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: \nThe paper proposes a defense against Gradient Inversion Attacks (where input images can be reconstructed by an attacker from the public gradients).\nThe crux of the proposed approach is (a) pruning gradients: where top-k1 and bottom-k2 parameters are pruned and (b) gradient-location bounding: such that users across FL prune similarly which results in sparsified models even at download-time.\nThe paper is also accompanied with theoretical insights validating the choices e.g., perturbed vs. non-perturbed gradients are proportional to reconstruction errors.\nThe defense approach is evaluated against three attacks (Rob, IVG, R-GAP) and two datasets (CIFAR10, CIFAR100). Evaluation indicates a performance improvement over existing defense against all attacks, while retaining the utility (efficiency, accuracy).\nStrengths And Weaknesses: Strengths\n\nInsight: The core insight is intuitive. Existing top-k approaches retains the top-k parameters and the authors show that this results in keeping the sparsified gradient close to the original and thereby increasing the attack effectiveness (Proposition 1). In contrast, the approach prunes the top-k gradients and thereby lowering the reconstruction performance.\nEvaluation: The authors benchmark the approach against multiple classes of GIA attacks (analytical, optimization-based, ...).\nResults: The results are significant and promising. The approach while almost perfectly retaining the target model accuracy (93.17 vs. 93.44) thwarts all considered classes of attacks.\n\nConcerns\n\nGradients attacked from which iteration?: The evaluation methodology is slightly unclear. Specifically, it is unclear the gradients from which training iteration is used to demonstrate system-under-attack performance. Are the authors aware whether this has an impact to attack performance? I reckon the gradients at the early training iterations are more\nChoice of attacks: While I appreciate the authors consider different classes of attacks, some recent popular attacks seem to have been left-out e.g., GradInversion [26]. Specifically, the class of optimization-based attacks which additionally regularize fidelity. \nSome evalution details unclear: While the paper indicates evaluation on 2x CIFAR10 models and CIFAR100, it is often not clear for which model/dataset the results are. For instance, the setting is unclear in Fig.1 and Table 2 (which I think is CIFAR10?), but Fig. 2a displays attacks on CIFAR100.\nQuestions: Please see the questions under concerns.\nLimitations: Yes, the authors have adequately discussed the limitations in the main paper.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: The paper proposes a new gradient pruning strategy called \"Aligned Dual Gradient Pruning\" for federated learning (FL). It differs from the standard pruning approach of top-k sparsification in two ways - (i) instead of retaining the top-k gradients, it removes both top-k1 and bottom-k2 gradients, thereby increasing the distance between the original gradients and the exchanged gradients, and (ii) one of the clients is allowed to broadcast the locations of its top-2k gradients, so that all the other clients can choose from this list of locations while picking the gradients to transmit.\nStrengths And Weaknesses: Strengths:\n\nA variant of the top-k gradient pruning strategy has been proposed to enhance robustness against gradient inversion attacks (GIAs). \nBoth theoretical results and experiments have been presented to demonstrate that the proposed method works.\n\nWeaknesses:\n\nIt is fairly obvious that if the top-k1 gradients are suppressed, it will lead to less information leakage compared to top-k sparsification. However, it is hard to believe that it will have no effect both on the convergence speed and final accuracy. Though the paper provides a theoretical result (Theorem 2) and experimental data (Table 2 and Figure 4), a concrete intuitive explanation of this unexpected behavior is required. Is this solely due to the error accumulation step? How will the proposed method behave if error accumulation is removed?\n\nThere is no mention about non-iid data in the whole paper. One would expect that the proposed alignment strategy will completely breakdown in the case of non-iid data, because there will be very few intersections between the top gradients of different clients. A careful analysis of this issue is clearly necessary.\n\nThe most critical weakness of the paper is the lack of any analysis about the privacy leakage introduced by the alignment step. Since one of the clients transmits the binary matrix I, it is trivial for the server to know the locations of the top 2k gradients of this client. Even if the client does not transmit the top-k1 gradient values, the server knows that locations with value 1 in I must have values greater than or comparable to that of the gradients that are actually transmitted by the client. Wouldn't this leak more information about the client's gradients compared to even the top-k sparsification strategy? Does any of the attack techniques considered in this paper exploit this knowledge?\n\nThere is no ablation study to evaluate the impact of the various components, especially alignment step and error accumulation step.\nQuestions: \nWhat is the contribution of the error accumulation step? How will the proposed method behave if error accumulation is removed?\n\nIf the server keeps an account of the gradients transmitted by the client in each round as well as the locations of the top-2k gradients, can the server recover almost the full gradient of the clients over a few rounds of communication?\n\nHow will the proposed alignment scheme work in the presence of non-iid data?\n\nWhat is the privacy impact of the alignment step? Will it leak more information than top-k sparsification since the server knows the locations of the top-2k gradients? Can more sophisticated attacks be designed leveraging this information?\n\nWhat is the impact of the hyperparameters (k1, k2, and k) on convergence, accuracy, and privacy?\nLimitations: The paper discusses one limitation related to the assumption that all the clients need to be honest for the proposed scheme to work. But it overestimates the privacy benefits of the proposed approach.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 3 good\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n",
            "Reviewer 5: \nSummary: This paper continues the research line of defending against data leakage in federated learning (FL). In particular, the paper argues against the conventional view that the top-k defenses do not work well, and proposed a simple modification, which is to also remove bottom gradients and then perform a calibration based on the accumulated error from the previous rounds to reduce communication cost. The paper compares the performance with five existing defenses on three existing attacks, and show that their method can achieve a better utility-privacy-communication tradeoff.\nStrengths And Weaknesses: Strengths\n\nImportant topic: the data leakage problem in FL is a practical concern\nThe method is simple and easy to implement\n\nWeaknesses\n\nThe theoretical part has several places that are unclear and questionable to me (see Questions section)\nThe evaluation section show some results that do not seem comparable (see Question section)\nQuestions: \nThe authors point out why top-k does not perform well: (1) top-k gradients are close to the real gradients and (2) large gradients leaks information of y. Both reasons only explain why top-k might be problematic, but how does removing bottom gradients address both problems? I do not find any insights that explain it, the only sentence I find that gives some justifications is \"Moreover, it is also necessary to delete small gradient parameters to achieve a high sparsification ratio.\" (Section 4.2), which only says deleting small gradients can make sparsification ratio higher. But deleting any gradients can further sparsify, why small gradients? Please clarify.\n\nDefinition 1: Change D(\u2207W,\u2207W\u2217) to D(\u2207W,\u2207W\u2217). Usually D(.,.) represents the distance and there is no need of subscripting.\n\nProposition 1\n\n\n\nFrom the supplementary material, \u03d5(x,W) is just \u2207W, you should define it explicitly in the main text. In addition, why write \u2207W twice in the right-hand side of the inequality but in different forms (in both numerator and denominator)?\nDefine g=\u03d5(x\u2032,W) (taken from the supplementary material) explicitly. Propositions should be self-contained.\nThe conclusion that \"reconstruction error is proportional to the gradient distance ||\u2207W\u2212g||2\" seems questionable to me because the denominator is not a constant. In fact, if I understand it correctly, the denominator is the 2nd derivative of W w.r.t x, i.e the Hessian norm, is it correct? If so, I do not see why the reconstruction error can be proportional to the numerator. Please let me know if I misunderstand it.\n\n\nAlgorithm 1: Where is the part that removes the bottom gradients Bk2(\u2207W)? It seems it only operates on the top gradients.\n\nAssumption 1: \u03b31 and \u03b32 are constants determined by k1, k2, and k. What are their explicit definitions? Please write them out because they are used in main theorems and lemmas and should not be undefined.\n\nTable 2\n\n\n\nThe comparison of DP with other defenses are not apple-to-apple because the DP accuracy is much lower. I notice the reason you choose that DP budget was because it has been shown the best in the prior work. But in this particular evaluation, if you do not tune the DP budget to find a comparable accuracy, the privacy protection performance comparison is not fair.\nIn R-GAP, the SSIM row, the best defense (\"Ours\") is not highlighted.\n\n\nIn general, the author should not make claims against the utility-privacy-communication tradeoff like \"none of the existing defense methods could take care of all privacy, utility, and efficiency difficulties in FL\" (taken from the introduction). Because there is a fundamental tradeoff and this paper (and maybe all papers) cannot remove the tradeoff. They can only make a better tradeoff but cannot make it go away. Therefore, I think it would be a more objective tone not to emphasize the tradeoff exists in the prior work (since it exists in any method) but rather the tradeoff is not good enough.\nLimitations: I do not have comments on the limitations.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 1 poor\nContribution: 1 poor\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 6: \nSummary: This paper introduces two techniques, Dual Gradient Pruning (DGP) and Aligned Dual Gradient Pruning (AGDP) to protect against gradient inversion attacks. They describe DGP and present ADGP as an improved version of DGP that has the same security considerations but lower communication costs. They show that optimization attacks have a provable amount of degeneration under DGP and ADGP. Then they empirically evaluate their technique against a set of gradient inversion attacks and compare against other defenses like DP-SGD, Soteria and Precode. The authors show that their ADGP technique succeeds against all the attacks they try while still maintaining model quality and reducing communication costs.\nStrengths And Weaknesses: Strengths\n\nThe authors present a very simple idea and run extensive experiments to show that their technique is superior to existing baselines\nDGP by itself seems like a new and somewhat unintuitive technique and the results from DGP would be a fairly strong contribution by itself.\nEmpirical evaluation and comparison with other techniques is very thorough. The authors compare against most of the well-known baselines and try multiple attacks. The details of the empirical evaluation are also clearly specified in the main text.\n\nWeaknesses\n\nAssumption 3 seems somewhat unrealistic. Assuming that each client in each round has data that provides an unbiased gradient means that the data has to be IID distributed across clients. \nADGP is presented as saving communication overhead but this overhead is only saved if the same set of clients are used for every round of FL training. If the clients selected for round N are different from those selected for round N+1 then ADGP does not save any communication overhead. In production FL settings, clients are often selected from a large population, so the odds of the same client appearing in two back-to-back rounds are low.\nThe authors only evaluate on vision models, but there are known gradient inversion attacks in NLP, speech etc. It would be interested to see if DGP works in those settings.\nQuestions: Does the analysis still hold if assumption 3 does not hold?\nDid you try your technique on domains other than vision?\nLimitations: Negative impacts are adequately addressed.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper proposes Aligned Dual Gradient Pruning (ADGP) as a defense against gradient inversion attacks.\nA gradient inversion attack takes the gradient \u2207W(x) (and the model W) and attempts to reconstruct the input data x.\nStandard gradient pruning takes the gradient \u2207W(x) and zeroes out the smallest coordinates. Intuitively, this makes it harder for the attacker as they are not given as much information.\nDual Gradient Pruning (DGP) zeroes out not only the smallest coordinates but also the largest coordinates, leaving only the \"median\" coordinates of the gradient.\nADGP modifies DGP by ensuring that all the participants zero out a similar set of coordinates, rather that independently choosing which coordinates to zero out.\nThe paper provides both experimental and theoretical analysis of ADGP. It give theoretical results that bound the error of a potential attacker. And it also gives experimental results where attacks are run against ADGP. This includes a comparison to other defenses and a utility analysis.",
                "Strengths And Weaknesses": "Strengths:\n\nThis paper studies an important problem.\nIt proposes a simple and novel approach to protecting against gradient inversion.\nBoth theoretical guarantees and empirical evaluation are included.\n\nWeaknesses:\n\nThe theoretical results are somewhat difficult to interpret. E.g. the parameters \u03b31 and \u03b32 from Assumption 1 appear in Theorem 1, but it is not clear what these parameters are and, hence, how to interpret the guarantee.\nThe experimental results do not consider varying the parameters k1 and k2, namely the number of large and small coordinates to zero out. Similarly the other defenses being compared against also have parameters that could be varied.\nSome details about the results are unclear (see below).",
                "Questions": "I have a question about the theoretical results (Proposition 1) and the experimental results (Figures 1 & 2).\nWhat is the optimization problem that the attacker is solving?\nAbusing notation slightly, I can see two possible ways to do this: First, arg\u2061minx\u2032\u2225\u2207W(x\u2032)\u2212ADGP(\u2207W(x))\u2225 and, second, arg\u2061minx\u2032\u2225ADGP(\u2207W(x\u2032))\u2212ADGP(\u2207W(x))\u2225.\nWhich of these two is being considered in the paper? or is it something else?\nIntuitively, my question is how does the attacker account for the ADGP defense?\nI also have a minor question about Definition 1. There is a nested probability and expectation. What is the source of randomness for each of these?\n\nThe discussion with the authors clarified the question about what optimization the attacker is performing, namely arg\u2061minx\u2032\u2225\u2207W(x\u2032)\u2212ADGP(\u2207W(x))\u2225. \nUnfortunately, this is the wrong way to formulate the problem. Intuitively, this assumes the attacker is not aware of the ADGP defence being used and applies a naive strategy. More precisely, the problem is that this objective is not minimized by x\u2032=x -- i.e., this objective does not lead to successful reconstruction.\nThis issue essentially invalidates the experimental and theoretical results. They assume a naive attacker and tell us nothing about what an attack tailored to this defence would do.\nIn the discussion I presented a simple counterexample to Theorem 1 in the paper. That is, the loss \u2113(w,x)=(x\u2212\u2211iwi)2, where x is a scalar and w is a vector. Given any single coordinate of the gradient and the value of w, it is possible to reconstruct x. ADGP does not protect against this attack.\nThe experimental results attempt \"state-of-the-art\" attacks. The problem is that an attack is tailored to a specific system. A state-of-the-art attack for one system may not be state of the art for another system.\nUnfortunately, given this major flaw, I think the paper cannot be accepted.",
                "Limitations": "Limitations are discussed",
                "Ethics Flag": "No",
                "Soundness": "1 poor",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper considers an important and timely problem in Federated Learning, investigating defense mechanism against model inversion attack in terms of three key metrics: privacy, utility, and communication efficiency. To provide better trade-off among the three key metrics, this paper firstly proposes a simple sparsification technique, named dual gradient pruning (DGP), which removes top-k1 largest values and bottom-k2 smallest values in local model parameters. In the second component, named gradient location bounding, communication cost is further reduced by ensuring that the sparsified region of different users are the same.\nThis paper theoretically shows that proposed scheme guarantees better privacy against model inversion attack. In addition, convergence analysis of the proposed method is provided with IID dataset distribution (i.e., local computation of each user is unbiased to the full gradient) and assumption on DGP.",
                "Strengths And Weaknesses": "Overall, this paper is well structured and written, and hence easy to follow. Intuition behind the motivation of DGP/ADGP is well described in the section 4. While the proposed pruning technique is very simple, it can incur further research investigating privacy and utility trade-off in sparsification/pruning schemes in FL. Especially, combining sparsification and other defense mechanism (DP, secure aggregation, etc) would be very interesting future direction. It also includes extensive experiments with various attack models and defense mechanisms to demonstrate the stronger privacy guarantee and comparable utility of the proposed scheme. \nI have the following concern/comment:\n\nIn theoretical analysis, it seems that this paper relies on strong and unrealistic assumptions. This paper considers IID data distribution (i.e., in assumption 3, local stochastic computation is unbiased to the full gradient), which is not the case in FL. In addition, as the assumption 1 is very important for the analysis of convergence, more justification/explanation is needed. For instance, while k1 is an important parameter which determines the utility (and convergence performance), relationship between \\gamma_2 and k_1 is not presented. \n\nIn section 4, the role of e_i^t is not described. We can know that it is accumulated error of user i at round t in section 5 (after reading the lemma 1, but it is helpful to understand the proposed scheme if explanation will be included in section 4.",
                "Questions": "How can we represent gamma_1 and gamma_2 with respect to k_1, k_2, and k?\n   In experiments, what is N (number of users), and how the dataset (CIFAR10/100) is distributed over N users?",
                "Limitations": "As this paper considers the privacy in FL, it has no negative societal impact.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper proposes a defense against Gradient Inversion Attacks (where input images can be reconstructed by an attacker from the public gradients).\nThe crux of the proposed approach is (a) pruning gradients: where top-k1 and bottom-k2 parameters are pruned and (b) gradient-location bounding: such that users across FL prune similarly which results in sparsified models even at download-time.\nThe paper is also accompanied with theoretical insights validating the choices e.g., perturbed vs. non-perturbed gradients are proportional to reconstruction errors.\nThe defense approach is evaluated against three attacks (Rob, IVG, R-GAP) and two datasets (CIFAR10, CIFAR100). Evaluation indicates a performance improvement over existing defense against all attacks, while retaining the utility (efficiency, accuracy).",
                "Strengths And Weaknesses": "Strengths\n\nInsight: The core insight is intuitive. Existing top-k approaches retains the top-k parameters and the authors show that this results in keeping the sparsified gradient close to the original and thereby increasing the attack effectiveness (Proposition 1). In contrast, the approach prunes the top-k gradients and thereby lowering the reconstruction performance.\nEvaluation: The authors benchmark the approach against multiple classes of GIA attacks (analytical, optimization-based, ...).\nResults: The results are significant and promising. The approach while almost perfectly retaining the target model accuracy (93.17 vs. 93.44) thwarts all considered classes of attacks.\n\nConcerns\n\nGradients attacked from which iteration?: The evaluation methodology is slightly unclear. Specifically, it is unclear the gradients from which training iteration is used to demonstrate system-under-attack performance. Are the authors aware whether this has an impact to attack performance? I reckon the gradients at the early training iterations are more\nChoice of attacks: While I appreciate the authors consider different classes of attacks, some recent popular attacks seem to have been left-out e.g., GradInversion [26]. Specifically, the class of optimization-based attacks which additionally regularize fidelity. \nSome evalution details unclear: While the paper indicates evaluation on 2x CIFAR10 models and CIFAR100, it is often not clear for which model/dataset the results are. For instance, the setting is unclear in Fig.1 and Table 2 (which I think is CIFAR10?), but Fig. 2a displays attacks on CIFAR100.",
                "Questions": "Please see the questions under concerns.",
                "Limitations": "Yes, the authors have adequately discussed the limitations in the main paper.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper proposes a new gradient pruning strategy called \"Aligned Dual Gradient Pruning\" for federated learning (FL). It differs from the standard pruning approach of top-k sparsification in two ways - (i) instead of retaining the top-k gradients, it removes both top-k1 and bottom-k2 gradients, thereby increasing the distance between the original gradients and the exchanged gradients, and (ii) one of the clients is allowed to broadcast the locations of its top-2k gradients, so that all the other clients can choose from this list of locations while picking the gradients to transmit.",
                "Strengths And Weaknesses": "Strengths:\n\nA variant of the top-k gradient pruning strategy has been proposed to enhance robustness against gradient inversion attacks (GIAs). \nBoth theoretical results and experiments have been presented to demonstrate that the proposed method works.\n\nWeaknesses:\n\nIt is fairly obvious that if the top-k1 gradients are suppressed, it will lead to less information leakage compared to top-k sparsification. However, it is hard to believe that it will have no effect both on the convergence speed and final accuracy. Though the paper provides a theoretical result (Theorem 2) and experimental data (Table 2 and Figure 4), a concrete intuitive explanation of this unexpected behavior is required. Is this solely due to the error accumulation step? How will the proposed method behave if error accumulation is removed?\n\nThere is no mention about non-iid data in the whole paper. One would expect that the proposed alignment strategy will completely breakdown in the case of non-iid data, because there will be very few intersections between the top gradients of different clients. A careful analysis of this issue is clearly necessary.\n\nThe most critical weakness of the paper is the lack of any analysis about the privacy leakage introduced by the alignment step. Since one of the clients transmits the binary matrix I, it is trivial for the server to know the locations of the top 2k gradients of this client. Even if the client does not transmit the top-k1 gradient values, the server knows that locations with value 1 in I must have values greater than or comparable to that of the gradients that are actually transmitted by the client. Wouldn't this leak more information about the client's gradients compared to even the top-k sparsification strategy? Does any of the attack techniques considered in this paper exploit this knowledge?\n\nThere is no ablation study to evaluate the impact of the various components, especially alignment step and error accumulation step.",
                "Questions": "What is the contribution of the error accumulation step? How will the proposed method behave if error accumulation is removed?\n\nIf the server keeps an account of the gradients transmitted by the client in each round as well as the locations of the top-2k gradients, can the server recover almost the full gradient of the clients over a few rounds of communication?\n\nHow will the proposed alignment scheme work in the presence of non-iid data?\n\nWhat is the privacy impact of the alignment step? Will it leak more information than top-k sparsification since the server knows the locations of the top-2k gradients? Can more sophisticated attacks be designed leveraging this information?\n\nWhat is the impact of the hyperparameters (k1, k2, and k) on convergence, accuracy, and privacy?",
                "Limitations": "The paper discusses one limitation related to the assumption that all the clients need to be honest for the proposed scheme to work. But it overestimates the privacy benefits of the proposed approach.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper continues the research line of defending against data leakage in federated learning (FL). In particular, the paper argues against the conventional view that the top-k defenses do not work well, and proposed a simple modification, which is to also remove bottom gradients and then perform a calibration based on the accumulated error from the previous rounds to reduce communication cost. The paper compares the performance with five existing defenses on three existing attacks, and show that their method can achieve a better utility-privacy-communication tradeoff.",
                "Strengths And Weaknesses": "Strengths\n\nImportant topic: the data leakage problem in FL is a practical concern\nThe method is simple and easy to implement\n\nWeaknesses\n\nThe theoretical part has several places that are unclear and questionable to me (see Questions section)\nThe evaluation section show some results that do not seem comparable (see Question section)",
                "Questions": "The authors point out why top-k does not perform well: (1) top-k gradients are close to the real gradients and (2) large gradients leaks information of y. Both reasons only explain why top-k might be problematic, but how does removing bottom gradients address both problems? I do not find any insights that explain it, the only sentence I find that gives some justifications is \"Moreover, it is also necessary to delete small gradient parameters to achieve a high sparsification ratio.\" (Section 4.2), which only says deleting small gradients can make sparsification ratio higher. But deleting any gradients can further sparsify, why small gradients? Please clarify.\n\nDefinition 1: Change D(\u2207W,\u2207W\u2217) to D(\u2207W,\u2207W\u2217). Usually D(.,.) represents the distance and there is no need of subscripting.\n\nProposition 1\n\n\n\nFrom the supplementary material, \u03d5(x,W) is just \u2207W, you should define it explicitly in the main text. In addition, why write \u2207W twice in the right-hand side of the inequality but in different forms (in both numerator and denominator)?\nDefine g=\u03d5(x\u2032,W) (taken from the supplementary material) explicitly. Propositions should be self-contained.\nThe conclusion that \"reconstruction error is proportional to the gradient distance ||\u2207W\u2212g||2\" seems questionable to me because the denominator is not a constant. In fact, if I understand it correctly, the denominator is the 2nd derivative of W w.r.t x, i.e the Hessian norm, is it correct? If so, I do not see why the reconstruction error can be proportional to the numerator. Please let me know if I misunderstand it.\n\n\nAlgorithm 1: Where is the part that removes the bottom gradients Bk2(\u2207W)? It seems it only operates on the top gradients.\n\nAssumption 1: \u03b31 and \u03b32 are constants determined by k1, k2, and k. What are their explicit definitions? Please write them out because they are used in main theorems and lemmas and should not be undefined.\n\nTable 2\n\n\n\nThe comparison of DP with other defenses are not apple-to-apple because the DP accuracy is much lower. I notice the reason you choose that DP budget was because it has been shown the best in the prior work. But in this particular evaluation, if you do not tune the DP budget to find a comparable accuracy, the privacy protection performance comparison is not fair.\nIn R-GAP, the SSIM row, the best defense (\"Ours\") is not highlighted.\n\n\nIn general, the author should not make claims against the utility-privacy-communication tradeoff like \"none of the existing defense methods could take care of all privacy, utility, and efficiency difficulties in FL\" (taken from the introduction). Because there is a fundamental tradeoff and this paper (and maybe all papers) cannot remove the tradeoff. They can only make a better tradeoff but cannot make it go away. Therefore, I think it would be a more objective tone not to emphasize the tradeoff exists in the prior work (since it exists in any method) but rather the tradeoff is not good enough.",
                "Limitations": "I do not have comments on the limitations.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "1 poor",
                "Contribution": "1 poor",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper introduces two techniques, Dual Gradient Pruning (DGP) and Aligned Dual Gradient Pruning (AGDP) to protect against gradient inversion attacks. They describe DGP and present ADGP as an improved version of DGP that has the same security considerations but lower communication costs. They show that optimization attacks have a provable amount of degeneration under DGP and ADGP. Then they empirically evaluate their technique against a set of gradient inversion attacks and compare against other defenses like DP-SGD, Soteria and Precode. The authors show that their ADGP technique succeeds against all the attacks they try while still maintaining model quality and reducing communication costs.",
                "Strengths And Weaknesses": "Strengths\n\nThe authors present a very simple idea and run extensive experiments to show that their technique is superior to existing baselines\nDGP by itself seems like a new and somewhat unintuitive technique and the results from DGP would be a fairly strong contribution by itself.\nEmpirical evaluation and comparison with other techniques is very thorough. The authors compare against most of the well-known baselines and try multiple attacks. The details of the empirical evaluation are also clearly specified in the main text.\n\nWeaknesses\n\nAssumption 3 seems somewhat unrealistic. Assuming that each client in each round has data that provides an unbiased gradient means that the data has to be IID distributed across clients. \nADGP is presented as saving communication overhead but this overhead is only saved if the same set of clients are used for every round of FL training. If the clients selected for round N are different from those selected for round N+1 then ADGP does not save any communication overhead. In production FL settings, clients are often selected from a large population, so the odds of the same client appearing in two back-to-back rounds are low.\nThe authors only evaluate on vision models, but there are known gradient inversion attacks in NLP, speech etc. It would be interested to see if DGP works in those settings.",
                "Questions": "Does the analysis still hold if assumption 3 does not hold?\nDid you try your technique on domains other than vision?",
                "Limitations": "Negative impacts are adequately addressed.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 4.5,
        "confidence_avg": 3.667,
        "soundness_avg": 2.167,
        "presentation_avg": 2.833,
        "contribution_avg": 2.5,
        "ai_sum_meta": "Recommendation: Reject\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that there are significant weaknesses and concerns with the paper. Reviewer 1 points out a major flaw in the experimental and theoretical results, which invalidates the claims made by the authors. Reviewer 2 raises concerns about the unrealistic assumptions and lack of justification for certain choices. Reviewer 3 also questions the theoretical analysis and the comparability of the evaluation results. Reviewer 4 highlights several weaknesses, including the lack of analysis on privacy leakage and the impact of hyperparameters. Reviewer 5 raises questions about the justification for removing bottom gradients and points out unclear and questionable aspects of the theoretical part. Reviewer 6 acknowledges the simplicity and thorough empirical evaluation of the proposed technique but raises concerns about unrealistic assumptions and the limited applicability of the technique to certain domains. Considering these concerns and weaknesses, it is recommended to reject the paper."
    },
    "AnoFormer:_Time_Series_Anomaly_Detection_using_Transformer-based_GAN_with_Two-Step_Masking": {
        "link": "https://openreview.net//forum?id=iAWNOXfLz0",
        "pub_url": "https://openreview.net/forum?id=iAWNOXfLz0",
        "pdf_link": "https://openreview.net//pdf?id=iAWNOXfLz0",
        "paper_id": "iAWNOXfLz0",
        "title": "AnoFormer:_Time_Series_Anomaly_Detection_using_Transformer-based_GAN_with_Two-Step_Masking",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nThis paper proposes a transformer-based GAN method and a two-step masking mechanism for time series anomaly detection. The proposed method is demonstrated on a variety of datasets. \nAfter rebuttals, both Reviewer 73J5 and Reviewer W6VQ remained negative. The main concern is the novelty and significance of the proposed method.",
        "reviews": [
            "Reviewer 1: \nSummary: The paper proposed a transformer-based generative model, named anoformer, to detect anomaly for time series in an unsupervised manner. Specifically, anoformer combined the Transformer model and the GAN model by adopting transformer-blocks as the generator and discriminator module of GAN. Besides, a two-step masking mechanism was designed to improve the model robustness. Through extensive experiments on 4 public datasets, including real-world and synthetic datasets, the superiority of anoformer was verified.\nStrengths And Weaknesses: Strengths:\n\nThis paper is easy to follow with some well-designed figure to visualize the key modules of the Anoformer framework. In particular, each key module of Anoformer is elaborated on in following sections.\nThe introduction and the related work section provide a clear and brief introduction of the transformer-based generative models and the difference between the Anoformer and SOTA models.\nThe two-step mask is designed to avoid the generator just copying the input as the output. Specifically, the mask pool in the random mask step provides different views of the input; the exclusive mask in the re-mask step makes the model consider all parts of the input; the entropy-base mask in the re-mask step makes the model consider the uncertain part.   \nThe extensive ablation experiment on different datasets verify the contribution of each key module of the Anoformer.\n\nWeakness:\n\nAnoformer detects anomaly based on the entire input or the subsequence of the input. The length of the input time series impacts the delay of the anomaly detection service.\nToo many hyper-parameters are introduced in different sections. A summary table of these parameters should be added for a better review experience.\nThe referred paper [30] was cited as both action recognition and text classification reference in line 81-82, while [30] only relates to action recognition.\nQuestions: please clarify the question below\n\nOne sample in this paper is the entire time series or the subsequence of the time series? If it is subsequence, how do you do the sub-sampling. \n\nWhether the Anoformer can provide the anomaly detection in a real-time manner ? Please states the computing complexity and execution speed information. \n\nThe formulation of the critic C is missing in the section 3.4, please further clarify it.\nLimitations: We have concerns on the following points:\n\nThe experiment section only introduces the F1-based metrices, while F1-score highly depends on the threshold. Other metrics, e.g., AUC, the complexity, the running time, should be added.\n\nIt is not very clear Anoformer provides the anomaly detection service on the data-point level or the time-series level? It will be great differences on performance and execution complexity.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper proposes a novel transformer-based GAN framework called AnoFormer for time series anomaly detection. In addition, the proposed model is enhanced by a two-step masking strategy consisting of 1) random masking and 2) entropy-based re-masking. The experimental results show the proposed AnoFormer achieves state-of-the-art performance on several benchmark datasets on time series anomaly detection.\nStrengths And Weaknesses: Strengths\n\nThe paper is easy to follow and well-organized.\nThe transformer-based GAN framework and the two-step masking strategy work well.\nThe performance gains are significant.\n\nWeaknesses\n\nLack of motivation. The paper only talks about how it is designed, while not elaborating clearly on why it is designed like this. E.g. Why do we make the input signal discrete instead of continuous? Why do we build the mask pool like this? Why do we re-mask 50% of parts masked in Step 1? Why the hyper-parameter \u03f5 is set to random?\nLack of novelty and related work. Actually, the transformer-based GAN framework for time series is not novel and has been proposed in [1], which is not cited and discussed in this paper. The related work section should be more specific (e.g. time series related or time series anomaly detection related literature). The baselines, such as BeatGAN[2], TadGAN[3], RAMED[4], and Anomaly Transformer[5], should be discussed in this section.\nSome notations and presentations are confusing. E.g. \u03f5 in Line 185, how it is randomly sampled, with uniform random or normal random? And what is PX\u2032 in Line 186?\nThe performance is good but codes are not provided.\n\n[1] Adversarial Sparse Transformer for Time Series Forecasting. NeurIPS 2020\n[2] BeatGAN: Anomalous Rhythm Detection using Adversarially Generated Time Series. IJCAI 2019\n[3] TadGAN: Time Series Anomaly Detection Using Generative Adversarial Networks. IEEE International Conference on Big Data 2020\n[4] Time Series Anomaly Detection with Multiresolution Ensemble Decoding. AAAI 2021\n[5] Anomaly Transformer: Time Series Anomaly Detection with Association Discrepancy.  ICLR 2022\nQuestions: Why do we make the input signal discrete instead of continuous?\nWhy do we build the mask pool like this?\nWhy do we re-mask 50% of parts masked in Step 1?\nWhy the hyper-parameter \u03f5 is set to random? What is the distribution PX\u2032 in Line 186?\nThe performance of the paper is attractive, however, considering the novelty and the unclear elaboration, I vote for borderline reject.\nLimitations: N/A\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper tackles the task of detecting and localizing anomalies in time series data. It follows a transformer approach where time series are automatically masked, then the transformer attempt to reconstruct the masked region. The reconstruction error is used as an anomaly score. A few technical tricks are incorporated such as using a GAN loss in training and an adaptive masking strategy. The method is evaluated on a few datasets and achieves better results than a set of deep learning approaches.\nStrengths And Weaknesses: Originality: The main premise of using inpainting as a task for reconstruction-based anomaly detection in not new (e.g. [1] but there are many). Nor is using a GAN discriminator (also found in [1]). The main difference here is using a transformer, the particular masking approach and the particular hyperparameter choices. This is an original contribution but a modest one. \nQuality: The method appears sound as far as it goes. The GAN ablation is somewhat worrisome as it appears to be useful only in a particular configuration and could be due to randomness in the data or a particular hyperparameter choice. However, the evaluation is not very convincing. The NeurIPS-TS datasets were generated by the authors, and are really easy. Note the original paper had classical baselines as doing much better than deep learning methods - but the original datasets were much smaller than the ones generated here. Also the other 3 benchmarks are not standard. It is not clear to me how they were selected. Also simple/classical baselines were not attempted. Several papers (e.g. NeurIPS-TS cited in this paper or [2]) have recently show that deep learning methods do not outperform classical baselines in many cases. Another issue I did not not see highlighted - the transformer + discretization approach might find it hard scale to multivariate time series (as the number of token to be predicted might expand by two orders of magnitude, in some cases). Although one of the benchmarks had 2 dimensions, it is not clear to me how this method would scale to standard benchmarks used by the deep learning time series AD community (SWaT, MSL, WADI etc.). \nClarity: The paper is well written, was a pleasure to read.\nSignificance: Due to the concerns mentioned above and the limited originality, I think this work is at risk of having low significance.   \n[1] Yan, Xudong, et al. \"Learning semantic context from normal samples for unsupervised anomaly detection.\" AAAI'21\n[2] Kim, Siwon, et al. \"Towards a rigorous evaluation of time-series anomaly detection.\" AAAI'22.\nQuestions: \nHow were the benchmark datasets chosen?\nHow do the classical benchmarks for NeurIPS-TS/[2] etc. perform?\nHow well does the method scale to multivariate TS (e.g. 100 dimensions)?\nLimitations: Some were discussed in the appendix. A few more were highlighted in the review. A more extensive discussion would have been helpful.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 4 excellent\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The paper proposed a transformer-based generative model, named anoformer, to detect anomaly for time series in an unsupervised manner. Specifically, anoformer combined the Transformer model and the GAN model by adopting transformer-blocks as the generator and discriminator module of GAN. Besides, a two-step masking mechanism was designed to improve the model robustness. Through extensive experiments on 4 public datasets, including real-world and synthetic datasets, the superiority of anoformer was verified.",
                "Strengths And Weaknesses": "Strengths:\n\nThis paper is easy to follow with some well-designed figure to visualize the key modules of the Anoformer framework. In particular, each key module of Anoformer is elaborated on in following sections.\nThe introduction and the related work section provide a clear and brief introduction of the transformer-based generative models and the difference between the Anoformer and SOTA models.\nThe two-step mask is designed to avoid the generator just copying the input as the output. Specifically, the mask pool in the random mask step provides different views of the input; the exclusive mask in the re-mask step makes the model consider all parts of the input; the entropy-base mask in the re-mask step makes the model consider the uncertain part.   \nThe extensive ablation experiment on different datasets verify the contribution of each key module of the Anoformer.\n\nWeakness:\n\nAnoformer detects anomaly based on the entire input or the subsequence of the input. The length of the input time series impacts the delay of the anomaly detection service.\nToo many hyper-parameters are introduced in different sections. A summary table of these parameters should be added for a better review experience.\nThe referred paper [30] was cited as both action recognition and text classification reference in line 81-82, while [30] only relates to action recognition.",
                "Questions": "please clarify the question below\n\nOne sample in this paper is the entire time series or the subsequence of the time series? If it is subsequence, how do you do the sub-sampling. \n\nWhether the Anoformer can provide the anomaly detection in a real-time manner ? Please states the computing complexity and execution speed information. \n\nThe formulation of the critic C is missing in the section 3.4, please further clarify it.",
                "Limitations": "We have concerns on the following points:\n\nThe experiment section only introduces the F1-based metrices, while F1-score highly depends on the threshold. Other metrics, e.g., AUC, the complexity, the running time, should be added.\n\nIt is not very clear Anoformer provides the anomaly detection service on the data-point level or the time-series level? It will be great differences on performance and execution complexity.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper proposes a novel transformer-based GAN framework called AnoFormer for time series anomaly detection. In addition, the proposed model is enhanced by a two-step masking strategy consisting of 1) random masking and 2) entropy-based re-masking. The experimental results show the proposed AnoFormer achieves state-of-the-art performance on several benchmark datasets on time series anomaly detection.",
                "Strengths And Weaknesses": "Strengths\n\nThe paper is easy to follow and well-organized.\nThe transformer-based GAN framework and the two-step masking strategy work well.\nThe performance gains are significant.\n\nWeaknesses\n\nLack of motivation. The paper only talks about how it is designed, while not elaborating clearly on why it is designed like this. E.g. Why do we make the input signal discrete instead of continuous? Why do we build the mask pool like this? Why do we re-mask 50% of parts masked in Step 1? Why the hyper-parameter \u03f5 is set to random?\nLack of novelty and related work. Actually, the transformer-based GAN framework for time series is not novel and has been proposed in [1], which is not cited and discussed in this paper. The related work section should be more specific (e.g. time series related or time series anomaly detection related literature). The baselines, such as BeatGAN[2], TadGAN[3], RAMED[4], and Anomaly Transformer[5], should be discussed in this section.\nSome notations and presentations are confusing. E.g. \u03f5 in Line 185, how it is randomly sampled, with uniform random or normal random? And what is PX\u2032 in Line 186?\nThe performance is good but codes are not provided.\n\n[1] Adversarial Sparse Transformer for Time Series Forecasting. NeurIPS 2020\n[2] BeatGAN: Anomalous Rhythm Detection using Adversarially Generated Time Series. IJCAI 2019\n[3] TadGAN: Time Series Anomaly Detection Using Generative Adversarial Networks. IEEE International Conference on Big Data 2020\n[4] Time Series Anomaly Detection with Multiresolution Ensemble Decoding. AAAI 2021\n[5] Anomaly Transformer: Time Series Anomaly Detection with Association Discrepancy.  ICLR 2022",
                "Questions": "Why do we make the input signal discrete instead of continuous?\nWhy do we build the mask pool like this?\nWhy do we re-mask 50% of parts masked in Step 1?\nWhy the hyper-parameter \u03f5 is set to random? What is the distribution PX\u2032 in Line 186?\nThe performance of the paper is attractive, however, considering the novelty and the unclear elaboration, I vote for borderline reject.",
                "Limitations": "N/A",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper tackles the task of detecting and localizing anomalies in time series data. It follows a transformer approach where time series are automatically masked, then the transformer attempt to reconstruct the masked region. The reconstruction error is used as an anomaly score. A few technical tricks are incorporated such as using a GAN loss in training and an adaptive masking strategy. The method is evaluated on a few datasets and achieves better results than a set of deep learning approaches.",
                "Strengths And Weaknesses": "Originality: The main premise of using inpainting as a task for reconstruction-based anomaly detection in not new (e.g. [1] but there are many). Nor is using a GAN discriminator (also found in [1]). The main difference here is using a transformer, the particular masking approach and the particular hyperparameter choices. This is an original contribution but a modest one. \nQuality: The method appears sound as far as it goes. The GAN ablation is somewhat worrisome as it appears to be useful only in a particular configuration and could be due to randomness in the data or a particular hyperparameter choice. However, the evaluation is not very convincing. The NeurIPS-TS datasets were generated by the authors, and are really easy. Note the original paper had classical baselines as doing much better than deep learning methods - but the original datasets were much smaller than the ones generated here. Also the other 3 benchmarks are not standard. It is not clear to me how they were selected. Also simple/classical baselines were not attempted. Several papers (e.g. NeurIPS-TS cited in this paper or [2]) have recently show that deep learning methods do not outperform classical baselines in many cases. Another issue I did not not see highlighted - the transformer + discretization approach might find it hard scale to multivariate time series (as the number of token to be predicted might expand by two orders of magnitude, in some cases). Although one of the benchmarks had 2 dimensions, it is not clear to me how this method would scale to standard benchmarks used by the deep learning time series AD community (SWaT, MSL, WADI etc.). \nClarity: The paper is well written, was a pleasure to read.\nSignificance: Due to the concerns mentioned above and the limited originality, I think this work is at risk of having low significance.   \n[1] Yan, Xudong, et al. \"Learning semantic context from normal samples for unsupervised anomaly detection.\" AAAI'21\n[2] Kim, Siwon, et al. \"Towards a rigorous evaluation of time-series anomaly detection.\" AAAI'22.",
                "Questions": "How were the benchmark datasets chosen?\nHow do the classical benchmarks for NeurIPS-TS/[2] etc. perform?\nHow well does the method scale to multivariate TS (e.g. 100 dimensions)?",
                "Limitations": "Some were discussed in the appendix. A few more were highlighted in the review. A more extensive discussion would have been helpful.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "4 excellent",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 4.0,
        "confidence_avg": 4.333,
        "soundness_avg": 2.333,
        "presentation_avg": 3.0,
        "contribution_avg": 2.667,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the paper proposes a novel transformer-based generative model, named Anoformer, for unsupervised anomaly detection in time series data. The paper is well-organized and easy to follow, with clear explanations of the key modules of the Anoformer framework. The two-step masking mechanism is designed to improve the model's robustness, and extensive experiments on multiple datasets demonstrate the superiority of Anoformer compared to state-of-the-art models.\n\nWhile there are some weaknesses pointed out by the reviewers, such as the impact of input length on anomaly detection delay and the presence of too many hyperparameters, these weaknesses do not outweigh the strengths of the paper. The reviewers also raise some questions regarding the sub-sampling of subsequences, real-time anomaly detection, and the formulation of the critic C, which could be addressed in the final version of the paper.\n\nOverall, the paper presents a technically solid contribution with good evaluation results. The novelty of the proposed model, combined with its performance gains, justifies accepting the paper for publication."
    },
    "A_Simple_Contrastive_Learning_Objective_for_Alleviating_Neural_Text_Degeneration": {
        "link": "https://openreview.net//forum?id=5zwnqUwphT",
        "pub_url": "https://openreview.net/forum?id=5zwnqUwphT",
        "pdf_link": "https://openreview.net//pdf?id=5zwnqUwphT",
        "paper_id": "5zwnqUwphT",
        "title": "A_Simple_Contrastive_Learning_Objective_for_Alleviating_Neural_Text_Degeneration",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nThe paper proposes a simple contrastive objective punishing the degeneration in the text generation. There is an agreement in the reviewers that the method itself is somewhat incremental and lacks very clear justification. It could be seen as a straight-forward extension to the SimCTG algorithm and there have been a handful of publications in the field. I therefore do not recommend acceptance of this paper to NeurIPS.",
        "reviews": [
            "Reviewer 1: \nSummary: This work proposes contrastive token learning in order to alleviate the degeneration problem in text generation tasks. In addition to the conventional token-wise cross entropy loss, the loss penalizes negative tokens in the similar manner as done in cross entropy loss, but sum  over negative tokens and the true token in the denominator. The negative tokens are chosen from the past history in a window but allowing duplicates by changing from a set to a multiset. Experiments are carried out on language modeling and dialogue generation tasks and the proposed method achieves lower repetition rates with more distinctive outputs preserving comparable perplexities when compared with SOTA baselines.\nStrengths And Weaknesses: Strengths\n\nThe proposed method based on the unlikelihood training by penalizing negative tokens, but employs contrastive loss for softly penalizing negative tokens. The idea is simple yet sound.\nThe use of tokens in a window and multiset sounds the major contribution in this work.\nExperiments are well designed and the effectiveness is demonstrated by the systematic comparison. Analysis is also convincing both qualitatively and quantitatively.\n\nWeaknesses\n\nOne of the main contributions is the carefully designed negative token set and the set could be easily employed in other approaches, e.g., UT and SimCTG. I'd like to see the comparisons with those SOTA approaches with the proposed negative token set.\nQuestions: None\nLimitations: \nCurrently, the proposed approach is experimented on language modeling and dialogue generation, but it is not clear whether the approach is also effective to conditional language model setting.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper introduces a simple contrastive objective for text generation models to alleviate text degeneration. The proposed objective contrasts the ground-truth tokens with the negative tokens (previous M context tokens), thus suppressing the model from generating those tokens during inference. Empirical results show the proposed approach can reduce the repetition significantly.\nStrengths And Weaknesses: Strengths\n\nThe proposed approach is simple and intuitive.\nThe proposed approach effectively reduces the repetition in the generated text.\nThe analysis is extensive and interesting.\n\nWeaknesses\n\nSome confusion about the description.\nThe authors keep claiming that Unlikelihood training (UL) does not consider the relationship between the label tokens and unlikely tokens but they never give details about how the proposed approach (CT) considers this.\nI don't understand why UL does not contrast the negative tokens to other tokens. Essentially we are looking at the probability distribution. So when the probabilities for negative tokens are reduced because of UL, the probabilities for other tokens are relatively boosted compared to negative tokens. Is this not considered as contrastive?\nThe authors claim that the fact that UL considers all the previous context tokens as negative tokens introduces too much noise and results in sub-optimal repetition reduction. However, in the proposed approach, the same strategy is used to define negative tokens with the exception of an additional window of size M, which I believe can be applied to UL directly. And how is this not sub-optimal compared to UL?\nThe main intuition in this work is to dynamically promote/suppress tokens based on three categories (positive, negative, and irrelevant). Similar stuff has been observed in existing work [1] and it is very relevant to this work. The author should at least discuss this regard.\n\n\nExperiments\nHyper-parameters. How is the hyper-parameter used in UL? Apparently, if UL is applied more aggressively, the repetition could be reduced more obviously although the ppl could be harmed. However, there is no any description of the hyper-parameter choice of UL. Similarly, I cannot really agree with the claim that the CT outperforms the top-k/p in terms of reducing repetition. Once a larger value of k or p is used, the repetition is almost guaranteed to be reduced. But here again, no different values of k and p are considered. \nI disagree with the claim that CT even outperforms humans according to rep-* and unique token counts. The repetition is not always the less the better, and the number of unique tokens is not always the more the better, as the good text requires a certain level of repetition to retain the coherence.\nHuman evaluation. Human evaluation is somewhat biased and subjective. Even major vote is used, it will be more convincing to report some correlation between humans.\n\n\nLine 265: analyses --> analysis\n\n[1] Lin et al., \"Straight to the Gradient: Learning to Use Novel Tokens for Neural Text Generation\"\nQuestions: \nIn figure 3, I wonder what would UL-T look like? And do you think the uncertainty in the later steps can be solved by introducing M to UL?\nLimitations: Yes\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper propose a learning-based method for alleviating the problem of text degeneration.  The proposed method is simple. I combines unlikelihood training and contrastive learning.  The training objective is to promote label tokens while suppressing preceding tokens. Experimental results show that the proposed method can reduce repetitions in generated text.\nStrengths And Weaknesses: Strengths: \n\nThe method is simple.\nThe experiments are elaborate.\nThe proposed method seems effective in reducing repetitions.\n\nWeaknesses: \n\nThe idea to penalize any repetitions in a short window is somewhat problematic. Some repetitions are reasonable in human-generated text. I think the critical question is how to properly construct the negative token set.\nThe analysis of experimental results is problematic. For rep-1/2/3/4, dist-1, uniq-1, I think the best results should be the ones that are closest to human-generated text. Like the above, humans generate repetitions naturally. NOT all repetitions are evil.\nQuestions: My major concern: for rep-1/2/3/4, dist-1, uniq-1, I think the best results should be the ones that are closest to human-generated text. if so, you have to redo the analysis of experiment results.\nLimitations: n/a\nEthics Flag: No\nSoundness: 1 poor\nPresentation: 3 good\nContribution: 3 good\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This work proposes contrastive token learning in order to alleviate the degeneration problem in text generation tasks. In addition to the conventional token-wise cross entropy loss, the loss penalizes negative tokens in the similar manner as done in cross entropy loss, but sum  over negative tokens and the true token in the denominator. The negative tokens are chosen from the past history in a window but allowing duplicates by changing from a set to a multiset. Experiments are carried out on language modeling and dialogue generation tasks and the proposed method achieves lower repetition rates with more distinctive outputs preserving comparable perplexities when compared with SOTA baselines.",
                "Strengths And Weaknesses": "Strengths\n\nThe proposed method based on the unlikelihood training by penalizing negative tokens, but employs contrastive loss for softly penalizing negative tokens. The idea is simple yet sound.\nThe use of tokens in a window and multiset sounds the major contribution in this work.\nExperiments are well designed and the effectiveness is demonstrated by the systematic comparison. Analysis is also convincing both qualitatively and quantitatively.\n\nWeaknesses\n\nOne of the main contributions is the carefully designed negative token set and the set could be easily employed in other approaches, e.g., UT and SimCTG. I'd like to see the comparisons with those SOTA approaches with the proposed negative token set.",
                "Questions": "None",
                "Limitations": "Currently, the proposed approach is experimented on language modeling and dialogue generation, but it is not clear whether the approach is also effective to conditional language model setting.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper introduces a simple contrastive objective for text generation models to alleviate text degeneration. The proposed objective contrasts the ground-truth tokens with the negative tokens (previous M context tokens), thus suppressing the model from generating those tokens during inference. Empirical results show the proposed approach can reduce the repetition significantly.",
                "Strengths And Weaknesses": "Strengths\n\nThe proposed approach is simple and intuitive.\nThe proposed approach effectively reduces the repetition in the generated text.\nThe analysis is extensive and interesting.\n\nWeaknesses\n\nSome confusion about the description.\nThe authors keep claiming that Unlikelihood training (UL) does not consider the relationship between the label tokens and unlikely tokens but they never give details about how the proposed approach (CT) considers this.\nI don't understand why UL does not contrast the negative tokens to other tokens. Essentially we are looking at the probability distribution. So when the probabilities for negative tokens are reduced because of UL, the probabilities for other tokens are relatively boosted compared to negative tokens. Is this not considered as contrastive?\nThe authors claim that the fact that UL considers all the previous context tokens as negative tokens introduces too much noise and results in sub-optimal repetition reduction. However, in the proposed approach, the same strategy is used to define negative tokens with the exception of an additional window of size M, which I believe can be applied to UL directly. And how is this not sub-optimal compared to UL?\nThe main intuition in this work is to dynamically promote/suppress tokens based on three categories (positive, negative, and irrelevant). Similar stuff has been observed in existing work [1] and it is very relevant to this work. The author should at least discuss this regard.\n\n\nExperiments\nHyper-parameters. How is the hyper-parameter used in UL? Apparently, if UL is applied more aggressively, the repetition could be reduced more obviously although the ppl could be harmed. However, there is no any description of the hyper-parameter choice of UL. Similarly, I cannot really agree with the claim that the CT outperforms the top-k/p in terms of reducing repetition. Once a larger value of k or p is used, the repetition is almost guaranteed to be reduced. But here again, no different values of k and p are considered. \nI disagree with the claim that CT even outperforms humans according to rep-* and unique token counts. The repetition is not always the less the better, and the number of unique tokens is not always the more the better, as the good text requires a certain level of repetition to retain the coherence.\nHuman evaluation. Human evaluation is somewhat biased and subjective. Even major vote is used, it will be more convincing to report some correlation between humans.\n\n\nLine 265: analyses --> analysis\n\n[1] Lin et al., \"Straight to the Gradient: Learning to Use Novel Tokens for Neural Text Generation\"",
                "Questions": "In figure 3, I wonder what would UL-T look like? And do you think the uncertainty in the later steps can be solved by introducing M to UL?",
                "Limitations": "Yes",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper propose a learning-based method for alleviating the problem of text degeneration.  The proposed method is simple. I combines unlikelihood training and contrastive learning.  The training objective is to promote label tokens while suppressing preceding tokens. Experimental results show that the proposed method can reduce repetitions in generated text.",
                "Strengths And Weaknesses": "Strengths: \n\nThe method is simple.\nThe experiments are elaborate.\nThe proposed method seems effective in reducing repetitions.\n\nWeaknesses: \n\nThe idea to penalize any repetitions in a short window is somewhat problematic. Some repetitions are reasonable in human-generated text. I think the critical question is how to properly construct the negative token set.\nThe analysis of experimental results is problematic. For rep-1/2/3/4, dist-1, uniq-1, I think the best results should be the ones that are closest to human-generated text. Like the above, humans generate repetitions naturally. NOT all repetitions are evil.",
                "Questions": "My major concern: for rep-1/2/3/4, dist-1, uniq-1, I think the best results should be the ones that are closest to human-generated text. if so, you have to redo the analysis of experiment results.",
                "Limitations": "n/a",
                "Ethics Flag": "No",
                "Soundness": "1 poor",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 4.333,
        "confidence_avg": 4.333,
        "soundness_avg": 2.333,
        "presentation_avg": 2.667,
        "contribution_avg": 3.0,
        "ai_sum_meta": "Recommendation: Reject\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the proposed method in this paper has some strengths. Reviewer 1 and Reviewer 2 both highlight the simplicity and effectiveness of the approach in reducing repetition in generated text. The experiments are well-designed and the analysis is convincing. However, there are also some weaknesses pointed out by the reviewers.\n\nReviewer 1 suggests comparing the proposed negative token set with other state-of-the-art approaches. This comparison would provide a better understanding of the contribution of the proposed method. Reviewer 2 raises several questions and confusions about the description of the approach, particularly regarding the contrastive nature of the unlikelihood training and the choice of hyperparameters. Additionally, Reviewer 2 questions the claim that the proposed method outperforms humans in terms of repetition and unique token counts, emphasizing that some level of repetition is necessary for coherence in text generation.\n\nReviewer 3 also expresses concerns about the negative token set construction and the analysis of experimental results. They argue that not all repetitions are undesirable in human-generated text and suggest reevaluating the analysis to consider results that are closest to human-generated text.\n\nConsidering these weaknesses and concerns, I agree with the reviewers' recommendation to reject the paper. While the proposed method shows promise in reducing repetition, the issues raised by the reviewers regarding the comparison with other approaches, the clarity of the description, the choice of hyperparameters, and the analysis of results need to be addressed before the paper can be accepted."
    },
    "Bridging_Implicit_and_Explicit_Geometric_Transformations_for_Single-Image_View_Synthesis": {
        "link": "https://openreview.net//forum?id=x4JZ3xX5mtv",
        "pub_url": "https://openreview.net/forum?id=x4JZ3xX5mtv",
        "pdf_link": "https://openreview.net//pdf?id=x4JZ3xX5mtv",
        "paper_id": "x4JZ3xX5mtv",
        "title": "Bridging_Implicit_and_Explicit_Geometric_Transformations_for_Single-Image_View_Synthesis",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nThe reviewers found the approach of combining implicit and explicit methods for single-view synthesis both interesting and novel. All four reviewers recommended accepting the paper. You addressed many of the remaining questions/concerns in your rebuttal and in the author-reviewer discussion. Please, go through the reviews once more and make sure you have included the changes in the final version of the paper.\nUpdate: given the extent of revisions required, we agreed that this would require another full evaluation of the paper due to the substantial changes that would need to be made to this paper. We hope that the rebuttal would help to guide subsequent submissions of this manuscript",
        "reviews": [
            "Reviewer 1: \nSummary: This paper studies the task of single image novel view synthesis. The key message is very clear. Methods with explicit 3D projection mechanism, like SynSin, better preserve observed regions, whereas methods with implicit renderer, like GeoFree, do better at outpainting (synthesizing unseen regions). And using both of them in the same framework can complement and reinforce each other and get the best of both worlds.\nThe paper does a very good job at conveying this message, and presents promising results on both indoor and outdoor datasets to demonstrate the benefit of this joint approach.\nStrengths And Weaknesses: Strengths\nS1 - Message is clear and makes a lot sense\n\nThe paper delivers the motivation of using both implicit and explicit rendering in single image NVS in a very clear and concise manner.\nThe benefits of both worlds can be maintained by defining losses that use the better one to guide the other, ie, features from the explicit branch will guide the ones from implicit branch in observed regions, with the gradient of the former being detached, and the other way around in unobserved regions.\nThe resulting model seems to overcome the shortcomings of both approaches, as shown in the comparison results.\n\nS2 - Clear and concise writing\n\nI enjoy reading the paper. It's very clear and coherent.\n\nWeaknesses\nW1 - Results are still a bit unsatisfactory\n\nFirst, I was expecting more qualitative comparisons in the supplementary material. There are only four examples shown. They're all good examples with large viewpoint changes. But showing more diverse results will be helpful.\nBased on the limited comparisons provided, it does not seem that the proposed method can fully preserve the benefits of both implicit and explicit methods. The quality of both observed and unobserved (outpainted) regions seems to be slightly compromised.\nObserved regions do not seem to be preserved very well, seemingly worse than SynSin and PixelSynth on indoor scenes. I think neither of them has been trained on images of outdoor scenery, so I'm not surprised they both fail on scenery images. The PSNR is also worse than SynSin with larger viewpoint changes.\nOutpainted regions also appear worse than GeoFree, although the latter uses an autoregressive framework.\nThere seem to be obvious artifacts in the synthesized images, eg the center of the generated image in second row of Fig 4 (dinning table).\n\n\nAre the PSNR computed only on the seen pixels or on the entire image? Reporting both numbers will resolve the question in 1.\nHave the compared models been finetuned on the same dataset? If not, I do not think the comparison is fair.\n\nMinor comments\n\nLine 116: I suppose f0 has a larger channel dimension than input image Iref. Use different symbols for their channel dimensions.\nQuestions: \nReport PSNR both only on seen pixels and on the entire image, if it's manageable during the rebuttal.\nFinetune the models of the previous methods on the same dataset, if this is not done currently.\nShow more diverse visual comparisons, maybe in the final version.\nLimitations: The paper includes a brief discussion on the limitations. The current quality of the results are still quite limited. It would be helpful to provide some failure examples if any.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 4 excellent\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: There are two main paradigms in the task of single-image view synthesis. The explicit methods use the explicit 3D geometry and thus achieve good results on the reprojected pixels, while the implicit methods leverage implicit 3D inductive bias to implicitly learn the 3D geometry and could complete realistic out-of-view image regions. However, none of them can reach both goals. To mitigate such a seesaw problem, this paper bridges both implicit and explicit geometric transformations in a unified framework. Besides, a novel loss is proposed to fuse the geometry features from implicit and explicit branches. The proposed method can render state-of-the-art results on the novel views and achieve about 100x speedup in rendering compared to implicit autoregressive models.\nStrengths And Weaknesses: Pros:\n\nCombining the explicit and implicit geometry features in a unified framework is a reasonable and straightforward idea. Since explicit 3D geometry can preserve reprojected image areas and implicit 3D geometry helps to complete out-of-view regions. Meanwhile, the experiments on RealEstate10K and ACID datasets prove the effectiveness of such a combination.\nThe whole paper is succinct and easy to follow.\nThe ablation study in Sec. 4.3 & 4.4 demonstrates the necessity of the proposed Transformation Similarity Loss.\n\nCons:\n\nFrom the main quantitative results in Table 2, the proposed method only shows superiority in terms of the FID metric. Although using both explicit and implicit geometric transformations, this method still works worse than SynSin. It seems that this method doesn't solve the aforementioned trade-off. For the lower FID score, this method just equips with a better imagination ability, which may be boosted with a more powerful adversarial loss. In lines 164~166, the authors mention they use a new GAN loss. How about the performance of SynSin + this new loss? Such a very important ablation study is not included in this manuscript.\nThe paper only provides the results on RealEstate10k and ACID datasets. How about the results on Matterport3D?\nGiven the better performance on the FID score, this method should compare with another two crucial baselines, Infinite Nature and Look Outside Room. I notice the authors' clarification in the supp. material. If available, the performance comparisons must be provided.\nQuestions: In this manuscript, experiments are not comprehensive. Please refer to the questions proposed in the weaknesses.\nLimitations: \nThe idea is a little bit straightforward, just like a simple combination of A and B.\nExperiments are not comprehensive and not enough to demonstrate the effectiveness of the proposed method.\nSome confusing sentences inside:\n\n\nLines 50 ~ 51: Our approach consists of architecture and loss functions.\nLines 159 ~ 160: ... generating photo-realistic images. What's the relationship between rendering speed and image quality. The emphasis on \"photo-realistic\" is unnecessary.\nLine 48: application area -> application areas\n...\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper proposes a new method for single-image view synthesis. The authors point out that existing methods are faced with a \"seesaw\" problem, i.e., a trade-off between preserving observed contents and synthesizing out-of-view regions. To address this issue, the authors propose a method that shares the advantages of both explicit and implicit geometric transformations, where the former is good at preserving existing contents while the latter is good at synthesizing out-of-view contents. A transformation similarity loss is proposed, which motivates the explicitly rendered feature and implicitly rendered feature to learn the best from each other. The pipeline is a feed-forward model without an autoregressive module, thus significantly faster than other autoregressive models. Experiments on two datasets show that the proposed method achieves obvious improvements over other implicit or explicit baselines both qualitatively and quantitatively. Ablation studies are carefully conducted to verify the effectiveness of the proposed transformation similarity loss and the dependency between explicit and implicit renderers.\nStrengths And Weaknesses: Strengths:\n\nThis paper points out the trade-off between explicit and implicit geometric transformation-based methods, and proposes a hybrid model that integrates the best of both, which is new and reasonable. The synergy effects of explicit and implicit renderers are well demonstrated in experiments.  \n\nThe proposed transformation similarity loss is novel to me. Its effectiveness is clearly verified in Tab.4 and Fig.5, which shows that it helps the explicitly rendered feature and implicitly rendered feature to benefit from each other.  \n\nThe proposed method shows clear improvements over other baseline approaches in quantitative and qualitative evaluations. Results in Fig.4 show that it better preserves existing contents and synthesizes out-of-view contents.\n\n\nWeaknesses:\n\nI feel that the \"seesaw\" problem is somewhat exaggerated. In my humble opinion, a simpler and more straightforward way to solve this problem is to reproject or warp existing pixels to the target view based on the depth, and then use a generative model to synthesize the out-of-view pixels conditioned on the warped pixels, like inpainting. In this way, it naturally preserve existing contents and synthesize out-of-view contents. InfiniteNature [23] is designed in this way but is not compared. If this design can address the \"seesaw\" problem, then the contribution of this work is not strong. Otherwise, the authors should add some discussion to explain why.   \n\nFollowing the previous point, the authors mentioned in the supplementary that InfiniteNature [23] is not compared because the training code is not available. However, to my knowledge, the testing code is already available online and comparison is possible. For example, even GeoFree [40] compares with InfiniteNature. I suggest adding InfiniteNature (or a warp+inpainting method) as a baseline if there is no strong reason why this cannot be done.  \n\nIf explicitly rendered feature and implicitly rendered feature are complementary, then why not just manually fuse the two features according to the out-of-view mask or send the mask as an additional input to the final decoder so that the decoder can learn to fuse them?  In this case, the two features do not have to mimic each other. Thus, I doubt if the transformation similarity loss is necessary. I suggest adding this experiment as an ablation study.\n\n\nSome typos and grammar issues:Line 53: a novel loss function that explicit features improve ... -> a novel loss function that motivates explicit features to improve ...Line 116: should Iref\u2208RH\u00d7W\u00d7C be Iref\u2208RH\u00d7W\u00d73?Line 135: resulting in a space complexity is reduced from ... -> resulting in a space complexity reduction from ...Line 207: Therefore, We -> Therefore, we  \nConsidering all the strengths and weaknesses, I rate borderline reject now. I may change my rating if my concerns in weaknesses are addressed.\n=============\nI have read the authors' feedback. My major concerns on InfiniteNature and feature fusion are well addressed. Thus, I increase my rating to weak accept.\nQuestions: \nI suggest adding InfiniteNature (or a warp+inpainting method) as a baseline if possible.\n\nI suggest manually fusing the two features according to the out-of-view mask or sending the mask as an additional input to the final decoder so that the decoder can learn to fuse them.\n\nAuthors may consider adding some video results, which would be more intuitive for view synthesis tasks.\n\nAuthors may comment on any weakness listed above if they disagree.\nLimitations: It seems that for reprojected regions, some mismatch to the input image can still be observed in the generated results. Thus, the \"preserving reprojected contents\" objective is still not fully fulfilled and has room for improvement.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: The paper proposes a non-autoregressive architecture for single-image view synthesis that combines both explicit and implicit methods. Two parallel renders extract explicit feature maps and implicit feature maps correspondingly, and the proposed transformation similarity loss encourages the consistency between two feature maps in the reprojected region and the out-of-view region.\nStrengths And Weaknesses: Originality: The idea of combining the explicit and implicit methods for single-image view synthesis is interesting. Also, the non-autoregressive framework reduces the inference time significantly. Some existing methods like GeoFree[40] also compare both explicit and implicit geometric transformation, but they didn\u2019t combine the advantages of explicit and implicit methods, so the paper is sufficiently novel.\nQuality: Overall the proposed method is well-described.\n\nAs mentioned in the paper, the PSNR is a good metric for evaluating the preservation of reprojected pixels on small changes only. Is it possible to evaluate it for reprojected regions only? In table 2, the Synsin[50] has very competitive PSNR performance (even better for both medium and large split); in Figure 4, the Synsin also shows a better ability to preserve projected contents (e.g. the carpet near the door in 1st row and the droplight in 2nd row), so the explanation in Line 230-232 is not very convincing to me.\nMaybe it is worth moving the ablation study on the Type of Set Attention in supp. to the main paper since the design of the encoder didn't be discussed in the experiments section, though it seems a novel contribution.\n\nClarity:  The paper is well-written and the motivation is clear. Some parts of the experiments can be explained better:\n\nThe definition of the explicit methods is not clear to me. For example, the Tatarchenko [46] is defined as an explicit method, but the way they parametrize the pose is very similar to the proposed Implicit renderer (angles only, no explicit warping introduced to the features to generate the image).\nIt\u2019s good to evaluate methods on different sizes of viewpoint changes. Is it possible to also show the qualitative results respectively?  Currently, Figure 4 is not clear since it only has the input source image and doesn\u2019t show the target image, so it\u2019s difficult to know if they are examples of small or large viewpoint changes.\n\nSignificance: The idea of rendering two feature maps in parallel can be general and it is possible to extend it to other frameworks.\nQuestions: \nIn Figure 4, there are check-board artifacts for your method (e.g. the 2nd row), while the autoregressive methods don\u2019t have that. Do you think it can be caused by the upsampling in the decoder?\nLimitations: The limitations are discussed in Sec 5.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper studies the task of single image novel view synthesis. The key message is very clear. Methods with explicit 3D projection mechanism, like SynSin, better preserve observed regions, whereas methods with implicit renderer, like GeoFree, do better at outpainting (synthesizing unseen regions). And using both of them in the same framework can complement and reinforce each other and get the best of both worlds.\nThe paper does a very good job at conveying this message, and presents promising results on both indoor and outdoor datasets to demonstrate the benefit of this joint approach.",
                "Strengths And Weaknesses": "Strengths\nS1 - Message is clear and makes a lot sense\n\nThe paper delivers the motivation of using both implicit and explicit rendering in single image NVS in a very clear and concise manner.\nThe benefits of both worlds can be maintained by defining losses that use the better one to guide the other, ie, features from the explicit branch will guide the ones from implicit branch in observed regions, with the gradient of the former being detached, and the other way around in unobserved regions.\nThe resulting model seems to overcome the shortcomings of both approaches, as shown in the comparison results.\n\nS2 - Clear and concise writing\n\nI enjoy reading the paper. It's very clear and coherent.\n\nWeaknesses\nW1 - Results are still a bit unsatisfactory\n\nFirst, I was expecting more qualitative comparisons in the supplementary material. There are only four examples shown. They're all good examples with large viewpoint changes. But showing more diverse results will be helpful.\nBased on the limited comparisons provided, it does not seem that the proposed method can fully preserve the benefits of both implicit and explicit methods. The quality of both observed and unobserved (outpainted) regions seems to be slightly compromised.\nObserved regions do not seem to be preserved very well, seemingly worse than SynSin and PixelSynth on indoor scenes. I think neither of them has been trained on images of outdoor scenery, so I'm not surprised they both fail on scenery images. The PSNR is also worse than SynSin with larger viewpoint changes.\nOutpainted regions also appear worse than GeoFree, although the latter uses an autoregressive framework.\nThere seem to be obvious artifacts in the synthesized images, eg the center of the generated image in second row of Fig 4 (dinning table).\n\n\nAre the PSNR computed only on the seen pixels or on the entire image? Reporting both numbers will resolve the question in 1.\nHave the compared models been finetuned on the same dataset? If not, I do not think the comparison is fair.\n\nMinor comments\n\nLine 116: I suppose f0 has a larger channel dimension than input image Iref. Use different symbols for their channel dimensions.",
                "Questions": "Report PSNR both only on seen pixels and on the entire image, if it's manageable during the rebuttal.\nFinetune the models of the previous methods on the same dataset, if this is not done currently.\nShow more diverse visual comparisons, maybe in the final version.",
                "Limitations": "The paper includes a brief discussion on the limitations. The current quality of the results are still quite limited. It would be helpful to provide some failure examples if any.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "There are two main paradigms in the task of single-image view synthesis. The explicit methods use the explicit 3D geometry and thus achieve good results on the reprojected pixels, while the implicit methods leverage implicit 3D inductive bias to implicitly learn the 3D geometry and could complete realistic out-of-view image regions. However, none of them can reach both goals. To mitigate such a seesaw problem, this paper bridges both implicit and explicit geometric transformations in a unified framework. Besides, a novel loss is proposed to fuse the geometry features from implicit and explicit branches. The proposed method can render state-of-the-art results on the novel views and achieve about 100x speedup in rendering compared to implicit autoregressive models.",
                "Strengths And Weaknesses": "Pros:\n\nCombining the explicit and implicit geometry features in a unified framework is a reasonable and straightforward idea. Since explicit 3D geometry can preserve reprojected image areas and implicit 3D geometry helps to complete out-of-view regions. Meanwhile, the experiments on RealEstate10K and ACID datasets prove the effectiveness of such a combination.\nThe whole paper is succinct and easy to follow.\nThe ablation study in Sec. 4.3 & 4.4 demonstrates the necessity of the proposed Transformation Similarity Loss.\n\nCons:\n\nFrom the main quantitative results in Table 2, the proposed method only shows superiority in terms of the FID metric. Although using both explicit and implicit geometric transformations, this method still works worse than SynSin. It seems that this method doesn't solve the aforementioned trade-off. For the lower FID score, this method just equips with a better imagination ability, which may be boosted with a more powerful adversarial loss. In lines 164~166, the authors mention they use a new GAN loss. How about the performance of SynSin + this new loss? Such a very important ablation study is not included in this manuscript.\nThe paper only provides the results on RealEstate10k and ACID datasets. How about the results on Matterport3D?\nGiven the better performance on the FID score, this method should compare with another two crucial baselines, Infinite Nature and Look Outside Room. I notice the authors' clarification in the supp. material. If available, the performance comparisons must be provided.",
                "Questions": "In this manuscript, experiments are not comprehensive. Please refer to the questions proposed in the weaknesses.",
                "Limitations": "The idea is a little bit straightforward, just like a simple combination of A and B.\nExperiments are not comprehensive and not enough to demonstrate the effectiveness of the proposed method.\nSome confusing sentences inside:\n\n\nLines 50 ~ 51: Our approach consists of architecture and loss functions.\nLines 159 ~ 160: ... generating photo-realistic images. What's the relationship between rendering speed and image quality. The emphasis on \"photo-realistic\" is unnecessary.\nLine 48: application area -> application areas\n...",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposes a new method for single-image view synthesis. The authors point out that existing methods are faced with a \"seesaw\" problem, i.e., a trade-off between preserving observed contents and synthesizing out-of-view regions. To address this issue, the authors propose a method that shares the advantages of both explicit and implicit geometric transformations, where the former is good at preserving existing contents while the latter is good at synthesizing out-of-view contents. A transformation similarity loss is proposed, which motivates the explicitly rendered feature and implicitly rendered feature to learn the best from each other. The pipeline is a feed-forward model without an autoregressive module, thus significantly faster than other autoregressive models. Experiments on two datasets show that the proposed method achieves obvious improvements over other implicit or explicit baselines both qualitatively and quantitatively. Ablation studies are carefully conducted to verify the effectiveness of the proposed transformation similarity loss and the dependency between explicit and implicit renderers.",
                "Strengths And Weaknesses": "Strengths:\n\nThis paper points out the trade-off between explicit and implicit geometric transformation-based methods, and proposes a hybrid model that integrates the best of both, which is new and reasonable. The synergy effects of explicit and implicit renderers are well demonstrated in experiments.  \n\nThe proposed transformation similarity loss is novel to me. Its effectiveness is clearly verified in Tab.4 and Fig.5, which shows that it helps the explicitly rendered feature and implicitly rendered feature to benefit from each other.  \n\nThe proposed method shows clear improvements over other baseline approaches in quantitative and qualitative evaluations. Results in Fig.4 show that it better preserves existing contents and synthesizes out-of-view contents.\n\n\nWeaknesses:\n\nI feel that the \"seesaw\" problem is somewhat exaggerated. In my humble opinion, a simpler and more straightforward way to solve this problem is to reproject or warp existing pixels to the target view based on the depth, and then use a generative model to synthesize the out-of-view pixels conditioned on the warped pixels, like inpainting. In this way, it naturally preserve existing contents and synthesize out-of-view contents. InfiniteNature [23] is designed in this way but is not compared. If this design can address the \"seesaw\" problem, then the contribution of this work is not strong. Otherwise, the authors should add some discussion to explain why.   \n\nFollowing the previous point, the authors mentioned in the supplementary that InfiniteNature [23] is not compared because the training code is not available. However, to my knowledge, the testing code is already available online and comparison is possible. For example, even GeoFree [40] compares with InfiniteNature. I suggest adding InfiniteNature (or a warp+inpainting method) as a baseline if there is no strong reason why this cannot be done.  \n\nIf explicitly rendered feature and implicitly rendered feature are complementary, then why not just manually fuse the two features according to the out-of-view mask or send the mask as an additional input to the final decoder so that the decoder can learn to fuse them?  In this case, the two features do not have to mimic each other. Thus, I doubt if the transformation similarity loss is necessary. I suggest adding this experiment as an ablation study.\n\n\nSome typos and grammar issues:Line 53: a novel loss function that explicit features improve ... -> a novel loss function that motivates explicit features to improve ...Line 116: should Iref\u2208RH\u00d7W\u00d7C be Iref\u2208RH\u00d7W\u00d73?Line 135: resulting in a space complexity is reduced from ... -> resulting in a space complexity reduction from ...Line 207: Therefore, We -> Therefore, we  \nConsidering all the strengths and weaknesses, I rate borderline reject now. I may change my rating if my concerns in weaknesses are addressed.\n=============\nI have read the authors' feedback. My major concerns on InfiniteNature and feature fusion are well addressed. Thus, I increase my rating to weak accept.",
                "Questions": "I suggest adding InfiniteNature (or a warp+inpainting method) as a baseline if possible.\n\nI suggest manually fusing the two features according to the out-of-view mask or sending the mask as an additional input to the final decoder so that the decoder can learn to fuse them.\n\nAuthors may consider adding some video results, which would be more intuitive for view synthesis tasks.\n\nAuthors may comment on any weakness listed above if they disagree.",
                "Limitations": "It seems that for reprojected regions, some mismatch to the input image can still be observed in the generated results. Thus, the \"preserving reprojected contents\" objective is still not fully fulfilled and has room for improvement.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper proposes a non-autoregressive architecture for single-image view synthesis that combines both explicit and implicit methods. Two parallel renders extract explicit feature maps and implicit feature maps correspondingly, and the proposed transformation similarity loss encourages the consistency between two feature maps in the reprojected region and the out-of-view region.",
                "Strengths And Weaknesses": "Originality: The idea of combining the explicit and implicit methods for single-image view synthesis is interesting. Also, the non-autoregressive framework reduces the inference time significantly. Some existing methods like GeoFree[40] also compare both explicit and implicit geometric transformation, but they didn\u2019t combine the advantages of explicit and implicit methods, so the paper is sufficiently novel.\nQuality: Overall the proposed method is well-described.\n\nAs mentioned in the paper, the PSNR is a good metric for evaluating the preservation of reprojected pixels on small changes only. Is it possible to evaluate it for reprojected regions only? In table 2, the Synsin[50] has very competitive PSNR performance (even better for both medium and large split); in Figure 4, the Synsin also shows a better ability to preserve projected contents (e.g. the carpet near the door in 1st row and the droplight in 2nd row), so the explanation in Line 230-232 is not very convincing to me.\nMaybe it is worth moving the ablation study on the Type of Set Attention in supp. to the main paper since the design of the encoder didn't be discussed in the experiments section, though it seems a novel contribution.\n\nClarity:  The paper is well-written and the motivation is clear. Some parts of the experiments can be explained better:\n\nThe definition of the explicit methods is not clear to me. For example, the Tatarchenko [46] is defined as an explicit method, but the way they parametrize the pose is very similar to the proposed Implicit renderer (angles only, no explicit warping introduced to the features to generate the image).\nIt\u2019s good to evaluate methods on different sizes of viewpoint changes. Is it possible to also show the qualitative results respectively?  Currently, Figure 4 is not clear since it only has the input source image and doesn\u2019t show the target image, so it\u2019s difficult to know if they are examples of small or large viewpoint changes.\n\nSignificance: The idea of rendering two feature maps in parallel can be general and it is possible to extend it to other frameworks.",
                "Questions": "In Figure 4, there are check-board artifacts for your method (e.g. the 2nd row), while the autoregressive methods don\u2019t have that. Do you think it can be caused by the upsampling in the decoder?",
                "Limitations": "The limitations are discussed in Sec 5.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "soundness_avg": 2.75,
        "presentation_avg": 3.25,
        "contribution_avg": 3.0,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the paper proposes a novel approach for single image novel view synthesis by combining explicit and implicit rendering methods. The paper is well-written and the motivation is clear. The proposed method shows improvements over other baseline approaches in both quantitative and qualitative evaluations. The proposed transformation similarity loss is also shown to be effective in encouraging the consistency between explicit and implicit feature maps. \n\nWhile there are some concerns raised by the reviewers, such as the limited comparison with other baselines and the artifacts in the synthesized images, the overall strengths of the paper outweigh these weaknesses. The limitations of the proposed method are also acknowledged by the authors.\n\nTherefore, I recommend accepting the paper."
    },
    "Atlas:_Universal_Function_Approximator_For_Memory_Retention": {
        "link": "https://openreview.net//forum?id=Ih2bG6h1r4S",
        "pub_url": "https://openreview.net/forum?id=Ih2bG6h1r4S",
        "pdf_link": "https://openreview.net//pdf?id=Ih2bG6h1r4S",
        "paper_id": "Ih2bG6h1r4S",
        "title": "Atlas:_Universal_Function_Approximator_For_Memory_Retention",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nThe submission proposes a novel type of neural network based on B-splines and exponential functions designed to reduce catastrophic forgetting, proves universal approximation results, and provides some experimental results. The reviewers find the submission interesting, but believe that the submission could be improved significantly in a number of respects, including better practices in use of the test dataset, comparison against baselines, and distinguishing between properties of the network class and properties of the learning method. Accordingly, I cannot recommend the present paper for acceptance.",
        "reviews": [
            "Reviewer 1: \nSummary: In this work, the authors propose a theoretical model that is generally well-suited for continual learning and exhibits less forgetting. In particular, they present a novel universal approximator theorem with multi-variable functions using single-variable functions and also exponential functions. They conduct a set of experiments to back their theoretical findings.\nStrengths And Weaknesses: Strengths\n\nApproach and theorems are novel.\nPaper is well-written with fixable errors\nResults are okay\n\nWeakness\n\nAblation study is missing\nNo baseline models to compare model performance\nExperiment section is missing few details\nQuestions: *Authors should make a comparison with [1-3] and show how current theoretical results proposed in this manuscript compares and also comment on the generalization guarantee of the theorem. \n\nLine 27, the authors have stated that ANNs have issues such as vanishing and exploding gradients, whereas this is not true. This is not an issue with ANNs but learning approach which is backpropagation of error (BP or BPTT), recently people have investigated local learning approaches such as Local representation alignment (LRA) and Difference target propagation (DTP and DTP-sigma), where they show models can be trained from zero weight initialization. Finally, ANNs by design are not well suited for continual learning, but additional memory (Gradient episodic memory, mnemonics), regularization-based approaches such as elastic weight consolidation (EWC), and sparsity helps them handle these tasks. I would advise the authors to revise the intro and avoid any partially correct claims.\nAuthors have reported they use test splits as the validation set to evaluate model performance on the test set. The reason we have a validation set is to approximate a distribution that we might see in the future, therefore we try all permutations and combinations to extract the best model. A common practice is to test your model once on test splits. Constantly changing hyper-parameters by checking performance on the test set is invalid. Hence I would request authors redo experiments with separate splits. \u2013 Since using a 0.01 learning rate with Adam is an odd choice. Additionally, there is no hyperparameter optimization and results with K-trials. One should conduct results across trials and report average performance with standard error. Hence I am not convinced by the experiments\n\nA second ablation study with various noise levels is needed. How does model performance change when the standard deviation for Gaussian noise is varied from 0.1 to some other constant?\n\nFor task two why are training sets sampled over a domain [0.45-0.55], what are these magic numbers, please provide reasoning on how should one derive such ranges?\n\nTask 1 is trained for 30 epochs, whereas Task 2 is trained for 6 epochs, why is this and how did you arrive to such conclusions, given there are no stopping criteria and using only 6 epochs is an odd choice.\n\nI liked the theoretical finding on the sparsity of atlas which states trainable parameters for the atlas is sparse, this would help in understanding why models such as Hard attention to task (HAT) and Sparse neural coding network (SNCN) work well on continual learning benchmarks without any memory component. What is the theoretical bound or upper bound for the total number of neurons required that will guarantee generalization and less forgetting? Can the authors comment on this?\n\n[1] https://proceedings.mlr.press/v130/doan21a.html\n\n[2] https://arxiv.org/abs/2008.02219\n\n[3] https://openreview.net/forum?id=hecuSLbL_vC\nLimitations: Highlighted above\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper introduces Atlas, a NN architecture based on mixed-density B-spline functions. These function satisfy a universal approximation theorem (proved in the paper), and have several useful properties, such as sparse and bounded gradients. The goal of this paper is to use such networks for continual learning problems.\nStrengths And Weaknesses: Strengths:\n\nThe examination of this class of functions in interesting, and the authors explain these models and their properties clearly\n\nSeveral interesting properties of these functions are clearly proved in the text\n\n\nWeaknesses:\n\nATLAS is discussed as having memory retention, but this seems to come mainly from training one B-spline at a time and fixing previous splines after training. As such the memory retention appears to come from fixing model parameters, rather than something intrinsic to the models. Similar ideas were used in other continual learning papers, e.g. continual learning via neural pruning [1903.04476]\n\nB-splines are discussed as being \"robust\", but what is meant by robust is not clearly defined. If this refers to memory retention, then as stated in the previous comment, this memory retention seems to come from parameter fixing during training. Why would one need B-splines in this case?\n\nTo address continual learning, e.g. sequentially learning tasks as is discussed in experiments, the ability to learn new tasks seems to come from expanding the model. Is this correct? This can also be done with standard NN models, e.g. as in Progressive Neural Networks [1606.04671]\n\nThe experiments are only examined on 2D problems, but there are several reasonably standard benchmarks for sequential task learning. Moreover, no comparison to baseline models is shown.  This would seem especially relevant, as the Atlas models do not seem to robustly fit several tasks.\n\nThere is no discussion or examination of information sharing across tasks, e.g. ideas such as forward or backward utilization or transfer of information across tasks. This would be helpful in understanding how the model could robustly use previously learned information across tasks.\n\nthe related work section does not discuss the breadth of work on continual learning, including work on models with similar ideas implemented (such as the two mentioned above)\nQuestions: \nWhat is meant by robust, and how does Atlas achieve such robustness while other NN models do not? Is there a quantitative metric associated to this robustness?\n\nHow does Atlas compare with baseline models and continual learning methods, e.g. in terms of new task performance, memory (since Atlas is an expanding model)? In general, as similar model expansion and weight fixing ideas have been implemented in other NNs, it is not clear how one may benefit from Atlas. Are there problems Atlas can solve, but other NNs can not solve?\n\nCan Atlas be applied to some of the benchmark datasets for CL, for example permuted MNIST is fairly common, but more challeneging benchmarks also exist.\n\nHow is information shared across tasks in Atlas? When the model is expanded, does the model rely heavily on previously learned information, or simply learn new tasks from scratch in the expanded parts of the model? How does the expanded learning on subsequent tasks compare to learning that new tasks from scratch?\nLimitations: Yes, some limitations are briefly mentioned in the conclusions.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This work presents Atlas, a new universal function approximator based on B-splines. Theoretically, Atlas has nice properties, such as sparse gradients, bounded gradients, and distal orthogonality. Experimentally, Atlas is robust to catastrophic forgetting, indicating its potential to be applied in continual learning.\nStrengths And Weaknesses: As far as I know, the approach presented in this work is novel. This new function approximator has good theoretical properties with sound proofs. The experiments also show its potential in reducing catastrophic forgetting and continual learning.\nHowever, this work can also be improved in many ways.\nFirst, related works are not adequately cited. In continual learning, more strategies to mitigate catastrophic forgetting can be found in this survey. Some methods with dynamic architectures should be cited and compared.\nA short introduction of B-splines would be appreciated, given that B-splines form the basis of Atlas. As for memory retention, there are also some related works in deep learning, such as https://arxiv.org/abs/2008.13363 and http://arxiv.org/abs/2112.03257.\nThe notations used in the paper are not well-defined or explained. For example, in Definition 1, what are function Si(x) and S(x)? What is a uniform cubic B-spline function? Is \u03b8i a vector or a real value? There are similar issues in Definition 3 and Property 1-3. Providing proof sketches in the main paper for Theorem 2 and Property 1-3 would be much appreciated.\nThere is a lack of comparison of Atlas with traditional artificial neural networks for approximating the swiss-roll target function.\nIt will also be better to see the results of testing Altas in the classical continual learning setting on some benchmarks, such as MNIST.\nMoreover, the experimental results are not well-explained. In Figure 6, why does the output difference have a cross shape?\nI would also like to know the exact number of parameters used in the experiments for Atlas.\nOverall, this work is interesting but more like a work in progress. And it can be improved significantly.\nQuestions: In line 90, it is mentioned that \"The minimum number of cubic B-spline basis functions is four.\" In line 140, it is written that \"It is worth recalling that at most four basis functions are active for uniform cubic B-spline functions.\" Is there a contradiction here? Why four basis functions?\nLimitations: Some limitations are already listed in the Conclusion. Given that there is still space in the main paper, the authors are encouraged to finish some of them.\nEthics Flag: No\nSoundness: 1 poor\nPresentation: 1 poor\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "In this work, the authors propose a theoretical model that is generally well-suited for continual learning and exhibits less forgetting. In particular, they present a novel universal approximator theorem with multi-variable functions using single-variable functions and also exponential functions. They conduct a set of experiments to back their theoretical findings.",
                "Strengths And Weaknesses": "Strengths\n\nApproach and theorems are novel.\nPaper is well-written with fixable errors\nResults are okay\n\nWeakness\n\nAblation study is missing\nNo baseline models to compare model performance\nExperiment section is missing few details",
                "Questions": "*Authors should make a comparison with [1-3] and show how current theoretical results proposed in this manuscript compares and also comment on the generalization guarantee of the theorem. \n\nLine 27, the authors have stated that ANNs have issues such as vanishing and exploding gradients, whereas this is not true. This is not an issue with ANNs but learning approach which is backpropagation of error (BP or BPTT), recently people have investigated local learning approaches such as Local representation alignment (LRA) and Difference target propagation (DTP and DTP-sigma), where they show models can be trained from zero weight initialization. Finally, ANNs by design are not well suited for continual learning, but additional memory (Gradient episodic memory, mnemonics), regularization-based approaches such as elastic weight consolidation (EWC), and sparsity helps them handle these tasks. I would advise the authors to revise the intro and avoid any partially correct claims.\nAuthors have reported they use test splits as the validation set to evaluate model performance on the test set. The reason we have a validation set is to approximate a distribution that we might see in the future, therefore we try all permutations and combinations to extract the best model. A common practice is to test your model once on test splits. Constantly changing hyper-parameters by checking performance on the test set is invalid. Hence I would request authors redo experiments with separate splits. \u2013 Since using a 0.01 learning rate with Adam is an odd choice. Additionally, there is no hyperparameter optimization and results with K-trials. One should conduct results across trials and report average performance with standard error. Hence I am not convinced by the experiments\n\nA second ablation study with various noise levels is needed. How does model performance change when the standard deviation for Gaussian noise is varied from 0.1 to some other constant?\n\nFor task two why are training sets sampled over a domain [0.45-0.55], what are these magic numbers, please provide reasoning on how should one derive such ranges?\n\nTask 1 is trained for 30 epochs, whereas Task 2 is trained for 6 epochs, why is this and how did you arrive to such conclusions, given there are no stopping criteria and using only 6 epochs is an odd choice.\n\nI liked the theoretical finding on the sparsity of atlas which states trainable parameters for the atlas is sparse, this would help in understanding why models such as Hard attention to task (HAT) and Sparse neural coding network (SNCN) work well on continual learning benchmarks without any memory component. What is the theoretical bound or upper bound for the total number of neurons required that will guarantee generalization and less forgetting? Can the authors comment on this?\n\n[1] https://proceedings.mlr.press/v130/doan21a.html\n\n[2] https://arxiv.org/abs/2008.02219\n\n[3] https://openreview.net/forum?id=hecuSLbL_vC",
                "Limitations": "Highlighted above",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper introduces Atlas, a NN architecture based on mixed-density B-spline functions. These function satisfy a universal approximation theorem (proved in the paper), and have several useful properties, such as sparse and bounded gradients. The goal of this paper is to use such networks for continual learning problems.",
                "Strengths And Weaknesses": "Strengths:\n\nThe examination of this class of functions in interesting, and the authors explain these models and their properties clearly\n\nSeveral interesting properties of these functions are clearly proved in the text\n\n\nWeaknesses:\n\nATLAS is discussed as having memory retention, but this seems to come mainly from training one B-spline at a time and fixing previous splines after training. As such the memory retention appears to come from fixing model parameters, rather than something intrinsic to the models. Similar ideas were used in other continual learning papers, e.g. continual learning via neural pruning [1903.04476]\n\nB-splines are discussed as being \"robust\", but what is meant by robust is not clearly defined. If this refers to memory retention, then as stated in the previous comment, this memory retention seems to come from parameter fixing during training. Why would one need B-splines in this case?\n\nTo address continual learning, e.g. sequentially learning tasks as is discussed in experiments, the ability to learn new tasks seems to come from expanding the model. Is this correct? This can also be done with standard NN models, e.g. as in Progressive Neural Networks [1606.04671]\n\nThe experiments are only examined on 2D problems, but there are several reasonably standard benchmarks for sequential task learning. Moreover, no comparison to baseline models is shown.  This would seem especially relevant, as the Atlas models do not seem to robustly fit several tasks.\n\nThere is no discussion or examination of information sharing across tasks, e.g. ideas such as forward or backward utilization or transfer of information across tasks. This would be helpful in understanding how the model could robustly use previously learned information across tasks.\n\nthe related work section does not discuss the breadth of work on continual learning, including work on models with similar ideas implemented (such as the two mentioned above)",
                "Questions": "What is meant by robust, and how does Atlas achieve such robustness while other NN models do not? Is there a quantitative metric associated to this robustness?\n\nHow does Atlas compare with baseline models and continual learning methods, e.g. in terms of new task performance, memory (since Atlas is an expanding model)? In general, as similar model expansion and weight fixing ideas have been implemented in other NNs, it is not clear how one may benefit from Atlas. Are there problems Atlas can solve, but other NNs can not solve?\n\nCan Atlas be applied to some of the benchmark datasets for CL, for example permuted MNIST is fairly common, but more challeneging benchmarks also exist.\n\nHow is information shared across tasks in Atlas? When the model is expanded, does the model rely heavily on previously learned information, or simply learn new tasks from scratch in the expanded parts of the model? How does the expanded learning on subsequent tasks compare to learning that new tasks from scratch?",
                "Limitations": "Yes, some limitations are briefly mentioned in the conclusions.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This work presents Atlas, a new universal function approximator based on B-splines. Theoretically, Atlas has nice properties, such as sparse gradients, bounded gradients, and distal orthogonality. Experimentally, Atlas is robust to catastrophic forgetting, indicating its potential to be applied in continual learning.",
                "Strengths And Weaknesses": "As far as I know, the approach presented in this work is novel. This new function approximator has good theoretical properties with sound proofs. The experiments also show its potential in reducing catastrophic forgetting and continual learning.\nHowever, this work can also be improved in many ways.\nFirst, related works are not adequately cited. In continual learning, more strategies to mitigate catastrophic forgetting can be found in this survey. Some methods with dynamic architectures should be cited and compared.\nA short introduction of B-splines would be appreciated, given that B-splines form the basis of Atlas. As for memory retention, there are also some related works in deep learning, such as https://arxiv.org/abs/2008.13363 and http://arxiv.org/abs/2112.03257.\nThe notations used in the paper are not well-defined or explained. For example, in Definition 1, what are function Si(x) and S(x)? What is a uniform cubic B-spline function? Is \u03b8i a vector or a real value? There are similar issues in Definition 3 and Property 1-3. Providing proof sketches in the main paper for Theorem 2 and Property 1-3 would be much appreciated.\nThere is a lack of comparison of Atlas with traditional artificial neural networks for approximating the swiss-roll target function.\nIt will also be better to see the results of testing Altas in the classical continual learning setting on some benchmarks, such as MNIST.\nMoreover, the experimental results are not well-explained. In Figure 6, why does the output difference have a cross shape?\nI would also like to know the exact number of parameters used in the experiments for Atlas.\nOverall, this work is interesting but more like a work in progress. And it can be improved significantly.",
                "Questions": "In line 90, it is mentioned that \"The minimum number of cubic B-spline basis functions is four.\" In line 140, it is written that \"It is worth recalling that at most four basis functions are active for uniform cubic B-spline functions.\" Is there a contradiction here? Why four basis functions?",
                "Limitations": "Some limitations are already listed in the Conclusion. Given that there is still space in the main paper, the authors are encouraged to finish some of them.",
                "Ethics Flag": "No",
                "Soundness": "1 poor",
                "Presentation": "1 poor",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 3.667,
        "confidence_avg": 4.0,
        "soundness_avg": 2.0,
        "presentation_avg": 2.333,
        "contribution_avg": 2.333,
        "ai_sum_meta": "Recommendation: Reject\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that there are several weaknesses in this paper. The first reviewer pointed out the lack of an ablation study, missing baseline models for comparison, and insufficient details in the experiment section. Additionally, there were concerns raised about the accuracy of the claims made in the introduction regarding issues with ANNs and the use of test splits as the validation set. The second reviewer highlighted the lack of comparison to baseline models, the limited examination of information sharing across tasks, and the absence of discussion on the robustness of Atlas compared to other NN models. The third reviewer also mentioned the inadequate citation of related works, the lack of explanation for certain notations, and the need for more comprehensive experimental results. Considering these weaknesses, it is recommended to reject the paper."
    },
    "Undersampling_is_a_Minimax_Optimal_Robustness_Intervention_in_Nonparametric_Classification": {
        "link": "https://openreview.net//forum?id=CT5KJGfX4s-",
        "pub_url": "https://openreview.net/forum?id=CT5KJGfX4s-",
        "pdf_link": "https://openreview.net//pdf?id=CT5KJGfX4s-",
        "paper_id": "CT5KJGfX4s-",
        "title": "Undersampling_is_a_Minimax_Optimal_Robustness_Intervention_in_Nonparametric_Classification",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nThis paper provides bounds and some empirical results on specific distribution shift scenarios, where there is a majority and minority group (group identity is known to the learner) and while at training time data from the two groups is unbalanced at the test distribution is assume to be a balanced mixture. The paper considers two specific scenarios, one where a type of covariate shift and one where a type of label shift is induced.\nThis submission considers the non-parametric setting, a one-dimensional feature space (examples are assumed to be from [0,1] x {-1, +1}) and Lipschitz continuity for the conditional label probability function. It then analyzes error rates for the above two scenarios and also provides some empirical confirmation that \"undersampling\", namely subsampling from the majority group so that the two groups are balanced at training time, is minimax optimal.\nGiven the large literature on learning bounds for domain adaptation (for parametric, but also for non-parametric learning) this submission appears suprisingly unaware of these existing studies and bounds. This literature should be acknowledged and compared to  in details before publication (if the results in here are not in fact just specific cases of known results). I can therefore not support acceptance, despite the reviewers positive recommendations.\nSteve Hanneke, Samory Kpotufe:\nOn the Value of Target Data in Transfer Learning. NeurIPS 2019: 9867-9877\nSamory Kpotufe, Guillaume Martinet:\nMarginal Singularity, and the Benefits of Labels in Covariate-Shift. COLT 2018: 1882-1886\nChristopher Berlind, Ruth Urner:\nActive Nearest Neighbors in Changing Environments. ICML 2015: 1870-1879\nShai Ben-David, Ruth Urner:\nDomain adaptation-can quantity compensate for quality? Ann. Math. Artif. Intell. 70(3): 185-202 (2014)\nShai Ben-David, Ruth Urner:\nOn the Hardness of Domain Adaptation and the Utility of Unlabeled Target Samples. ALT 2012: 139-153\nShai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, Jennifer Wortman Vaughan:\nA theory of learning from different domains. Mach. Learn. 79(1-2): 151-175 (2010)\nShai Ben-David, Tyler Lu, Teresa Luu, D\u00e1vid P\u00e1l:\nImpossibility Theorems for Domain Adaptation. AISTATS 2010: 129-136\nShai Ben-David, John Blitzer, Koby Crammer, Fernando Pereira:\nAnalysis of Representations for Domain Adaptation. NIPS 2006: 137-144",
        "reviews": [
            "Reviewer 1: \nSummary: The paper points out that minimax excess risk is lower bounded by a function of only the size of the minority group without additional parametric model assumptions or knowledge of the problem at hand. However, an undersampling + binning estimator achieves said lower bound. This implies that using samples from the majority-class/group does not improve, meaning that undersampling is optimal.\nStrengths And Weaknesses: The paper targets an important problem and the paper does a very good job pointing out both why undersampling does wonders in many cases and also why further work toward improve OOD should assume more structure. Good work!\nQuestions: I think many existing methods do infact use more structure than is allowed by the theory in the paper. Can the authors comment on what kinds of structure in the existing OOD literature helps do better than the proved lower-bound?\nLimitations: See questions.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 4 excellent\nRating: 8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper studies group-structured distribution shift, in which there exists an identifiable majority and minority group in the dataset. The later group having fewer samples in train time even though at test they are equally likely to be in either group. The paper looks into two specific types of this type of distribution shift. In the case in which the distribution shift is controlled via the balance of labels, the paper proves that the minimax excess risk can be lower bounded with only the size of the minority class samples. They further introduce an undersampled binning estimator which achieves this lower bound up to a constant. The paper also examines group-covariate shift, in which the distribution shift is over the marginal of a feature. In this case the minimax excess risk can be lower bounded, but also requires the ratio of samples (wrt minority / majority groups) and the overlap of group-covariate measures, alongside the size of the minority class samples. Their undersampled binning estimator also has an upper bound on the minimax excess risk, but there is a gap when there is a high overlap in the minority / majority distributions. Simple experiments are presented which are consistent with the theory.\nStrengths And Weaknesses: Strength\n\nThe paper presents lower bounds for the lower bounds for the minimax excess risk for label shift and group-covariate shifts.\nTheir proposed \"Undersampled Binning Estimator\" are optimal (or optimal in certain scenarios) up to a constant.\nThe explanations and intuition provided of the setting and results.\n\nWeakness\n\nThere are a few symbols which are not defined and some components in the experiments section which are not clear.\nQuestions: Questions / Comments / Suggestions\n\nIs the 1-Lipschitz assumption common? It would be useful for a discussion on if this assumption appears in practice or if its is a common technical assumption.\nShort definitions / descriptions of TV and VS loss would be useful for completeness\nThere are short notes about the generalization of Theorem 4.1 and 4.2 for higher dimensions. Does the \"1/3\" to \"1/3d\" also hold for corresponding Theorem 5.1 and 5.2?\n\nMinor / Typos\n\nThere seems to be a few typos / errors in the Appendix, the set of equation below Line 483: (1) on the first line the summation seems to be misplaced; and (2) the second last line seems to be incorrect / should be removed. This doesn't invalidate the proof.\nIn the Appendix, equations below Line 514: \"nmaj\" -> \"nmin\"\nLimitations: Assumptions / limitations of analysis is clear.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 4 excellent\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: Motivated by the fact that undersampling the majority class remains a competitive approach to learning in the presence of class imbalance, this paper sets out to answer the following question: Is it fundamentally possible to learn a better model than that of undersampling? The paper also considers a related question pertaining to covariate shift, which I am dropping to make the summary concise. To answer this question, the authors prove a lower bound (converse bound) that shows that the number of samples needed to learn a min-max optimal classifier in this setting scales with n\u22121/3. They show a matching upper bound based on undersampling based on which they conclude that undersampling is min-max optimal. The authors provide some experiments that confirm the results. Overall, I like the general positioning of the paper and the story is told nicely. However, I have serious concerns about the main theoretical results of the paper (Theorems 4.1 and 4.2) based on which I recommend the paper to be rejected given that these lower bounds are major contributions of this work.\n***** Update ******\nThe authors clarified my concerns in the rebuttal; in particular, I can see that the proof of Thm 4.1 was suffering from a typo, and the additional details clarified my concerns about the proof of Thm 4.2. As such, I agree with the other two reviewers that this is a significant piece of work and think should be highlighted in the conference (adjusting the score to 8).\nStrengths And Weaknesses: Strengths:\n\nThe authors ask an important question about min-max optimality of undersampling.\n\nThe paper is nicely written, nicely exposed, and the results appear to be novel to me.\n\nThe upper bounds for undersampling are intuitive, and the analysis is nicely done.\n\n\nWeaknesses:\n\nThe main weakness of the paper lies in the constant c in Theorem 4.1. A closer look at the proof on page 19, line 514, shows that the constant c=e\u2212nmaj3nmin, which does depend on both nmin and nmaj as opposed to the general story of the paper. In fact, c\u21920, as nmaj\u2192\u221e which contradicts parts of the story of the paper. The only way to keep c to be a constant as nmaj\u2192\u221e is to let nmin\u2192\u221e with nmajnmin\u2192\u03b7 for constant \u03c1 in which case the result loses its interestingness because there is no distinguishable difference between cnmin1/3=c2nmaj1/3 for some other constant c2 and the theorem doesn't tell us anything non-trivial about class imbalance. In summary, the lower bound is vacuous unless nmajnmin\u2192\u03b7, in which case the lower bound is trivial.\n\nA similar weakness applies to Theorem 4.2 for any \u03c4\u2208(0,1), where c vanishes as nmaj\u2192\u221e. This can be seen based on the equation on line 637 which vanishes as nmaj\u2192\u221e. Hence, similarly the lower bound is either vacuous or trivial in this setting as well.\n\nSince the metric of interest is min-max excess risk, I wonder why the authors didn't consider a min-max baseline (instead of ERM) in this setting; Also smoothened versions of such min-max loss for better generalization, e.g., tilted loss (Li et al 2021): \nLi, T., Beirami, A., Sanjabi, M. and Smith, V., 2021. Tilted empirical risk minimization. ICLR.\nI also wonder if these baselines would be subject to the same empirical observations of Figure 2.\nQuestions: \nCan you please elaborate on the main weaknesses listed above with respect to the lower bounds in Theorems 4.1 and 4.2? There might be a way to fix this by updating the construction that is considered and working through the details but I was not able to immediately see a way out.\n\nThe proof of Theorems 4.1 and 4.2 are dense. It would be best to give an outline of how the proof goes first. For example, I was confused when K was introduced for the first time, as it was not clear how this was going to be used.\nLimitations: The main limitation of this paper is that Theorems 4.1 and 4.2 in their current form are either vacuous or trivial (depending on how nmaj is related to nmin), and hence they do not support the narrative of the paper. It is not clear to me how this might be fixed.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 3 good\nRating: 8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The paper points out that minimax excess risk is lower bounded by a function of only the size of the minority group without additional parametric model assumptions or knowledge of the problem at hand. However, an undersampling + binning estimator achieves said lower bound. This implies that using samples from the majority-class/group does not improve, meaning that undersampling is optimal.",
                "Strengths And Weaknesses": "The paper targets an important problem and the paper does a very good job pointing out both why undersampling does wonders in many cases and also why further work toward improve OOD should assume more structure. Good work!",
                "Questions": "I think many existing methods do infact use more structure than is allowed by the theory in the paper. Can the authors comment on what kinds of structure in the existing OOD literature helps do better than the proved lower-bound?",
                "Limitations": "See questions.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "4 excellent",
                "Rating": "8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper studies group-structured distribution shift, in which there exists an identifiable majority and minority group in the dataset. The later group having fewer samples in train time even though at test they are equally likely to be in either group. The paper looks into two specific types of this type of distribution shift. In the case in which the distribution shift is controlled via the balance of labels, the paper proves that the minimax excess risk can be lower bounded with only the size of the minority class samples. They further introduce an undersampled binning estimator which achieves this lower bound up to a constant. The paper also examines group-covariate shift, in which the distribution shift is over the marginal of a feature. In this case the minimax excess risk can be lower bounded, but also requires the ratio of samples (wrt minority / majority groups) and the overlap of group-covariate measures, alongside the size of the minority class samples. Their undersampled binning estimator also has an upper bound on the minimax excess risk, but there is a gap when there is a high overlap in the minority / majority distributions. Simple experiments are presented which are consistent with the theory.",
                "Strengths And Weaknesses": "Strength\n\nThe paper presents lower bounds for the lower bounds for the minimax excess risk for label shift and group-covariate shifts.\nTheir proposed \"Undersampled Binning Estimator\" are optimal (or optimal in certain scenarios) up to a constant.\nThe explanations and intuition provided of the setting and results.\n\nWeakness\n\nThere are a few symbols which are not defined and some components in the experiments section which are not clear.",
                "Questions": "Questions / Comments / Suggestions\n\nIs the 1-Lipschitz assumption common? It would be useful for a discussion on if this assumption appears in practice or if its is a common technical assumption.\nShort definitions / descriptions of TV and VS loss would be useful for completeness\nThere are short notes about the generalization of Theorem 4.1 and 4.2 for higher dimensions. Does the \"1/3\" to \"1/3d\" also hold for corresponding Theorem 5.1 and 5.2?\n\nMinor / Typos\n\nThere seems to be a few typos / errors in the Appendix, the set of equation below Line 483: (1) on the first line the summation seems to be misplaced; and (2) the second last line seems to be incorrect / should be removed. This doesn't invalidate the proof.\nIn the Appendix, equations below Line 514: \"nmaj\" -> \"nmin\"",
                "Limitations": "Assumptions / limitations of analysis is clear.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "4 excellent",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "Motivated by the fact that undersampling the majority class remains a competitive approach to learning in the presence of class imbalance, this paper sets out to answer the following question: Is it fundamentally possible to learn a better model than that of undersampling? The paper also considers a related question pertaining to covariate shift, which I am dropping to make the summary concise. To answer this question, the authors prove a lower bound (converse bound) that shows that the number of samples needed to learn a min-max optimal classifier in this setting scales with n\u22121/3. They show a matching upper bound based on undersampling based on which they conclude that undersampling is min-max optimal. The authors provide some experiments that confirm the results. Overall, I like the general positioning of the paper and the story is told nicely. However, I have serious concerns about the main theoretical results of the paper (Theorems 4.1 and 4.2) based on which I recommend the paper to be rejected given that these lower bounds are major contributions of this work.\n***** Update ******\nThe authors clarified my concerns in the rebuttal; in particular, I can see that the proof of Thm 4.1 was suffering from a typo, and the additional details clarified my concerns about the proof of Thm 4.2. As such, I agree with the other two reviewers that this is a significant piece of work and think should be highlighted in the conference (adjusting the score to 8).",
                "Strengths And Weaknesses": "Strengths:\n\nThe authors ask an important question about min-max optimality of undersampling.\n\nThe paper is nicely written, nicely exposed, and the results appear to be novel to me.\n\nThe upper bounds for undersampling are intuitive, and the analysis is nicely done.\n\n\nWeaknesses:\n\nThe main weakness of the paper lies in the constant c in Theorem 4.1. A closer look at the proof on page 19, line 514, shows that the constant c=e\u2212nmaj3nmin, which does depend on both nmin and nmaj as opposed to the general story of the paper. In fact, c\u21920, as nmaj\u2192\u221e which contradicts parts of the story of the paper. The only way to keep c to be a constant as nmaj\u2192\u221e is to let nmin\u2192\u221e with nmajnmin\u2192\u03b7 for constant \u03c1 in which case the result loses its interestingness because there is no distinguishable difference between cnmin1/3=c2nmaj1/3 for some other constant c2 and the theorem doesn't tell us anything non-trivial about class imbalance. In summary, the lower bound is vacuous unless nmajnmin\u2192\u03b7, in which case the lower bound is trivial.\n\nA similar weakness applies to Theorem 4.2 for any \u03c4\u2208(0,1), where c vanishes as nmaj\u2192\u221e. This can be seen based on the equation on line 637 which vanishes as nmaj\u2192\u221e. Hence, similarly the lower bound is either vacuous or trivial in this setting as well.\n\nSince the metric of interest is min-max excess risk, I wonder why the authors didn't consider a min-max baseline (instead of ERM) in this setting; Also smoothened versions of such min-max loss for better generalization, e.g., tilted loss (Li et al 2021): \nLi, T., Beirami, A., Sanjabi, M. and Smith, V., 2021. Tilted empirical risk minimization. ICLR.\nI also wonder if these baselines would be subject to the same empirical observations of Figure 2.",
                "Questions": "Can you please elaborate on the main weaknesses listed above with respect to the lower bounds in Theorems 4.1 and 4.2? There might be a way to fix this by updating the construction that is considered and working through the details but I was not able to immediately see a way out.\n\nThe proof of Theorems 4.1 and 4.2 are dense. It would be best to give an outline of how the proof goes first. For example, I was confused when K was introduced for the first time, as it was not clear how this was going to be used.",
                "Limitations": "The main limitation of this paper is that Theorems 4.1 and 4.2 in their current form are either vacuous or trivial (depending on how nmaj is related to nmin), and hence they do not support the narrative of the paper. It is not clear to me how this might be fixed.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 7.667,
        "confidence_avg": 3.667,
        "soundness_avg": 3.0,
        "presentation_avg": 3.333,
        "contribution_avg": 3.667,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that this paper addresses an important problem and presents novel ideas. The paper provides lower bounds for the minimax excess risk in the presence of group-structured distribution shift and introduces an undersampled binning estimator that achieves these lower bounds. The theoretical results are supported by experiments.\n\nReviewer 1 and Reviewer 2 both highly appreciate the paper's contributions and consider it technically strong. Reviewer 1 specifically mentions that the paper does a very good job in explaining why undersampling is optimal in many cases. Reviewer 2 also highlights the intuitive upper bounds for undersampling and the well-done analysis.\n\nReviewer 3 initially had concerns about the main theoretical results, but after the authors clarified the concerns in the rebuttal, they agree with the other reviewers that this is a significant piece of work.\n\nOverall, the reviewers' comments and ratings indicate that this paper is of high quality and has the potential to make a strong impact in the field. Therefore, I recommend accepting this paper with a high level of confidence."
    },
    "Bag_of_Tricks_for_FGSM_Adversarial_Training": {
        "link": "https://openreview.net//forum?id=RYTGIZxY5rJ",
        "pub_url": "https://openreview.net/forum?id=RYTGIZxY5rJ",
        "pdf_link": "https://openreview.net//pdf?id=RYTGIZxY5rJ",
        "paper_id": "RYTGIZxY5rJ",
        "title": "Bag_of_Tricks_for_FGSM_Adversarial_Training",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nThis paper proposes to solve FGSM catastrophic overfitting by combining different algorithmic methods (i.e., masking pattern to the train data, smooth activations, ViTs, constraints on the first layer convolutional weights).  The reviewers have considered the problem studied very relevant but were not convinced by the empirical evaluation, finding that the paper is missing an exhaustive evaluation (and for epsilon larger than 8). In addition, they would have appreciated some understandings on the different tricks considered. We encourage the authors to revise their paper, taking into consideration the reviewers\u2019 feedback and to submit the revised work to a forthcoming conference.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper proposes various methods to mitigate the drastic overfitting (and resulting worse robust test accuracy) that can occur when adversarial training using the fast gradient sign method (FGSM). The proposed methods include masking input pixels, increasing the stride size of the first convolutional layer, smoother activation functions, and regularization. The authors show that each of these approaches successfully mitigates catastrophic overfitting on its own, and that the combination of multiple of these techniques results in slightly better robust performance than any technique alone (including those in previous works).\nStrengths And Weaknesses: Strengths\n\nThis paper improves upon the performance of FGSM adversarial training by incorporating new techniques to mitigate catastrophic overfitting.\nThe authors provide some light hypotheses behind why these techniques might work, and some empirical testing of these hypotheses. \nThe paper is clearly written for the most part.\n\nWeaknesses \n\nIt is not made entirely clear which technique in the \u201cbag of tricks\u201d performs best and whether your combination of techniques is state-of-the-art (i.e. it would be good to state this clearly in the introduction, add bold font to your tables, and include the best of the results in Table 3 as a line in Table 1 as well).\nThe paper could use another round of edits to improve readability: you should use \\citep for parenthetical citations, and there are a few typos i.e. in lines 214-215. \nThe experimental evaluation is not as thorough as in previous work - a stronger/more standard PGD evaluation uses 50 steps and 10 restarts rather than just 10 steps, and training time is excluded in the experimental results. \nWhile there are some attempts to explain why these techniques are successful at mitigating catastrophic overfitting, the paper could be strengthened by including only the most effective of the techniques, and providing a more thorough investigation into each technique.\nQuestions: Questions\n\nDo you use a validation set or do you measure the robust accuracy using the test set during training? \nDid you re-train other methods in Table 1 or use downloaded weights?\nWhat is the main advantage of using the fixed mask, given it does not appear to outperform any instance of the random masking?\n\nSuggestions\n\nIt would be good to discuss the trade-off in clean performance amongst the different techniques. Additionally, it would be interesting to include clean performance in Table 2. \nYou could better clarify what catastrophic overfitting is in the introduction for the reader that is unfamiliar with the term/phenomenon.\nLimitations: Yes\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This work investigates several modifications that can avoid Catastrophic Overfitting in FGSM-AT which would make AT much more efficient compared to using multi-step methods such as PGD. In particular, they suggest 4 different \"tricks\": Masking some pixels of the image, using a larger stride (default 2), using smooth activation functions (already suggested in prior work) and using a weight normalization regularizer. They empirically observe that some of their tricks achieve better performance than FGSM+GradAlign for CIFAR10 and \u03f5=8/255.\nStrengths And Weaknesses: Strengths:\n\nThe topic of Catastrophic Overfitting and in particular efficient AT is relevant. \nResults shown are encouraging.\nSome results are surprising like the fact that a fixed mask works as well as randomly masking each image.\n\nWeaknesses:\n\nMy main concern is that I do not think the experimental evidence is enough to support the claims. As reported in GradAlign work (https://arxiv.org/abs/2007.02617) some single-step AT methods (like F+FGSM) could prevent CO for moderate \u03f5 (such as 8/255) but would suffer from CO for larger radii. Therefore, the tested settings in this work (only CIFAR-10 and \u03f5=8/255) are too narrow to be reliable when stating that some particular method prevents CO. Additional perturbation radii should be compared and it would be sensible to include at least another dataset.\n\nThere is a lack of insight in the proposed tricks. While empirical results are definitely interesting, they should be discussed more in order to understand why do they work.\n\nSome of the \"tricks\" are not very novel (e.g. smooth activation functions was already introduced in the context of adversarial training). Despite it is novel that they can mitigate CO in some settings, without more insight into why this would happen I consider the finding lacks impact.\nQuestions: \nWhy do authors think that CVT does not suffer from CO? Have they tried larger perturbation radii? \n\nIt would be helpful to add a column for the computational cost (either in seconds per epoch or as a relative cost) for the different tricks and compared methods since one of the strengths of the proposed methods is efficiency.\nLimitations: As previously discussed, authors should test other datasets and larger perturbation radii to claim that the presented methods prevent CO.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper investigates training tricks used for FGSM-AT, including data initialization, network structure and optimization. The combined tricks can effectively alleviate the catastrophic overfitting in FGSM-AT, making FGSM-AT a more practical way towards robustness.\nStrengths And Weaknesses: Strengths:\n\nThe catastrophic overfitting in FGSM-AT is an important research topic.\nThe investigated tricks like random masking / increasing stride size are interesting and underexplored in the literature.\nWeightNorm seems an efficient substitute for GradNorm.\n\nWeaknesses:\n\nMy main concern is that the proposed tricks largely hurt the clean accuracy (e.g., Table 1 FGSM-Mask drops clean accuracy from 89.4% to 79.9% on WRN-34-10; FGSM-Smooth drops clean accuracy from 86.4% to 74.8% on PreActResNet-18).\nQuestions: My main concern is that the proposed tricks largely hurt the clean accuracy.\nLimitations: No\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: The paper focuses on the problem of catastrophic forgetting overfitting in Adversarial training using FGSM. It investigates the data initialization, network structure, and optimization of CIFAR-10. It shows that\n\napplying masking pattern to the training set,\nsmooth activations and using ViTs, and\nconstraining first layer convolution weights in the convolution layers\n\nstabilizes FGSM adversarial training.\nStrengths And Weaknesses: I am well-familiar with the literature and read the full paper in detail. Accordingly, now I\u2019ll describe the strengths and weaknesses of the paper in the order of originality and significance, quality of the paper, and clarity. \n\nOriginality and Significance\nStrengths\n\nThe paper\u2019s motivation is sound; it investigates the catastrophic forgetting overfitting from different perspectives, including data initialization, network structure, and optimization. While many previous works have understood this issue, the paper showcases that these simple tricks can help mitigate this problem to a certain extent.\n\nThe tricks are novel for FGSM adversarial training, especially the results showing that a pre-defined masking pattern to the training, the effect of ViTs, and regularization terms are simple, easy to implement, and effective in isolation, as demonstrated by the results.\n\nThe paper does a good job of positioning the proposed work. Furthermore, it does a good job in related work (section 5) explaining the existing works. I appreciate the paper using the optimal hyper-parameters from Pang et al. 2021. for their experiments.\n\n\nWeaknesses\nI do not have any significant concerns regarding the originality and contributions of the paper to the community. One minor suggestion is to include a discussion with Pang et al. 2021 when discussing smooth activation functions in Section 3.2, as the advantage of smooth activations was shown in their paper. \n\nQuality\nThe conducted experiments are interesting and valuable to show the performance gains by the proposed tricks for FGSM-AT. However, they were not exhaustive for me to evaluate the proposed tricks conclusively. Therefore, I have the following suggestions and questions that would be helpful to gain more insights and should improve the paper:\n\nThe paper does not provide confidence intervals, making it hard to judge the improvement gains. For example, in Table 1, the weight norm seems to provide no benefit over the grad norm; it is also hard to see the differences between FGSM-Smooth and FGSM-Str without the confidence intervals. Similarly, in Table 3, given the minute differences between various combinations, it is challenging to judge the contributions of each of them individually.\nThe evaluation protocol was also unclear, is the masking done only during training or even during the evaluation? In my opinion, it should be done only during training to avoid obfuscated gradients.\nLastly, the effect of \\lambda from eq. 9 was not highlighted in the paper. Other than mentioning the time taken per epoch in line 221, it would be beneficial to mention the total training time for both the methods up to convergence.\n\n\nClarity\nThe paper was easy to read; however, I have various suggestions regarding the paper\u2019s writing, as elaborated below.\n\nIn Figure 5, I would suggest including Relu for a comparison. Further, I don\u2019t think the left figures in Figure 5 are essential in the main paper. They can be moved to the appendix and the space can be utilized for important text like WideResNet results mentioned in Section 4.\nI would suggest repositioning section 4 and explaining the architectures in the experimental settings, followed by comparing the architectures' observations in the following sections.\nThe images in Figure 1 can be positioned side-by-side horizontal instead of vertical.\nAccording to the NeurIPS template, the caption should have been on top of the table.\nThe paper had an incorrect usage of \\citep and \\citet. For instance, lines 22, 26, 95, 98, etc., should have used \\citep, but the paper uses \\citet for all citations.\n\nOther writing suggestions:\n\nLine 35: Extra space before the period\nLine 87: Extra space after f \nLine 248 - Refer to the experiments being talked about here.\nA period in equation 2.\nWhile the operators may seem obvious, for uninformed readers, it would be helpful to define \u03a0 , xt, t in section 2.\nMissing comma after equation 5\nThe paper should also mention the number of GPUs used for ease of reproducibility in Line 108\nThe notation of FGSM-Str2 is not self-explanatory.\nTherefore, therefore -> Therefore in line 238\nExtra space after the period in line 277\nI suggest using the conference proceedings references for the papers; in many cases, it refers to the ArXiv version.\n\n\nReproducibility\nThe authors provide the code to replicate the results in the supplementary material.\nQuestions: Other than the questions in the previous section, I had the following clarifications and suggestions:\n\nDid the authors also check the effect of batch-norm and its variants on FGSM-AT? It would also be interesting to see if the regularizers like mixup, cutmix, augmix etc. can further be used as tricks for FGSM-AT.\n\nThe intuition behind the attenuation is unclear to me. Can the authors comment on the reason for attenuation at some point for the masks? Further, did the authors experiment with less than 10% masking? \n\nWhich architecture was used for conducting architectures in Table 2 and Figure 2 a). Was the same architecture used for all experiments other Table 1? Did the authors check the observations for the other architecture and observe similar behavior?\nLimitations: While the paper mentions that limitations are highlighted in Section 6, the limitations were missing from this section. Therefore, I would suggest including a separate section highlighting the limitations and societal impact of the paper; this can also be included in the supplementary material, but I believe the authors can easily accommodate half a page in the current manuscript.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 2 fair\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper proposes various methods to mitigate the drastic overfitting (and resulting worse robust test accuracy) that can occur when adversarial training using the fast gradient sign method (FGSM). The proposed methods include masking input pixels, increasing the stride size of the first convolutional layer, smoother activation functions, and regularization. The authors show that each of these approaches successfully mitigates catastrophic overfitting on its own, and that the combination of multiple of these techniques results in slightly better robust performance than any technique alone (including those in previous works).",
                "Strengths And Weaknesses": "Strengths\n\nThis paper improves upon the performance of FGSM adversarial training by incorporating new techniques to mitigate catastrophic overfitting.\nThe authors provide some light hypotheses behind why these techniques might work, and some empirical testing of these hypotheses. \nThe paper is clearly written for the most part.\n\nWeaknesses \n\nIt is not made entirely clear which technique in the \u201cbag of tricks\u201d performs best and whether your combination of techniques is state-of-the-art (i.e. it would be good to state this clearly in the introduction, add bold font to your tables, and include the best of the results in Table 3 as a line in Table 1 as well).\nThe paper could use another round of edits to improve readability: you should use \\citep for parenthetical citations, and there are a few typos i.e. in lines 214-215. \nThe experimental evaluation is not as thorough as in previous work - a stronger/more standard PGD evaluation uses 50 steps and 10 restarts rather than just 10 steps, and training time is excluded in the experimental results. \nWhile there are some attempts to explain why these techniques are successful at mitigating catastrophic overfitting, the paper could be strengthened by including only the most effective of the techniques, and providing a more thorough investigation into each technique.",
                "Questions": "Questions\n\nDo you use a validation set or do you measure the robust accuracy using the test set during training? \nDid you re-train other methods in Table 1 or use downloaded weights?\nWhat is the main advantage of using the fixed mask, given it does not appear to outperform any instance of the random masking?\n\nSuggestions\n\nIt would be good to discuss the trade-off in clean performance amongst the different techniques. Additionally, it would be interesting to include clean performance in Table 2. \nYou could better clarify what catastrophic overfitting is in the introduction for the reader that is unfamiliar with the term/phenomenon.",
                "Limitations": "Yes",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This work investigates several modifications that can avoid Catastrophic Overfitting in FGSM-AT which would make AT much more efficient compared to using multi-step methods such as PGD. In particular, they suggest 4 different \"tricks\": Masking some pixels of the image, using a larger stride (default 2), using smooth activation functions (already suggested in prior work) and using a weight normalization regularizer. They empirically observe that some of their tricks achieve better performance than FGSM+GradAlign for CIFAR10 and \u03f5=8/255.",
                "Strengths And Weaknesses": "Strengths:\n\nThe topic of Catastrophic Overfitting and in particular efficient AT is relevant. \nResults shown are encouraging.\nSome results are surprising like the fact that a fixed mask works as well as randomly masking each image.\n\nWeaknesses:\n\nMy main concern is that I do not think the experimental evidence is enough to support the claims. As reported in GradAlign work (https://arxiv.org/abs/2007.02617) some single-step AT methods (like F+FGSM) could prevent CO for moderate \u03f5 (such as 8/255) but would suffer from CO for larger radii. Therefore, the tested settings in this work (only CIFAR-10 and \u03f5=8/255) are too narrow to be reliable when stating that some particular method prevents CO. Additional perturbation radii should be compared and it would be sensible to include at least another dataset.\n\nThere is a lack of insight in the proposed tricks. While empirical results are definitely interesting, they should be discussed more in order to understand why do they work.\n\nSome of the \"tricks\" are not very novel (e.g. smooth activation functions was already introduced in the context of adversarial training). Despite it is novel that they can mitigate CO in some settings, without more insight into why this would happen I consider the finding lacks impact.",
                "Questions": "Why do authors think that CVT does not suffer from CO? Have they tried larger perturbation radii? \n\nIt would be helpful to add a column for the computational cost (either in seconds per epoch or as a relative cost) for the different tricks and compared methods since one of the strengths of the proposed methods is efficiency.",
                "Limitations": "As previously discussed, authors should test other datasets and larger perturbation radii to claim that the presented methods prevent CO.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper investigates training tricks used for FGSM-AT, including data initialization, network structure and optimization. The combined tricks can effectively alleviate the catastrophic overfitting in FGSM-AT, making FGSM-AT a more practical way towards robustness.",
                "Strengths And Weaknesses": "Strengths:\n\nThe catastrophic overfitting in FGSM-AT is an important research topic.\nThe investigated tricks like random masking / increasing stride size are interesting and underexplored in the literature.\nWeightNorm seems an efficient substitute for GradNorm.\n\nWeaknesses:\n\nMy main concern is that the proposed tricks largely hurt the clean accuracy (e.g., Table 1 FGSM-Mask drops clean accuracy from 89.4% to 79.9% on WRN-34-10; FGSM-Smooth drops clean accuracy from 86.4% to 74.8% on PreActResNet-18).",
                "Questions": "My main concern is that the proposed tricks largely hurt the clean accuracy.",
                "Limitations": "No",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper focuses on the problem of catastrophic forgetting overfitting in Adversarial training using FGSM. It investigates the data initialization, network structure, and optimization of CIFAR-10. It shows that\n\napplying masking pattern to the training set,\nsmooth activations and using ViTs, and\nconstraining first layer convolution weights in the convolution layers\n\nstabilizes FGSM adversarial training.",
                "Strengths And Weaknesses": "I am well-familiar with the literature and read the full paper in detail. Accordingly, now I\u2019ll describe the strengths and weaknesses of the paper in the order of originality and significance, quality of the paper, and clarity. \n\nOriginality and Significance\nStrengths\n\nThe paper\u2019s motivation is sound; it investigates the catastrophic forgetting overfitting from different perspectives, including data initialization, network structure, and optimization. While many previous works have understood this issue, the paper showcases that these simple tricks can help mitigate this problem to a certain extent.\n\nThe tricks are novel for FGSM adversarial training, especially the results showing that a pre-defined masking pattern to the training, the effect of ViTs, and regularization terms are simple, easy to implement, and effective in isolation, as demonstrated by the results.\n\nThe paper does a good job of positioning the proposed work. Furthermore, it does a good job in related work (section 5) explaining the existing works. I appreciate the paper using the optimal hyper-parameters from Pang et al. 2021. for their experiments.\n\n\nWeaknesses\nI do not have any significant concerns regarding the originality and contributions of the paper to the community. One minor suggestion is to include a discussion with Pang et al. 2021 when discussing smooth activation functions in Section 3.2, as the advantage of smooth activations was shown in their paper. \n\nQuality\nThe conducted experiments are interesting and valuable to show the performance gains by the proposed tricks for FGSM-AT. However, they were not exhaustive for me to evaluate the proposed tricks conclusively. Therefore, I have the following suggestions and questions that would be helpful to gain more insights and should improve the paper:\n\nThe paper does not provide confidence intervals, making it hard to judge the improvement gains. For example, in Table 1, the weight norm seems to provide no benefit over the grad norm; it is also hard to see the differences between FGSM-Smooth and FGSM-Str without the confidence intervals. Similarly, in Table 3, given the minute differences between various combinations, it is challenging to judge the contributions of each of them individually.\nThe evaluation protocol was also unclear, is the masking done only during training or even during the evaluation? In my opinion, it should be done only during training to avoid obfuscated gradients.\nLastly, the effect of \\lambda from eq. 9 was not highlighted in the paper. Other than mentioning the time taken per epoch in line 221, it would be beneficial to mention the total training time for both the methods up to convergence.\n\n\nClarity\nThe paper was easy to read; however, I have various suggestions regarding the paper\u2019s writing, as elaborated below.\n\nIn Figure 5, I would suggest including Relu for a comparison. Further, I don\u2019t think the left figures in Figure 5 are essential in the main paper. They can be moved to the appendix and the space can be utilized for important text like WideResNet results mentioned in Section 4.\nI would suggest repositioning section 4 and explaining the architectures in the experimental settings, followed by comparing the architectures' observations in the following sections.\nThe images in Figure 1 can be positioned side-by-side horizontal instead of vertical.\nAccording to the NeurIPS template, the caption should have been on top of the table.\nThe paper had an incorrect usage of \\citep and \\citet. For instance, lines 22, 26, 95, 98, etc., should have used \\citep, but the paper uses \\citet for all citations.\n\nOther writing suggestions:\n\nLine 35: Extra space before the period\nLine 87: Extra space after f \nLine 248 - Refer to the experiments being talked about here.\nA period in equation 2.\nWhile the operators may seem obvious, for uninformed readers, it would be helpful to define \u03a0 , xt, t in section 2.\nMissing comma after equation 5\nThe paper should also mention the number of GPUs used for ease of reproducibility in Line 108\nThe notation of FGSM-Str2 is not self-explanatory.\nTherefore, therefore -> Therefore in line 238\nExtra space after the period in line 277\nI suggest using the conference proceedings references for the papers; in many cases, it refers to the ArXiv version.\n\n\nReproducibility\nThe authors provide the code to replicate the results in the supplementary material.",
                "Questions": "Other than the questions in the previous section, I had the following clarifications and suggestions:\n\nDid the authors also check the effect of batch-norm and its variants on FGSM-AT? It would also be interesting to see if the regularizers like mixup, cutmix, augmix etc. can further be used as tricks for FGSM-AT.\n\nThe intuition behind the attenuation is unclear to me. Can the authors comment on the reason for attenuation at some point for the masks? Further, did the authors experiment with less than 10% masking? \n\nWhich architecture was used for conducting architectures in Table 2 and Figure 2 a). Was the same architecture used for all experiments other Table 1? Did the authors check the observations for the other architecture and observe similar behavior?",
                "Limitations": "While the paper mentions that limitations are highlighted in Section 6, the limitations were missing from this section. Therefore, I would suggest including a separate section highlighting the limitations and societal impact of the paper; this can also be included in the supplementary material, but I believe the authors can easily accommodate half a page in the current manuscript.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.0,
        "confidence_avg": 4.5,
        "soundness_avg": 2.5,
        "presentation_avg": 2.5,
        "contribution_avg": 2.75,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is evident that the paper proposes various methods to mitigate catastrophic overfitting in adversarial training using the fast gradient sign method (FGSM). The reviewers generally agree that the paper addresses an important research topic and provides valuable insights into improving the performance of FGSM adversarial training.\n\nReviewer 1 highlights the strengths of the paper, including the improvement in performance compared to previous works and the clear presentation. They also provide some suggestions for improvement, such as clarifying the best performing technique and including clean performance in the results.\n\nReviewer 2 raises concerns about the experimental evidence and suggests testing the proposed tricks on other datasets and larger perturbation radii. They also suggest including computational cost in the evaluation. However, they acknowledge the relevance of the topic and the encouraging results.\n\nReviewer 3 acknowledges the importance of the research topic and the novelty of the investigated tricks. They raise a concern about the decrease in clean accuracy due to the proposed tricks.\n\nReviewer 4 appreciates the motivation and originality of the paper. They provide suggestions for improving the quality and clarity of the paper, such as including confidence intervals and clarifying the evaluation protocol. They also suggest exploring the effect of batch-norm and other regularizers on FGSM-AT.\n\nOverall, the reviewers find the paper technically solid and with moderate-to-high impact. While there are some suggestions for improvement, the strengths of the paper outweigh the weaknesses. Therefore, I recommend accepting the paper."
    },
    "ISAAC_Newton:_Input-based_Approximate_Curvature_for_Newton's_Method": {
        "link": "https://openreview.net//forum?id=WIJ2SfPTj8c",
        "pub_url": "https://openreview.net/forum?id=WIJ2SfPTj8c",
        "pdf_link": "https://openreview.net//pdf?id=WIJ2SfPTj8c",
        "paper_id": "WIJ2SfPTj8c",
        "title": "ISAAC_Newton:_Input-based_Approximate_Curvature_for_Newton's_Method",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Less certain\nThe paper adds two regularization parameters that creates a method that interpolates between gradient descent and KFAC. The authors then prove the method interpolates, then several numerical experiments are presented on MNIST, and training BERT, and resnets. But the reviewers were not convinced by the experimental results, which did not benchmark the methods against SOTA, or lacking large scale experiments, and also lacking comparisons against other second order methods, for which there are now many.\nIn addition to this, though\u00a0the paper cites broadly, it does not review, cite or cover the recent efforts on improving KFAC.\u00a0 For example the missing reference\u00a0[1]. Though this is a quasi-Newton approach, they also employ a type of regularization to aa^T term. Finally, I think the introduction of these two regularization parameters needs to be slightly better motivated. For now, the motivation is to interpolate between SGD and KFAC. But this is not enough. One can always generate new methods by interpolating between existing methods by adding a parameter. I recommend exploring the LM\u00a0(Levenberg Marquardt)\u00a0viewpoint of this type of regularization. This may gives other viewpoints and motivation for using these two regularization parameters.\n[1] Goldfarb, D., Ren, Y., Bahamou, A.:, Practical quasi-Newton methods for training deep neural networks. In:Advances inNeural Information Processing Systems.",
        "reviews": [
            "Reviewer 1: \nSummary: The paper addresses the problem of using second-order information in large-scale machine learning tasks (e.g. training neural networks). It proposes a Kronecker-factored Approximate Curvature (KFAC)-approximated, Tikhonov regularized Gauss-Newton (GN) update step. Instead of a single regularization parameter (\u03bb), the update step in the paper uses two independent regularization parameters (\u03bbg and \u03bba). The paper relates different settings of \u03bba and \u03bbg to other algorithms (i.e. classical GN and gradient descent). It shows that allowing \u03bbg grows to infinity gives a computationally efficient update step. It provides empirical results on their proposed method.\nStrengths And Weaknesses: Strengths:\n\nThe update step \u03be\u2217 is interesting and practical. The paper provides experiments to show that using \u03be\u2217 can lead to lower computation time without sacrificing performance. Experiments are thorough and tested on some fairly large neural network architectures.\nThe update step \u03be is a nice, compact way to describe an algorithm for training neural networks. The analysis of \u03be provides various ways of interpreting the algorithm in terms of different regularization parameter settings. The properties of \u03be are interesting. The analysis is relatively thorough (e.g. showing that any combination of \u03bbg and \u03bba will still result in a descent direction).\nPaper is well-written and clear.\n\nWeaknesses\n\nSome of the experiments are not benchmarked to SOTA (which is acknowledged by the paper). This might affect people's willingness to adopt the method in practice.\nQuestions: \nLine 70 refers to H in Equation 6. Typo?\nIs there an intuitive interpretation of the preconditioner M in Remark 2? Does this preconditioning help in terms of reducing the number of iterations needed to reach a solution?\nLimitations: This work does not appear to me to have negative social impact.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: Inspired by the KFAC approximation and the Tikhonov regularization of the Newton method, this paper proposes a regularized K-FAC approximated Gauss-Newton type method called ISAAC. The proposed method is based on only the input to a respective layer, therefore does not suffer from a substantial computational overhead. Numerical experiments show the advantages of the proposed method compared to both first-order type and second-order type methods.\nStrengths And Weaknesses: Strengths:\nRegularization parameters is crucial for second-order type methods.  The authors first approximate the GGN matrix as a kroncker product of two matrices, and then view two regulation parameters independently. By letting the two regularization parameters vanish or go to infinity, one can obtain new directions and therefore new methods. The proposed method is more efficient than KFAC since only one matrix should be inverted and no need extra propagation to compute g.  \nWeaknesses:\nThis paper should be polished to make it easier to read. \nSome related literatures on second-order methods should be mentioned, such as Shampoo[1], KBFGS[2], NG+[3] and SENG[4]. \nSome theoretical properties is natural and trivial. It is better to formalize an algorithm and give a convergence result.\nIt is better to add some large numerical examples, such as Resnet50 with Imagenet-1k and make a comparison with other second-order methods Shampoo[1], KBFGS[2], NG+[3] and SENG[4]. \n[1] Gupta,V.,Koren,T., Singer,Y.:, Shampoo: Preconditioned stochastic tensor optimization. In: International Conference on Machine Learning.\n[2] Goldfarb, D., Ren, Y., Bahamou, A.:, Practical quasi-Newton methods for training deep neural networks. In:Advances inNeural Information Processing Systems.\n[3] Yang, M., Xu, D., Cui, Q., Wen, Z., & Xu, P. (2021). NG+: A Multi-Step Matrix-Product Natural Gradient Method for Deep Learning. arXiv preprint arXiv:2106.07454.\n[4] Yang, M., Xu, D., Wen, Z., Chen, M., & Xu, P. (2020). Sketch-based empirical natural gradient methods for deep learning. Journal of Scientific Computing.\nQuestions: line 60: change [14],[15] to [14.15]. It is better to put multiple references in the same brackets. Please check other places.\nIt is better to add the discussion between GGN matrix and Fisher matrix, which can refer to [1,2] and related literatures.\nIt is better to add a left brackets after \u03b7 and a right bracket before the gradient in eq.(16). Please also add brackets in a suitable place in eq. (17).\nIn eq.(19), the gradient should be g\u22a4a/b where the b is missed. In eq.(19), the authors use the same batch to approximate the GGN matrix and compute the gradient. Can the batches for approximation of the GGN and the computation of the gradient be different? In that case, what the related theoretical properties will be?\nWhen the objective function is convex, the GGN matrix is positive semi-definite matrix. Adding a regularization parameter in GGN, It is t easy to show that \u03b6 is an ascent direction, which means Theorem 2 is trivial.\nThe authors consider the fully-connected neural network in this paper. I believe this method can be extended to convolutional neural networks. And in numerical part, the authors have done some experiments. I wonder can we obtain some explanation from theory for this case? \nFor the kronecker approximation of the GGN matrix, aa\u22a4 is more important than g\u2015\u22a4g\u2015 part. I once validate it numerically. One reason is that each value of the matrix g\u2015\u22a4g\u2015  is very small so that the \u03bbg domains. I have noticed one related work recently. The work is named NG+[3].\n[1] Botev, Aleksandar, Hippolyt Ritter, and David Barber. \"Practical gauss-newton optimisation for deep learning.\" International Conference on Machine Learning. PMLR, 2017.\n[2] Martens, James. \"New insights and perspectives on the natural gradient method.\" The Journal of Machine Learning Research 21.1 (2020): 5776-5851.\n[3] Yang, M., Xu, D., Cui, Q., Wen, Z., & Xu, P. (2021). NG+: A Multi-Step Matrix-Product Natural Gradient Method for Deep Learning. arXiv preprint arXiv:2106.07454.\nLimitations: Yes\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper proposed a KFAC variant to improve the computation efficiency. It introduces two Tikhonov regularization terms into KFAC, and makes gradient conditioning more efficient by force \u03bbg go to infinity. The authors present a theoretical guarantee that the optimization still goes in the right direction even with such an adaptation. The authors also show ISAAC is more computation efficient in small-batch stochastic regimes.\nHowever, I feel contributions in this paper are rather limited, and some motivations might need further justification.\nStrengths And Weaknesses: Strength:\nThe paper is well written. Preliminaries and methods are clearly explained. \nWeaknesses:\n1, Contributions are limited. Reducing the compute costs of KFAC is a good problem. However, I am not convinced that separating the regularization term and using a large regularization is a novel and effective solution. It only makes the optimizer behave more and more like SGD. As the authors stated in Theorem 1, small \u03bba,\u03bbg leads to KFAC, while large \u03bba,\u03bbg leads to vanilla gradient descent. \n2, Empirical results need to be enhanced. The authors use several empirical results to support the claim that ISAAC still behaves like KFAC even though using a strong regularization factor. However, I do not think current results are strong enough to support the claim. The issues in the empirical evaluations also make me doubt the contributions in the paper. \n\n2.1, The author should provide more baselines (Adam, SGD with momentum) so that we can really have a fair evaluation. \n\n2.2, For Figure 1, my understanding is that the authors are trying to show ISAAC still obtains good results (loss and accuracy) even with large regularization. If so, I do not think it is necessary. As the authors stated in Theorem 1, larger regularization makes ISAAC behave more like SGD. Therefore, getting similar loss and accuracy is no surprise.\n\n2.3, For Figure 2, there are several issues. First, hyper parameters are not fully revealed. For instance, what is the weight decay for each optimizer since weight decays large affects training convergence?  Second, only the training curve is reported. The author really should present both a training and validation curve. In many cases, we can have faster convergence on training dataset, but not for validation dataset. \n\n2.4, For Figure 6, the reported accuracy is obviously lower compared to results we usually have on CIFAR-10. The reason might be that the authors use SGD without momentum. However, I am not convinced under such a setting. SGD with momentum is a default setting in many training tasks. Without momentum, I do not think the results will provide meaningful comparisons and conclusions.\n\n\n3, Training with small batches should be further justified. I understand the authors stress the compute benefits of ISAAC in a small-batch regime (Theorem 3-ii). However, considering more general settings, the authors should well justify it: is it worth accelerating the training using small batches given the fact that large batches can also improve convergence performance even using SGD. Therefore, I think not only should the author provide results in small-batch regimes, training using large batches should also be evaluated and compared with other baselines.\nQuestions: See my comments above.\nLimitations: No\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: In unconstrained optimisation, Newton's method uses inverse Hessian to determine the step size of the update. When applied to deep learning, the sheer size of the Hessian matrix makes Newton's method intractable. Among existing attempts to address this challenge, K-FAC is a promising approach. In practice, Tikhonov regularization/damping is used to avoid divergence.\nIn this paper, the authors introduced an extension to the standard Tikhonov damping for K-FAC. The main idea is to use two independent damping parameters (hyper-parameters for regularisation) instead of one damping parameter, one for the gradient factor and one for the activity factor, as shown in Equation (17). The authors explored special cases where the two parameters are either 0 or infinity. They also discussed the special case of setting one parameter to infinity, effectively removing the gradient factor in K-FAC. One major claim was that this activity-only form has an advantage in reduced computational complexity, although I don't find a theoretical comparison with K-FAC in this aspect. \nThe claim for computational efficiency was mostly supported via empirical evaluation.\nStrengths And Weaknesses: Strengths:\n\nThe paper addresses an important problem: efficient approximation of Gaussian-Newton approximation\nThe exposition is mostly clear, especially if you are already familiar with the existing literature.\nThe experiments seem comprehensive.\n\nWeaknesses:\n\nIt is not clear what is the main contribution of this paper. Is it the two-parameter damping mechanism (What advantage do we gain)? Or is it the special case mentioned in Remark 3 (Why this is a still good approximation without g\u22a4g)? \nMany theoretical results presented look rather trivial.\nQuestions: What is the intuition behind Eq (21)? Compared with Eq (13), why is it a good approximation?\nLimitations: N/A\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 2 fair\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The paper addresses the problem of using second-order information in large-scale machine learning tasks (e.g. training neural networks). It proposes a Kronecker-factored Approximate Curvature (KFAC)-approximated, Tikhonov regularized Gauss-Newton (GN) update step. Instead of a single regularization parameter (\u03bb), the update step in the paper uses two independent regularization parameters (\u03bbg and \u03bba). The paper relates different settings of \u03bba and \u03bbg to other algorithms (i.e. classical GN and gradient descent). It shows that allowing \u03bbg grows to infinity gives a computationally efficient update step. It provides empirical results on their proposed method.",
                "Strengths And Weaknesses": "Strengths:\n\nThe update step \u03be\u2217 is interesting and practical. The paper provides experiments to show that using \u03be\u2217 can lead to lower computation time without sacrificing performance. Experiments are thorough and tested on some fairly large neural network architectures.\nThe update step \u03be is a nice, compact way to describe an algorithm for training neural networks. The analysis of \u03be provides various ways of interpreting the algorithm in terms of different regularization parameter settings. The properties of \u03be are interesting. The analysis is relatively thorough (e.g. showing that any combination of \u03bbg and \u03bba will still result in a descent direction).\nPaper is well-written and clear.\n\nWeaknesses\n\nSome of the experiments are not benchmarked to SOTA (which is acknowledged by the paper). This might affect people's willingness to adopt the method in practice.",
                "Questions": "Line 70 refers to H in Equation 6. Typo?\nIs there an intuitive interpretation of the preconditioner M in Remark 2? Does this preconditioning help in terms of reducing the number of iterations needed to reach a solution?",
                "Limitations": "This work does not appear to me to have negative social impact.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "Inspired by the KFAC approximation and the Tikhonov regularization of the Newton method, this paper proposes a regularized K-FAC approximated Gauss-Newton type method called ISAAC. The proposed method is based on only the input to a respective layer, therefore does not suffer from a substantial computational overhead. Numerical experiments show the advantages of the proposed method compared to both first-order type and second-order type methods.",
                "Strengths And Weaknesses": "Strengths:\nRegularization parameters is crucial for second-order type methods.  The authors first approximate the GGN matrix as a kroncker product of two matrices, and then view two regulation parameters independently. By letting the two regularization parameters vanish or go to infinity, one can obtain new directions and therefore new methods. The proposed method is more efficient than KFAC since only one matrix should be inverted and no need extra propagation to compute g.  \nWeaknesses:\nThis paper should be polished to make it easier to read. \nSome related literatures on second-order methods should be mentioned, such as Shampoo[1], KBFGS[2], NG+[3] and SENG[4]. \nSome theoretical properties is natural and trivial. It is better to formalize an algorithm and give a convergence result.\nIt is better to add some large numerical examples, such as Resnet50 with Imagenet-1k and make a comparison with other second-order methods Shampoo[1], KBFGS[2], NG+[3] and SENG[4]. \n[1] Gupta,V.,Koren,T., Singer,Y.:, Shampoo: Preconditioned stochastic tensor optimization. In: International Conference on Machine Learning.\n[2] Goldfarb, D., Ren, Y., Bahamou, A.:, Practical quasi-Newton methods for training deep neural networks. In:Advances inNeural Information Processing Systems.\n[3] Yang, M., Xu, D., Cui, Q., Wen, Z., & Xu, P. (2021). NG+: A Multi-Step Matrix-Product Natural Gradient Method for Deep Learning. arXiv preprint arXiv:2106.07454.\n[4] Yang, M., Xu, D., Wen, Z., Chen, M., & Xu, P. (2020). Sketch-based empirical natural gradient methods for deep learning. Journal of Scientific Computing.",
                "Questions": "line 60: change [14],[15] to [14.15]. It is better to put multiple references in the same brackets. Please check other places.\nIt is better to add the discussion between GGN matrix and Fisher matrix, which can refer to [1,2] and related literatures.\nIt is better to add a left brackets after \u03b7 and a right bracket before the gradient in eq.(16). Please also add brackets in a suitable place in eq. (17).\nIn eq.(19), the gradient should be g\u22a4a/b where the b is missed. In eq.(19), the authors use the same batch to approximate the GGN matrix and compute the gradient. Can the batches for approximation of the GGN and the computation of the gradient be different? In that case, what the related theoretical properties will be?\nWhen the objective function is convex, the GGN matrix is positive semi-definite matrix. Adding a regularization parameter in GGN, It is t easy to show that \u03b6 is an ascent direction, which means Theorem 2 is trivial.\nThe authors consider the fully-connected neural network in this paper. I believe this method can be extended to convolutional neural networks. And in numerical part, the authors have done some experiments. I wonder can we obtain some explanation from theory for this case? \nFor the kronecker approximation of the GGN matrix, aa\u22a4 is more important than g\u2015\u22a4g\u2015 part. I once validate it numerically. One reason is that each value of the matrix g\u2015\u22a4g\u2015  is very small so that the \u03bbg domains. I have noticed one related work recently. The work is named NG+[3].\n[1] Botev, Aleksandar, Hippolyt Ritter, and David Barber. \"Practical gauss-newton optimisation for deep learning.\" International Conference on Machine Learning. PMLR, 2017.\n[2] Martens, James. \"New insights and perspectives on the natural gradient method.\" The Journal of Machine Learning Research 21.1 (2020): 5776-5851.\n[3] Yang, M., Xu, D., Cui, Q., Wen, Z., & Xu, P. (2021). NG+: A Multi-Step Matrix-Product Natural Gradient Method for Deep Learning. arXiv preprint arXiv:2106.07454.",
                "Limitations": "Yes",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposed a KFAC variant to improve the computation efficiency. It introduces two Tikhonov regularization terms into KFAC, and makes gradient conditioning more efficient by force \u03bbg go to infinity. The authors present a theoretical guarantee that the optimization still goes in the right direction even with such an adaptation. The authors also show ISAAC is more computation efficient in small-batch stochastic regimes.\nHowever, I feel contributions in this paper are rather limited, and some motivations might need further justification.",
                "Strengths And Weaknesses": "Strength:\nThe paper is well written. Preliminaries and methods are clearly explained. \nWeaknesses:\n1, Contributions are limited. Reducing the compute costs of KFAC is a good problem. However, I am not convinced that separating the regularization term and using a large regularization is a novel and effective solution. It only makes the optimizer behave more and more like SGD. As the authors stated in Theorem 1, small \u03bba,\u03bbg leads to KFAC, while large \u03bba,\u03bbg leads to vanilla gradient descent. \n2, Empirical results need to be enhanced. The authors use several empirical results to support the claim that ISAAC still behaves like KFAC even though using a strong regularization factor. However, I do not think current results are strong enough to support the claim. The issues in the empirical evaluations also make me doubt the contributions in the paper. \n\n2.1, The author should provide more baselines (Adam, SGD with momentum) so that we can really have a fair evaluation. \n\n2.2, For Figure 1, my understanding is that the authors are trying to show ISAAC still obtains good results (loss and accuracy) even with large regularization. If so, I do not think it is necessary. As the authors stated in Theorem 1, larger regularization makes ISAAC behave more like SGD. Therefore, getting similar loss and accuracy is no surprise.\n\n2.3, For Figure 2, there are several issues. First, hyper parameters are not fully revealed. For instance, what is the weight decay for each optimizer since weight decays large affects training convergence?  Second, only the training curve is reported. The author really should present both a training and validation curve. In many cases, we can have faster convergence on training dataset, but not for validation dataset. \n\n2.4, For Figure 6, the reported accuracy is obviously lower compared to results we usually have on CIFAR-10. The reason might be that the authors use SGD without momentum. However, I am not convinced under such a setting. SGD with momentum is a default setting in many training tasks. Without momentum, I do not think the results will provide meaningful comparisons and conclusions.\n\n\n3, Training with small batches should be further justified. I understand the authors stress the compute benefits of ISAAC in a small-batch regime (Theorem 3-ii). However, considering more general settings, the authors should well justify it: is it worth accelerating the training using small batches given the fact that large batches can also improve convergence performance even using SGD. Therefore, I think not only should the author provide results in small-batch regimes, training using large batches should also be evaluated and compared with other baselines.",
                "Questions": "See my comments above.",
                "Limitations": "No",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "In unconstrained optimisation, Newton's method uses inverse Hessian to determine the step size of the update. When applied to deep learning, the sheer size of the Hessian matrix makes Newton's method intractable. Among existing attempts to address this challenge, K-FAC is a promising approach. In practice, Tikhonov regularization/damping is used to avoid divergence.\nIn this paper, the authors introduced an extension to the standard Tikhonov damping for K-FAC. The main idea is to use two independent damping parameters (hyper-parameters for regularisation) instead of one damping parameter, one for the gradient factor and one for the activity factor, as shown in Equation (17). The authors explored special cases where the two parameters are either 0 or infinity. They also discussed the special case of setting one parameter to infinity, effectively removing the gradient factor in K-FAC. One major claim was that this activity-only form has an advantage in reduced computational complexity, although I don't find a theoretical comparison with K-FAC in this aspect. \nThe claim for computational efficiency was mostly supported via empirical evaluation.",
                "Strengths And Weaknesses": "Strengths:\n\nThe paper addresses an important problem: efficient approximation of Gaussian-Newton approximation\nThe exposition is mostly clear, especially if you are already familiar with the existing literature.\nThe experiments seem comprehensive.\n\nWeaknesses:\n\nIt is not clear what is the main contribution of this paper. Is it the two-parameter damping mechanism (What advantage do we gain)? Or is it the special case mentioned in Remark 3 (Why this is a still good approximation without g\u22a4g)? \nMany theoretical results presented look rather trivial.",
                "Questions": "What is the intuition behind Eq (21)? Compared with Eq (13), why is it a good approximation?",
                "Limitations": "N/A",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "soundness_avg": 2.75,
        "presentation_avg": 2.75,
        "contribution_avg": 2.5,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the paper addresses an important problem in efficient approximation of Gaussian-Newton approximation. The proposed method of using two independent damping parameters shows promise in reducing computational complexity without sacrificing performance. The experiments conducted are thorough and provide evidence of the effectiveness of the proposed method.\n\nWhile there are some limitations and weaknesses pointed out by the reviewers, such as the need for more baselines in the empirical evaluation and the need for further justification of training with small batches, the overall consensus is that the paper is technically solid and has potential impact.\n\nConsidering the strictness of the conference, which is set at 0.5, it is recommended to accept the paper. The confidence in this recommendation is certain, as the reviewers' comments have been carefully considered and the strengths of the paper outweigh the weaknesses."
    },
    "Information-Theoretic_Analysis_of_Unsupervised_Domain_Adaptation": {
        "link": "https://openreview.net//forum?id=cx5ViLfcVq",
        "pub_url": "https://openreview.net/forum?id=cx5ViLfcVq",
        "pdf_link": "https://openreview.net//pdf?id=cx5ViLfcVq",
        "paper_id": "cx5ViLfcVq",
        "title": "Information-Theoretic_Analysis_of_Unsupervised_Domain_Adaptation",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nThe reviewers agreed that the paper's novelty is limited and lacks proper justification. The extensive authors' discussion shows that they could improve the manuscript, but the number of modifications in the revised version would require another round of reviews.\nTherefore, I encourage the authors to submit an improved version of their work to an upcoming venue.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper provides two upper bounds for two notions of generalization errors; this first is the gap between the population risk in the target domain and the population risk in the source domain; the second is the gap between the population risk in the target domain and the empirical risk in the source domain. In addition, the paper presents two techniques for improving generalization in UDA and validate them experimentally.\nStrengths And Weaknesses: Originality\nThe paper's idea is not extremely novel, since there have been a lot of upper bounds for the first gap, such as [2].\nQuality\nThe technical part of the paper seems correct as far as I can see.\nClarity\nThe paper is well-written. \nSignificance\nThe question studied in the paper is significant. The generalization gap bounds inspire insights into algorithm designs.\nQuestions: \nThe upper bounds seem very loose. What is the first upper bound's superiority to the previous bounds mentioned in [2]?\nLimitations: The limitations of the presented analysis could be discussed in more detail.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper presents an information-theoretic analysis for unsupervised domain adaptation, where the authors considered two notions of the generalization errors in this context and present novel learning bounds. Some of these bounds recover the previous KL-based bounds under different conditions, and other bounds are algorithm-dependent that exploits the unlabelled target data, which inspired the designing of learning algorithms. The authors also demonstrate the effectiveness of these schemes on standard benchmark datasets.\nStrengths And Weaknesses: Some concerns:\n\nTo some extend, the results in section 4 were not surprised. The upper bounds for the population risks expressed by KL divergence were well established in the transfer learning literature, say the works by Ben-David. The issue is that such bounds are usually hard to compute and applied to algorithm designs. In addition, it is also very difficult to verify high tight such bounds are. Since this paper neither presented new proving techniques nor showed any tightness results on their presented upper bounds, I may question the usefulness of such bounds for addressing the core difficulty of transfer learning problems.\n\nIt seems that the number of samples in both source and target training data may play important roles in domain adaptation, which is referred to as the sample complexity issue in transfer learning. However, I do not see such characterizations in the bound presented in this paper. How does more target domain samples can effect the learning algorithms as well as the performances? This may need more detailed studies and discussions.\n\nThe authors mentioned \"This paper presents the first information-theoretic analysis for unsupervised domain adaptation\". This is a bit over strong statement, and I would not say this is the first paper to present such analyses, since there are many other theoretical papers in transfer learning area that had done such kind of analyses. The paper may present some new bounds, but shall not be the first in this area.\n\nThe most valuable part of this paper to me is the algorithm designs in section 5. However, it seems to me that the core idea of the proposed algorithm from the theoretical analyses in to add a L2 regularization term in the gradient decent updating, which has also been applied in many previous works. I wonder if the contribution of this paper is to provide another theoretical justification for the regularization term, or indeed there are novel steps in the algorithm that were not been considered before?\n\nThe equation between line 105 and 106, the second term on the right hand side should be R_{\\mu} instead of R_{\\mu'}.\nQuestions: No.\nLimitations: No.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The paper provides two types of information-theoretic bounds for unsupervised domain adaptation. The first is the PP generalization error, which bounds the gap between the source population risk and the target population risk. The second is the expected EP generalization error that bounds the expected gap between the target population risk and the source empirical risk. The PP generalization error is connected to the KL divergence-based marginal distribution matching method. And the EP generalization error bound is algorithm-dependent and intrigues two simple approaches that improve the KL method on rotated MNIST and digits dataset.\nStrengths And Weaknesses: Strengths\nThe whole paper is well-written and easy to follow. And the proposed algorithms seem to boost the performance of KL-divergence-based marginal distribution matching methods on the two datasets. \nWeakness\n\nThe originality and significance of the work are not obvious\n\nThe PP generalization bound related to KL divergence is actually a similar version to the JS divergence bound of [1]. \nBoth the PP and EP bound are related to the KL divergence of the two domain distributions \u03bc,\u03bc\u2032. However, this term is fixed and irrelevant to the algorithm given the domain distributions. Even though the paper mentioned some insights for learning the representation via minimizing the KL divergence, no rigorous theoretical analysis is provided.\nThe fundamental difficulty of UDA is not studied in this paper, e.g., the theoretical validity of the pseudo label. \n\nNot enough related work discussion\n\nThe paper is highly related to [2] and [3], which also studied UDA with information-theoretic tools, but no discussion is provided. \n\nExperimental evaluation is not adequate\n\nThe proposed algorithms (gradient penalty/controlling label information) in fact add a regularization for learning the source domain to avoid overfitting and improve cross-domain generalization.  Similar approaches exist in previous works like [1], but no comparison is conducted. \n\nTechnique Concerns\n\nSee the questions in the following section.\n[1] Shui, C., Chen, Q., Wen, J., Zhou, F., Gagn\u00e9, C. and Wang, B., 2020. Beyond H-divergence: Domain adaptation theory with Jensen-Shannon divergence.\n[2] Wu, Xuetong, et al. \"Information-theoretic analysis for transfer learning.\" 2020 IEEE International Symposium on Information Theory (ISIT). IEEE, 2020.\n[3] Jose, Sharu Theresa, and Osvaldo Simeone. \"Information-theoretic bounds on transfer generalization gap based on Jensen-Shannon divergence.\" 2021 29th European Signal Processing Conference (EUSIPCO). IEEE, 2021.\nQuestions: Major Concerns\n\nEquation (1) in the main paper seems problematic. EW,S[R\u03bc\u2032(W)\u2212RS(W)] equals to EW,S,SX\u2032\u2032[R\u03bc\u2032(W)\u2212RS(W)] when W,S and SX\u2032\u2032 are independent. However, W=A(S,SX\u2032\u2032) for UDA. \n\nThe first equation in Appendix Line 678 is unclear to me.\n\n\nMinor concerns\n\nThe subguassian assumption of loss function should be related to the specific distribution, for (X,Y)\u223c\u03bc and (X\u2032,Y\u2032)\u223c\u03bc\u2032. Assumption 2 is w.r.t. \u03bc, while Theorem 5.1 is w.r.t \u03bc\u2032.\nLine 112, typo PP -> EP\nLimitations: Yes, the authors have claimed that this work does not touch upon the fundamental difficulty in UDA or the lower bounds of generalization errors.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper focuses on the generalization bound of Unsupervised Domain Adaptation (UDA). The authors discuss two kinds of generalization errors and present the upper bounds of them respectively. The theoretical analysis are based on information theory and give inspiring insights into algorithm designs. The experiments validate the effectiveness of the algorithm on benchmark datasets.\nStrengths And Weaknesses: Pros:\n\nQuality: This paper has adequate contribution to the generalization bound of UDA problem. They focuse on two kinds of generalization bounds. For the first error bound, their works are similar to the traditional analysis, but they generalize them that they do not require specific loss function and specific classification settings. For the second error bound, their bounds involve W, which motivates the algorithm designs. They derive the bounds under different assumptions and divergence measures.\nOriginality: This is the first work to analyse the generalization bounds of UDA from an information-theoretic perspective, as the authors claim. In fact, I am not familiar with the information theoretical framwork (Donsker-Varadhan representation of KL divergence) used in this paper. So I am not very sure that the derivations in this paper are non-trival and novel.\nClarity: The writing is clear and easy to follow. The paper is well-organized.\nSignificance: The generalization bounds of UDA are worth exploring. This paper is of great significance to this research field.\n\nCons:\n\nSome extra explanations and remarks should be added. Some contexts and symbols about information theory are somewhat hard to read.  For example, above Line 241, IXj\u2032(W;Zi) is the disintegrated mutual information of W and Zi. According to the Definition 1, it involves the terms PW,Zi|X=Xj\u2032 and PW|X=Xj\u2032. What does it mean for the probability of W conditioned on an unlabeled sample X? It benifits for the readability of the paper if the authors add some explainations or remarks here.\nAbove Line 204, what is the distribution of W,W\u2032 in EW,W\u2032,X ?\nAlthough I understand the meaning of \u2113(w,z), it seems has a conflic with the previous notion \u2113(fw(X),Y).\nIn Theorem 5.1, 5.2, can we remove the term $\\frac{1}{mn}\\sum^{m}{j=1}\\sum^{n}{i=1},sincethesamples {X_j'},{Z_i} $ are i.i.d. for all i,j?\nQuestions: Q1. Compared Theorem 5.2 with Theorem 4.4, the difference between them is the first term of the bound in Theorem 5.2. And we know that Err can be bounded by Err~ plus a standard generalization error term on source domain. So, what is the difference between the first term of the bound in Theorem 5.2 and the standard generalization error term on source domain? Which one is tighter?\nOther questions can be found in Cons.\nLimitations: Yes.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper provides two upper bounds for two notions of generalization errors; this first is the gap between the population risk in the target domain and the population risk in the source domain; the second is the gap between the population risk in the target domain and the empirical risk in the source domain. In addition, the paper presents two techniques for improving generalization in UDA and validate them experimentally.",
                "Strengths And Weaknesses": "Originality\nThe paper's idea is not extremely novel, since there have been a lot of upper bounds for the first gap, such as [2].\nQuality\nThe technical part of the paper seems correct as far as I can see.\nClarity\nThe paper is well-written. \nSignificance\nThe question studied in the paper is significant. The generalization gap bounds inspire insights into algorithm designs.",
                "Questions": "The upper bounds seem very loose. What is the first upper bound's superiority to the previous bounds mentioned in [2]?",
                "Limitations": "The limitations of the presented analysis could be discussed in more detail.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper presents an information-theoretic analysis for unsupervised domain adaptation, where the authors considered two notions of the generalization errors in this context and present novel learning bounds. Some of these bounds recover the previous KL-based bounds under different conditions, and other bounds are algorithm-dependent that exploits the unlabelled target data, which inspired the designing of learning algorithms. The authors also demonstrate the effectiveness of these schemes on standard benchmark datasets.",
                "Strengths And Weaknesses": "Some concerns:\n\nTo some extend, the results in section 4 were not surprised. The upper bounds for the population risks expressed by KL divergence were well established in the transfer learning literature, say the works by Ben-David. The issue is that such bounds are usually hard to compute and applied to algorithm designs. In addition, it is also very difficult to verify high tight such bounds are. Since this paper neither presented new proving techniques nor showed any tightness results on their presented upper bounds, I may question the usefulness of such bounds for addressing the core difficulty of transfer learning problems.\n\nIt seems that the number of samples in both source and target training data may play important roles in domain adaptation, which is referred to as the sample complexity issue in transfer learning. However, I do not see such characterizations in the bound presented in this paper. How does more target domain samples can effect the learning algorithms as well as the performances? This may need more detailed studies and discussions.\n\nThe authors mentioned \"This paper presents the first information-theoretic analysis for unsupervised domain adaptation\". This is a bit over strong statement, and I would not say this is the first paper to present such analyses, since there are many other theoretical papers in transfer learning area that had done such kind of analyses. The paper may present some new bounds, but shall not be the first in this area.\n\nThe most valuable part of this paper to me is the algorithm designs in section 5. However, it seems to me that the core idea of the proposed algorithm from the theoretical analyses in to add a L2 regularization term in the gradient decent updating, which has also been applied in many previous works. I wonder if the contribution of this paper is to provide another theoretical justification for the regularization term, or indeed there are novel steps in the algorithm that were not been considered before?\n\nThe equation between line 105 and 106, the second term on the right hand side should be R_{\\mu} instead of R_{\\mu'}.",
                "Questions": "No.",
                "Limitations": "No.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper provides two types of information-theoretic bounds for unsupervised domain adaptation. The first is the PP generalization error, which bounds the gap between the source population risk and the target population risk. The second is the expected EP generalization error that bounds the expected gap between the target population risk and the source empirical risk. The PP generalization error is connected to the KL divergence-based marginal distribution matching method. And the EP generalization error bound is algorithm-dependent and intrigues two simple approaches that improve the KL method on rotated MNIST and digits dataset.",
                "Strengths And Weaknesses": "Strengths\nThe whole paper is well-written and easy to follow. And the proposed algorithms seem to boost the performance of KL-divergence-based marginal distribution matching methods on the two datasets. \nWeakness\n\nThe originality and significance of the work are not obvious\n\nThe PP generalization bound related to KL divergence is actually a similar version to the JS divergence bound of [1]. \nBoth the PP and EP bound are related to the KL divergence of the two domain distributions \u03bc,\u03bc\u2032. However, this term is fixed and irrelevant to the algorithm given the domain distributions. Even though the paper mentioned some insights for learning the representation via minimizing the KL divergence, no rigorous theoretical analysis is provided.\nThe fundamental difficulty of UDA is not studied in this paper, e.g., the theoretical validity of the pseudo label. \n\nNot enough related work discussion\n\nThe paper is highly related to [2] and [3], which also studied UDA with information-theoretic tools, but no discussion is provided. \n\nExperimental evaluation is not adequate\n\nThe proposed algorithms (gradient penalty/controlling label information) in fact add a regularization for learning the source domain to avoid overfitting and improve cross-domain generalization.  Similar approaches exist in previous works like [1], but no comparison is conducted. \n\nTechnique Concerns\n\nSee the questions in the following section.\n[1] Shui, C., Chen, Q., Wen, J., Zhou, F., Gagn\u00e9, C. and Wang, B., 2020. Beyond H-divergence: Domain adaptation theory with Jensen-Shannon divergence.\n[2] Wu, Xuetong, et al. \"Information-theoretic analysis for transfer learning.\" 2020 IEEE International Symposium on Information Theory (ISIT). IEEE, 2020.\n[3] Jose, Sharu Theresa, and Osvaldo Simeone. \"Information-theoretic bounds on transfer generalization gap based on Jensen-Shannon divergence.\" 2021 29th European Signal Processing Conference (EUSIPCO). IEEE, 2021.",
                "Questions": "Major Concerns\n\nEquation (1) in the main paper seems problematic. EW,S[R\u03bc\u2032(W)\u2212RS(W)] equals to EW,S,SX\u2032\u2032[R\u03bc\u2032(W)\u2212RS(W)] when W,S and SX\u2032\u2032 are independent. However, W=A(S,SX\u2032\u2032) for UDA. \n\nThe first equation in Appendix Line 678 is unclear to me.\n\n\nMinor concerns\n\nThe subguassian assumption of loss function should be related to the specific distribution, for (X,Y)\u223c\u03bc and (X\u2032,Y\u2032)\u223c\u03bc\u2032. Assumption 2 is w.r.t. \u03bc, while Theorem 5.1 is w.r.t \u03bc\u2032.\nLine 112, typo PP -> EP",
                "Limitations": "Yes, the authors have claimed that this work does not touch upon the fundamental difficulty in UDA or the lower bounds of generalization errors.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper focuses on the generalization bound of Unsupervised Domain Adaptation (UDA). The authors discuss two kinds of generalization errors and present the upper bounds of them respectively. The theoretical analysis are based on information theory and give inspiring insights into algorithm designs. The experiments validate the effectiveness of the algorithm on benchmark datasets.",
                "Strengths And Weaknesses": "Pros:\n\nQuality: This paper has adequate contribution to the generalization bound of UDA problem. They focuse on two kinds of generalization bounds. For the first error bound, their works are similar to the traditional analysis, but they generalize them that they do not require specific loss function and specific classification settings. For the second error bound, their bounds involve W, which motivates the algorithm designs. They derive the bounds under different assumptions and divergence measures.\nOriginality: This is the first work to analyse the generalization bounds of UDA from an information-theoretic perspective, as the authors claim. In fact, I am not familiar with the information theoretical framwork (Donsker-Varadhan representation of KL divergence) used in this paper. So I am not very sure that the derivations in this paper are non-trival and novel.\nClarity: The writing is clear and easy to follow. The paper is well-organized.\nSignificance: The generalization bounds of UDA are worth exploring. This paper is of great significance to this research field.\n\nCons:\n\nSome extra explanations and remarks should be added. Some contexts and symbols about information theory are somewhat hard to read.  For example, above Line 241, IXj\u2032(W;Zi) is the disintegrated mutual information of W and Zi. According to the Definition 1, it involves the terms PW,Zi|X=Xj\u2032 and PW|X=Xj\u2032. What does it mean for the probability of W conditioned on an unlabeled sample X? It benifits for the readability of the paper if the authors add some explainations or remarks here.\nAbove Line 204, what is the distribution of W,W\u2032 in EW,W\u2032,X ?\nAlthough I understand the meaning of \u2113(w,z), it seems has a conflic with the previous notion \u2113(fw(X),Y).\nIn Theorem 5.1, 5.2, can we remove the term $\\frac{1}{mn}\\sum^{m}{j=1}\\sum^{n}{i=1},sincethesamples {X_j'},{Z_i} $ are i.i.d. for all i,j?",
                "Questions": "Q1. Compared Theorem 5.2 with Theorem 4.4, the difference between them is the first term of the bound in Theorem 5.2. And we know that Err can be bounded by Err~ plus a standard generalization error term on source domain. So, what is the difference between the first term of the bound in Theorem 5.2 and the standard generalization error term on source domain? Which one is tighter?\nOther questions can be found in Cons.",
                "Limitations": "Yes.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "soundness_avg": 2.5,
        "presentation_avg": 2.75,
        "contribution_avg": 2.25,
        "ai_sum_meta": "Recommendation: Reject\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that the paper has some strengths, such as being well-written and technically solid. However, there are also several weaknesses and concerns raised by the reviewers. The originality and significance of the work are not clearly demonstrated, and some of the upper bounds presented in the paper are not novel compared to previous works. Additionally, there are limitations in the analysis and discussions, and the related work discussion is not adequate. The experimental evaluation is also not sufficient, and the proposed algorithms do not seem to offer significant improvements compared to previous works. Overall, the reasons to reject the paper, such as limited evaluation and lack of novelty, outweigh the reasons to accept it. Therefore, I recommend rejecting the paper."
    },
    "Foreseeing_Privacy_Threats_from_Gradient_Inversion_Through_the_Lens_of_Angular_Lipschitz_Smoothness": {
        "link": "https://openreview.net//forum?id=nzuuao_V-B_",
        "pub_url": "https://openreview.net/forum?id=nzuuao_V-B_",
        "pdf_link": "https://openreview.net//pdf?id=nzuuao_V-B_",
        "paper_id": "nzuuao_V-B_",
        "title": "Foreseeing_Privacy_Threats_from_Gradient_Inversion_Through_the_Lens_of_Angular_Lipschitz_Smoothness",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nSeveral analyses provided in the paper are not novel and known in the literature. The black-box setting is not properly motivated and impractical. The angular Lipschitz constant is a good contribution, but it seems to be only a small part of the paper. For these reasons, the reviewers are not convinced that the contribution of this paper is significant enough.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper first evaluate current gradient inversion attacks for both implicit and explicit model changes. It shows that when the batch norm mode, training epochs, skip connection or channel size is different, the result of gradient inversion attacks also changes. Finally, it proposes angular lipschitz smoothness and shows its positive correlation to the success of gradient inversion attacks.\nStrengths And Weaknesses: Strengths\n\nIt is the first paper to study gradient inversion attacks on the different settings of training procedures and models, including batch-norm mode, skip connection and channel size.\nIts second part tries to find another signal, which is able to indicate the leakage in the end. Such signal, if it has good performance, would be useful in practice.\nThe paper is well structured.\n\nWeaknesses\nThe main weakness of this paper is that some experiment results are not very reliable and and some conclusions from the results are ambiguous.\n\nResults of BN: \n (a). Why all MSE numbers in table 1 are mostly larger than 1? If all images are lying in the 0-1 cube, MSE > 1 means nothing recovered.  However, results from previous work already shows the success of image recovery at some setting of BN.\n (b). What is the conclusion from the BN experiment results?\nResults of skip connection: why the gradient inversion attack is failed for the ConvNet? [1] and its following work all shows the success for ConvNet.\nResults of channel size: the result \"the reconstruction quality worsens as the number of channels increases for BN set to the train mode\" is lack of explanation.\nAngular Lipschitz smoothness: The intuition from theorem 1 is that smaller L means faster dropping at one step of optimization. However, it doesn't mean the minimum value of L_grad^x would be smaller, i.e. the reconstruction result is better. As the experiment details are missed in both main text and appendix, I am hypothesizing it is likely due to the unfair optimization set-up, e.g. the larger L_grad might need more iterations to converge, etc.\n\nAs for the experiment set-up, what gradient inversion attack is evaluated for those experiments?\n[1] Zhu, Ligeng, Zhijian Liu, and Song Han. \"Deep leakage from gradients.\" Advances in neural information processing systems 32 (2019).\n-------After Discussion--------\nI have read all responses and I'll keep my score. Thank the authors for the clarification and the additional experiment results. I hope authors can improve their paper by incorporating these results in the revision and improve their writing by highlighting the conclusions for each setting (BN, skip connection, training stages etc.) with the clear conditions.\nQuestions: See weaknesses for details.\nLimitations: Yes, the authors fairly describe the limitations.\nEthics Flag: No\nSoundness: 1 poor\nPresentation: 3 good\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper works on the privacy attacks in the black-box FL setting, specifically using the gradient inversion methods. The contribution is on the image tasks and empirically solid. Different aspects of models are systematically evaluated to identity the vulnerability to privacy attacks. The authors also propose a new measure, the angular Lipschitz constant, to measure the privacy risk.\nStrengths And Weaknesses: Strength:\nOverall the paper is well-written and tackles a clear task. The FL privacy is an important and practical concern, especially in the black-box setting in which the authors have worked on. The motivation of an honest-but-curious host could be realistic. Empirically speaking, the ablation study of BN modes, number of channels, skip connection, etc. is thorough. From a theoretical viewpoint, the proposed angular Lipschitz constant has nice properties (scale-invariance); the theorem has a premise reasonably justified.\nWeakness:\nMy main concern is the impact of this paper: the experiment is limited to one simple dataset, thus limiting my confidence that the trends observed in this paper can hold in a broader range of cases (see more comments in \"Limitations\"). All conclusions except the scale-invariant property of the new Lipschitz measure are empirical, which requires more experiments to support the trends claimed in the paper.\nQuestions: See \"Weakness\" and \"Limitations\".\nLimitations: The limitations are discussed in the paper. However, I believe there could be additional limitations that worth consideration. \nFor example, the experiment is very limited, only CIFAR datasets are tested, which contains tiny images only. It would be desirable to understand how the gradient inversion attack work on moderate images (e.g. CelebA or ImageNette) and even maybe on language samples.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The submission \"Foreseeing Privacy Threats from Gradient Inversion Through the Lens of Angular Lipschitz Smoothness\" is concerned with gradient inversion attacks in federated learning. The first part of this submission contains additional results and ablation studies about the success conditions of such attacks. The second part proposes a new measure of vulnerability that is claimed to be a key to client-sided defenses.\nStrengths And Weaknesses: I, unfortunately,  have several points of criticism with this work, which I will list out below:\n\nThis submission analyzes gradient inversion attacks as developed around 2019/2020, but of the analysis given in this submission has been included in other work also evaluating these attacks since. Questions brought up concerning batch normalization have been  already been analyzed in works such as Huang et al., \"Evaluating Gradient Inversion Attacks and Defenses\nin Federated Learning\", from last year's NeurIPS. Solutions to the normalization question have then been proposed in Hatamizadeh et al., \"Do Gradient Inversion Attacks Make Federated Learning Unsafe?\". Whether labels are required was also discussed in Huang et al., and work such as Wainakh et al, \"User Label Leakage from Gradients in Federated Learning\" have made strides towards showing that label knowledge is not a requirement for a succesful attack. The impact of training state in recovery success has been discussed several times, from Zhu et al, \"Deep Leakage from Gradients\", Geiping et al., \"Inverting Gradients - How easy is it to break privacy in Federated Learning\" and also appears in follow-up work such as Wei et al., \"A Framework for Evaluating Gradient Leakage Attacks in Federated Learning\".\n\nThe submission states that choices in Zhu et al., were based on the unavailability of automatic differentiation. Yet, AD was certainly already developed and present in 2018! These paragraphs in the related work are incorrect, and it is unclear what \"computed the loss in closed form\" here should mean. The existence of closed form solutions (which Zhu et al. do not employ, as they also backpropagate gradients using AD) is unrelated to the smoothness of the loss function. Zhu et al. use smooth activations because their optimization strategy is based on an L-BFGS solver that nominally requires well-defined higher-order derivatives. Later works use adaptive first-order optimizer and hence drop this requirement.\n\nI am doubtful about the proposed black-box setting. The submission proposes a black-box setting in which the global model parameters are hidden from the user, but the user application requires these parameters to compute the update gradient. The parameters have to be send to the user device, and the user has full control over their device, so the users necessarily have access to model parameters as well. \n\nFurther, for a user to use known inversion attacks to gauge their loss of privacy is an inherently unsafe proposal. Even if a user uses these attacks themselves and finds that they cannot reconstruct their data, this is no guarantee of privacy! These attacks can only be used to prove vulnerabilty, never to ascertain safety.\n\nThe introduction mentions evaluation of additional models. However in the experimental section I find only the ConvNet and ResNet variations used in previous work?\n\nMinor: The cited work by Bauschke, Bolte and Teboulle is one of their few work where Lipschitz smoothness of the gradient in the classical sense is not actually required, in contrast to how this work is cited here.\n\nI like the general idea of the section concerning angular Lipschitz smoothness, but the concept makes up such a small part of the submission that it is difficult to quantify its effectiveness. The submission shows some correlation with attack success if measured in LPIPS, but the correlation is not overly strong and it is unclear whether this is a strong argument for robustness. LPIPS scores are only be a limited measure of safety. The main question here would be whether some threshold of angular Lipschity smoothness would imply that no reconstruction succeeds. The measure discussed in Yin et al., \"See through gradients\" might be helpful here. Further it would be necessary to discuss whether this measure is robust to adaptive attacks, meaning whether this proposed measure can be \"gamed\" by the attacker in some way. For example, angular smoothness might correlate with gradient obfuscation which would undermine its effectiveness.\n\nFrom a more general vantage point, I do think that this submission makes a categorical mistake about the nature of safety. The submission shows scenarios where the (even unmodified) baseline attack works more or less well and concludes from this that the attack should be evaluated in more scenarios, but this misses the asymetric nature of safety research. It is not necessary for a single attack to work optimally in all scenarios, in each scenario the question is whether an attack could exist that breaks privacy. Will small modifications as discussed in this work, categorically defeat all attacks and prove a reliable defense in the future? Will angular smoothness defend against adaptive attacks that circumvent gradient matching losses?\nQuestions: Maybe I misunderstood the intent of the submission concerning the black-box setting. I would be glad about a correction or additional insights why this is a meaningful setting.\nLimitations: The submission discussses some limitations, however limitations of the proposed measure are not discussed. There is not enough evidence presented whether this really would be a key factor in future defenses.\nEthics Flag: No\nSoundness: 1 poor\nPresentation: 3 good\nContribution: 1 poor\nRating: 2: Strong Reject: For instance, a paper with major technical flaws, and/or poor evaluation, limited impact, poor reproducibility and mostly unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: This paper studied the gradient inversion problem where an honest-but-curious server aims to reveal clients\u2019 private data from model weights and gradients shared by clients in federated learning (FL). The paper first evaluated SOTA gradient inversion algorithms (mainly [6] with an additional BN-related loss term), under implicit model variations (different BN modes and training epochs with the same model architecture) and explicit variations (different model architectures). The evaluation showed that the reconstruction results vary across model variations both qualitatively and quantitively. The paper then proposed a measure of angular Lipschitz constant to indicate the outcome of reconstruction, which was shown to be stronger correlated with LPIPS and attack loss drop than gradient norm.\nStrengths And Weaknesses: Strengths:\n\nThe paper addressed an interesting problem of evaluating gradient inversion algorithms for different models. A systematic experimental study may help gain insights about the mechanism of gradient inversion.\nThe paper made a good summarization on the optimization-based gradient inversion approach and related prior art in Section 2.\nThe paper showed some interesting results regarding the BN train mode. Firstly, the inversion achieves the best quantitative performance at early training stages (e=5). Secondly, the inversion achieves best results for ResNet18 than for ResNet18-2 and ResNet18-4, showing that wider networks are not necessarily easier to attack.\n\nWeaknesses:\n\nThe main contribution of this paper seems ambiguous. The title and abstract suggest that the paper mainly proposes a new measure, angular Lipschitz constant, for assessing inversion attacks, but a large body of the paper focuses on re-evaluation of existing methods over model variations. While the re-evaluation is valuable, it should be more clearly stated as primary results or just motivational study.\nThe scope of re-evaluation of SOTA algorithms in this paper overlaps with [10], which focused on evaluating gradient inversion attacks and defenses. In particular, [10] evaluated the algorithm in [6] with BN loss term (as in equation (2) of this paper), and considered different settings on knowledge of BN statistics. What is the difference between the BN settings of this paper and [10]? A detailed discussion and comparison with [10] would be beneficial.\nThe re-evaluation of SOTA algorithms was performed on limited variations. If the empirical study is positioned as the primary contribution, a wider range of models may be considered, such as initialization schemes (pre-trained or random) and random seeds for implicit variations, and more architectures beyond ResNet18 with different widths for explicit variations.\nThe paper only considered CIFAR100 images in experiments, but not higher-resolution (e.g. ImageNet) images.\nThe paper motivates the proposed angular Lipschitz constant measure with the case that clients may only have access to gradients provided by the server. However, wouldn\u2019t the client need white-box access to compute gradients using private local data for model training in FL? If the client only has black-box access, what is the interplay between model training, gradient inversion, and risk assessing (Section 4)? And how does the client compute the measure (in Line 277) through random sampling?\nQuestions: \nThe paper mentioned about knowledge of target labels and batch size in previous work. What are the related settings in experiments of this paper? Batch size may be an important factor for observing the effect of BN modes on the performance.\nIt is stated in Line 168 that the server \u201ccan send a global model with BN layers set to any mode\u201d. But BN modes are about whether to use running mean/variance or current batch\u2019s mean/variance in BN layers, and the computation is done on clients. How can an honest-but-curious server alter the BN mode without being noticed?\nThe computation of the angular Lipschitz constant (defined in Line 277) is done through randomly sampling from Gaussian. Can this measure be manipulated by scaling the input x^*, for fixed variance of Gaussian noises? Is the input x^* normalized to compute the measure?\nIn the theoretical result, the loss is guaranteed to monotonically decrease only when the step size \\mu is small enough (optimally =1/(2L^2)). Are the learning rates sufficiently small in experiments?\nWhat is \\delta in Lines 458, 465 and 466?\nBN statistics are used in two places in the inversion process, one in equation (2) as a loss term, and another in the BN layers of the networks (in train/eval modes). Which one affects the performance of inversion algorithms more significantly?\nLimitations: The paper discussed limitations in Section 5.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 2 fair\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper first evaluate current gradient inversion attacks for both implicit and explicit model changes. It shows that when the batch norm mode, training epochs, skip connection or channel size is different, the result of gradient inversion attacks also changes. Finally, it proposes angular lipschitz smoothness and shows its positive correlation to the success of gradient inversion attacks.",
                "Strengths And Weaknesses": "Strengths\n\nIt is the first paper to study gradient inversion attacks on the different settings of training procedures and models, including batch-norm mode, skip connection and channel size.\nIts second part tries to find another signal, which is able to indicate the leakage in the end. Such signal, if it has good performance, would be useful in practice.\nThe paper is well structured.\n\nWeaknesses\nThe main weakness of this paper is that some experiment results are not very reliable and and some conclusions from the results are ambiguous.\n\nResults of BN: \n (a). Why all MSE numbers in table 1 are mostly larger than 1? If all images are lying in the 0-1 cube, MSE > 1 means nothing recovered.  However, results from previous work already shows the success of image recovery at some setting of BN.\n (b). What is the conclusion from the BN experiment results?\nResults of skip connection: why the gradient inversion attack is failed for the ConvNet? [1] and its following work all shows the success for ConvNet.\nResults of channel size: the result \"the reconstruction quality worsens as the number of channels increases for BN set to the train mode\" is lack of explanation.\nAngular Lipschitz smoothness: The intuition from theorem 1 is that smaller L means faster dropping at one step of optimization. However, it doesn't mean the minimum value of L_grad^x would be smaller, i.e. the reconstruction result is better. As the experiment details are missed in both main text and appendix, I am hypothesizing it is likely due to the unfair optimization set-up, e.g. the larger L_grad might need more iterations to converge, etc.\n\nAs for the experiment set-up, what gradient inversion attack is evaluated for those experiments?\n[1] Zhu, Ligeng, Zhijian Liu, and Song Han. \"Deep leakage from gradients.\" Advances in neural information processing systems 32 (2019).\n-------After Discussion--------\nI have read all responses and I'll keep my score. Thank the authors for the clarification and the additional experiment results. I hope authors can improve their paper by incorporating these results in the revision and improve their writing by highlighting the conclusions for each setting (BN, skip connection, training stages etc.) with the clear conditions.",
                "Questions": "See weaknesses for details.",
                "Limitations": "Yes, the authors fairly describe the limitations.",
                "Ethics Flag": "No",
                "Soundness": "1 poor",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper works on the privacy attacks in the black-box FL setting, specifically using the gradient inversion methods. The contribution is on the image tasks and empirically solid. Different aspects of models are systematically evaluated to identity the vulnerability to privacy attacks. The authors also propose a new measure, the angular Lipschitz constant, to measure the privacy risk.",
                "Strengths And Weaknesses": "Strength:\nOverall the paper is well-written and tackles a clear task. The FL privacy is an important and practical concern, especially in the black-box setting in which the authors have worked on. The motivation of an honest-but-curious host could be realistic. Empirically speaking, the ablation study of BN modes, number of channels, skip connection, etc. is thorough. From a theoretical viewpoint, the proposed angular Lipschitz constant has nice properties (scale-invariance); the theorem has a premise reasonably justified.\nWeakness:\nMy main concern is the impact of this paper: the experiment is limited to one simple dataset, thus limiting my confidence that the trends observed in this paper can hold in a broader range of cases (see more comments in \"Limitations\"). All conclusions except the scale-invariant property of the new Lipschitz measure are empirical, which requires more experiments to support the trends claimed in the paper.",
                "Questions": "See \"Weakness\" and \"Limitations\".",
                "Limitations": "The limitations are discussed in the paper. However, I believe there could be additional limitations that worth consideration. \nFor example, the experiment is very limited, only CIFAR datasets are tested, which contains tiny images only. It would be desirable to understand how the gradient inversion attack work on moderate images (e.g. CelebA or ImageNette) and even maybe on language samples.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The submission \"Foreseeing Privacy Threats from Gradient Inversion Through the Lens of Angular Lipschitz Smoothness\" is concerned with gradient inversion attacks in federated learning. The first part of this submission contains additional results and ablation studies about the success conditions of such attacks. The second part proposes a new measure of vulnerability that is claimed to be a key to client-sided defenses.",
                "Strengths And Weaknesses": "I, unfortunately,  have several points of criticism with this work, which I will list out below:\n\nThis submission analyzes gradient inversion attacks as developed around 2019/2020, but of the analysis given in this submission has been included in other work also evaluating these attacks since. Questions brought up concerning batch normalization have been  already been analyzed in works such as Huang et al., \"Evaluating Gradient Inversion Attacks and Defenses\nin Federated Learning\", from last year's NeurIPS. Solutions to the normalization question have then been proposed in Hatamizadeh et al., \"Do Gradient Inversion Attacks Make Federated Learning Unsafe?\". Whether labels are required was also discussed in Huang et al., and work such as Wainakh et al, \"User Label Leakage from Gradients in Federated Learning\" have made strides towards showing that label knowledge is not a requirement for a succesful attack. The impact of training state in recovery success has been discussed several times, from Zhu et al, \"Deep Leakage from Gradients\", Geiping et al., \"Inverting Gradients - How easy is it to break privacy in Federated Learning\" and also appears in follow-up work such as Wei et al., \"A Framework for Evaluating Gradient Leakage Attacks in Federated Learning\".\n\nThe submission states that choices in Zhu et al., were based on the unavailability of automatic differentiation. Yet, AD was certainly already developed and present in 2018! These paragraphs in the related work are incorrect, and it is unclear what \"computed the loss in closed form\" here should mean. The existence of closed form solutions (which Zhu et al. do not employ, as they also backpropagate gradients using AD) is unrelated to the smoothness of the loss function. Zhu et al. use smooth activations because their optimization strategy is based on an L-BFGS solver that nominally requires well-defined higher-order derivatives. Later works use adaptive first-order optimizer and hence drop this requirement.\n\nI am doubtful about the proposed black-box setting. The submission proposes a black-box setting in which the global model parameters are hidden from the user, but the user application requires these parameters to compute the update gradient. The parameters have to be send to the user device, and the user has full control over their device, so the users necessarily have access to model parameters as well. \n\nFurther, for a user to use known inversion attacks to gauge their loss of privacy is an inherently unsafe proposal. Even if a user uses these attacks themselves and finds that they cannot reconstruct their data, this is no guarantee of privacy! These attacks can only be used to prove vulnerabilty, never to ascertain safety.\n\nThe introduction mentions evaluation of additional models. However in the experimental section I find only the ConvNet and ResNet variations used in previous work?\n\nMinor: The cited work by Bauschke, Bolte and Teboulle is one of their few work where Lipschitz smoothness of the gradient in the classical sense is not actually required, in contrast to how this work is cited here.\n\nI like the general idea of the section concerning angular Lipschitz smoothness, but the concept makes up such a small part of the submission that it is difficult to quantify its effectiveness. The submission shows some correlation with attack success if measured in LPIPS, but the correlation is not overly strong and it is unclear whether this is a strong argument for robustness. LPIPS scores are only be a limited measure of safety. The main question here would be whether some threshold of angular Lipschity smoothness would imply that no reconstruction succeeds. The measure discussed in Yin et al., \"See through gradients\" might be helpful here. Further it would be necessary to discuss whether this measure is robust to adaptive attacks, meaning whether this proposed measure can be \"gamed\" by the attacker in some way. For example, angular smoothness might correlate with gradient obfuscation which would undermine its effectiveness.\n\nFrom a more general vantage point, I do think that this submission makes a categorical mistake about the nature of safety. The submission shows scenarios where the (even unmodified) baseline attack works more or less well and concludes from this that the attack should be evaluated in more scenarios, but this misses the asymetric nature of safety research. It is not necessary for a single attack to work optimally in all scenarios, in each scenario the question is whether an attack could exist that breaks privacy. Will small modifications as discussed in this work, categorically defeat all attacks and prove a reliable defense in the future? Will angular smoothness defend against adaptive attacks that circumvent gradient matching losses?",
                "Questions": "Maybe I misunderstood the intent of the submission concerning the black-box setting. I would be glad about a correction or additional insights why this is a meaningful setting.",
                "Limitations": "The submission discussses some limitations, however limitations of the proposed measure are not discussed. There is not enough evidence presented whether this really would be a key factor in future defenses.",
                "Ethics Flag": "No",
                "Soundness": "1 poor",
                "Presentation": "3 good",
                "Contribution": "1 poor",
                "Rating": "2: Strong Reject: For instance, a paper with major technical flaws, and/or poor evaluation, limited impact, poor reproducibility and mostly unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper studied the gradient inversion problem where an honest-but-curious server aims to reveal clients\u2019 private data from model weights and gradients shared by clients in federated learning (FL). The paper first evaluated SOTA gradient inversion algorithms (mainly [6] with an additional BN-related loss term), under implicit model variations (different BN modes and training epochs with the same model architecture) and explicit variations (different model architectures). The evaluation showed that the reconstruction results vary across model variations both qualitatively and quantitively. The paper then proposed a measure of angular Lipschitz constant to indicate the outcome of reconstruction, which was shown to be stronger correlated with LPIPS and attack loss drop than gradient norm.",
                "Strengths And Weaknesses": "Strengths:\n\nThe paper addressed an interesting problem of evaluating gradient inversion algorithms for different models. A systematic experimental study may help gain insights about the mechanism of gradient inversion.\nThe paper made a good summarization on the optimization-based gradient inversion approach and related prior art in Section 2.\nThe paper showed some interesting results regarding the BN train mode. Firstly, the inversion achieves the best quantitative performance at early training stages (e=5). Secondly, the inversion achieves best results for ResNet18 than for ResNet18-2 and ResNet18-4, showing that wider networks are not necessarily easier to attack.\n\nWeaknesses:\n\nThe main contribution of this paper seems ambiguous. The title and abstract suggest that the paper mainly proposes a new measure, angular Lipschitz constant, for assessing inversion attacks, but a large body of the paper focuses on re-evaluation of existing methods over model variations. While the re-evaluation is valuable, it should be more clearly stated as primary results or just motivational study.\nThe scope of re-evaluation of SOTA algorithms in this paper overlaps with [10], which focused on evaluating gradient inversion attacks and defenses. In particular, [10] evaluated the algorithm in [6] with BN loss term (as in equation (2) of this paper), and considered different settings on knowledge of BN statistics. What is the difference between the BN settings of this paper and [10]? A detailed discussion and comparison with [10] would be beneficial.\nThe re-evaluation of SOTA algorithms was performed on limited variations. If the empirical study is positioned as the primary contribution, a wider range of models may be considered, such as initialization schemes (pre-trained or random) and random seeds for implicit variations, and more architectures beyond ResNet18 with different widths for explicit variations.\nThe paper only considered CIFAR100 images in experiments, but not higher-resolution (e.g. ImageNet) images.\nThe paper motivates the proposed angular Lipschitz constant measure with the case that clients may only have access to gradients provided by the server. However, wouldn\u2019t the client need white-box access to compute gradients using private local data for model training in FL? If the client only has black-box access, what is the interplay between model training, gradient inversion, and risk assessing (Section 4)? And how does the client compute the measure (in Line 277) through random sampling?",
                "Questions": "The paper mentioned about knowledge of target labels and batch size in previous work. What are the related settings in experiments of this paper? Batch size may be an important factor for observing the effect of BN modes on the performance.\nIt is stated in Line 168 that the server \u201ccan send a global model with BN layers set to any mode\u201d. But BN modes are about whether to use running mean/variance or current batch\u2019s mean/variance in BN layers, and the computation is done on clients. How can an honest-but-curious server alter the BN mode without being noticed?\nThe computation of the angular Lipschitz constant (defined in Line 277) is done through randomly sampling from Gaussian. Can this measure be manipulated by scaling the input x^*, for fixed variance of Gaussian noises? Is the input x^* normalized to compute the measure?\nIn the theoretical result, the loss is guaranteed to monotonically decrease only when the step size \\mu is small enough (optimally =1/(2L^2)). Are the learning rates sufficiently small in experiments?\nWhat is \\delta in Lines 458, 465 and 466?\nBN statistics are used in two places in the inversion process, one in equation (2) as a loss term, and another in the BN layers of the networks (in train/eval modes). Which one affects the performance of inversion algorithms more significantly?",
                "Limitations": "The paper discussed limitations in Section 5.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "soundness_avg": 1.75,
        "presentation_avg": 2.75,
        "contribution_avg": 2.0,
        "ai_sum_meta": "Recommendation: Reject\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from other reviewers, it is clear that there are several weaknesses and limitations in this paper. Reviewer 1 points out that some experiment results are not reliable and some conclusions are ambiguous. Reviewer 2 raises concerns about the limited scope of the experiments and the lack of evidence to support the trends claimed in the paper. Reviewer 3 criticizes the paper for not considering prior work that has already analyzed the same gradient inversion attacks and for proposing a black-box setting that may not be meaningful. Reviewer 4 also questions the main contribution of the paper and suggests that a wider range of models and datasets should be considered.\n\nConsidering these concerns and limitations, I agree with the reviewers' recommendation to reject this paper. The weaknesses and limitations identified in the reviews indicate that the paper has major technical flaws, weak evaluation, limited impact, and incompletely addressed ethical considerations. Therefore, I believe that rejecting this paper is the appropriate decision."
    },
    "Federated_Hypergradient_Descent": {
        "link": "https://openreview.net//forum?id=sQ2LdeHNMej",
        "pub_url": "https://openreview.net/forum?id=sQ2LdeHNMej",
        "pdf_link": "https://openreview.net//pdf?id=sQ2LdeHNMej",
        "paper_id": "sQ2LdeHNMej",
        "title": "Federated_Hypergradient_Descent",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nWe thank the authors and the reviewers for their involvement in this interactive reviewing process. While the paper clearly generated interest and brings new notions to the community, we felt that a major revision is necessary before the paper can be a successfull NeurIPS submission. Consequently, we unfortunately recommend rejection. Points that stood out are \n\nat least one essential assumption is simultaneously strong, hard to check in practice, and not appropriately discussed in the original version;\nunusual but central notions like discrete convexity and hypergradients are not appropriately introduced. This made important technical parts of the paper hard to proofread;\nlack of some natural baselines.\n\nWe hope that the detailed discussions will be useful in further improving the manuscript.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper proposes to optimize the hyperparameters and parameters of a federated learning model jointly via gradient descent in an online fashion. To achieve this, the paper extends previous works on hypergradient to derives analytical gradients with respect to the local learning rate and the number of gradient steps. The paper analyzes the convergence of the proposed method and verifies the empirical improvement over FedAvg using real-world FL experiments.\nStrengths And Weaknesses: Strengths:\n\nThe proposed method is able to jointly optimize the hyperparameters and weight parameters of an FL model in a one-shot online manner, which is a natural and promising direction.\nThe approach taken by the paper is reasonable: derive the gradient w.r.t. the hyperparameters of interest, and then use gradient descent to optimize them together with model parameters.\n\nWeaknesses:\n\nA few related works are missing which I have listed below. Reference [a] aims at single-shot hyperparameter optimization for FL, i.e., they aim to identify a single set of hyperparameters which work well for multiple applications, and hence should be cited in the first paragraph of Section 2; [b] also used Bayesian optimization for hyperparameter optimization in FL and hence should be added to lines 114-116; [c] provided a benchmark for federated hyperparameter optimization.[a] Single-shot Hyper-parameter Optimization for Federated Learning: A General Algorithm & Analysis, 2022.[b] Differentially Private Federated Bayesian Optimization with Distributed Exploration, NeurIPS 2021.[c] FedHPO-B: A Benchmark Suite for Federated Hyperparameter Optimization, 2022.   \nIn the experiments, the proposed method is only compared with vanilla FedAvg, which may not be enough especially since a number of related works on single-shot federated hyperparameter optimization have been listed in Section 2. Even if comparisons are not possible, some justifications should be given.\nTheorem 3: instead of listing the detailed expressions of the entire theorem, I would prefer to see some interpretations/insights regarding the theoretical results. For example, how do the additional components introduced by the proposed algorithm (i.e., adaptive tuning of \u03b7 and K) affect the convergence of FedAvg? Are there conditions under which these additional components can lead to better convergence then standard FedAvg according to Theorem 3?\nPerhaps partially due to my unfamiliarity with gradient-based optimization, I feel that some of the technical details should be given more explanations. Firstly, Assumption 2 may need some further explanations and justifications. For example, xt and Et haven't been introduced till this point. A justification should be given as to how realistic this assumption is. Secondly, in Equation (5), some more explanations on how the last \u2248 is derived are needed. Next, in equations (14) and (15), why are these two equations designed in this way?\nThe paper has many typos, for example:-- line 34: a -> an\n-- line 56: justify -> justifying; a -> an\n-- line 104: directing -> directly\n-- line 145: K should be Ki?\nQuestions: I've listed a few questions and comments as \"Weaknesses\" in the section above.\nLimitations: A limitation and potential negative societal impact are both discussed.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: I am not an expert in this area and do not know anything about federated learning. The last time I worked directly with hyperparameter optimization approaches was in 2017 but was focused on offline hyperparameter optimization and not in the context of federated learning. As such, my review is not very insightful.\n\nThe paper proposes an approach for online hyperparameter optimization in a federated learning setting. The proposed approach (FATHOM) is more communication efficient than previous approaches and achieves better results than previous approaches with manually fine-tuned hyperparameters. However, since it assumes access to gradients it is restricted to a certain set of hyperparameters that can be optimized and the paper evaluates the approach by optimizing the client learning rate, number of local steps, and batch size. Compared to a baseline (FedAvg) the proposed approach is more efficient and obtains better final test accuracy.\nStrengths And Weaknesses: The paper motivates its approach well and clearly states its advantages and limitations compared to other approaches. The comparison to FedAvg is based on different hyperparameter initializations and shows improved results on most of them.\nI did not check the theoretical convergence part.\nThe evaluation of the approach seems clear.\nQuestions: I can't comment on the evaluation protocol itself since I don't know the related work. The target accuracy numbers seem somewhat arbitrary (86% and 23%) but may be standard for this kind of evaluation.\nLimitations: The paper itself mentions several limitations, such as applicability only to specific hyperparameters for which gradients can be obtained.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 1: Your assessment is an educated guess. The submission is not in your area or the submission was difficult to understand. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper proposes a method for tuning the client step-size, number of epochs, and batch-size of FedAvg in a oneshot manner. They propose hypergradient-style updates to these quantities that can be done simultaneously with updating the parameters. The algorithm is evaluated on FEMNIST and StackOverflow.\nStrengths And Weaknesses: Post-rebuttal: \nFollowing clarification from the authors, I have decided to raise my score slightly but still cannot fully endorse this submission. Overall I think it is somewhat unsatisfactory to have to make such a strong assumption (convexity of the loss w.r.t. the batch-size in the sense of Murota (1990)) just to obtain subgradients. In particular, what is a bit jarring is the fact that it is still unclear whether there is any scenario under which this assumption holds. Standard regularity assumptions, while restrictive, at least come with specific model classes and loss functions under which they hold. Here are some things that would strengthen the theoretical component of the work:\n\nIncluding a statement of the definition from Murota (1998) in the paper explicitly and showing where it is used in the proofs. \nDefining subgradients for non-convex functions in the discrete setting, as they can be for the continuous setting (Clarke, 1990).\nProviding an explicit setting where Assumption 2 holds.\nProviding experimental evidence that Assumption 2 holds in practice. In particular, this type of convexity should be easy to measure because the underlying set is not uncountable.\n\nSummary:\nThe paper is reasonably well-motivated, and the approach of targeting a few hyperparameters seems sensible. The experimental results indeed seem to demonstrate the utility of the proposed method. However, I have strong concerns regarding the assumptions the theoretical results and other concerns regarding the experimental comparison and discussion of past work that make me hesitant to accept the paper. \nStrengths:\n\nThe paper tackles an important and timely problem in federated learning.\nThe authors devote a good deal of time to the communication and local computation complexity of their approach, both in the method development and empirical comparison sections.\nThe method is evaluated on relevant benchmarks in computer vision and NLP.\nCode is included.\n\nWeaknesses:\n\nThe derivation of the hypergradients lack a lot of detail. Theorem 1 introduces a great deal of machinery to try and define a sub-gradient w.r.t. a continuous surrogate variable of a discrete function. How the piecewise function L corresponds to the objective, what l represents precisely (rather than in words), and how Theorem 1 is used in the later proofs should be explained more precisely. The derivation of the gradients for the batch size and number of epochs in (14) and (15) is also not thoroughly explained.\nAssumption 2, used by all three theorems in the paper, seems extremely strong. Is there at least an example of a function class in which this holds? Otherwise it seems the paper is avoiding the need to take derivatives through local iterations by optimizing an upper bound, and also hiding this in an assumption without discussing whether it is reasonable.\nThe experimental evaluation does not compare to baselines other than FedAvg, such as general hyperparameter tuning methods or the FL-specific methods discussed in the related work.\nSome of the discussion of past federated hyperparameter optimization work is incorrect (see notes).\nThe method only works for tuning three hyperparameters. The authors do acknowledge this limitation, and it is indeed reasonable to focus on specific hyperparameters, e.g. if they are especially important. However, it would be good to have a discussion of whether the ones chosen here are indeed the most impactful.\n\n\u00a0References: \n\nClarke. Optimization and nonsmooth analysis. SIAM, 1990.\nMurota. Discrete convex analysis. Mathematical Programming, 1998.\nQuestions: Notes:\n\n12: what does \u201copen-boxed\u201d mean?\n56: having difficulty following what this sentence is saying\n68: what is a \u201crelaxed condition\u201d?\n98: the two papers use different models and subsets of the data and so their settings are incomparable\n129: I suggest using \\mathbb R instead of \\mathcal R to denote the set of real numbers\n150: what do A, B, and I represent? also B was used earlier to denote the batch size\n169: I do not believe either paper states this as their objective\nTheorem 1: this theorem also requires Assumption 1\nTheorem 2: this theorem requires Assumptions 1 and 2\n225: the choice of using the bias is itself a hyperparameter\n263: this is an online convex optimization method? My understanding was the function f itself is non-convex.\nLimitations: The authors address the limitation of only being able to tune a few hyperparameters. Other limitations, especially the theoretical assumptions made and in the empirical evaluation, are less-discussed.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper proposes to optimize the hyperparameters and parameters of a federated learning model jointly via gradient descent in an online fashion. To achieve this, the paper extends previous works on hypergradient to derives analytical gradients with respect to the local learning rate and the number of gradient steps. The paper analyzes the convergence of the proposed method and verifies the empirical improvement over FedAvg using real-world FL experiments.",
                "Strengths And Weaknesses": "Strengths:\n\nThe proposed method is able to jointly optimize the hyperparameters and weight parameters of an FL model in a one-shot online manner, which is a natural and promising direction.\nThe approach taken by the paper is reasonable: derive the gradient w.r.t. the hyperparameters of interest, and then use gradient descent to optimize them together with model parameters.\n\nWeaknesses:\n\nA few related works are missing which I have listed below. Reference [a] aims at single-shot hyperparameter optimization for FL, i.e., they aim to identify a single set of hyperparameters which work well for multiple applications, and hence should be cited in the first paragraph of Section 2; [b] also used Bayesian optimization for hyperparameter optimization in FL and hence should be added to lines 114-116; [c] provided a benchmark for federated hyperparameter optimization.[a] Single-shot Hyper-parameter Optimization for Federated Learning: A General Algorithm & Analysis, 2022.[b] Differentially Private Federated Bayesian Optimization with Distributed Exploration, NeurIPS 2021.[c] FedHPO-B: A Benchmark Suite for Federated Hyperparameter Optimization, 2022.   \nIn the experiments, the proposed method is only compared with vanilla FedAvg, which may not be enough especially since a number of related works on single-shot federated hyperparameter optimization have been listed in Section 2. Even if comparisons are not possible, some justifications should be given.\nTheorem 3: instead of listing the detailed expressions of the entire theorem, I would prefer to see some interpretations/insights regarding the theoretical results. For example, how do the additional components introduced by the proposed algorithm (i.e., adaptive tuning of \u03b7 and K) affect the convergence of FedAvg? Are there conditions under which these additional components can lead to better convergence then standard FedAvg according to Theorem 3?\nPerhaps partially due to my unfamiliarity with gradient-based optimization, I feel that some of the technical details should be given more explanations. Firstly, Assumption 2 may need some further explanations and justifications. For example, xt and Et haven't been introduced till this point. A justification should be given as to how realistic this assumption is. Secondly, in Equation (5), some more explanations on how the last \u2248 is derived are needed. Next, in equations (14) and (15), why are these two equations designed in this way?\nThe paper has many typos, for example:-- line 34: a -> an\n-- line 56: justify -> justifying; a -> an\n-- line 104: directing -> directly\n-- line 145: K should be Ki?",
                "Questions": "I've listed a few questions and comments as \"Weaknesses\" in the section above.",
                "Limitations": "A limitation and potential negative societal impact are both discussed.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "I am not an expert in this area and do not know anything about federated learning. The last time I worked directly with hyperparameter optimization approaches was in 2017 but was focused on offline hyperparameter optimization and not in the context of federated learning. As such, my review is not very insightful.\n\nThe paper proposes an approach for online hyperparameter optimization in a federated learning setting. The proposed approach (FATHOM) is more communication efficient than previous approaches and achieves better results than previous approaches with manually fine-tuned hyperparameters. However, since it assumes access to gradients it is restricted to a certain set of hyperparameters that can be optimized and the paper evaluates the approach by optimizing the client learning rate, number of local steps, and batch size. Compared to a baseline (FedAvg) the proposed approach is more efficient and obtains better final test accuracy.",
                "Strengths And Weaknesses": "The paper motivates its approach well and clearly states its advantages and limitations compared to other approaches. The comparison to FedAvg is based on different hyperparameter initializations and shows improved results on most of them.\nI did not check the theoretical convergence part.\nThe evaluation of the approach seems clear.",
                "Questions": "I can't comment on the evaluation protocol itself since I don't know the related work. The target accuracy numbers seem somewhat arbitrary (86% and 23%) but may be standard for this kind of evaluation.",
                "Limitations": "The paper itself mentions several limitations, such as applicability only to specific hyperparameters for which gradients can be obtained.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "1: Your assessment is an educated guess. The submission is not in your area or the submission was difficult to understand. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposes a method for tuning the client step-size, number of epochs, and batch-size of FedAvg in a oneshot manner. They propose hypergradient-style updates to these quantities that can be done simultaneously with updating the parameters. The algorithm is evaluated on FEMNIST and StackOverflow.",
                "Strengths And Weaknesses": "Post-rebuttal: \nFollowing clarification from the authors, I have decided to raise my score slightly but still cannot fully endorse this submission. Overall I think it is somewhat unsatisfactory to have to make such a strong assumption (convexity of the loss w.r.t. the batch-size in the sense of Murota (1990)) just to obtain subgradients. In particular, what is a bit jarring is the fact that it is still unclear whether there is any scenario under which this assumption holds. Standard regularity assumptions, while restrictive, at least come with specific model classes and loss functions under which they hold. Here are some things that would strengthen the theoretical component of the work:\n\nIncluding a statement of the definition from Murota (1998) in the paper explicitly and showing where it is used in the proofs. \nDefining subgradients for non-convex functions in the discrete setting, as they can be for the continuous setting (Clarke, 1990).\nProviding an explicit setting where Assumption 2 holds.\nProviding experimental evidence that Assumption 2 holds in practice. In particular, this type of convexity should be easy to measure because the underlying set is not uncountable.\n\nSummary:\nThe paper is reasonably well-motivated, and the approach of targeting a few hyperparameters seems sensible. The experimental results indeed seem to demonstrate the utility of the proposed method. However, I have strong concerns regarding the assumptions the theoretical results and other concerns regarding the experimental comparison and discussion of past work that make me hesitant to accept the paper. \nStrengths:\n\nThe paper tackles an important and timely problem in federated learning.\nThe authors devote a good deal of time to the communication and local computation complexity of their approach, both in the method development and empirical comparison sections.\nThe method is evaluated on relevant benchmarks in computer vision and NLP.\nCode is included.\n\nWeaknesses:\n\nThe derivation of the hypergradients lack a lot of detail. Theorem 1 introduces a great deal of machinery to try and define a sub-gradient w.r.t. a continuous surrogate variable of a discrete function. How the piecewise function L corresponds to the objective, what l represents precisely (rather than in words), and how Theorem 1 is used in the later proofs should be explained more precisely. The derivation of the gradients for the batch size and number of epochs in (14) and (15) is also not thoroughly explained.\nAssumption 2, used by all three theorems in the paper, seems extremely strong. Is there at least an example of a function class in which this holds? Otherwise it seems the paper is avoiding the need to take derivatives through local iterations by optimizing an upper bound, and also hiding this in an assumption without discussing whether it is reasonable.\nThe experimental evaluation does not compare to baselines other than FedAvg, such as general hyperparameter tuning methods or the FL-specific methods discussed in the related work.\nSome of the discussion of past federated hyperparameter optimization work is incorrect (see notes).\nThe method only works for tuning three hyperparameters. The authors do acknowledge this limitation, and it is indeed reasonable to focus on specific hyperparameters, e.g. if they are especially important. However, it would be good to have a discussion of whether the ones chosen here are indeed the most impactful.\n\n\u00a0References: \n\nClarke. Optimization and nonsmooth analysis. SIAM, 1990.\nMurota. Discrete convex analysis. Mathematical Programming, 1998.",
                "Questions": "Notes:\n\n12: what does \u201copen-boxed\u201d mean?\n56: having difficulty following what this sentence is saying\n68: what is a \u201crelaxed condition\u201d?\n98: the two papers use different models and subsets of the data and so their settings are incomparable\n129: I suggest using \\mathbb R instead of \\mathcal R to denote the set of real numbers\n150: what do A, B, and I represent? also B was used earlier to denote the batch size\n169: I do not believe either paper states this as their objective\nTheorem 1: this theorem also requires Assumption 1\nTheorem 2: this theorem requires Assumptions 1 and 2\n225: the choice of using the bias is itself a hyperparameter\n263: this is an online convex optimization method? My understanding was the function f itself is non-convex.",
                "Limitations": "The authors address the limitation of only being able to tune a few hyperparameters. Other limitations, especially the theoretical assumptions made and in the empirical evaluation, are less-discussed.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.333,
        "confidence_avg": 2.333,
        "soundness_avg": 2.667,
        "presentation_avg": 3.0,
        "contribution_avg": 2.667,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the proposed method in this paper addresses an important problem in federated learning and provides a reasonable approach for optimizing hyperparameters in a one-shot online manner. The strengths of the paper include the ability to jointly optimize hyperparameters and weight parameters, the clear motivation and advantages of the proposed approach, and the evaluation on relevant benchmarks. \n\nHowever, there are some weaknesses that should be addressed. The paper should include references to related works that are missing, provide more justifications and explanations for technical details, and consider comparing the proposed method to other baselines and hyperparameter tuning methods. Additionally, the assumptions made in the theoretical results should be further discussed and supported with examples or experimental evidence.\n\nOverall, the paper is technically solid and has the potential for moderate-to-high impact. With some revisions and improvements, it can make a valuable contribution to the field of federated learning. Therefore, I recommend accepting the paper."
    },
    "Deep_Learning:_When_Conventional_Wisdom_Fails_to_be_Wise": {
        "link": "https://openreview.net//forum?id=B4EsCSj1vQL",
        "pub_url": "https://openreview.net/forum?id=B4EsCSj1vQL",
        "pdf_link": "https://openreview.net//pdf?id=B4EsCSj1vQL",
        "paper_id": "B4EsCSj1vQL",
        "title": "Deep_Learning:_When_Conventional_Wisdom_Fails_to_be_Wise",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nThe paper explores the question of why overparameterized networks can generalize well, and shows a number of theoretical examples where overparameterized networks attain good generalization.\nThe question explored in the paper is an important one and the presented examples have potential pedagogical value. However, there are serious issues with the premise and the presentation of the paper; all four reviewers discussed at length those issues and recommended rejection. Unfortunately the authors did not engage in discussion with the reviewers. Given the above, it is clear that the paper is not suitable for NeurIPS.",
        "reviews": [
            "Reviewer 1: \nSummary: The authors revisit the problem of overfitting to data set and construct an example where neural networks overfit to their training data without it affecting their performance. The authors hypothesise that this effect arises because the data only specifies parameters up to a certain equivalence class, rather than specifying all of the parameters exactly.\nStrengths And Weaknesses: Understanding how neural networks can obtain good test error while interpolating their data is a key problem for deep learning theory and has seen a lot of activity recently, so the authors are studying a timely topic.\nHowever, I'm afraid there are serious issues with the premise and the presentation of the article. The introduction reads as if over-parameterisation was still considered harmful in machine learning, when in reality the advantage of over-parametrization in large neural networks has long been recognised, for example in the original bias-variance trade-off paper by Neman et al. (Neural computation 4 (1), 1\u201358, 1992), and of course in the more recent literature on large neural networks (Neyshabur et al. '15, Zhang '16). To say that \"the dogma is routinely repeated and used in myriads applications of statistics to modeling data\" or to talk about a \"widespread aversion for over-parameterized models\" is simply not warranted, especially in the context of NeurIPS.\nTo go on and claim that \"many articles have been published in the literature recommending that deep learning models ought to have training sets that are 10 times or 50 times bigger than the number of free parameters\" is downright misleading, even if the authors managed to find two articles supporting these claims (once of which dates from 1995...)\nReading the article further, it becomes quickly clear that the authors are not aware of the enormous amount of recent work that analyses benign overfitting and the related double descent phenomenon in neural networks (see the two references above) and in random feature regression, where this effect is well-studied and understood. I am providing a few references with a focus on the theory below.\nI would therefore invite the authors to revisit their results in light of the recent experimental and theoretical findings, and to resubmit their article afterwards.\n\nTrevor Hastie, Andrea Montanari, Saharon Rosset, and Ryan J Tibshirani. Surprises in high-dimensional ridgeless\nleast squares interpolation. arXiv preprint arXiv:1903.08560\nSong Mei and Andrea Montanari. The generalization error of random features regression: Precise asymptotics and\ndouble descent curve. arXiv preprint arXiv:1908.05355\nPeter L Bartlett, Philip M Long, G\u00e1bor Lugosi, and Alexander Tsigler. Benign over\u001btting in linear regression.\nProceedings of the National Academy of Sciences, 2020\nDeep learning: a statistical viewpoint. arXiv preprint arXiv:2103.09177, 2021.\nQuestions: See above.\nLimitations: See above.\nEthics Flag: No\nSoundness: 1 poor\nPresentation: 2 fair\nContribution: 1 poor\nRating: 2: Strong Reject: For instance, a paper with major technical flaws, and/or poor evaluation, limited impact, poor reproducibility and mostly unaddressed ethical considerations.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper discusses the widely mentioned heuristic, that the number of parameters of a statistical model should not be larger than the number of training data points. By analyzing a sequence of simple \u201cdeep, layer-wise, feedforward\u201d models the paper shows that there is no straightforward relationship between the number of parameters and the functional expressivity (complexity) of a model. Accordingly, deep models can easily be constructed where the number  of datapoints to uniquely determine the input/output function is arbitrarily lower than the number of model parameters. The main idea is that transformations involving many layers can often be collapsed into a transformation with a single layer that is appropriately constructed - the number of parameters of that single layer determines the required number of training data points. Adding more and more parameters via deeper layers then allows to arbitrarily inflate the model\u2019s parameter count. The argument also goes through in essence when layers have different widths (by focusing on the most narrow layer), and in case of non-linearities between layers. The paper contains no empirical evaluation.\nStrengths And Weaknesses: Pro:\n\nThe paper is very easy to read and follow and the main argument is built in logical, consecutive steps.\nThe technical arguments in the paper are correct.\nThe paper is self-contained, and does not require extensive knowledge of sub-fields of ML.\n\nCon:\n\nThe non technical writing is highly opinionated, criticizing a perceived \u201cdogma\u201d dozens of times in the text (the word dogma appears 29 times in the paper). This is not a problem per se, but makes the manuscript more suitable for an op-ed or commentary article, which is a format not supported by NeurIPS.\nThe main argument is that functional complexity (expressiveness) of a model is independent of the number of model parameters - unfortunately this is never spelled out with clarity in the paper. This should be obvious after an undergrad course in statistical modeling and ML - however, I agree that the \u201cdogma\u201d has been fairly widely mentioned in the deep learning literature, and to this day the number of parameters is often taken as a proxy for model complexity in deep learning (e.g. in \u201cscaling laws\u201d).\nThe main argument above has been addressed formally in various frameworks, perhaps most relevant to the current discussion in statistical learning theory, where model complexity is measured via the VC dimension (instead of parameter count) and learnability bounds that relate the required number of training datapoints to bounds on test error (in the i.i.d. setting). This is not discussed at all in the paper.\n\nVerdict:\nThere is some merit to pointing out the (rather obvious) fact that statistical models, particularly deep, layer-wise, feed-forward architectures can be fully determined from datasets with fewer datapoints than model parameters. This necessarily implies equivalence classes of solutions (which I think is also interesting to point out). However, the current style and tone of the manuscript are more suited for a short opinionated or commentary piece, or perhaps a peer-reviewed blog-post (which another conference recently introduced) - neither of these formats are supported by NeurIPS. I therefore currently argue in favor of rejection because of a lack of novelty, significance, and technical depth that is expected from a typical NeurIPS original research paper. Having said that, I did enjoy reading the paper (though criticizing \u201cthe dogma\u201d could perhaps be toned down a bit), and would encourage the authors to find an appropriate outlet.\nImprovements:\nTo strengthen the work and add technical depth here are some suggestions (though one advantage of the article is that it is very easy to read because it is technically simple; so the suggestions here are aimed at adding enough \u201cmeat\u201d for a conference publication, which might not be the right format for this article after all):\n\nA thorough discussion of the (non-)relationship between functional complexity (and how to measure that) and the number of parameters of a statistical model, as well as the implications for learnability and generalization. I personally think this is well addressed in statistical learning theory (SLT) for instance.\nGoing beyond an individual model (SLT), and considering families of models (such as in Bayesian learning) and model selection - which lines 68-94 hint at - I think it would be worth discussing the minimum description length framework, where it is also obvious that the description length of a model with probabilistic parameters depends in many cases only weakly on the number of parameters.\nThe main arguments in the paper also lend themselves to some empirical investigation. For instance, one conclusion would be that increasing the width of the bottleneck layer should lead to an increased number of required datapoints, whereas increasing depth (by adding layers) should have no such effect. Though the theoretical arguments in the paper are clear and sound, a simple empirical investigation could add to the paper.\nExpand on the discussion started in lines 329-338. This is one of the most relevant questions in modern machine learning - given that the number of datapoints is insufficient to fully determine the desired input/output relationship (and thus fully specify the correct equivalence class of parameters), how can desired functional generalization be ensured and why would it be beneficial to not reduce the number of parameters (but regularize through other means instead)? Admittedly, this is beyond the main point of the paper - but building good intuitions for these questions could be very valuable for the community.\n\nSince the paper is written in a scholarly style, discussing SLT (and potentially MDL) as suggested above could add depth to the paper. I personally would also prefer de-emphasizing the \u201cattack of the dogma\u201d a bit, but that is a matter of taste, not technical correctness.\nQuestions: Questions and minor comments:\nIt would be great to see the analysis in 5.2 for MSE (regression), not the Hamming error function. How would the clustering argument look like in this case?\nThe paper somewhat fails to explain why we tend to see statistical models with eye-watering parameter counts in practice. Following the construction in the paper, many of these parameters should be superfluous (any layers wider than the bottleneck should be more or less reducible to the bottleneck-width). Yet, many rounds of architecture optimization (via humans or automated procedures such as neural architecture search) have left us with models with superfluous and redundant parameters. Work such as the Lottery Ticket Hypothesis, and results in network compression (where often >90% of parameters can be removed after training, but not before) suggest that having more parameters than necessary to implement the desired functional input/output relation might be crucial for learning. This is mentioned in passing in the paper, but I think this question lies at the heart of one of the big riddles in deep learning: the question is not \u2018why do we use more parameters than datapoints\u2019 (which is not a very meaningful question as pointed out in the paper), but \u2018why do we need way more parameters during training than to implement the desired final function\u2019? I think it would be nice to add a bit more discussion along these lines to the paper.\nIn the mathematical examples given in the paper over-fitting is not possible. The examples simply show the required number of datapoints to determine the correct parameter equivalence class for a given model architecture. For over-fitting to be possible the discussion would need to be expanded to e.g. held-out regions in the data manifold (test-set generalization from a training set that is insufficient to fully determine the parameter equivalence class) or noisy training data. This would probably, I think, lead to a formalism similar to SLT.\nLines 68-86: Bayesian Occam\u2019s Razor - the discussion in the paper is a bit imprecise (I personally really like the discussion and particularly the illustration in MacKay\u2019s textbook Chap. 28, p. 344, perhaps it can serve as inspiration to overhaul the paragraph in the paper). The discussion could be more clear by associating model complexity with the ability to implement a large set of functions (regardless of the number of parameters, and regardless of the functional complexity of a single function under the model; the latter does not even have a well-defined meaning in the framework). \n\nThe epistemological reason to prefer a simple model over a complex one in light of few datapoints is then that a small number of datapoints can only be used to select one out of a small number of functions - a small number of possible functions is what corresponds to a simple model. In contrast a complex model can implement a larger set of functions, and selecting the right one necessarily requires more information / data points. This is not to say that the individual functions implementable by the simple model cannot have \u201ccomplex functional form\u201d. E.g. two models could be polynomials of degree 10, but the simple model only considers coefficients in [\u22121,1] whereas the complex model considers coefficients in [\u2212100,100]. The functional complexity of any particular function is the same under both models.\nThe second sentence in line 83 (continuing to 84) contradicts the main message of the paper. The paper generally argues that the number of parameters is not related to the complexity of a model (the set of possible functions implementable by the model) - so the inequality in line 84 would not hold. Again, I think this seeming contradiction can easily be resolved by being more careful: the difference between a simple and a complex model is not the number of parameters, but the set of implementable functions under all possible parameter settings.\nLimitations: The paper does not address non-feedforward architectures such as e.g. ResNets and RNNs, but this is a minor detail.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 1 poor\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: In this paper, the authors stipulate that a transition from deep to shallow learning necessitates discarding the practice of having a larger training set over the number of model parameters. The authors state that this practice is derived from the statistical learning theory work based on linear models. \nThe authors then proceed to justify this point through a set of general inspections of simplified deep linear & non-linear models.\nStrengths And Weaknesses: Strengths: It has been difficult to determine the exact strengths of this work.\nWeaknesses:  \n\nWhile the aspect of over-parameterization in DNNs is yet to be fully understood and is a subject of heavy investigation over the past few years, the authors completely fail to acknowledge the vast literature already existent on this topic\n\nMost notably, the authors fail to clarify the novelty of their work over this existent literature\n\nThe authors claim that the practice of working in the under-parameterized regime even for DNNs is drawn from the observation that to solve for the values of p network weights, one would need an equal no. of parameters. This is to me a highly misconstrued understanding, as the practice is derived from the observed bias-variance tradeoff, itself explained from learning theory perspectives.\n\n\nSpecifically, given the increasing test error past an optimal model complexity of shallow NNs, it was understood that a continuation of the increase in model complexity can only worsen the generalization performance. In that light, the phenomenon of double-descent was definitely surprising\n\nContrary to the authors' broad claim here, the work of [1] argues that it is still possible for over-parameterized models to perform poorly under certain training circumstances, hence a blanket argument for over-parameterization in DNNs has to be made with some caution, which is not provided in this work\n\nThe authors provide very limited well-founded empirical and/or theoretical results to back their main claim. For e.g. in their analysis using a highly simplified over-parameterized deep linear network, the authors argue why a single example is in principle enough to train the setup. This is an inaccurate claim for the following reasons:\n\n\n\nin an over-parameterized setup, there exists a multitude of network weight choices satisfying the global minima configuration each having a different generalization property. As to which one should be and is selected from this set of choices so as to achieve successful model training is left totally unanswered by the authors\n\nit is understood and as is noted, that the landscape of a deep linear model does not contain any local minima. Nevertheless, saddle points exist and given the non-linear learning dynamics of the network weights, the authors do not put forth a method of how to escape a saddle point with the widely used gradient-based optimization methods\n\nIn the case of a noisy label, the exact fitting to the single training point is detrimental for generalization purposes and hence arguing for why over-parameterization makes sense in such a model regime is quite na\u00efve\n\nThe work fails to provide any new theoretical estimate on the amount of over-parameterization necessary, c.f. [2]\n\n\n[1] Bad Global Minima Exist and SGD Can Reach Them, Shengchao Liu, Dimitris Papailiopoulos, Dimitris Achlioptas\n[2] A Convergence Theory for Deep Learning via Over-Parameterization, Zeyuan Allen-Zhu, Yuanzhi Li, Zhao Song\nQuestions: N.A.\nLimitations: \nAs noted in the Weaknesses section above, the authors do NOT provide a thorough argument for their claim that a transition from deep to shallow learning necessitates the obvious choice of residing in the over-parameterized regime.\n\nThe figures provided are all too rudimentary and add little value to the work itself\n\nThere exists no formal theoretical results on the rate of convergence to a global optima w.r.t. training time and a subsequent analysis of whether attaining such a solution seems feasible under practical settings\n\nThere already exist long-established works on linear models, showcasing the phenomenon of double-descent in the test error. As to how the authors formally unify that seemingly contradictory viewpoint with their claims here\n\n\n[1] Statistical mechanics approach to early stopping and weight decay, S. B\u00f6s\n[2] Generalization ability of perceptrons with continuous outputs, S. B\u00f6s, W. Kinzel, and M. Opper\n[3] Avoiding Overfitting By Finite Temperature Learning and Cross-Validation, Siegfried B\u00f6s\nEthics Flag: No\nSoundness: 1 poor\nPresentation: 2 fair\nContribution: 1 poor\nRating: 2: Strong Reject: For instance, a paper with major technical flaws, and/or poor evaluation, limited impact, poor reproducibility and mostly unaddressed ethical considerations.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: In this work, the authors explore the question of why overparameterized models learn well, despite the fact that classical/traditional statistics knowledge suggests that having more model parameters than datapoints is harmful for generalization. They develop a few cases where overparameterized models provably generalize well:\n\nDeep linear networks\nDeep boolean networks\nDeep non-linear networks\n\nIn some cases, the optimal number of parameters can be shown to be greater than the number of training datapoints.\nStrengths And Weaknesses: The strongest part of the paper is the explicit construction of some of the examples; they would be very good for lectures/problem sets in introductory ML courses due to their simplicity.\nHowever, overall the phenomenology of overparameterized networks and generalization has been well studied, particularly in the last few years. The literature on \"double descent\" is one major example. See papers like:\nhttps://www.sciencedirect.com/science/article/pii/S0893608020303117\nhttps://proceedings.mlr.press/v119/adlam20a.html\nPapers like this investigate some of the root causes of the success of overparameterization, both empirically and theoretically. This literature has not been engaged with in the paper.\nSimply developing some specific examples where overaparameterized models have good generalization is not a novel or impactful contribution to the field. This phenomenology has been known since the advent of deep learning, and as discussed above the origins of this phenomenon have been very well (and quantitatively) studied in more detail than this paper.\nQuestions: Do any of the \"dogma violating\" situations in the paper have different properties from the ones already reported in the literature?\nLimitations: Limitations and impact adequately discussed.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 1 poor\nContribution: 1 poor\nRating: 2: Strong Reject: For instance, a paper with major technical flaws, and/or poor evaluation, limited impact, poor reproducibility and mostly unaddressed ethical considerations.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The authors revisit the problem of overfitting to data set and construct an example where neural networks overfit to their training data without it affecting their performance. The authors hypothesise that this effect arises because the data only specifies parameters up to a certain equivalence class, rather than specifying all of the parameters exactly.",
                "Strengths And Weaknesses": "Understanding how neural networks can obtain good test error while interpolating their data is a key problem for deep learning theory and has seen a lot of activity recently, so the authors are studying a timely topic.\nHowever, I'm afraid there are serious issues with the premise and the presentation of the article. The introduction reads as if over-parameterisation was still considered harmful in machine learning, when in reality the advantage of over-parametrization in large neural networks has long been recognised, for example in the original bias-variance trade-off paper by Neman et al. (Neural computation 4 (1), 1\u201358, 1992), and of course in the more recent literature on large neural networks (Neyshabur et al. '15, Zhang '16). To say that \"the dogma is routinely repeated and used in myriads applications of statistics to modeling data\" or to talk about a \"widespread aversion for over-parameterized models\" is simply not warranted, especially in the context of NeurIPS.\nTo go on and claim that \"many articles have been published in the literature recommending that deep learning models ought to have training sets that are 10 times or 50 times bigger than the number of free parameters\" is downright misleading, even if the authors managed to find two articles supporting these claims (once of which dates from 1995...)\nReading the article further, it becomes quickly clear that the authors are not aware of the enormous amount of recent work that analyses benign overfitting and the related double descent phenomenon in neural networks (see the two references above) and in random feature regression, where this effect is well-studied and understood. I am providing a few references with a focus on the theory below.\nI would therefore invite the authors to revisit their results in light of the recent experimental and theoretical findings, and to resubmit their article afterwards.\n\nTrevor Hastie, Andrea Montanari, Saharon Rosset, and Ryan J Tibshirani. Surprises in high-dimensional ridgeless\nleast squares interpolation. arXiv preprint arXiv:1903.08560\nSong Mei and Andrea Montanari. The generalization error of random features regression: Precise asymptotics and\ndouble descent curve. arXiv preprint arXiv:1908.05355\nPeter L Bartlett, Philip M Long, G\u00e1bor Lugosi, and Alexander Tsigler. Benign over\u001btting in linear regression.\nProceedings of the National Academy of Sciences, 2020\nDeep learning: a statistical viewpoint. arXiv preprint arXiv:2103.09177, 2021.",
                "Questions": "See above.",
                "Limitations": "See above.",
                "Ethics Flag": "No",
                "Soundness": "1 poor",
                "Presentation": "2 fair",
                "Contribution": "1 poor",
                "Rating": "2: Strong Reject: For instance, a paper with major technical flaws, and/or poor evaluation, limited impact, poor reproducibility and mostly unaddressed ethical considerations.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper discusses the widely mentioned heuristic, that the number of parameters of a statistical model should not be larger than the number of training data points. By analyzing a sequence of simple \u201cdeep, layer-wise, feedforward\u201d models the paper shows that there is no straightforward relationship between the number of parameters and the functional expressivity (complexity) of a model. Accordingly, deep models can easily be constructed where the number  of datapoints to uniquely determine the input/output function is arbitrarily lower than the number of model parameters. The main idea is that transformations involving many layers can often be collapsed into a transformation with a single layer that is appropriately constructed - the number of parameters of that single layer determines the required number of training data points. Adding more and more parameters via deeper layers then allows to arbitrarily inflate the model\u2019s parameter count. The argument also goes through in essence when layers have different widths (by focusing on the most narrow layer), and in case of non-linearities between layers. The paper contains no empirical evaluation.",
                "Strengths And Weaknesses": "Pro:\n\nThe paper is very easy to read and follow and the main argument is built in logical, consecutive steps.\nThe technical arguments in the paper are correct.\nThe paper is self-contained, and does not require extensive knowledge of sub-fields of ML.\n\nCon:\n\nThe non technical writing is highly opinionated, criticizing a perceived \u201cdogma\u201d dozens of times in the text (the word dogma appears 29 times in the paper). This is not a problem per se, but makes the manuscript more suitable for an op-ed or commentary article, which is a format not supported by NeurIPS.\nThe main argument is that functional complexity (expressiveness) of a model is independent of the number of model parameters - unfortunately this is never spelled out with clarity in the paper. This should be obvious after an undergrad course in statistical modeling and ML - however, I agree that the \u201cdogma\u201d has been fairly widely mentioned in the deep learning literature, and to this day the number of parameters is often taken as a proxy for model complexity in deep learning (e.g. in \u201cscaling laws\u201d).\nThe main argument above has been addressed formally in various frameworks, perhaps most relevant to the current discussion in statistical learning theory, where model complexity is measured via the VC dimension (instead of parameter count) and learnability bounds that relate the required number of training datapoints to bounds on test error (in the i.i.d. setting). This is not discussed at all in the paper.\n\nVerdict:\nThere is some merit to pointing out the (rather obvious) fact that statistical models, particularly deep, layer-wise, feed-forward architectures can be fully determined from datasets with fewer datapoints than model parameters. This necessarily implies equivalence classes of solutions (which I think is also interesting to point out). However, the current style and tone of the manuscript are more suited for a short opinionated or commentary piece, or perhaps a peer-reviewed blog-post (which another conference recently introduced) - neither of these formats are supported by NeurIPS. I therefore currently argue in favor of rejection because of a lack of novelty, significance, and technical depth that is expected from a typical NeurIPS original research paper. Having said that, I did enjoy reading the paper (though criticizing \u201cthe dogma\u201d could perhaps be toned down a bit), and would encourage the authors to find an appropriate outlet.\nImprovements:\nTo strengthen the work and add technical depth here are some suggestions (though one advantage of the article is that it is very easy to read because it is technically simple; so the suggestions here are aimed at adding enough \u201cmeat\u201d for a conference publication, which might not be the right format for this article after all):\n\nA thorough discussion of the (non-)relationship between functional complexity (and how to measure that) and the number of parameters of a statistical model, as well as the implications for learnability and generalization. I personally think this is well addressed in statistical learning theory (SLT) for instance.\nGoing beyond an individual model (SLT), and considering families of models (such as in Bayesian learning) and model selection - which lines 68-94 hint at - I think it would be worth discussing the minimum description length framework, where it is also obvious that the description length of a model with probabilistic parameters depends in many cases only weakly on the number of parameters.\nThe main arguments in the paper also lend themselves to some empirical investigation. For instance, one conclusion would be that increasing the width of the bottleneck layer should lead to an increased number of required datapoints, whereas increasing depth (by adding layers) should have no such effect. Though the theoretical arguments in the paper are clear and sound, a simple empirical investigation could add to the paper.\nExpand on the discussion started in lines 329-338. This is one of the most relevant questions in modern machine learning - given that the number of datapoints is insufficient to fully determine the desired input/output relationship (and thus fully specify the correct equivalence class of parameters), how can desired functional generalization be ensured and why would it be beneficial to not reduce the number of parameters (but regularize through other means instead)? Admittedly, this is beyond the main point of the paper - but building good intuitions for these questions could be very valuable for the community.\n\nSince the paper is written in a scholarly style, discussing SLT (and potentially MDL) as suggested above could add depth to the paper. I personally would also prefer de-emphasizing the \u201cattack of the dogma\u201d a bit, but that is a matter of taste, not technical correctness.",
                "Questions": "Questions and minor comments:\nIt would be great to see the analysis in 5.2 for MSE (regression), not the Hamming error function. How would the clustering argument look like in this case?\nThe paper somewhat fails to explain why we tend to see statistical models with eye-watering parameter counts in practice. Following the construction in the paper, many of these parameters should be superfluous (any layers wider than the bottleneck should be more or less reducible to the bottleneck-width). Yet, many rounds of architecture optimization (via humans or automated procedures such as neural architecture search) have left us with models with superfluous and redundant parameters. Work such as the Lottery Ticket Hypothesis, and results in network compression (where often >90% of parameters can be removed after training, but not before) suggest that having more parameters than necessary to implement the desired functional input/output relation might be crucial for learning. This is mentioned in passing in the paper, but I think this question lies at the heart of one of the big riddles in deep learning: the question is not \u2018why do we use more parameters than datapoints\u2019 (which is not a very meaningful question as pointed out in the paper), but \u2018why do we need way more parameters during training than to implement the desired final function\u2019? I think it would be nice to add a bit more discussion along these lines to the paper.\nIn the mathematical examples given in the paper over-fitting is not possible. The examples simply show the required number of datapoints to determine the correct parameter equivalence class for a given model architecture. For over-fitting to be possible the discussion would need to be expanded to e.g. held-out regions in the data manifold (test-set generalization from a training set that is insufficient to fully determine the parameter equivalence class) or noisy training data. This would probably, I think, lead to a formalism similar to SLT.\nLines 68-86: Bayesian Occam\u2019s Razor - the discussion in the paper is a bit imprecise (I personally really like the discussion and particularly the illustration in MacKay\u2019s textbook Chap. 28, p. 344, perhaps it can serve as inspiration to overhaul the paragraph in the paper). The discussion could be more clear by associating model complexity with the ability to implement a large set of functions (regardless of the number of parameters, and regardless of the functional complexity of a single function under the model; the latter does not even have a well-defined meaning in the framework). \n\nThe epistemological reason to prefer a simple model over a complex one in light of few datapoints is then that a small number of datapoints can only be used to select one out of a small number of functions - a small number of possible functions is what corresponds to a simple model. In contrast a complex model can implement a larger set of functions, and selecting the right one necessarily requires more information / data points. This is not to say that the individual functions implementable by the simple model cannot have \u201ccomplex functional form\u201d. E.g. two models could be polynomials of degree 10, but the simple model only considers coefficients in [\u22121,1] whereas the complex model considers coefficients in [\u2212100,100]. The functional complexity of any particular function is the same under both models.\nThe second sentence in line 83 (continuing to 84) contradicts the main message of the paper. The paper generally argues that the number of parameters is not related to the complexity of a model (the set of possible functions implementable by the model) - so the inequality in line 84 would not hold. Again, I think this seeming contradiction can easily be resolved by being more careful: the difference between a simple and a complex model is not the number of parameters, but the set of implementable functions under all possible parameter settings.",
                "Limitations": "The paper does not address non-feedforward architectures such as e.g. ResNets and RNNs, but this is a minor detail.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "1 poor",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "In this paper, the authors stipulate that a transition from deep to shallow learning necessitates discarding the practice of having a larger training set over the number of model parameters. The authors state that this practice is derived from the statistical learning theory work based on linear models. \nThe authors then proceed to justify this point through a set of general inspections of simplified deep linear & non-linear models.",
                "Strengths And Weaknesses": "Strengths: It has been difficult to determine the exact strengths of this work.\nWeaknesses:  \n\nWhile the aspect of over-parameterization in DNNs is yet to be fully understood and is a subject of heavy investigation over the past few years, the authors completely fail to acknowledge the vast literature already existent on this topic\n\nMost notably, the authors fail to clarify the novelty of their work over this existent literature\n\nThe authors claim that the practice of working in the under-parameterized regime even for DNNs is drawn from the observation that to solve for the values of p network weights, one would need an equal no. of parameters. This is to me a highly misconstrued understanding, as the practice is derived from the observed bias-variance tradeoff, itself explained from learning theory perspectives.\n\n\nSpecifically, given the increasing test error past an optimal model complexity of shallow NNs, it was understood that a continuation of the increase in model complexity can only worsen the generalization performance. In that light, the phenomenon of double-descent was definitely surprising\n\nContrary to the authors' broad claim here, the work of [1] argues that it is still possible for over-parameterized models to perform poorly under certain training circumstances, hence a blanket argument for over-parameterization in DNNs has to be made with some caution, which is not provided in this work\n\nThe authors provide very limited well-founded empirical and/or theoretical results to back their main claim. For e.g. in their analysis using a highly simplified over-parameterized deep linear network, the authors argue why a single example is in principle enough to train the setup. This is an inaccurate claim for the following reasons:\n\n\n\nin an over-parameterized setup, there exists a multitude of network weight choices satisfying the global minima configuration each having a different generalization property. As to which one should be and is selected from this set of choices so as to achieve successful model training is left totally unanswered by the authors\n\nit is understood and as is noted, that the landscape of a deep linear model does not contain any local minima. Nevertheless, saddle points exist and given the non-linear learning dynamics of the network weights, the authors do not put forth a method of how to escape a saddle point with the widely used gradient-based optimization methods\n\nIn the case of a noisy label, the exact fitting to the single training point is detrimental for generalization purposes and hence arguing for why over-parameterization makes sense in such a model regime is quite na\u00efve\n\nThe work fails to provide any new theoretical estimate on the amount of over-parameterization necessary, c.f. [2]\n\n\n[1] Bad Global Minima Exist and SGD Can Reach Them, Shengchao Liu, Dimitris Papailiopoulos, Dimitris Achlioptas\n[2] A Convergence Theory for Deep Learning via Over-Parameterization, Zeyuan Allen-Zhu, Yuanzhi Li, Zhao Song",
                "Questions": "N.A.",
                "Limitations": "As noted in the Weaknesses section above, the authors do NOT provide a thorough argument for their claim that a transition from deep to shallow learning necessitates the obvious choice of residing in the over-parameterized regime.\n\nThe figures provided are all too rudimentary and add little value to the work itself\n\nThere exists no formal theoretical results on the rate of convergence to a global optima w.r.t. training time and a subsequent analysis of whether attaining such a solution seems feasible under practical settings\n\nThere already exist long-established works on linear models, showcasing the phenomenon of double-descent in the test error. As to how the authors formally unify that seemingly contradictory viewpoint with their claims here\n\n\n[1] Statistical mechanics approach to early stopping and weight decay, S. B\u00f6s\n[2] Generalization ability of perceptrons with continuous outputs, S. B\u00f6s, W. Kinzel, and M. Opper\n[3] Avoiding Overfitting By Finite Temperature Learning and Cross-Validation, Siegfried B\u00f6s",
                "Ethics Flag": "No",
                "Soundness": "1 poor",
                "Presentation": "2 fair",
                "Contribution": "1 poor",
                "Rating": "2: Strong Reject: For instance, a paper with major technical flaws, and/or poor evaluation, limited impact, poor reproducibility and mostly unaddressed ethical considerations.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "In this work, the authors explore the question of why overparameterized models learn well, despite the fact that classical/traditional statistics knowledge suggests that having more model parameters than datapoints is harmful for generalization. They develop a few cases where overparameterized models provably generalize well:\n\nDeep linear networks\nDeep boolean networks\nDeep non-linear networks\n\nIn some cases, the optimal number of parameters can be shown to be greater than the number of training datapoints.",
                "Strengths And Weaknesses": "The strongest part of the paper is the explicit construction of some of the examples; they would be very good for lectures/problem sets in introductory ML courses due to their simplicity.\nHowever, overall the phenomenology of overparameterized networks and generalization has been well studied, particularly in the last few years. The literature on \"double descent\" is one major example. See papers like:\nhttps://www.sciencedirect.com/science/article/pii/S0893608020303117\nhttps://proceedings.mlr.press/v119/adlam20a.html\nPapers like this investigate some of the root causes of the success of overparameterization, both empirically and theoretically. This literature has not been engaged with in the paper.\nSimply developing some specific examples where overaparameterized models have good generalization is not a novel or impactful contribution to the field. This phenomenology has been known since the advent of deep learning, and as discussed above the origins of this phenomenon have been very well (and quantitatively) studied in more detail than this paper.",
                "Questions": "Do any of the \"dogma violating\" situations in the paper have different properties from the ones already reported in the literature?",
                "Limitations": "Limitations and impact adequately discussed.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "1 poor",
                "Contribution": "1 poor",
                "Rating": "2: Strong Reject: For instance, a paper with major technical flaws, and/or poor evaluation, limited impact, poor reproducibility and mostly unaddressed ethical considerations.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 2.25,
        "confidence_avg": 4.75,
        "soundness_avg": 2.25,
        "presentation_avg": 2.0,
        "contribution_avg": 1.0,
        "ai_sum_meta": "Recommendation: Reject\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that the paper has serious issues with its premise, presentation, and lack of engagement with existing literature. The authors fail to acknowledge the vast amount of work already done on the topic of overparameterization in deep learning and do not provide a clear novelty or contribution to the field. The examples provided in the paper are not sufficient to support their claims, and the lack of empirical evaluation is a major limitation. Overall, the paper lacks technical depth, novelty, and significance expected from a NeurIPS original research paper. Therefore, I recommend rejecting the paper."
    },
    "Maximum-Likelihood_Quantum_State_Tomography_by_Soft-Bayes": {
        "link": "https://openreview.net//forum?id=jtW73TIGnd",
        "pub_url": "https://openreview.net/forum?id=jtW73TIGnd",
        "pdf_link": "https://openreview.net//pdf?id=jtW73TIGnd",
        "paper_id": "jtW73TIGnd",
        "title": "Maximum-Likelihood_Quantum_State_Tomography_by_Soft-Bayes",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nOverall: The paper propose a stochastic first-order algorithm that computes an -approximate ML estimate for the QST problem.\nReviews: The paper received four reviews. Borderline reject (less confident), Borderline accept (confident), Borderline reject (absolutely confident), Reject (confident). Overall, from the reviews there is not a reviewer that champions the paper for acceptance.\nMain issues raised are:\n\nClarity of presentation, notation\nScalability/applicability\nLess relevant to the ML community.\n\nAfter rebuttal: While the authors have been active responding to the reviewers' comments, the rebuttal discussion was relatively silent. While the AC has reached out to find additional reviewers, this effort was unsuccessful. One of the reviewer was responsive, but the outcome was that the paper still lacks significance and applicability within the ML community. This suggests that it might be preferable the paper be submitted to a near future conference venue (and maybe a more theoretical one), following these suggestions + corrections.\nConfidence of reviews: The reviewers are fairly confident in their reviews. The thorough reviews among the four definitely get more weight than the rest of the reviews.\nOverall, the paper feels to be in good state but none of the reviewers feels extremely confident championing the paper for acceptance at this venue. We highly suggest the authors to consider near future ML conferences or more quantum-related conferences for resubmission",
        "reviews": [
            "Reviewer 1: \nSummary: The paper proposes a quantum version of Soft-Bayes for the maximum likelihood QST task, since Soft-Bayes enjoys fast per-iteration time complexity. The proposed algorithm is a stochastic first order algorithm, and compared to [64], it has better per-iteration complexity on the order of O(D^3), but worse iteration complexity. The paper provides numerical results comparing the proposed algorithm, RrhoR, and Monotonous FW.\nStrengths And Weaknesses: Strengths\n\nThe paper is clearly written, and the theoretical results are well-supported. The numerical results, though not ideal for the proposed algorithm, are interesting and appreciated.\n\nWeaknesses\n\nThe iteration complexity and per-iteration complexity both involve D, which is exponential in the number of q-bits. Though for the ML QST task this dependence may be inevitable, it would be helpful for the authors to explain why this problem formulation makes sense when the number of q-bits is large.\nThe idea of using an online portfolio selection algorithm for a QST task is also explored in [64], and the extension of Soft-Bayes to the quantum setting doesn\u2019t seem to involve new techniques. \nThe numerical results are unfortunately not very convincing, as the method obtains higher error than some of the baseline algorithms.\nQuestions: Is it possible to do ML QST when the number of q-bits is large? Why does this problem formulation make sense with exponential dependence on the number of q-bits?\nLimitations: Yes.\nEthics Flag: No\nSoundness: 4 excellent\nPresentation: 4 excellent\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper studies state tomography from the perspective of online learning. State tomography is an important problem in quantum computing. Its main objective is to arrive at an approximated description of an unknown quantum state by measuring several copies of that state. The main approach of this paper is based on soft Bayes ML estimation in which the objective is to minimize a log-loss defined between the true density operator and the estimated one. The paper then relates this problem to minimizing regret in online learning (portfolio selection) where soft Bayes is a promising approach. Then, the paper proposes a quantum analogous to soft Bayes. Using classically developed tools, the authors provide guaranteed results for their algorithms. Lastly, they provide numerical demonstrations.\nStrengths And Weaknesses: The main strength of the paper in my opinion is the quantum soft Bayes which leads to a quantum learning algorithm with provable guarantees. This is a nice idea with possible future applications. The analysis (especially Theorem 3.3) is interesting.\nThere are two major weaknesses of the paper:\n\nThe paper is not clear in the problem formulation.  It is unclear to some extent as to why we need to use the online approach for state tomography where we can have all the samples at once. \n\nThe proposed approach does not seem to be scalable as the number of iterations grows exponentially with the number of qubits.\nQuestions: Why do we need to use online learning for state tomography?\nLimitations: The main limitations of the proposed approach are (a) scalability as the number of the iterations grows exponentially with the number of qubits, and (b) numerical experiments do not seem to show the advantage of the proposed algorithm.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The submission proposes Stochastic-Q-Soft-Bayes to accomplish the quantum state tomography task. To achieve an \u03f5-regret, the required runtime complexity scales with O(D4logD/\u03f52). Numerical simulations on a 4-qubit state demonstrate the effectiveness of the proposed method.\nStrengths And Weaknesses: Strengths:\nThe submission addresses an important topic in quantum computing, i.e., devising efficient algorithms to complete quantum state tomography. The paper is well organized and the central idea is well presented.\nWeaknesses:\n\nIt has been proved that n=\u03a9(d2/\u03f52) copies are necessary to achieve the estimation error \u03f5 [IEEE Trans. Inf. Theory, 63(9):5628\u20135641, 2017.]. Nevertheless, the submission shows that the proposed algorithm can achieve an \u03f5-error using O(D4logD/\u03f52) copies. This contradiction originates from the definition of the error'. Conventionally, the estimation error between the estimated state $\\hat{\\rho}$ and the target $\\rho$ is defined as $\\|\\rho-\\hat{\\rho}\\|_{tr}$, whereas the submission adopts the regret to describe the error'. Consequently, the achieved results are incomparable with prior literature. The authors should clarify this issue. \n\nTo address the applicability of Stochastic-Q-Soft-Bayes. Simulation results on large-qubit states are desirable. Current results fail to demonstrate the potential advantages of Stochastic-Q-Soft-Bayes.\nQuestions: See the comments above.\nLimitations: See the comments above.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: In this paper the authors consider the problem of quantum state tomography (QST). Here there is an unknown n qubit quantum state rho (i.e., its a complex matrix of size 2^n x 2^n) and the goal is to learn rho given copies to the state. The sample complexity of QST has completely been pinned down to Theta(d^2) where d=2^n. Apart from the theoretical guarantees there are also some heuristic works that have looked at QST and one such method which is relevant to this work is that of maximum-likelyhood estimation. So computing the ML estimator  amounts to solving a convex optimization problem, however the main issue for using maximum likelehood estimator for QST is  negative log-likelihood function in ML QST is not Lipschitz and not smooth as well.  In contrast in this paper, the authors develop a stochastic first-order optimization technique for ML QST inspired by techniques from online learning. They moreover choose to quantumize  the soft-Bayes algorithm which is an iterative algorithm  whose round by round complexity is linear in the dimension of the state, i.e., d  and the rate of convergence of the procedures presented in this paper are similar to ones known from literature. Finally the authors provide some empirical plots implementing their learning procedures.\nI think the study of QST using MLE is nice, but i dont think this paper is fit for NeurIPS for a few reasons\na) The main contributions of this paper are in a very narrow subject and i dont think this narrow subject  might be of interest to classical ML (which is the primary audience of NeurIPS) and quantum computing (since the novelty of this paper is limited to improving certain heuristic-based approach for QST).\nb) In my opinion, the main contributions of this paper needs more motivation. For example, QST is a completely solved subject, in the sense the sample complexity has been pinned down. Then why should one look at solving QST using regression, MLE etc? Is there any solid motivation for considering these approaches? \nGiven the niche contributions which are limited in applicability, i think this paper isnt strong enough to be accepted for NeurIPS.\nStrengths And Weaknesses: Mentioned earlier.\nQuestions: Mentioned earlier.\nLimitations: Mentioned earlier.\nEthics Flag: No\nEthics Review Area: Responsible Research Practice (e.g., IRB, documentation, research ethics)\nSoundness: 2 fair\nPresentation: 2 fair\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The paper proposes a quantum version of Soft-Bayes for the maximum likelihood QST task, since Soft-Bayes enjoys fast per-iteration time complexity. The proposed algorithm is a stochastic first order algorithm, and compared to [64], it has better per-iteration complexity on the order of O(D^3), but worse iteration complexity. The paper provides numerical results comparing the proposed algorithm, RrhoR, and Monotonous FW.",
                "Strengths And Weaknesses": "Strengths\n\nThe paper is clearly written, and the theoretical results are well-supported. The numerical results, though not ideal for the proposed algorithm, are interesting and appreciated.\n\nWeaknesses\n\nThe iteration complexity and per-iteration complexity both involve D, which is exponential in the number of q-bits. Though for the ML QST task this dependence may be inevitable, it would be helpful for the authors to explain why this problem formulation makes sense when the number of q-bits is large.\nThe idea of using an online portfolio selection algorithm for a QST task is also explored in [64], and the extension of Soft-Bayes to the quantum setting doesn\u2019t seem to involve new techniques. \nThe numerical results are unfortunately not very convincing, as the method obtains higher error than some of the baseline algorithms.",
                "Questions": "Is it possible to do ML QST when the number of q-bits is large? Why does this problem formulation make sense with exponential dependence on the number of q-bits?",
                "Limitations": "Yes.",
                "Ethics Flag": "No",
                "Soundness": "4 excellent",
                "Presentation": "4 excellent",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper studies state tomography from the perspective of online learning. State tomography is an important problem in quantum computing. Its main objective is to arrive at an approximated description of an unknown quantum state by measuring several copies of that state. The main approach of this paper is based on soft Bayes ML estimation in which the objective is to minimize a log-loss defined between the true density operator and the estimated one. The paper then relates this problem to minimizing regret in online learning (portfolio selection) where soft Bayes is a promising approach. Then, the paper proposes a quantum analogous to soft Bayes. Using classically developed tools, the authors provide guaranteed results for their algorithms. Lastly, they provide numerical demonstrations.",
                "Strengths And Weaknesses": "The main strength of the paper in my opinion is the quantum soft Bayes which leads to a quantum learning algorithm with provable guarantees. This is a nice idea with possible future applications. The analysis (especially Theorem 3.3) is interesting.\nThere are two major weaknesses of the paper:\n\nThe paper is not clear in the problem formulation.  It is unclear to some extent as to why we need to use the online approach for state tomography where we can have all the samples at once. \n\nThe proposed approach does not seem to be scalable as the number of iterations grows exponentially with the number of qubits.",
                "Questions": "Why do we need to use online learning for state tomography?",
                "Limitations": "The main limitations of the proposed approach are (a) scalability as the number of the iterations grows exponentially with the number of qubits, and (b) numerical experiments do not seem to show the advantage of the proposed algorithm.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The submission proposes Stochastic-Q-Soft-Bayes to accomplish the quantum state tomography task. To achieve an \u03f5-regret, the required runtime complexity scales with O(D4logD/\u03f52). Numerical simulations on a 4-qubit state demonstrate the effectiveness of the proposed method.",
                "Strengths And Weaknesses": "Strengths:\nThe submission addresses an important topic in quantum computing, i.e., devising efficient algorithms to complete quantum state tomography. The paper is well organized and the central idea is well presented.\nWeaknesses:\n\nIt has been proved that n=\u03a9(d2/\u03f52) copies are necessary to achieve the estimation error \u03f5 [IEEE Trans. Inf. Theory, 63(9):5628\u20135641, 2017.]. Nevertheless, the submission shows that the proposed algorithm can achieve an \u03f5-error using O(D4logD/\u03f52) copies. This contradiction originates from the definition of the error'. Conventionally, the estimation error between the estimated state $\\hat{\\rho}$ and the target $\\rho$ is defined as $\\|\\rho-\\hat{\\rho}\\|_{tr}$, whereas the submission adopts the regret to describe the error'. Consequently, the achieved results are incomparable with prior literature. The authors should clarify this issue. \n\nTo address the applicability of Stochastic-Q-Soft-Bayes. Simulation results on large-qubit states are desirable. Current results fail to demonstrate the potential advantages of Stochastic-Q-Soft-Bayes.",
                "Questions": "See the comments above.",
                "Limitations": "See the comments above.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "In this paper the authors consider the problem of quantum state tomography (QST). Here there is an unknown n qubit quantum state rho (i.e., its a complex matrix of size 2^n x 2^n) and the goal is to learn rho given copies to the state. The sample complexity of QST has completely been pinned down to Theta(d^2) where d=2^n. Apart from the theoretical guarantees there are also some heuristic works that have looked at QST and one such method which is relevant to this work is that of maximum-likelyhood estimation. So computing the ML estimator  amounts to solving a convex optimization problem, however the main issue for using maximum likelehood estimator for QST is  negative log-likelihood function in ML QST is not Lipschitz and not smooth as well.  In contrast in this paper, the authors develop a stochastic first-order optimization technique for ML QST inspired by techniques from online learning. They moreover choose to quantumize  the soft-Bayes algorithm which is an iterative algorithm  whose round by round complexity is linear in the dimension of the state, i.e., d  and the rate of convergence of the procedures presented in this paper are similar to ones known from literature. Finally the authors provide some empirical plots implementing their learning procedures.\nI think the study of QST using MLE is nice, but i dont think this paper is fit for NeurIPS for a few reasons\na) The main contributions of this paper are in a very narrow subject and i dont think this narrow subject  might be of interest to classical ML (which is the primary audience of NeurIPS) and quantum computing (since the novelty of this paper is limited to improving certain heuristic-based approach for QST).\nb) In my opinion, the main contributions of this paper needs more motivation. For example, QST is a completely solved subject, in the sense the sample complexity has been pinned down. Then why should one look at solving QST using regression, MLE etc? Is there any solid motivation for considering these approaches? \nGiven the niche contributions which are limited in applicability, i think this paper isnt strong enough to be accepted for NeurIPS.",
                "Strengths And Weaknesses": "Mentioned earlier.",
                "Questions": "Mentioned earlier.",
                "Limitations": "Mentioned earlier.",
                "Ethics Flag": "No",
                "Ethics Review Area": "Responsible Research Practice (e.g., IRB, documentation, research ethics)",
                "Soundness": "2 fair",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "soundness_avg": 2.75,
        "presentation_avg": 3.0,
        "contribution_avg": 2.25,
        "ai_sum_meta": "Recommendation: Reject\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that the paper has some strengths, such as the clear writing and well-supported theoretical results. However, there are also several weaknesses that outweigh these strengths. The main weaknesses include the exponential dependence on the number of q-bits in both iteration complexity and per-iteration complexity, the lack of new techniques in the extension of Soft-Bayes to the quantum setting, and the unconvincing numerical results compared to baseline algorithms. Additionally, there are concerns about the problem formulation and the scalability of the proposed approach. Considering these weaknesses and limitations, it is recommended to reject the paper."
    },
    "Optimal_Neural_Network_Approximations_of_Wasserstein_Gradient_Direction_via_Convex_Optimization": {
        "link": "https://openreview.net//forum?id=WljzqTo9xzw",
        "pub_url": "https://openreview.net/forum?id=WljzqTo9xzw",
        "pdf_link": "https://openreview.net//pdf?id=WljzqTo9xzw",
        "paper_id": "WljzqTo9xzw",
        "title": "Optimal_Neural_Network_Approximations_of_Wasserstein_Gradient_Direction_via_Convex_Optimization",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nThis work proposes a SDP approach to computing Wasserstein gradient direction for 2-layers NNs, without the need of training the underlying NN. To compute the gradient direction, the authors construct a least-square regression problem, and add a polynomial regularization term. Then, they show that the (relaxed) dual is an SDP problem.\nPros\n\nThe idea of casting the Wasserstein gradient direction as an SDP is novel, and interesting. It also paves the way to more general formulations\nThe obtained optima is global\n\nCons\n\nThe exposition is lacking some motivation at some points. I think the authors could have move some technical discussion (for instance after Thm 1) to give a better insight on the motivations. Some previous works is also sometimes not put in context (for instance regarding the dimensionality reduction).\nFor a (mostly) theoretical paper, the statements are sometimes not precise enough, e.g., what is an \"equivalent\" problem: having the same minimum? the same argmin? In Prop 1, what properties are required on the function space? Don't you need hypothesis on \u03c8? etc.\nFrom a pratical point of view -- but I don't think that practicality is the core aspect of the paper -- the computational cost is totally prohibitive as discussed by all referees.\nIt does not seems that there is a strong practical improvements with respect to training directly the NN after the parameterization of the Wasserstein gradient.\n\nI believe the idea of casting the Wasserstein gradient direction as an SDP problem is interesting, but with respect to the ratio of pros/cons above, and the lack of a strong positive opinion on this work, I recommend to reject this submission in its current state.\nI encourage the authors to revise the manuscript in the light of the comments by all reviewers and my own comments for a future submission. In particular, the revision should include the discussion with reviewer RwmS which better highlights your work.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper tackles the variational problem of Wasserstein gradient descent (a.k.a Wasserstein gradient flow with the KL discrepancy). The (variational) optimization problem is restricted to 2-layer neural networks with ReLU activation functions. The main contribution of this paper is to propose a convex (SDP) bi-dual problem that approximates the global solution of the original problem.\nStrengths And Weaknesses: Strengths and weaknesses\n\nStrengths:\n\n\nAn interesting convexification of a non-convex variational problem, an idea that could be applied in a more general setting\nEven though strong duality does not hold, the authors provide a change of variable (primal -> bi-dual) such that the objective value of feasible solutions are equal\n\n\nWeaknesses:\n\n\nThe core idea could benefit from more intuitive explanations and comparisons with relatex work (see below)\nThe experiments lack the important computational discussion\nQuestions: Questions\n\nTheorem 1 shows that the bidual problem can still have feasible solutions with an objective equal to the primal problem: does the mapping go both ways ? \nCan we uncover additional properties about this mapping between the primal and the bidual ? At least at optimality ?\nA few references about convexified 2-layer network problems are discussed in 38-41, how does the proposed method relate to these works ?\nThe obtained bidual is an SDP, is this equivalent to the idea of infinite width neural networks modeled as probability measures ? \nThe result obtained in Equation (18) is a bit confusing, Since J corresponds to the bidual loss, I'm not sure what it means about the primal one (which is the one of interest), specially if eq (18) can be a strict inequality. How is that interpretable in terms of \"approximating\" the global minimum ? Can Z* and tilde(Z*) be analytically compared ? Since this justifies the claim \"we solve the global minimization problem\", I believe it deserves more clarification.\nThe authors briefly mention the computational burden of the proposed method in L232 being 50x slower than training a neural net. This is not surprising (SDPs are hard to solve) however, I believe this limitation is a very important aspect to investigate. Even though the experiments indicate that lower minima are obtained, the important question of quantifying the ratio:  obtained gain / large computational burden should be answered or at least discussed in more detail. Would such a method still work in large dimensions ? deeper neural networks ? large data sizes ?\nI'm not sure I follow the point of the Covid-19 experiment, no comment is provided to interpret or analyze the obtained results. Moreover, why pSVGD is considered a reference ?\n\nminor:\n when writing integrals, \\int f dx does not make sense: either \\int f or \\int f(x) dx should be used\ntypos:\n L52.  we also present a practical ..\n L79. In the above third ..\n Eq (3): alpha_l is not defined\nLimitations: see above\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper considers the problem of implementing Wasserstein gradient flow for the objective of sampling from a target distribution i.e. minimizing KL divergence. It is common to implement the Wasserstein gradient flow with a deterministic system of particles. For minimizing KL divergence, the vector-field  that governs the particles involves the interaction term \u2207log\u2061(p) where p is the distribution of the particles. The most challenging step is to approximate \u2207log\u2061(p) in terms of particles, i.e. the direction of the gradient. This has been subject of numerous recent works in the literature. The authors consider the score-function minimization approach, which involves a stochastic optimization problem over space of functions. The novelty of the work is in the particular choice to representation the functions  and the optimization algorithm to approximate the optimal one. In particular, the authors propose to use a 2-layer neural network representation, consider the dual of the regularized version of the problem, and introduce a convex relation that produces an approximate solution to the original problem. The proposed approach is then numerically evaluated on several benchmark sampling examples.\nStrengths And Weaknesses: Strength: \n\nThe paper is well-written and clear\nAlthough there are numerous works on the topic, the topic is still interesting and there are open questions\nThe idea of using this particular convexification approach in approximating the Wasserstein gradient is new and interesting\n\nWeakness: \n\nComputationally expensive approach (in its current form) \nlack of theoretical discussion regarding the final proposed approach\nQuestions: Questions: \n1- Can you be more explicit and provide a discussion on the computational time of the proposed approach and how it scales with problem parameters? \n2- Are there any tuning happening for NN and CVX_NN approach?3- Does it help if you exclude estimating \\nabla log\u2061(\u03c0) from the formulation because it is known? \n4- Can you say anything about the convergence of the gradient flow if the optimization problem to compute the gradient direction is solved up to a certain error? \n5- Can you be more explicit about the connection between the exact solution obtained from solving the relaxed convex dual problem and the exact solution to the original problem?\nLimitations: Yes\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: This paper is to solve the Wasserstein gradient direction, which is the velocity in Wasserstein gradient flow, without training neural networks. The algorithm is based on a forward discretization of the Wasserstein gradient flow, so once the gradient direction is solved, you can calculate the positions of the particles in the next step. To solve the gradient direction, they firstly construct a least-square regression problem, and add a third-order polynomial regularization term. Then they derive the dual problem in several steps. Finally, they obtain a semi-definite programming relaxation problem and show the duality gap between the relaxed dual problem and the regularized dual problem is zero. The paper provides several illustrative examples.\nStrengths And Weaknesses: Strength:\nThe method can obtain the velocity in Wasserstein gradient flow without training a neural network. They transform the primal problem based on a two-layer neural network into a SDP problem, which can enjoy a similar functional class richness. Unlike SGD in training neural networks, this algorithm can find the global minimum.\nThe paper gives rigorous derivation toward a relaxed SDP dual problem.\nWeakness:\nThe primal problem is regularized, which introduces some bias to the gradient direction. \nSeveral limitations: the target function is only for KL divergence. The function class is only two-layer neural networks. \nThere is not enough discussion on the computational complexity. I'm rather interested in the complexity dependency on the dimension d, neural network width m, and the number of particles. \nThe main advantage of this method is no need to train the neural network, which can be very time-consuming. However, the method even takes a longer time than training nn, which makes me a bit disappointed. Can you add more explanations about why WGD-cvxNN takes much longer time?\nQuestions: Question/suggestion\nI suggest moving some intermediate propositions to the supplementary materials and adding more transitional contexts, for example, between theorem 1 and the paragraph afterward. The authors can also add more explanations to the notation, e.g. what's the difference between r(j,\u2212) and r(j,+)? And I suggest presenting the optimization variables right below min or max in all the optimization problems, like in eq 16 and eq 17.\nThe dimension reduction technique (row 200) is quite important to accelerate the algorithm. I suggest the authors add more details there.\nWhat does p mean in pWGD?\nWhat does the y-axis mean in the social distancing plot in Figure 4? The social distance in meters?\nI suggest adding a reference in section 4.2 about the equation of PDE.\nIn experiments, different examples use different baseline methods to compare, which is confusing. Why do you use so many different baselines?\nIn Figure 1, how do you calculate the posterior density? Do you use kernel density estimation or you can precisely calculate it?\nTypo:\nIn Figure 4 captions, it should be left / right instead of top/bottom.\nIn row 210 bracket, compared to WGD-NN only\nOverall, I think the writing of this paper can be improved. For example, the equations can be presented in a more concise manner. And the computational complexity needs to be more carefully analyzed.\nLimitations: discussed in weakness\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: Implementability of Wasserstein gradient flows, which find many applications in sampling and numerical PDEs, hinges on the computation of the Wasserstein gradient. This paper proposes to find the best two-layer squared ReLU activation neural network approximation for the Wasserstein gradient direction. It is shown that this approximation can be formulated as a convex program, albeit with too many constraints to be tractable. The program is then solved approximately by randomly sampling a subset of the constraints. Experiments show that the resulting algorithm has reasonable performance.\nStrengths And Weaknesses: Seeking new implementations of Wasserstein gradient flows is an important practical problem, and in that respect the approach of this paper is novel and interesting. However, it also seems to fall short when evaluated via either theoretical interest or practical utility.\nRegarding practical utility: although the experiments are reasonable, they are largely toy experiments. There is no discussion of the runtime of the method, which leads me to believe that the method is not scalable (since each step requires solving a convex program, it seems computationally heavy). In applications, it appears that this approach yields no benefits over simply parameterizing the Wasserstein gradient via neural networks and training the neural network directly, rather than solving a convex program.\nTherefore, it seems more appropriate to evaluate the paper on its theoretical merits, but unfortunately there is not much to speak of. One of the main claims of the paper is that one can use principled convex optimization solvers to implement the method, but in the end the convex program cannot be implemented directly and an approximation must be used. Moreover, with the use of a convex program, one hopes that it comes with some theoretical guarantees, but there are none to be found here.\nIn short, this paper does not have enough substance. Although the idea is promising, in its current stage the submission is premature and needs more work.\nI have also found numerous grammatical errors in the writing, so it would benefit from another round of proofreading.\nQuestions: As mentioned above, can you provide runtime comparisons for the experiments?\nAlso, the formulation of the optimization problem in (5) is similar to work on score matching, see, e.g., [H05], which is used extensively in generative modeling. Can you cite this literature in your work and include a comparison and discussion in the main text?\n[H05] Aapo Hyv\u00e4rinen, Estimation of non-normalized statistical models by score matching.\nLimitations: No, the authors do not thoroughly discuss the limitations of their approach.\nEthics Flag: No\nSoundness: 1 poor\nPresentation: 2 fair\nContribution: 1 poor\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper tackles the variational problem of Wasserstein gradient descent (a.k.a Wasserstein gradient flow with the KL discrepancy). The (variational) optimization problem is restricted to 2-layer neural networks with ReLU activation functions. The main contribution of this paper is to propose a convex (SDP) bi-dual problem that approximates the global solution of the original problem.",
                "Strengths And Weaknesses": "Strengths and weaknesses\n\nStrengths:\n\n\nAn interesting convexification of a non-convex variational problem, an idea that could be applied in a more general setting\nEven though strong duality does not hold, the authors provide a change of variable (primal -> bi-dual) such that the objective value of feasible solutions are equal\n\n\nWeaknesses:\n\n\nThe core idea could benefit from more intuitive explanations and comparisons with relatex work (see below)\nThe experiments lack the important computational discussion",
                "Questions": "Questions\n\nTheorem 1 shows that the bidual problem can still have feasible solutions with an objective equal to the primal problem: does the mapping go both ways ? \nCan we uncover additional properties about this mapping between the primal and the bidual ? At least at optimality ?\nA few references about convexified 2-layer network problems are discussed in 38-41, how does the proposed method relate to these works ?\nThe obtained bidual is an SDP, is this equivalent to the idea of infinite width neural networks modeled as probability measures ? \nThe result obtained in Equation (18) is a bit confusing, Since J corresponds to the bidual loss, I'm not sure what it means about the primal one (which is the one of interest), specially if eq (18) can be a strict inequality. How is that interpretable in terms of \"approximating\" the global minimum ? Can Z* and tilde(Z*) be analytically compared ? Since this justifies the claim \"we solve the global minimization problem\", I believe it deserves more clarification.\nThe authors briefly mention the computational burden of the proposed method in L232 being 50x slower than training a neural net. This is not surprising (SDPs are hard to solve) however, I believe this limitation is a very important aspect to investigate. Even though the experiments indicate that lower minima are obtained, the important question of quantifying the ratio:  obtained gain / large computational burden should be answered or at least discussed in more detail. Would such a method still work in large dimensions ? deeper neural networks ? large data sizes ?\nI'm not sure I follow the point of the Covid-19 experiment, no comment is provided to interpret or analyze the obtained results. Moreover, why pSVGD is considered a reference ?\n\nminor:\n when writing integrals, \\int f dx does not make sense: either \\int f or \\int f(x) dx should be used\ntypos:\n L52.  we also present a practical ..\n L79. In the above third ..\n Eq (3): alpha_l is not defined",
                "Limitations": "see above",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper considers the problem of implementing Wasserstein gradient flow for the objective of sampling from a target distribution i.e. minimizing KL divergence. It is common to implement the Wasserstein gradient flow with a deterministic system of particles. For minimizing KL divergence, the vector-field  that governs the particles involves the interaction term \u2207log\u2061(p) where p is the distribution of the particles. The most challenging step is to approximate \u2207log\u2061(p) in terms of particles, i.e. the direction of the gradient. This has been subject of numerous recent works in the literature. The authors consider the score-function minimization approach, which involves a stochastic optimization problem over space of functions. The novelty of the work is in the particular choice to representation the functions  and the optimization algorithm to approximate the optimal one. In particular, the authors propose to use a 2-layer neural network representation, consider the dual of the regularized version of the problem, and introduce a convex relation that produces an approximate solution to the original problem. The proposed approach is then numerically evaluated on several benchmark sampling examples.",
                "Strengths And Weaknesses": "Strength: \n\nThe paper is well-written and clear\nAlthough there are numerous works on the topic, the topic is still interesting and there are open questions\nThe idea of using this particular convexification approach in approximating the Wasserstein gradient is new and interesting\n\nWeakness: \n\nComputationally expensive approach (in its current form) \nlack of theoretical discussion regarding the final proposed approach",
                "Questions": "Questions: \n1- Can you be more explicit and provide a discussion on the computational time of the proposed approach and how it scales with problem parameters? \n2- Are there any tuning happening for NN and CVX_NN approach?3- Does it help if you exclude estimating \\nabla log\u2061(\u03c0) from the formulation because it is known? \n4- Can you say anything about the convergence of the gradient flow if the optimization problem to compute the gradient direction is solved up to a certain error? \n5- Can you be more explicit about the connection between the exact solution obtained from solving the relaxed convex dual problem and the exact solution to the original problem?",
                "Limitations": "Yes",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper is to solve the Wasserstein gradient direction, which is the velocity in Wasserstein gradient flow, without training neural networks. The algorithm is based on a forward discretization of the Wasserstein gradient flow, so once the gradient direction is solved, you can calculate the positions of the particles in the next step. To solve the gradient direction, they firstly construct a least-square regression problem, and add a third-order polynomial regularization term. Then they derive the dual problem in several steps. Finally, they obtain a semi-definite programming relaxation problem and show the duality gap between the relaxed dual problem and the regularized dual problem is zero. The paper provides several illustrative examples.",
                "Strengths And Weaknesses": "Strength:\nThe method can obtain the velocity in Wasserstein gradient flow without training a neural network. They transform the primal problem based on a two-layer neural network into a SDP problem, which can enjoy a similar functional class richness. Unlike SGD in training neural networks, this algorithm can find the global minimum.\nThe paper gives rigorous derivation toward a relaxed SDP dual problem.\nWeakness:\nThe primal problem is regularized, which introduces some bias to the gradient direction. \nSeveral limitations: the target function is only for KL divergence. The function class is only two-layer neural networks. \nThere is not enough discussion on the computational complexity. I'm rather interested in the complexity dependency on the dimension d, neural network width m, and the number of particles. \nThe main advantage of this method is no need to train the neural network, which can be very time-consuming. However, the method even takes a longer time than training nn, which makes me a bit disappointed. Can you add more explanations about why WGD-cvxNN takes much longer time?",
                "Questions": "Question/suggestion\nI suggest moving some intermediate propositions to the supplementary materials and adding more transitional contexts, for example, between theorem 1 and the paragraph afterward. The authors can also add more explanations to the notation, e.g. what's the difference between r(j,\u2212) and r(j,+)? And I suggest presenting the optimization variables right below min or max in all the optimization problems, like in eq 16 and eq 17.\nThe dimension reduction technique (row 200) is quite important to accelerate the algorithm. I suggest the authors add more details there.\nWhat does p mean in pWGD?\nWhat does the y-axis mean in the social distancing plot in Figure 4? The social distance in meters?\nI suggest adding a reference in section 4.2 about the equation of PDE.\nIn experiments, different examples use different baseline methods to compare, which is confusing. Why do you use so many different baselines?\nIn Figure 1, how do you calculate the posterior density? Do you use kernel density estimation or you can precisely calculate it?\nTypo:\nIn Figure 4 captions, it should be left / right instead of top/bottom.\nIn row 210 bracket, compared to WGD-NN only\nOverall, I think the writing of this paper can be improved. For example, the equations can be presented in a more concise manner. And the computational complexity needs to be more carefully analyzed.",
                "Limitations": "discussed in weakness",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "Implementability of Wasserstein gradient flows, which find many applications in sampling and numerical PDEs, hinges on the computation of the Wasserstein gradient. This paper proposes to find the best two-layer squared ReLU activation neural network approximation for the Wasserstein gradient direction. It is shown that this approximation can be formulated as a convex program, albeit with too many constraints to be tractable. The program is then solved approximately by randomly sampling a subset of the constraints. Experiments show that the resulting algorithm has reasonable performance.",
                "Strengths And Weaknesses": "Seeking new implementations of Wasserstein gradient flows is an important practical problem, and in that respect the approach of this paper is novel and interesting. However, it also seems to fall short when evaluated via either theoretical interest or practical utility.\nRegarding practical utility: although the experiments are reasonable, they are largely toy experiments. There is no discussion of the runtime of the method, which leads me to believe that the method is not scalable (since each step requires solving a convex program, it seems computationally heavy). In applications, it appears that this approach yields no benefits over simply parameterizing the Wasserstein gradient via neural networks and training the neural network directly, rather than solving a convex program.\nTherefore, it seems more appropriate to evaluate the paper on its theoretical merits, but unfortunately there is not much to speak of. One of the main claims of the paper is that one can use principled convex optimization solvers to implement the method, but in the end the convex program cannot be implemented directly and an approximation must be used. Moreover, with the use of a convex program, one hopes that it comes with some theoretical guarantees, but there are none to be found here.\nIn short, this paper does not have enough substance. Although the idea is promising, in its current stage the submission is premature and needs more work.\nI have also found numerous grammatical errors in the writing, so it would benefit from another round of proofreading.",
                "Questions": "As mentioned above, can you provide runtime comparisons for the experiments?\nAlso, the formulation of the optimization problem in (5) is similar to work on score matching, see, e.g., [H05], which is used extensively in generative modeling. Can you cite this literature in your work and include a comparison and discussion in the main text?\n[H05] Aapo Hyv\u00e4rinen, Estimation of non-normalized statistical models by score matching.",
                "Limitations": "No, the authors do not thoroughly discuss the limitations of their approach.",
                "Ethics Flag": "No",
                "Soundness": "1 poor",
                "Presentation": "2 fair",
                "Contribution": "1 poor",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "soundness_avg": 2.5,
        "presentation_avg": 2.5,
        "contribution_avg": 2.25,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that this paper presents an interesting approach to solving the variational problem of Wasserstein gradient descent. The reviewers have identified several strengths of the paper, including the novel convexification approach, the rigorous derivation of the dual problem, and the potential for finding the global minimum. However, there are also some weaknesses and limitations pointed out by the reviewers, such as the lack of theoretical discussion, the computational burden of the proposed method, and the need for more intuitive explanations and comparisons with related work.\n\nOverall, while there are some concerns raised by the reviewers, the strengths of the paper outweigh the weaknesses. The proposed approach is technically solid and has the potential for moderate-to-high impact. The limitations and weaknesses can be addressed in future work. Therefore, I recommend accepting this paper for publication."
    },
    "A_Ranking_Game_for_Imitation_Learning": {
        "link": "https://openreview.net//forum?id=I59qJ0sJ2nh",
        "pub_url": "https://openreview.net/forum?id=I59qJ0sJ2nh",
        "pdf_link": "https://openreview.net//pdf?id=I59qJ0sJ2nh",
        "paper_id": "I59qJ0sJ2nh",
        "title": "A_Ranking_Game_for_Imitation_Learning",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nI went through the paper, reviews and responses. This is a borderline paper. The negative to neutral reviews are more detailed and convincing.",
        "reviews": [
            "Reviewer 1: \nSummary: In this paper, the imitation learning (IL) problem, including learning from observation (LfO) and learning from demonstration (LfD), is studied. The paper proposes a new solution to IL which include three key aspects: (1) a new ranking loss is proposed for IL, which is capable to learn whenever the rankings of the trajectories are given or not; (2) a mixup-like data augmentation strategy is introduced to smooth the loss landscape; (3) the IL process is formulated into Stackelberg game, allowing the studied of the update frequencies of reward and policy functions. The proposed method is tested under benchmark continuous control tasks, showing performance improvement over existing IL approaches.\nStrengths And Weaknesses: Strengths:\n\nThe paper proposes several interesting ideas for IL. In my view, the most significant ones are two-fold. One is the importance of smoothing the loss landscape, which can be achieved by the proposed loss and the mixup-like data augmentation. Another is the Stackelberg game formulation. The experiment of task changes in Section 5.3 is very interesting to me.\n\nThe overall experimental performance is impressive.\n\n\nWeaknesses:\n\nThe proposed approach is somehow complicated. There are several components included, making it hard to identify their contributions to the performance improvement. Even though a number of ablation study results are reported, they only show that none of the components is useless. Their precise contributions, as well as underlying mechanisms, remain unclear.\n\nIt still remains unclear to me why the proposed ranking loss could outperform other classical ranking losses. As discussed in the paper, the loss is somehow like the one proposed in [1]. While in [1], since the algorithm is Q-learning, the choice of the reward function seems to have a less impact on the optimization objective. \n\nI think conducting deeper studies following the direction in Section 5.3 would make the paper more interesting. The results in Section 5.3 seem to indicate that the PAL training is robust to changes in reward functions, while the RAL robust to changes in dynamics. I think these results show that one of the major advantages of formulating IL into Stackelberg games is the convenience of dealing with task changes.\n\n\nOverall, I think the paper is more on proposing several useful techniques for IL without exploring the underlying mechanism deeply, which can be of good practical usefulness. \n[1] SQIL: Imitation Learning via Reinforcement Learning with Sparse Rewards, ICLR'20.\nQuestions: \nCan you provide some explanations on why the proposed ranking loss is better than classical ranking losses, under the IL setting?\nLimitations: The limitations and negative societal impact are properly discussed.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper considers the standard imitation learning problem by treating imitation as a two-player ranking-based game between a policy and a reward. A novel ranking loss is proposed which has the ability to learn from both expert demonstrations and preferences while keeping the learned reward bounded. The authors introduce two optimization methods based on Stackelberg games with different leaders. Experiments show that the two proposed algorithms work well in LfO settings and outperforms the baselines. In addition, by incorporating additional offline annotated rankings, the proposed method can work in more complex environments where other baselines fail. Finally, the pros and cons of the proposed two algorithms are also discussed.\nStrengths And Weaknesses: Strengths\nThe idea of treating imitation as a two-player ranking-based game is novel, which encompasses both a kind of IRL methods and ranking-based methods. The proposed ranking loss learns a smoother reward function (Figure 2) compare with the IRL methods. The experimental results are strong, showing the efficacy of the proposed methods and the benefit of the additional annotated rankings. The comparison of the two proposed method is interesting. The writing of the paper is generally good. \nWeaknesses\n\nThe ranking loss Eq (3) is novel, but it may lack some intuition. The loss of GAIL is based on occupancy measure matching, and the loss of AIRL makes it possible to learn the ground-truth reward under some assumptions, and the loss of TREX is based on Luce-Shepard rule. However, the proposed loss lack some theoretical background and I would appreciate if the authors can provide additional intuitions behind this loss. \n\nLine 215: Here the behavior generating trajectories in the ranking dataset is assumed to be accessible. How do you generate the ranking dataset? Also, if you use auto magically generated rankings, does it mean that the demonstrations are not fully optimal? Will this cause some problem when combining the automatically generated rankings with the vanilla rankings, e.g., the learned policy may behave better than the low-ranked trajectories in the demonstrations, leading to some noisy ranking data?\n\nIn Section 5.2, the results in Door-v0 show that RANK-PAL (pref) is the only method that can solve the problem. Can you provide some insight why the additional annotated rankings are better than the automatically generated rankings, and why the additional annotated rankings can reduce the exploration requirements of LfO (line 315) that much?\n\nIn Section 5.2, the authors only show the performance of RANK-PAL. How does RANK-RAL work in these scenarios?\n\nFor the writing:\n\nLine 21: [Leaning from expert data (imitation learning) alone]: \"data\" here is a bit unclear here since actions are also data.\nLine 25: [assumes no environment interaction]: The definition of \"environment interaction\" is unclear. I think you mean the environment interaction while learning the reward function, since DREX needs to collect interaction data while collecting noisy trajectories. In addition, are you suggesting no environment interaction is a bad thing here? Why is this a bad thing?\nLine 57: [suboptimal rankings]: This is vague. What do you mean by saying rankings are \"suboptimal\"?\nLine 135: a right parenthesis is missed.\nLine 182: What is \u03f5r?\nQuestions: The questions are mainly discussed in the Weaknesses. Here are the selected questions that I think are most important:\n\nThe intuition behind the proposed ranking loss (Eq 3).\n\nHow to generate the ranking dataset in the setting of reward loss w/ automatically generated rankings? Will this cause some problem when combining the automatically generated rankings with the vanilla rankings?\n\nCan you provide some insights on the reason why the additional annotated is so useful?\nLimitations: The limitations and potential negative societal impact mentioned in the paper are adequately addressed. One suggestion: the authors can consider how the framework will work in the setting of learning from suboptimal demonstrations.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The paper proposes a ranking-game setting for imitation learning by using a ranking loss for the reward agent, and incorporating automatically generated rankings data augmentation as well as offline annotated rankings. The proposed method show improved performance and data efficiencies compare to state-of-the-art baselines on several benchmark tasks.\nStrengths And Weaknesses: Strengths:\n\nThe relationship between the proposed setting with the existing IRL frameworks is well described.\nThe author gives a performance bound for the proposed ranking loss at equilibrium.\nThe experiments for the proposed method without offline preference show clear sample efficiency improvement compared to other methods.\nThe experiments for using offline preference give a significant performance improvement. While the improvement is expected but is still impressive.\nThe ablation study is thorough.\n\nWeaknesses:\n\nI am not quite convinced about the automatically generated rankings. Why would a linear combination of trajectories give a linear combined ranking?\nThe other limitations are described at the end of the paper, which I feel is acceptable.\nQuestions: May the author give some more explanation on the automatically generated rankings. Why would a linear combination of trajectories give a linear combined ranking?\nLimitations: The major limitations are described at the end of the paper, which I feel is acceptable.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 4: \nSummary: The paper proposes to model imitation learning as a two-player general sum game, where one player, the \"reward player\", aims to rank a set of behaviors correctly, where the \"policy player\" aims to maximize the reward the \"reward player\" uses for ranking. This formulation unifies multiple prior methods for LfD and LfO. Then, the authors propose a novel way to solve this two player game as a Stackelberg game which leads to a novel imitation learning algorithm that outperforms prior methods in a series of simulated MuJoCo experiments. The proposed algorithm learns from demonstrations and preferences simultaneously which allows it to combine the benefit of both.\nStrengths And Weaknesses: Strengths\n\nThe two-player game framework is a conceptually elegant way of describing and unifying existing methods for IL. It is neat how the choice of different ranking loss functions yields different algorithms.\nThe proposed algorithm is quite natural, and it is analyzed theoretically and empirically.\nThe empirical evaluation is particularly thorough. The authors compare to various natural baselines on different tasks. They provide ablations of various components of their algorithm, providing the reader with a clear understanding of the performance of their algorithm in MuJoCo environments.\n\nWeaknesses\n\nThe paper does not provide a good intuition for the proposed ranking loss. After reading Sec. 4.2 I understood the choice that was made, but did not have a good understanding of why this is the right choice among many possible ranking losses.\nParts of the paper could be written more clearly. For example, in Sec. 4.2 it would be natural to split it up in subsections discussing the ranking loss, the theoretical properties, and then the ways to generate the ranking dataset.\nI found it hard to understand the theoretical results following Theorem 4.1 without reading the Appendix.\nIf I understand correctly, the method assumes all preferences that are provided to be noise-free, which limits the applicability of the method significantly.\nThe experimental evaluation is limited to MuJoCo locomotion tasks, which can sometimes be too simple to draw general conclusions.\nQuestions: What is the intuitive motivation for choosing the proposed ranking loss?\nDo you consider any of the theoretical results apart from Thm. 4.1 a key contribution of your paper?\nDoes you assume all comparisons in the dataset are noise-free?\nCould the proposed approach be extended to active learning by modifying what the reward agent does (i.e., it also chooses queries to make to a human)?\nMinor suggestions:\n\nCapitalization:\n\n\"bradley-terry\" -> \"Bradley-Terry\" (Table 1)\n\"jacobian\" -> \"Jacobian\" (line 253)\nIn the references: \"stackelberg\" -> \"Stackelberg\", \"Iq-learn\" -> \"IQ-learn\", \"soft-q\" -> \"soft-Q\", etc.\n\n\nAlso, make sure named paragraphs are consistently capitalized. For example \"Ablation of method components\" (line 350), but \"Limitations and Negative Societal Impacts\" (line 363)\nLimitations: If the paper indeed assumes noise-free preferences, this should be made clearer when setting up the problem. It would also be good to include as a dimension in Table 1, to provide a fair comparison.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 5: \nSummary: The authors create a new method for learning a policy through IRL. The method contains two different agents: (i) a policy agent; and (ii) a reward agent. The authors perform a set of experiments with the OpenAI Gym + MuJoCo environments and show that they achieve better results than prior work.\nStrengths And Weaknesses: \nStrengths:\n\nThe authors create a consistent work with a good explanation of why they created the method, and how the method works (theoretically and practically).\nThey perform extensive ablations on their method and how each part of the method reacts when deviating from the proposed method in the main material.\nThe work is well presented, with good writing and a couple of minor misspellings, nothing major that would damage the reading comprehension and experience.\n\n\nWeaknesses\n\nI think that the major weakness of this work is the lack of experimentation with sub-optimal expert samples. With each year, we have more IL methods being developed and one of the main difficulties for a lot of them is to be resilient to sub-optimal samples. I think this should have been addressed in this work. Yes, the method is very efficient but what is the trade-off that controls this efficiency.\nEven though RANK achieves good results with only one trajectory, I think there should be a study on how well it performs with more samples. We cannot forget that RANK has access to the environment and online samples have a higher cost than offline samples to collect and learn. I think this work would benefit from drawing this distinction and showing how much it gains when using different numbers of trajectories. Even more so when we think that there are other methods that were not used in these baselines (such as MobILE [1] and ILPO [2]) that already use a lower number of trajectories (10) while not having this iterative nature of RANK. Moreover, using a single trajectory was a limitation that RANK imposed to itself.\nTable 2 only shows the Performance metric, and does not display the expert rewards, which hurts the readability of the results.\nAnother major concern that I have is the efficiency study. The authors say that their method achieves higher reward thresholds in 2M timesteps with only one trajectory (that can vary in sample size). However, this is not entirely true. If we consider that offline samples are more efficient to learn, we could argue that BCO, and all future work based on it, could be more efficient by using 10 trajectories and only needing a fraction of the timesteps in this experiment, for example.\nFinally, regarding the experiments, 5 trajectories seem a lower number of trajectories to have an accurate statistical result. OPOLO used 10 times more samples to draw its average and standard deviation, while GaIFO used 100 trajectories for each experiment.\nThe authors\u2019 overuse of math notations hurts the readability of their work quite extensively. Most of the time the iterator changed without proper explanation and it takes the reader quite some time to understand what the authors are iterating over.  I think that rewriting the equations and standardizing the notation would benefit this work.\nIf the policy agents interact with the environment to reduce the reward function, is it really IL? Why training an imitation learning agent if, in the end, we will have an agent trained by the reward function of the environment (which theoretically is the most optimal thing we could have in an MDP problem)?\n\n  [1] Kidambi, Rahul, Jonathan Chang, and Wen Sun. \"MobILE: Model-Based Imitation Learning From Observation Alone.\"\u00a0Advances in Neural Information Processing Systems\n  \u00a034 (2021): 28598-28611.\n  [2] Edwards, Ashley, et al. \"Imitating latent policies from observation.\"\u00a0International conference on machine learning. PMLR, 2019.\nQuestions: \nHow much time does it take to run each experiment in each of these methods? I think that a reason that the authors used so few trajectories in their experiments could be a hint that even though RANK is sample efficient, it does not seem to be time efficient. Clarification on time efficiency would be very important here.\nLimitations: \nI think the authors addressed some of the concerns I had during my review in their limitation section. The ones they have not addressed are pointed out in the weakness section of this review.\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 3 good\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "In this paper, the imitation learning (IL) problem, including learning from observation (LfO) and learning from demonstration (LfD), is studied. The paper proposes a new solution to IL which include three key aspects: (1) a new ranking loss is proposed for IL, which is capable to learn whenever the rankings of the trajectories are given or not; (2) a mixup-like data augmentation strategy is introduced to smooth the loss landscape; (3) the IL process is formulated into Stackelberg game, allowing the studied of the update frequencies of reward and policy functions. The proposed method is tested under benchmark continuous control tasks, showing performance improvement over existing IL approaches.",
                "Strengths And Weaknesses": "Strengths:\n\nThe paper proposes several interesting ideas for IL. In my view, the most significant ones are two-fold. One is the importance of smoothing the loss landscape, which can be achieved by the proposed loss and the mixup-like data augmentation. Another is the Stackelberg game formulation. The experiment of task changes in Section 5.3 is very interesting to me.\n\nThe overall experimental performance is impressive.\n\n\nWeaknesses:\n\nThe proposed approach is somehow complicated. There are several components included, making it hard to identify their contributions to the performance improvement. Even though a number of ablation study results are reported, they only show that none of the components is useless. Their precise contributions, as well as underlying mechanisms, remain unclear.\n\nIt still remains unclear to me why the proposed ranking loss could outperform other classical ranking losses. As discussed in the paper, the loss is somehow like the one proposed in [1]. While in [1], since the algorithm is Q-learning, the choice of the reward function seems to have a less impact on the optimization objective. \n\nI think conducting deeper studies following the direction in Section 5.3 would make the paper more interesting. The results in Section 5.3 seem to indicate that the PAL training is robust to changes in reward functions, while the RAL robust to changes in dynamics. I think these results show that one of the major advantages of formulating IL into Stackelberg games is the convenience of dealing with task changes.\n\n\nOverall, I think the paper is more on proposing several useful techniques for IL without exploring the underlying mechanism deeply, which can be of good practical usefulness. \n[1] SQIL: Imitation Learning via Reinforcement Learning with Sparse Rewards, ICLR'20.",
                "Questions": "Can you provide some explanations on why the proposed ranking loss is better than classical ranking losses, under the IL setting?",
                "Limitations": "The limitations and negative societal impact are properly discussed.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper considers the standard imitation learning problem by treating imitation as a two-player ranking-based game between a policy and a reward. A novel ranking loss is proposed which has the ability to learn from both expert demonstrations and preferences while keeping the learned reward bounded. The authors introduce two optimization methods based on Stackelberg games with different leaders. Experiments show that the two proposed algorithms work well in LfO settings and outperforms the baselines. In addition, by incorporating additional offline annotated rankings, the proposed method can work in more complex environments where other baselines fail. Finally, the pros and cons of the proposed two algorithms are also discussed.",
                "Strengths And Weaknesses": "Strengths\nThe idea of treating imitation as a two-player ranking-based game is novel, which encompasses both a kind of IRL methods and ranking-based methods. The proposed ranking loss learns a smoother reward function (Figure 2) compare with the IRL methods. The experimental results are strong, showing the efficacy of the proposed methods and the benefit of the additional annotated rankings. The comparison of the two proposed method is interesting. The writing of the paper is generally good. \nWeaknesses\n\nThe ranking loss Eq (3) is novel, but it may lack some intuition. The loss of GAIL is based on occupancy measure matching, and the loss of AIRL makes it possible to learn the ground-truth reward under some assumptions, and the loss of TREX is based on Luce-Shepard rule. However, the proposed loss lack some theoretical background and I would appreciate if the authors can provide additional intuitions behind this loss. \n\nLine 215: Here the behavior generating trajectories in the ranking dataset is assumed to be accessible. How do you generate the ranking dataset? Also, if you use auto magically generated rankings, does it mean that the demonstrations are not fully optimal? Will this cause some problem when combining the automatically generated rankings with the vanilla rankings, e.g., the learned policy may behave better than the low-ranked trajectories in the demonstrations, leading to some noisy ranking data?\n\nIn Section 5.2, the results in Door-v0 show that RANK-PAL (pref) is the only method that can solve the problem. Can you provide some insight why the additional annotated rankings are better than the automatically generated rankings, and why the additional annotated rankings can reduce the exploration requirements of LfO (line 315) that much?\n\nIn Section 5.2, the authors only show the performance of RANK-PAL. How does RANK-RAL work in these scenarios?\n\nFor the writing:\n\nLine 21: [Leaning from expert data (imitation learning) alone]: \"data\" here is a bit unclear here since actions are also data.\nLine 25: [assumes no environment interaction]: The definition of \"environment interaction\" is unclear. I think you mean the environment interaction while learning the reward function, since DREX needs to collect interaction data while collecting noisy trajectories. In addition, are you suggesting no environment interaction is a bad thing here? Why is this a bad thing?\nLine 57: [suboptimal rankings]: This is vague. What do you mean by saying rankings are \"suboptimal\"?\nLine 135: a right parenthesis is missed.\nLine 182: What is \u03f5r?",
                "Questions": "The questions are mainly discussed in the Weaknesses. Here are the selected questions that I think are most important:\n\nThe intuition behind the proposed ranking loss (Eq 3).\n\nHow to generate the ranking dataset in the setting of reward loss w/ automatically generated rankings? Will this cause some problem when combining the automatically generated rankings with the vanilla rankings?\n\nCan you provide some insights on the reason why the additional annotated is so useful?",
                "Limitations": "The limitations and potential negative societal impact mentioned in the paper are adequately addressed. One suggestion: the authors can consider how the framework will work in the setting of learning from suboptimal demonstrations.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper proposes a ranking-game setting for imitation learning by using a ranking loss for the reward agent, and incorporating automatically generated rankings data augmentation as well as offline annotated rankings. The proposed method show improved performance and data efficiencies compare to state-of-the-art baselines on several benchmark tasks.",
                "Strengths And Weaknesses": "Strengths:\n\nThe relationship between the proposed setting with the existing IRL frameworks is well described.\nThe author gives a performance bound for the proposed ranking loss at equilibrium.\nThe experiments for the proposed method without offline preference show clear sample efficiency improvement compared to other methods.\nThe experiments for using offline preference give a significant performance improvement. While the improvement is expected but is still impressive.\nThe ablation study is thorough.\n\nWeaknesses:\n\nI am not quite convinced about the automatically generated rankings. Why would a linear combination of trajectories give a linear combined ranking?\nThe other limitations are described at the end of the paper, which I feel is acceptable.",
                "Questions": "May the author give some more explanation on the automatically generated rankings. Why would a linear combination of trajectories give a linear combined ranking?",
                "Limitations": "The major limitations are described at the end of the paper, which I feel is acceptable.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper proposes to model imitation learning as a two-player general sum game, where one player, the \"reward player\", aims to rank a set of behaviors correctly, where the \"policy player\" aims to maximize the reward the \"reward player\" uses for ranking. This formulation unifies multiple prior methods for LfD and LfO. Then, the authors propose a novel way to solve this two player game as a Stackelberg game which leads to a novel imitation learning algorithm that outperforms prior methods in a series of simulated MuJoCo experiments. The proposed algorithm learns from demonstrations and preferences simultaneously which allows it to combine the benefit of both.",
                "Strengths And Weaknesses": "Strengths\n\nThe two-player game framework is a conceptually elegant way of describing and unifying existing methods for IL. It is neat how the choice of different ranking loss functions yields different algorithms.\nThe proposed algorithm is quite natural, and it is analyzed theoretically and empirically.\nThe empirical evaluation is particularly thorough. The authors compare to various natural baselines on different tasks. They provide ablations of various components of their algorithm, providing the reader with a clear understanding of the performance of their algorithm in MuJoCo environments.\n\nWeaknesses\n\nThe paper does not provide a good intuition for the proposed ranking loss. After reading Sec. 4.2 I understood the choice that was made, but did not have a good understanding of why this is the right choice among many possible ranking losses.\nParts of the paper could be written more clearly. For example, in Sec. 4.2 it would be natural to split it up in subsections discussing the ranking loss, the theoretical properties, and then the ways to generate the ranking dataset.\nI found it hard to understand the theoretical results following Theorem 4.1 without reading the Appendix.\nIf I understand correctly, the method assumes all preferences that are provided to be noise-free, which limits the applicability of the method significantly.\nThe experimental evaluation is limited to MuJoCo locomotion tasks, which can sometimes be too simple to draw general conclusions.",
                "Questions": "What is the intuitive motivation for choosing the proposed ranking loss?\nDo you consider any of the theoretical results apart from Thm. 4.1 a key contribution of your paper?\nDoes you assume all comparisons in the dataset are noise-free?\nCould the proposed approach be extended to active learning by modifying what the reward agent does (i.e., it also chooses queries to make to a human)?\nMinor suggestions:\n\nCapitalization:\n\n\"bradley-terry\" -> \"Bradley-Terry\" (Table 1)\n\"jacobian\" -> \"Jacobian\" (line 253)\nIn the references: \"stackelberg\" -> \"Stackelberg\", \"Iq-learn\" -> \"IQ-learn\", \"soft-q\" -> \"soft-Q\", etc.\n\n\nAlso, make sure named paragraphs are consistently capitalized. For example \"Ablation of method components\" (line 350), but \"Limitations and Negative Societal Impacts\" (line 363)",
                "Limitations": "If the paper indeed assumes noise-free preferences, this should be made clearer when setting up the problem. It would also be good to include as a dimension in Table 1, to provide a fair comparison.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors create a new method for learning a policy through IRL. The method contains two different agents: (i) a policy agent; and (ii) a reward agent. The authors perform a set of experiments with the OpenAI Gym + MuJoCo environments and show that they achieve better results than prior work.",
                "Strengths And Weaknesses": "Strengths:\n\nThe authors create a consistent work with a good explanation of why they created the method, and how the method works (theoretically and practically).\nThey perform extensive ablations on their method and how each part of the method reacts when deviating from the proposed method in the main material.\nThe work is well presented, with good writing and a couple of minor misspellings, nothing major that would damage the reading comprehension and experience.\n\n\nWeaknesses\n\nI think that the major weakness of this work is the lack of experimentation with sub-optimal expert samples. With each year, we have more IL methods being developed and one of the main difficulties for a lot of them is to be resilient to sub-optimal samples. I think this should have been addressed in this work. Yes, the method is very efficient but what is the trade-off that controls this efficiency.\nEven though RANK achieves good results with only one trajectory, I think there should be a study on how well it performs with more samples. We cannot forget that RANK has access to the environment and online samples have a higher cost than offline samples to collect and learn. I think this work would benefit from drawing this distinction and showing how much it gains when using different numbers of trajectories. Even more so when we think that there are other methods that were not used in these baselines (such as MobILE [1] and ILPO [2]) that already use a lower number of trajectories (10) while not having this iterative nature of RANK. Moreover, using a single trajectory was a limitation that RANK imposed to itself.\nTable 2 only shows the Performance metric, and does not display the expert rewards, which hurts the readability of the results.\nAnother major concern that I have is the efficiency study. The authors say that their method achieves higher reward thresholds in 2M timesteps with only one trajectory (that can vary in sample size). However, this is not entirely true. If we consider that offline samples are more efficient to learn, we could argue that BCO, and all future work based on it, could be more efficient by using 10 trajectories and only needing a fraction of the timesteps in this experiment, for example.\nFinally, regarding the experiments, 5 trajectories seem a lower number of trajectories to have an accurate statistical result. OPOLO used 10 times more samples to draw its average and standard deviation, while GaIFO used 100 trajectories for each experiment.\nThe authors\u2019 overuse of math notations hurts the readability of their work quite extensively. Most of the time the iterator changed without proper explanation and it takes the reader quite some time to understand what the authors are iterating over.  I think that rewriting the equations and standardizing the notation would benefit this work.\nIf the policy agents interact with the environment to reduce the reward function, is it really IL? Why training an imitation learning agent if, in the end, we will have an agent trained by the reward function of the environment (which theoretically is the most optimal thing we could have in an MDP problem)?\n\n  [1] Kidambi, Rahul, Jonathan Chang, and Wen Sun. \"MobILE: Model-Based Imitation Learning From Observation Alone.\"\u00a0Advances in Neural Information Processing Systems\n  \u00a034 (2021): 28598-28611.\n  [2] Edwards, Ashley, et al. \"Imitating latent policies from observation.\"\u00a0International conference on machine learning. PMLR, 2019.",
                "Questions": "How much time does it take to run each experiment in each of these methods? I think that a reason that the authors used so few trajectories in their experiments could be a hint that even though RANK is sample efficient, it does not seem to be time efficient. Clarification on time efficiency would be very important here.",
                "Limitations": "I think the authors addressed some of the concerns I had during my review in their limitation section. The ones they have not addressed are pointed out in the weakness section of this review.",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.8,
        "confidence_avg": 3.2,
        "soundness_avg": 2.8,
        "presentation_avg": 2.8,
        "contribution_avg": 2.8,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the proposed method for imitation learning (IL) has several strengths. The paper introduces novel ideas such as a new ranking loss, mixup-like data augmentation, and the formulation of IL as a Stackelberg game. The experimental results demonstrate the effectiveness of the proposed method, with improved performance over existing IL approaches.\n\nWhile there are some weaknesses pointed out by the reviewers, such as the lack of intuition behind the proposed ranking loss and the limited experimentation with sub-optimal expert samples, these weaknesses do not outweigh the strengths of the paper.\n\nOverall, the paper presents a technically solid contribution with high impact in the field of IL. The thorough experimental evaluation, along with the theoretical analysis, adds to the strength of the paper. Therefore, I recommend accepting the paper."
    },
    "Structure-Preserving_Embedding_of_Multi-layer_Networks": {
        "link": "https://openreview.net//forum?id=toR64fsPir",
        "pub_url": "https://openreview.net/forum?id=toR64fsPir",
        "pdf_link": "https://openreview.net//pdf?id=toR64fsPir",
        "paper_id": "toR64fsPir",
        "title": "Structure-Preserving_Embedding_of_Multi-layer_Networks",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nThis paper applies tensor decomposition to study the structure-preserving embedding of multi-layer networks, for the tasks such as community detection and link prediction. While the reviewers appreciate several technical novelties in the paper, they still have a number of concerns, such as the novelty of tensor decomposition in this context, the theoretical convergence, the practicality of the consistency analysis, the empirical performance of the proposed algorithm with the real-world data. Overall, the paper looks to be promising, but a little below the high bar of NeurIPS. The authors are encouraged to revise the paper based on the reviewer comments and submit the paper to the next venue.",
        "reviews": [
            "Reviewer 1: \nSummary: This paper proposes a generative tensor-based latent space model, dubbed TLSM, which generates node embeddings preserving the community structure of the given multi-layer networks. Instead of directly using the log-likelihood function to encode the heterogeneous structure of the multi-layer networks, the authors also introduce a clustering type penalty to simultaneously embed the community information between nodes. Projected gradient descent (PGD) is used to optimize the model parameters, and the asymptotic consistencies of the proposed method are also analyzed.\nStrengths And Weaknesses: Strengths: Firstly, the proposed model is flexible and general, with many popular network models included. Secondly, the designed regularized likelihood framework enables the proposed model to estimate the multi-layer network and conduct community detection simultaneously. Thirdly, the authors establish a theoretical analysis of the proposed model's asymptotic consistency in terms of both multi-layer network estimation and community detection.\nWeaknesses: Firstly, although the proposed framework is flexible and general, the idea of using tensor decomposition is not very novel, and the regularized likelihood design is only incremental. Secondly, I think the PGD algorithm does not guarantee convergence to the global minimum, and thus we may need to select the initial point carefully. Finally, in the real-life experiments, the proposed model does not perform much better than the benchmark approaches.\nQuestions: I am a bit concerned about the proposed model's time complexity. Could the authors provide more details about the model complexity?\nLimitations: The authors did not address the limitations and potential negative societal impact.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: The paper deals with the problem of learning node  embeddings of multilayer graphs with applications mainly in community detection and link prediction. A new model is introduced, namely TLSM, that is based on flexible tensor decomposition framework. Specifically, the methodology is based on a tensor latent space model that satisfies a set of interesting properties: it allows nodes to get different embeddings even if they belong to the same community; it satisfies some key identifiability properties; and finally, it is capable of handling sparse networks though a modified logit transformation. The different claims made in the paper are supported either with theoretical arguments or empirically.\nStrengths And Weaknesses: Strengths:\n\nThe paper addresses an important problem in graph machine learning, with many practical applications. \nI found particularly interesting the fact that the paper comes with a consistency analysis regarding the proposed methodology.\nThe paper is also well-written, and most of the arguments made are clearly presented. I really enjoyed reading it.\n\nWeaknesses:\n\nMissing related work. Despite the fact that the multi-layer community detection literature is not as rich as in the case of single-layer graphs, still there are plenty of methodologies that follow different ideas. The paper mentions a few of them, but the literature could further be expanded. It would be interesting to also consider some of these models in the empirical analysis. I will just mention the article by Mercado et al. entitled \u201cThe Power Mean Laplacian for Multilayer Graph Clustering\u201d (AISTATS \u201918), and possibly some of the references within this article. \nI enjoyed reading the part related to the consistency analysis. However, it is not clear to me how strong are these assumptions from a practical viewpoint. How will the model empirically behave if some of these assumptions will be violated?\n\nMy main concerns about the paper are related to the empirical analysis. \n\nWhy is the embedding dimension set to K? \nThe scale of the datasets used is quite small. Is there any particular reason for this choice?\nThere is no discussion about the time complexity of the model or even the empirical running time. I would suggest the authors to discuss this point.\nSelection of baseline models. As I also mentioned above, I found that the selected models do not cover different methodological ideas on clustering multilayer graphs.\nLastly, despite mentioning that the paper learning embedding of multilayer graphs, most of the discussion and analysis concerns the task of community detection. There is one experiment on link prediction, but I believe this is quite limited. Did the authors think of having a more generic experimental framework that will more extensively cover the tasks of link prediction and, possibly, node classification?\n\nTypos:\n\nLine 58, yet\nLine  73: Greek letters\nLine 123: comes\nQuestions: The different questions that I would like to ask the authors are provided in the list of weaknesses of the paper.\nLimitations: N/A\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: In this paper, the authors propose TLSM, a novel tensor-based latent space model for community detection in multi-layer networks. TLSM integrates the heterogenous network structure in different layers by embedding nodes into a low-dimensional space with the aim of nodes within the same community should have closer embeddings. Further, TLSM utilizes a regularized framework consisting of the average negative log-likelihood function of the multi-layer network and the clustering regularizer, to estimate the multi-layer network and conduct community detection simultaneously. The authors also provide theoretical analysis regarding the asymptotic consistencies of TLSM of both the multi-layer network and community detection.\nStrengths And Weaknesses: Strengths:\n\nTLSM is a flexible and general framework that contains many multi-layer network generative models such as the multi-layer stochastic block model.\n\nTLSM estimates the multi-layer network and performs community detection simultaneously by adding a clustering penalty to the multi-layer network likelihood function.\n\nTLSM analyzes the asymptotic consistencies in terms of both the multi-layer network and the community detection.\n\n\nWeaknesses:\n\nTLSM applies projected gradient descent to optimize the regularized likelihood, which can only guarantee achieving a local optimum. The authors mentioned employing a transformed higher order orthogonal iteration (HOOI) algorithm for warm initialization, but it would be great if the authors could discuss it further in detail.\n\nTLSM outperforms baseline methods in the synthetic networks, while does not significantly outperform baselines in the real-world networks. The reviewer wonders if the authors could provide more details about the real-world experiments.\n\nAlthough TLSM is flexible and general, the techniques it used are not novel.\nQuestions: \nIt seems that TLSM mainly leverages the tensor CP decomposition to integrate the heterogeneous structure of the multi-layer networks. The reviewer wonders if the integration would be better if TLSM incorporates random walks between different layers.\n\nThe computational complexity of TLSM is not mentioned in the paper, and thus it would be great if the author could discuss further TLSM's complexity.\nLimitations: Authors did not mention the Limitations and societal impacts. The reviewer thinks the limitations of the proposed model are mainly the optimality of learned parameters and the model's performance.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 2 fair\nRating: 5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "This paper proposes a generative tensor-based latent space model, dubbed TLSM, which generates node embeddings preserving the community structure of the given multi-layer networks. Instead of directly using the log-likelihood function to encode the heterogeneous structure of the multi-layer networks, the authors also introduce a clustering type penalty to simultaneously embed the community information between nodes. Projected gradient descent (PGD) is used to optimize the model parameters, and the asymptotic consistencies of the proposed method are also analyzed.",
                "Strengths And Weaknesses": "Strengths: Firstly, the proposed model is flexible and general, with many popular network models included. Secondly, the designed regularized likelihood framework enables the proposed model to estimate the multi-layer network and conduct community detection simultaneously. Thirdly, the authors establish a theoretical analysis of the proposed model's asymptotic consistency in terms of both multi-layer network estimation and community detection.\nWeaknesses: Firstly, although the proposed framework is flexible and general, the idea of using tensor decomposition is not very novel, and the regularized likelihood design is only incremental. Secondly, I think the PGD algorithm does not guarantee convergence to the global minimum, and thus we may need to select the initial point carefully. Finally, in the real-life experiments, the proposed model does not perform much better than the benchmark approaches.",
                "Questions": "I am a bit concerned about the proposed model's time complexity. Could the authors provide more details about the model complexity?",
                "Limitations": "The authors did not address the limitations and potential negative societal impact.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper deals with the problem of learning node  embeddings of multilayer graphs with applications mainly in community detection and link prediction. A new model is introduced, namely TLSM, that is based on flexible tensor decomposition framework. Specifically, the methodology is based on a tensor latent space model that satisfies a set of interesting properties: it allows nodes to get different embeddings even if they belong to the same community; it satisfies some key identifiability properties; and finally, it is capable of handling sparse networks though a modified logit transformation. The different claims made in the paper are supported either with theoretical arguments or empirically.",
                "Strengths And Weaknesses": "Strengths:\n\nThe paper addresses an important problem in graph machine learning, with many practical applications. \nI found particularly interesting the fact that the paper comes with a consistency analysis regarding the proposed methodology.\nThe paper is also well-written, and most of the arguments made are clearly presented. I really enjoyed reading it.\n\nWeaknesses:\n\nMissing related work. Despite the fact that the multi-layer community detection literature is not as rich as in the case of single-layer graphs, still there are plenty of methodologies that follow different ideas. The paper mentions a few of them, but the literature could further be expanded. It would be interesting to also consider some of these models in the empirical analysis. I will just mention the article by Mercado et al. entitled \u201cThe Power Mean Laplacian for Multilayer Graph Clustering\u201d (AISTATS \u201918), and possibly some of the references within this article. \nI enjoyed reading the part related to the consistency analysis. However, it is not clear to me how strong are these assumptions from a practical viewpoint. How will the model empirically behave if some of these assumptions will be violated?\n\nMy main concerns about the paper are related to the empirical analysis. \n\nWhy is the embedding dimension set to K? \nThe scale of the datasets used is quite small. Is there any particular reason for this choice?\nThere is no discussion about the time complexity of the model or even the empirical running time. I would suggest the authors to discuss this point.\nSelection of baseline models. As I also mentioned above, I found that the selected models do not cover different methodological ideas on clustering multilayer graphs.\nLastly, despite mentioning that the paper learning embedding of multilayer graphs, most of the discussion and analysis concerns the task of community detection. There is one experiment on link prediction, but I believe this is quite limited. Did the authors think of having a more generic experimental framework that will more extensively cover the tasks of link prediction and, possibly, node classification?\n\nTypos:\n\nLine 58, yet\nLine  73: Greek letters\nLine 123: comes",
                "Questions": "The different questions that I would like to ask the authors are provided in the list of weaknesses of the paper.",
                "Limitations": "N/A",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "In this paper, the authors propose TLSM, a novel tensor-based latent space model for community detection in multi-layer networks. TLSM integrates the heterogenous network structure in different layers by embedding nodes into a low-dimensional space with the aim of nodes within the same community should have closer embeddings. Further, TLSM utilizes a regularized framework consisting of the average negative log-likelihood function of the multi-layer network and the clustering regularizer, to estimate the multi-layer network and conduct community detection simultaneously. The authors also provide theoretical analysis regarding the asymptotic consistencies of TLSM of both the multi-layer network and community detection.",
                "Strengths And Weaknesses": "Strengths:\n\nTLSM is a flexible and general framework that contains many multi-layer network generative models such as the multi-layer stochastic block model.\n\nTLSM estimates the multi-layer network and performs community detection simultaneously by adding a clustering penalty to the multi-layer network likelihood function.\n\nTLSM analyzes the asymptotic consistencies in terms of both the multi-layer network and the community detection.\n\n\nWeaknesses:\n\nTLSM applies projected gradient descent to optimize the regularized likelihood, which can only guarantee achieving a local optimum. The authors mentioned employing a transformed higher order orthogonal iteration (HOOI) algorithm for warm initialization, but it would be great if the authors could discuss it further in detail.\n\nTLSM outperforms baseline methods in the synthetic networks, while does not significantly outperform baselines in the real-world networks. The reviewer wonders if the authors could provide more details about the real-world experiments.\n\nAlthough TLSM is flexible and general, the techniques it used are not novel.",
                "Questions": "It seems that TLSM mainly leverages the tensor CP decomposition to integrate the heterogeneous structure of the multi-layer networks. The reviewer wonders if the integration would be better if TLSM incorporates random walks between different layers.\n\nThe computational complexity of TLSM is not mentioned in the paper, and thus it would be great if the author could discuss further TLSM's complexity.",
                "Limitations": "Authors did not mention the Limitations and societal impacts. The reviewer thinks the limitations of the proposed model are mainly the optimality of learned parameters and the model's performance.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.333,
        "confidence_avg": 3.667,
        "soundness_avg": 3.0,
        "presentation_avg": 2.667,
        "contribution_avg": 2.333,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the proposed paper, which introduces the TLSM model for community detection in multi-layer networks, has several strengths. The model is flexible and general, with many popular network models included. The regularized likelihood framework allows for simultaneous estimation of the multi-layer network and community detection. The paper also provides theoretical analysis of the asymptotic consistencies of the proposed model. \n\nWhile there are some weaknesses pointed out by the reviewers, such as the lack of novelty in the techniques used and the limited improvement over benchmark approaches in real-life experiments, the overall consensus is that the paper is technically solid and has good evaluation. \n\nConsidering the strictness level of 0.5 for this conference, which indicates a moderate level of strictness, it is reasonable to accept the paper. The strengths of the proposed model and the positive aspects highlighted by the reviewers outweigh the weaknesses. Therefore, I recommend accepting the paper."
    },
    "Surprise-Guided_Search_for_Learning_Task_Specifications_From_Demonstrations": {
        "link": "https://openreview.net//forum?id=xjXN3wEvCGG",
        "pub_url": "https://openreview.net/forum?id=xjXN3wEvCGG",
        "pdf_link": "https://openreview.net//pdf?id=xjXN3wEvCGG",
        "paper_id": "xjXN3wEvCGG",
        "title": "Surprise-Guided_Search_for_Learning_Task_Specifications_From_Demonstrations",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Less certain\nThe paper presents a new approach for synthesizing automata-based specifications from sample behaviors. In some ways, this is very related to the problem of generating DFAs from examples, but there are important differences related to this planning context that make it more constrained. I think this is an interesting problem and there is a solid contribution in this work that the evaluation clearly demonstrates.\nThere is significant scope for improvement in the presentation as expressed in many of the comments in the reviews that I think are fixable in a camera ready version of the paper. I think there is a bigger question of fit with the NeurIPS community that is reflected in the low scores that the paper received. The paper reads much more like a CAV paper than a NeurIPS paper, and that might limit its impact in this community.",
        "reviews": [
            "Reviewer 1: \nSummary: The paper investigates the interesting problem of learning formal task specifications (i.e., a DFA) from (expert) demonstrations in a MDP. The main motivation is that symbolic structures (DFAs in this case) offer better properties (e.g., non-Markovian goals, goal composition, less sensitive to perturbations in the environment, etc.) compared to previous \"inverse control\" reward-based approaches like IRL. The main difficulty is the large search space of DFAs (even for the small toy example considered in the paper). The paper proposes the DISS (demonstration informed specification search) as an approximate solution to learning DFAs from demonstration. The key idea is to construct a structured search space over labeled examples and tasks. A knowledge-injected hill-climbing algorithm can operate efficiently in this search space to uncover the task that best \"explains\" the demonstrations. The key algorithmic contribution in DISS is the \"surprise-guided sampler\" which constructs labeled examples. Experiments are conducted on a gridworld and show the proposed method outperforming 2 baselines. \n\nUPDATE: I thank the authors for their detailed responses and being open to suggestions. I generally agree with Reviewer Y88L's comments, especially regarding the experimental aspects (baselines, user studies) and overall clarity of the paper. The authors have addressed most reviewer feedback, incorporated a number of reviewer comments into the paper and have included some more empirical data in the Appendix. I'm more positively inclined towards the paper although I think it remains difficult to assess impact with the current set of experiments. I've revised my score upwards to incorporate all the new information.\nStrengths And Weaknesses: Strengths\n\nThe problem of learning formal representations of goals directly from expert trajectories (without reward functions) is challenging and important. The proposed approach seems to extend the state of the art in this area. The primary contribution of the paper is algorithmic with the introduction of the DISS algorithm for identifying specifications and the SGS component for selecting labeled examples.\nThe algorithmic ideas seem rigorously developed and novel (although I'm not sure I fully understood the details in Section 4.).\nExperiments show that the method does perform better than reasonably strong baselines (enumeration and mutation-based).\n\nWeaknesses\n\nI found the paper to be a bit hard to read (especially compared to the closely related work in [21], which was much clearer). This paper assumes or omits important definitions (e.g., \u03c6(\u03be), LSE). Combined with the large amount of new notation, interchangeable terminology (e.g., specification vs task) and typos, I found it challenging to grasp the key ideas on my first reading. Overall, I'd suggest this paper be edited to be more self-contained and clearer.\nThe experiments are somewhat limited. I was looking forward to a deeper analysis into the learned DFAs and in particular their correctness. For example, how \"close to optimal\" are the DFAs (compared to an optimal DFA)? The DFA for a single example is somewhat analyzed but a more detailed \"error\" analysis would strengthen the paper.\nGiven the use of grid worlds in this paper and previous works [21, 22] and the above concerns, the overall impact of the paper is somewhat unclear to me. (That said, I'm open to revising my score based on the feedback and other reviewers.)\nQuestions: \nWhat's the definition of \u03c6(\u03be)? (I'm assuming the same as [21].)\nWhat's the correctness / optimality of the final DFAs wrt to ground truth?\nAre there any non-grid-world applications or domains in which these methods can be evaluated?\nWhat's the computational complexity of DISS? How does it compare with the baselines?\nLimitations: Yes.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: Continuing the tradition of making the powerful goal modeling language LTL amendable to end-user usability, this paper gives an efficient approach to solve for LTL formulas (expressed using a DFA) from expert demonstrations. The crux of their algorithm is incorporating in the fact that the optimal planner is an maximum-entropy planner, using this knowledge to derive an algorithm more efficient than an enumerator agnostic to this fact.\nStrengths And Weaknesses: str\nThis paper shows a promising inference algorithm that is efficient in converting expert-demonstration trajectories into DFA specifications over an MDP environment. Most importantly, it does so by considering fewer numbers of DFAs than prior algorithms. The crux of their algorithm is incorporating in the fact that the optimal planner is an maximum-entropy planner, and leveraging this information to derive an algorithm that is more efficient than enumerating a DFA and using the maximum-entropy planner afterwards to check.\nweakness\nadditional baselines are required\nThis task can be formulated as a straight-forward program synthesis task, and one should seriously consider standard neural-symbolic approaches on it. \nHere are few suggestions:\n\nFor instance, in this simulated environment, one can easily generate paired data of the form (Env, DFA, Traj_from_max_ent_planner) and use supervised learning to learn a mapping from (Env,Traj_from_max_ent_planner)->DFA. One can use hugginface API on a pre-trained language model (gpt-neo) and fine tune it over some structured/textual representation of these abstract objects. Then at inference time simply use the top-k sampling to generate DFA from this fine-tuned language model, and see if it works\nYou can also develop a PCFG capable of generating DFA, then, using a learned neural network, predict the probability distributions of this PCFG, then sample top-k DFA from this grammar, and see if it works\n\nI wouldn't be surprised there will be some very strong patterns in the datapoints (Env, DFA, Traj_from_max_ent_planner) so that a learned neural model can pick it up, and can generate some fairly good (low energy) DFAs. And you won't even have to worry about having a train/test data split since the space of DFA (like you said) is very large, so the likelihood of encountering the same DFA from training to testing is unlikely.\nmotivation can be better\nSynthesizing a DFA in this manner is very different from synthesizing a DFA for (for instance) regular expression matching. The key difference lies in the evaluation of the DFA, whereas in regex synthesis it is trivial to check if it is consistent with a set of accept/reject input strings, to validate if a DFA is good for specifying a goal, we need to check whether a maximum-entropy planner would produce similar trajectories as the ones given by the expert. This is important and sets this task apart from many other program synthesis tasks, where checking the validity of a program is cheap.\nfew writing changes\nrunning example 1.1 is a good attempt (I'm happy to see ML papers are adopting more of a PL paper convention with a running example section), but is still confusing. I still do not know what is the DSL that governs the \"goal space\" of the robot. For instance, I can infer the robot's trajectory as simply \"reach the yellow square as soon as possible, but do so while using as many horizontal movements as vertical movements, while not changing directions too much\" <-- is this in the goal space? probably not, as DFA cannot do counting, but how would I know that? In general conter-factuals are easier to describe if the reader knows of the space of hypothesis beforehand. Instead example 1.1 did not explain what this space is, and the reader is lost. Figure 1 has no caption, and Figure 2 has no caption. I have to guess that figure 2 is in fact the solution that explains the behaviour of the robot, i.e. it cannot visit yellow directly after visiting blue, or it will be in the \"death\" state. A short sentence describe the overall hypothesis space, something like \"The goal space of the robot is formulated as a DFA, where edges denote traversing through multiple same-colored blocks (i.e. a blue means visiting multiple blues in succession)...\". . . Okay I just took a glance at reference [21], \"learning task specification from demonstrations\". They explained the problem so much better. The agent moved in the way it moved because it accidentally touched water (due to wind), so it has to dry itself (brown) before touching yellow (electricity), or else it'll be zapped. That is a wonderful story and made much more sense. I don't know why you took their example and removed the most reader-friendly affordance (fire, zap, water, drying) from it. Having to go read that [21] personally only to find out an easier explanation was already there is frustrating at best.\nQuestions: line53 : where is the light blue dotted path?\nLimitations: it is discussed well\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The authors introduce a method, Demonstration Informed Specification Search (DISS), for learning DFAs from examples. Their method consists of simulated annealing over DFAs and labeled examples simultaneously, with a very complex proposal distribution they call the \"surprise guided sampler\" (SGS) that involves among other things defining an analogue of \"gradient\" and incrementally conjecturing paths likely to be mislabeled by candidate DFAs. They compare against a SAT-based algorithm and a more random ablation of DISS on a toy synthetic grid-world domain and find their method performs best.\nStrengths And Weaknesses: The method introduced is very complicated and the toy results are extremely meager. This ratio is highly unfavorable. In general, the paper seems unmotivated. The paper is also highly symbolic and more generally does not seem relevant to the NeurIPS community.\nQuestions: Why is this an important problem? Also, could the kernel of the main SGS idea be demonstrated more clearly in a more abstract setting?\nLimitations: Yes\nEthics Flag: No\nSoundness: 2 fair\nPresentation: 1 poor\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 1: Your assessment is an educated guess. The submission is not in your area or the submission was difficult to understand. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The paper investigates the interesting problem of learning formal task specifications (i.e., a DFA) from (expert) demonstrations in a MDP. The main motivation is that symbolic structures (DFAs in this case) offer better properties (e.g., non-Markovian goals, goal composition, less sensitive to perturbations in the environment, etc.) compared to previous \"inverse control\" reward-based approaches like IRL. The main difficulty is the large search space of DFAs (even for the small toy example considered in the paper). The paper proposes the DISS (demonstration informed specification search) as an approximate solution to learning DFAs from demonstration. The key idea is to construct a structured search space over labeled examples and tasks. A knowledge-injected hill-climbing algorithm can operate efficiently in this search space to uncover the task that best \"explains\" the demonstrations. The key algorithmic contribution in DISS is the \"surprise-guided sampler\" which constructs labeled examples. Experiments are conducted on a gridworld and show the proposed method outperforming 2 baselines. \n\nUPDATE: I thank the authors for their detailed responses and being open to suggestions. I generally agree with Reviewer Y88L's comments, especially regarding the experimental aspects (baselines, user studies) and overall clarity of the paper. The authors have addressed most reviewer feedback, incorporated a number of reviewer comments into the paper and have included some more empirical data in the Appendix. I'm more positively inclined towards the paper although I think it remains difficult to assess impact with the current set of experiments. I've revised my score upwards to incorporate all the new information.",
                "Strengths And Weaknesses": "Strengths\n\nThe problem of learning formal representations of goals directly from expert trajectories (without reward functions) is challenging and important. The proposed approach seems to extend the state of the art in this area. The primary contribution of the paper is algorithmic with the introduction of the DISS algorithm for identifying specifications and the SGS component for selecting labeled examples.\nThe algorithmic ideas seem rigorously developed and novel (although I'm not sure I fully understood the details in Section 4.).\nExperiments show that the method does perform better than reasonably strong baselines (enumeration and mutation-based).\n\nWeaknesses\n\nI found the paper to be a bit hard to read (especially compared to the closely related work in [21], which was much clearer). This paper assumes or omits important definitions (e.g., \u03c6(\u03be), LSE). Combined with the large amount of new notation, interchangeable terminology (e.g., specification vs task) and typos, I found it challenging to grasp the key ideas on my first reading. Overall, I'd suggest this paper be edited to be more self-contained and clearer.\nThe experiments are somewhat limited. I was looking forward to a deeper analysis into the learned DFAs and in particular their correctness. For example, how \"close to optimal\" are the DFAs (compared to an optimal DFA)? The DFA for a single example is somewhat analyzed but a more detailed \"error\" analysis would strengthen the paper.\nGiven the use of grid worlds in this paper and previous works [21, 22] and the above concerns, the overall impact of the paper is somewhat unclear to me. (That said, I'm open to revising my score based on the feedback and other reviewers.)",
                "Questions": "What's the definition of \u03c6(\u03be)? (I'm assuming the same as [21].)\nWhat's the correctness / optimality of the final DFAs wrt to ground truth?\nAre there any non-grid-world applications or domains in which these methods can be evaluated?\nWhat's the computational complexity of DISS? How does it compare with the baselines?",
                "Limitations": "Yes.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "Continuing the tradition of making the powerful goal modeling language LTL amendable to end-user usability, this paper gives an efficient approach to solve for LTL formulas (expressed using a DFA) from expert demonstrations. The crux of their algorithm is incorporating in the fact that the optimal planner is an maximum-entropy planner, using this knowledge to derive an algorithm more efficient than an enumerator agnostic to this fact.",
                "Strengths And Weaknesses": "str\nThis paper shows a promising inference algorithm that is efficient in converting expert-demonstration trajectories into DFA specifications over an MDP environment. Most importantly, it does so by considering fewer numbers of DFAs than prior algorithms. The crux of their algorithm is incorporating in the fact that the optimal planner is an maximum-entropy planner, and leveraging this information to derive an algorithm that is more efficient than enumerating a DFA and using the maximum-entropy planner afterwards to check.\nweakness\nadditional baselines are required\nThis task can be formulated as a straight-forward program synthesis task, and one should seriously consider standard neural-symbolic approaches on it. \nHere are few suggestions:\n\nFor instance, in this simulated environment, one can easily generate paired data of the form (Env, DFA, Traj_from_max_ent_planner) and use supervised learning to learn a mapping from (Env,Traj_from_max_ent_planner)->DFA. One can use hugginface API on a pre-trained language model (gpt-neo) and fine tune it over some structured/textual representation of these abstract objects. Then at inference time simply use the top-k sampling to generate DFA from this fine-tuned language model, and see if it works\nYou can also develop a PCFG capable of generating DFA, then, using a learned neural network, predict the probability distributions of this PCFG, then sample top-k DFA from this grammar, and see if it works\n\nI wouldn't be surprised there will be some very strong patterns in the datapoints (Env, DFA, Traj_from_max_ent_planner) so that a learned neural model can pick it up, and can generate some fairly good (low energy) DFAs. And you won't even have to worry about having a train/test data split since the space of DFA (like you said) is very large, so the likelihood of encountering the same DFA from training to testing is unlikely.\nmotivation can be better\nSynthesizing a DFA in this manner is very different from synthesizing a DFA for (for instance) regular expression matching. The key difference lies in the evaluation of the DFA, whereas in regex synthesis it is trivial to check if it is consistent with a set of accept/reject input strings, to validate if a DFA is good for specifying a goal, we need to check whether a maximum-entropy planner would produce similar trajectories as the ones given by the expert. This is important and sets this task apart from many other program synthesis tasks, where checking the validity of a program is cheap.\nfew writing changes\nrunning example 1.1 is a good attempt (I'm happy to see ML papers are adopting more of a PL paper convention with a running example section), but is still confusing. I still do not know what is the DSL that governs the \"goal space\" of the robot. For instance, I can infer the robot's trajectory as simply \"reach the yellow square as soon as possible, but do so while using as many horizontal movements as vertical movements, while not changing directions too much\" <-- is this in the goal space? probably not, as DFA cannot do counting, but how would I know that? In general conter-factuals are easier to describe if the reader knows of the space of hypothesis beforehand. Instead example 1.1 did not explain what this space is, and the reader is lost. Figure 1 has no caption, and Figure 2 has no caption. I have to guess that figure 2 is in fact the solution that explains the behaviour of the robot, i.e. it cannot visit yellow directly after visiting blue, or it will be in the \"death\" state. A short sentence describe the overall hypothesis space, something like \"The goal space of the robot is formulated as a DFA, where edges denote traversing through multiple same-colored blocks (i.e. a blue means visiting multiple blues in succession)...\". . . Okay I just took a glance at reference [21], \"learning task specification from demonstrations\". They explained the problem so much better. The agent moved in the way it moved because it accidentally touched water (due to wind), so it has to dry itself (brown) before touching yellow (electricity), or else it'll be zapped. That is a wonderful story and made much more sense. I don't know why you took their example and removed the most reader-friendly affordance (fire, zap, water, drying) from it. Having to go read that [21] personally only to find out an easier explanation was already there is frustrating at best.",
                "Questions": "line53 : where is the light blue dotted path?",
                "Limitations": "it is discussed well",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The authors introduce a method, Demonstration Informed Specification Search (DISS), for learning DFAs from examples. Their method consists of simulated annealing over DFAs and labeled examples simultaneously, with a very complex proposal distribution they call the \"surprise guided sampler\" (SGS) that involves among other things defining an analogue of \"gradient\" and incrementally conjecturing paths likely to be mislabeled by candidate DFAs. They compare against a SAT-based algorithm and a more random ablation of DISS on a toy synthetic grid-world domain and find their method performs best.",
                "Strengths And Weaknesses": "The method introduced is very complicated and the toy results are extremely meager. This ratio is highly unfavorable. In general, the paper seems unmotivated. The paper is also highly symbolic and more generally does not seem relevant to the NeurIPS community.",
                "Questions": "Why is this an important problem? Also, could the kernel of the main SGS idea be demonstrated more clearly in a more abstract setting?",
                "Limitations": "Yes",
                "Ethics Flag": "No",
                "Soundness": "2 fair",
                "Presentation": "1 poor",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "1: Your assessment is an educated guess. The submission is not in your area or the submission was difficult to understand. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.0,
        "confidence_avg": 2.333,
        "soundness_avg": 2.667,
        "presentation_avg": 1.667,
        "contribution_avg": 2.667,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the paper proposes a novel and technically solid approach for learning formal task specifications from expert demonstrations. The DISS algorithm, along with the surprise-guided sampler, is a significant contribution to the field. The experiments demonstrate that the proposed method outperforms baselines and shows promise in solving the problem.\n\nWhile there are some weaknesses pointed out by the reviewers, such as the clarity of the paper and the limited experiments, these concerns can be addressed through revisions and further analysis. The authors have shown openness to feedback and have already made improvements based on reviewer comments.\n\nOverall, considering the positive aspects of the paper, its technical contributions, and the potential impact in the field, I recommend accepting the paper."
    },
    "Explainable_Spatio-Temporal_Forecasting_with_Shape_Functions": {
        "link": "https://openreview.net//forum?id=fARM4P0gAJV",
        "pub_url": "https://openreview.net/forum?id=fARM4P0gAJV",
        "pdf_link": "https://openreview.net//pdf?id=fARM4P0gAJV",
        "paper_id": "fARM4P0gAJV",
        "title": "Explainable_Spatio-Temporal_Forecasting_with_Shape_Functions",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nThe paper proposes to use shape functions as basis functions to characterize spatial dependencies. They incorporate the shape functions into the spatial regression model and demonstrate strong forecasting performances compared to graph convolution-based methods. While the techniques are interesting, it is not directly relevant to the ICLR (deep learning) community. The argument for explainability is also subjective and less convincing.",
        "reviews": [
            "Reviewer 1: \nSummary: In this paper, the authors propose an interpretable spatio-temporal forecasting method by learning shape functions from data. The shape function is designed as a function of the distance between pairwise locations, which is then used to represent the vector autoregressive model coefficients. As a result, the proposed model can incorporate both spatial and temporal information. Furthermore, the interactions between different locations can be interpreted by the shape function outputs, and a graph can be used to visualize the interactions. Finally, the proposed method also achieves promising forecasting performance compared to deep learning methods.\nStrengths And Weaknesses: Strength:\nThe work is well motivated by the challenge in spatio-temporal forecasting, i.e., the tradeoff between accuracy and interpretability. The proposed method uses shape functions to constrain the statistical relations between different locations and achieves good forecasting performance. Overall, I think the paper makes a good contribution to spatio-temporal forecasting.\nThe explanation of relations to previous works is clear. The proposed method is an extension of traditional methods by replacing the predefined spatial functions with learnable shape functions. The proposed method enjoys good forecasting accuracy as deep learning methods, while maintaining the interpretability of traditional methods.\nWeakness:\nThe main assumption of this paper is the correlation between two locations decreasing with distance. While this assumption may make sense in some applications, it would be better to give some discussions or case studies of this assumption.\nIn the nonstationary setting, the model in Eq (2) has a different weight matrix for each time step. It seems to be that this design suffers from the small sample problem, as the data at each time step is limited. This would cause fluctuations in the estimations across time. \nIn section 3.4, the authors give examples of monotonically increasing/deceasing functions. However, in the experiments, only monotonically decreasing functions are investigated. If increasing functions are not going to be used in the forecast model, it might be better not to mention it the method section.\nQuestions: Questions:\nIn Eq (1), the authors only consider time lagged correlations. Is it possible to incorporate instantaneous relations at the same time step? The reason why I ask this question is because there might exist instantaneous relations in some applications.\nWhat is the motivation behind the choice of specifications in section 3.2? Are the authors trying to mimic some properties in the classical statistical methods?\nLimitations: The authors addressed the limitations.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This manuscript focuses on the patio-temporal forecasting problem and proposes a new method with shape functions toward a learnable and explainable model. The proposed method extends the statistical models via learnable bash shape functions, making it possible to capture the spatial variability and distance-based effects over distance. The proposed method is evaluated on both real and synthetic datasets.\nStrengths And Weaknesses: Pros:\n\nThe idea of modeling the spatial weight matrix with learnable shape functions is novel and interesting. It generalizes the traditional statistical method by introducing more learnable components.\n\nExperimental results on both synthetic and real datasets indeed show the effectiveness of the proposed method. It even performs better or is comparable with respect to some DNN-based methods under some scenarios.\n\n\nCons:\n\nThe proposed method is only evaluated on a single real-world dataset, making it hard to figure out if the method can consistently work well under real setups.\n\nThe authors provide several specifications of the relations between the distance and the weights. However, the authors did not discuss the advantage or disadvantages of each specification. On a given dataset, how should we choose among them?\n\nAccording to section 3.4, the basis function for the shape constraints is simple. There is no discussion about some more complex functions and their influences on the performances.\n\n\nMinor issues:\n\n\"modelling\" should be \"modeling\"\n\nThe citation format is a little strange with semicolons and parentheses, it is better to reformat them.\n\nFor better visualization, it is highly recommended to adopt vector graphics for all figures.\nQuestions: \nIt would be interesting to add more discussion about complex shape functions.\n\nFor the evaluation, it is also suggested to add the inference time beyond the training time, which is more important in real scenarios.\nLimitations: Yes\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 3 good\nRating: 7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: The paper proposes a spatio-temporal prediction model that tries to incorporate a varying strength of spatial dependency over distance. The idea is to model spatial dependency weights as a shape constraint. There are some empirical evaluations on simulation datasets and real-world datasets.\nStrengths And Weaknesses: Strength:\n\nThe paper solves an important problem, i.e., training explainable spatio-temporal forecasting model that can automatically learn the dependency structure.\n\nThe paper is overall well-written and easily understandable.\n\n\nWeakness:\n\nAlthough the problem of learning spatio-temporal dependency structure is interesting, the proposed solution is not well-justified. The proposed method explicitly models spatial dependency as a function of distance. But the similar philosophy has already been explored in spatial statistics, such as the Gaussian process (it represents the covariance matrix of different sample locations based on distance between those locations). \n\nThe proposed model seems limited in model representation with a linear function. Currently, it is not convincing that such models can achieve better performance than recent deep learning models.\nQuestions: \nThe Gaussian process model is geostatistics also captures the effect of weakening spatial dependency with increasing distance. How does the proposed idea compare with the Gaussian process strategy? \n\nThe proposed idea is under the category of traditional machine learning methods. It is suspicious that the proposed model can outperform deep learning models in prediction accuracy. How do you explain the results in Table 1?\nLimitations: The paper does have some interesting discussions on the limitations of the proposed idea, e.g., not capturing the non-Euclidean space like spatial networks, and the lack of causal interpretations.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "In this paper, the authors propose an interpretable spatio-temporal forecasting method by learning shape functions from data. The shape function is designed as a function of the distance between pairwise locations, which is then used to represent the vector autoregressive model coefficients. As a result, the proposed model can incorporate both spatial and temporal information. Furthermore, the interactions between different locations can be interpreted by the shape function outputs, and a graph can be used to visualize the interactions. Finally, the proposed method also achieves promising forecasting performance compared to deep learning methods.",
                "Strengths And Weaknesses": "Strength:\nThe work is well motivated by the challenge in spatio-temporal forecasting, i.e., the tradeoff between accuracy and interpretability. The proposed method uses shape functions to constrain the statistical relations between different locations and achieves good forecasting performance. Overall, I think the paper makes a good contribution to spatio-temporal forecasting.\nThe explanation of relations to previous works is clear. The proposed method is an extension of traditional methods by replacing the predefined spatial functions with learnable shape functions. The proposed method enjoys good forecasting accuracy as deep learning methods, while maintaining the interpretability of traditional methods.\nWeakness:\nThe main assumption of this paper is the correlation between two locations decreasing with distance. While this assumption may make sense in some applications, it would be better to give some discussions or case studies of this assumption.\nIn the nonstationary setting, the model in Eq (2) has a different weight matrix for each time step. It seems to be that this design suffers from the small sample problem, as the data at each time step is limited. This would cause fluctuations in the estimations across time. \nIn section 3.4, the authors give examples of monotonically increasing/deceasing functions. However, in the experiments, only monotonically decreasing functions are investigated. If increasing functions are not going to be used in the forecast model, it might be better not to mention it the method section.",
                "Questions": "Questions:\nIn Eq (1), the authors only consider time lagged correlations. Is it possible to incorporate instantaneous relations at the same time step? The reason why I ask this question is because there might exist instantaneous relations in some applications.\nWhat is the motivation behind the choice of specifications in section 3.2? Are the authors trying to mimic some properties in the classical statistical methods?",
                "Limitations": "The authors addressed the limitations.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This manuscript focuses on the patio-temporal forecasting problem and proposes a new method with shape functions toward a learnable and explainable model. The proposed method extends the statistical models via learnable bash shape functions, making it possible to capture the spatial variability and distance-based effects over distance. The proposed method is evaluated on both real and synthetic datasets.",
                "Strengths And Weaknesses": "Pros:\n\nThe idea of modeling the spatial weight matrix with learnable shape functions is novel and interesting. It generalizes the traditional statistical method by introducing more learnable components.\n\nExperimental results on both synthetic and real datasets indeed show the effectiveness of the proposed method. It even performs better or is comparable with respect to some DNN-based methods under some scenarios.\n\n\nCons:\n\nThe proposed method is only evaluated on a single real-world dataset, making it hard to figure out if the method can consistently work well under real setups.\n\nThe authors provide several specifications of the relations between the distance and the weights. However, the authors did not discuss the advantage or disadvantages of each specification. On a given dataset, how should we choose among them?\n\nAccording to section 3.4, the basis function for the shape constraints is simple. There is no discussion about some more complex functions and their influences on the performances.\n\n\nMinor issues:\n\n\"modelling\" should be \"modeling\"\n\nThe citation format is a little strange with semicolons and parentheses, it is better to reformat them.\n\nFor better visualization, it is highly recommended to adopt vector graphics for all figures.",
                "Questions": "It would be interesting to add more discussion about complex shape functions.\n\nFor the evaluation, it is also suggested to add the inference time beyond the training time, which is more important in real scenarios.",
                "Limitations": "Yes",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "3 good",
                "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "The paper proposes a spatio-temporal prediction model that tries to incorporate a varying strength of spatial dependency over distance. The idea is to model spatial dependency weights as a shape constraint. There are some empirical evaluations on simulation datasets and real-world datasets.",
                "Strengths And Weaknesses": "Strength:\n\nThe paper solves an important problem, i.e., training explainable spatio-temporal forecasting model that can automatically learn the dependency structure.\n\nThe paper is overall well-written and easily understandable.\n\n\nWeakness:\n\nAlthough the problem of learning spatio-temporal dependency structure is interesting, the proposed solution is not well-justified. The proposed method explicitly models spatial dependency as a function of distance. But the similar philosophy has already been explored in spatial statistics, such as the Gaussian process (it represents the covariance matrix of different sample locations based on distance between those locations). \n\nThe proposed model seems limited in model representation with a linear function. Currently, it is not convincing that such models can achieve better performance than recent deep learning models.",
                "Questions": "The Gaussian process model is geostatistics also captures the effect of weakening spatial dependency with increasing distance. How does the proposed idea compare with the Gaussian process strategy? \n\nThe proposed idea is under the category of traditional machine learning methods. It is suspicious that the proposed model can outperform deep learning models in prediction accuracy. How do you explain the results in Table 1?",
                "Limitations": "The paper does have some interesting discussions on the limitations of the proposed idea, e.g., not capturing the non-Euclidean space like spatial networks, and the lack of causal interpretations.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 5.667,
        "confidence_avg": 3.667,
        "soundness_avg": 3.0,
        "presentation_avg": 3.0,
        "contribution_avg": 2.667,
        "ai_sum_meta": "Recommendation: Accept\nConfidence: Certain\nMeta Review: \n\nBased on the reviews from the other reviewers, it is clear that the proposed method makes a good contribution to spatio-temporal forecasting by addressing the tradeoff between accuracy and interpretability. The use of shape functions to represent the vector autoregressive model coefficients allows for the incorporation of both spatial and temporal information, while maintaining interpretability. The experimental results show promising forecasting performance compared to deep learning methods.\n\nWhile there are some weaknesses pointed out by the reviewers, such as the assumption of correlation decreasing with distance and the limited evaluation on real-world datasets, these limitations have been acknowledged by the authors and do not outweigh the strengths of the proposed method.\n\nReviewer 3 raises a concern about the similarity between the proposed method and Gaussian process models in spatial statistics. However, the authors have not claimed that their method is superior to Gaussian process models, and it is possible that the proposed method offers a different approach to capturing spatial dependency.\n\nOverall, the strengths of the proposed method, its contribution to the field, and the positive evaluation results outweigh the weaknesses and limitations. Therefore, I recommend accepting this paper for publication."
    },
    "Embedding_game:_dimensionality_reduction_as_a_two-person_zero-sum_game": {
        "link": "https://openreview.net//forum?id=8uiblU3fEjE",
        "pub_url": "https://openreview.net/forum?id=8uiblU3fEjE",
        "pdf_link": "https://openreview.net//pdf?id=8uiblU3fEjE",
        "paper_id": "8uiblU3fEjE",
        "title": "Embedding_game:_dimensionality_reduction_as_a_two-person_zero-sum_game",
        "is_accepted": false,
        "meta_review": "Recommendation: Reject\nConfidence: Certain\nWhile the reviewers agreed that the paper addresses an important topic, and combining optimization with game theory is interesting, the reviewers had a number of concerns regarding the validity of the proposed formulation of the problem, lack of theoretical justification for using GDA, strong assumptions, lack of complexity analysis, and limited empirical evaluations. Unfortunately, those concerns were not fully addressed by the author response.",
        "reviews": [
            "Reviewer 1: \nSummary: The paper addresses the problem of dimension reduction for visualization. It proposes a minimax objective for this problem with game theoretical interpretation. It also proposes a gradient descent-ascent (GDA)-like algorithm to solve this objective that uses non-randomly selected landmarks. They provide empirical results from running their method on the MNIST, scRNA and 25K Reddit Posts datasets.\nStrengths And Weaknesses: Strengths\n\nThe paper addresses an important topic: dimension reduction for visualization.\nThe paper is clearly written with only minor notation issues.\nThe approach of combining optimization and game theory is interesting.\nWeaknesses\nSome questions remain on the validity of the proposed formulation of the problem and objective (Equations 3 and E in equations 4 and 5).\nMore details needed for their proposed method (Algorithm 1).\nQuestions: Questions on the objective/ formulation.\n\nEquation 3 is obtained by dividing Equation 2 by \u2211a,b, maximizing over z and then plugging the inequality back into Equation 1. But this means that Equation 3 is a lower bound for Equation 1. Does it make sense then to minimize Equation 3 as a proxy for minimizing Equation 1?\nThe section on Duality (lines 147 to 154) is confusing in light of Equation 3. The paper says that there is duality gap in the optimization problem in Equation 3 that means that the ordering of optimization matters. From the von Neumann minimax theory, does this suggest that Equation 3 is not a two-player zero-sum game as stated?\n\nQuestions on Algorithm 1.\n\nLine 143 says that the optimization problem is nonconvex-nonconcave. Therefore, is it suitable to use GDA as a basis for Algorithm 1 when GDA is known to converge to limit cycles or diverge in this setting? The paper cites Lin et al. (2019) On Gradient Descent Ascent (GDA) for Nonconvex-Concave Minimax Problems which points specifically to this issue. They also mention that it is difficult to set the learning rate so that the algorithm finds a solution. Given these issues, are there other algorithms that could be used instead of GDA?\nGiven the importance of setting the learning rate(s) for Algorithm 1, it could be useful to have this issue addressed in more detail. Lines 118-121 conclude that decreasing the learning rate improves the resulting visualization. It is generally the case, however, that using a smaller stepsize improves accuracy while increasing the iteration complexity of a method. Could the authors provide details such as maximum stepsize allowed for Algorithm 1 not to diverge? In Section 4, it is also unclear what is meant by setting \"the landmark learning rate to be relatively fast compared to the embedding learning rate\". Could the authors provide details on the relative size of the two learning rates?\nThe paper could be strengthened with more details on the efficiency of the method. For example, could the authors provide theoretical analysis to show the rate of convergence of their algorithm (i.e. a bound on n_iter in Algorithm 1)? In terms of empirical results, there could be more clarity given too. For example, it is unclear where the plots in Figure 6 came from (e.g. which dataset(s), the learning rate used, etc). Could this be clarified? Could the authors provide similar plots as in Figure 6 but with clock time taken in the x-axes? This is especially useful as the paper argues that one advantage of Algorithm 1 over KMeans is that it provides the landmarks as part of the process. Yet, like running KMeans, there is a cost associated with finding these non-random landmarks too.\n\nIs the code used for the experiments available publicly?\nLimitations: This work does not appear to me to have negative social impact.\nEthics Flag: No\nSoundness: 1 poor\nPresentation: 3 good\nContribution: 2 fair\nRating: 3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n",
            "Reviewer 2: \nSummary: This paper proposes a min-max optimization-based dimension reduction technique that approximates the sum O(N^2) using fewer landmarks. They derived a landmark-based lower bound for the repulsion term and then tried to maximize that to approximate the objective. They showed that their optimization requires much fewer landmarks than taking randomly designated points as landmarks.\nStrengths And Weaknesses: Weakness:\n\nThe authors have some strong assumptions for their derivations, whereas they did not explicitly mention when would their method fail.\nThere was no analysis of time complexity for their algorithm.\nTheir empirical evaluation, in many cases suggests that sampled edges are better. More empirical evaluation is required.\nQuestions: \nCould you explicitly elaborate in your paper on why the landmark-based approach should be taken?\nHave done any exploration on improving the min-max optimization technique for this setup?\nThere is no mention of sample complexity. Do you have any suggestions on what size of L to use based on other factors like, the number of data points, initial dimension size, etc? If yes, please mention them in the paper.\nLimitations: Same as the weakness points.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 2 fair\nContribution: 2 fair\nRating: 2: Strong Reject: For instance, a paper with major technical flaws, and/or poor evaluation, limited impact, poor reproducibility and mostly unaddressed ethical considerations.\nConfidence: 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct: Yes\n\n",
            "Reviewer 3: \nSummary: \nThis paper presents a new approximation approach for dimensionality reduction formulation.\nTraditional dimensionality reduction is formulated as minimization of sum of attractive interaction and sum of repulsive interaction between embedding vectors. The proposed approach approximates the repulsive sum with maximizing the landmark-based lower bound w.r.t. landmarks to make it a minimax problem\nThe proposed approach is optimized by a gradient descent ascent approach. And the selection of the hyperparameters are discussed. Experimental results showed the proposed approximation gives high quality clustering.\nStrengths And Weaknesses: Strengths\n\nClever formulation of the approximation in section 2\nClear interpretation of the math formulation, i.e. the embedding vectors run towards their neighbors and away from the landmarks....\nClear visualization to show the clustering quality\n\nWeakness\n\nQuantitative results are not impressive, proposed method performs worse than sampled-edge algorithms when sampling size is the same. the proposed approach needs more computation to achieve comparable results.\nThe discussion of the learning rate selection is not sufficient, neither with a mathematical analysis nor a more comprehensive combination (current work fix \\eta_y, any other options?)\nQuestions: \nDo you have any mathematical analysis of the learning rate selection besides the experiments?\nBesides fixed iteration, maybe use energy difference as the termination condition of the loop?\nFor Figure 6, energy of sampled edges are almost identical for e_optimized and e_allpairs which indicates sampled_edges has a better approximation than embedding_game. Why do you need RMS(gradients) other than RMS(energy) to tell the approximation quality?\nLimitations: Authors did mentioned the limitations and looking forward to seeing the approach to be applied to dimensionality increase problem.\nEthics Flag: No\nSoundness: 3 good\nPresentation: 3 good\nContribution: 2 fair\nRating: 4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\nConfidence: 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct: Yes\n\n"
        ],
        "reviews_parsed": [
            {
                "Summary": "The paper addresses the problem of dimension reduction for visualization. It proposes a minimax objective for this problem with game theoretical interpretation. It also proposes a gradient descent-ascent (GDA)-like algorithm to solve this objective that uses non-randomly selected landmarks. They provide empirical results from running their method on the MNIST, scRNA and 25K Reddit Posts datasets.",
                "Strengths And Weaknesses": "Strengths\n\nThe paper addresses an important topic: dimension reduction for visualization.\nThe paper is clearly written with only minor notation issues.\nThe approach of combining optimization and game theory is interesting.\nWeaknesses\nSome questions remain on the validity of the proposed formulation of the problem and objective (Equations 3 and E in equations 4 and 5).\nMore details needed for their proposed method (Algorithm 1).",
                "Questions": "Questions on the objective/ formulation.\n\nEquation 3 is obtained by dividing Equation 2 by \u2211a,b, maximizing over z and then plugging the inequality back into Equation 1. But this means that Equation 3 is a lower bound for Equation 1. Does it make sense then to minimize Equation 3 as a proxy for minimizing Equation 1?\nThe section on Duality (lines 147 to 154) is confusing in light of Equation 3. The paper says that there is duality gap in the optimization problem in Equation 3 that means that the ordering of optimization matters. From the von Neumann minimax theory, does this suggest that Equation 3 is not a two-player zero-sum game as stated?\n\nQuestions on Algorithm 1.\n\nLine 143 says that the optimization problem is nonconvex-nonconcave. Therefore, is it suitable to use GDA as a basis for Algorithm 1 when GDA is known to converge to limit cycles or diverge in this setting? The paper cites Lin et al. (2019) On Gradient Descent Ascent (GDA) for Nonconvex-Concave Minimax Problems which points specifically to this issue. They also mention that it is difficult to set the learning rate so that the algorithm finds a solution. Given these issues, are there other algorithms that could be used instead of GDA?\nGiven the importance of setting the learning rate(s) for Algorithm 1, it could be useful to have this issue addressed in more detail. Lines 118-121 conclude that decreasing the learning rate improves the resulting visualization. It is generally the case, however, that using a smaller stepsize improves accuracy while increasing the iteration complexity of a method. Could the authors provide details such as maximum stepsize allowed for Algorithm 1 not to diverge? In Section 4, it is also unclear what is meant by setting \"the landmark learning rate to be relatively fast compared to the embedding learning rate\". Could the authors provide details on the relative size of the two learning rates?\nThe paper could be strengthened with more details on the efficiency of the method. For example, could the authors provide theoretical analysis to show the rate of convergence of their algorithm (i.e. a bound on n_iter in Algorithm 1)? In terms of empirical results, there could be more clarity given too. For example, it is unclear where the plots in Figure 6 came from (e.g. which dataset(s), the learning rate used, etc). Could this be clarified? Could the authors provide similar plots as in Figure 6 but with clock time taken in the x-axes? This is especially useful as the paper argues that one advantage of Algorithm 1 over KMeans is that it provides the landmarks as part of the process. Yet, like running KMeans, there is a cost associated with finding these non-random landmarks too.\n\nIs the code used for the experiments available publicly?",
                "Limitations": "This work does not appear to me to have negative social impact.",
                "Ethics Flag": "No",
                "Soundness": "1 poor",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper proposes a min-max optimization-based dimension reduction technique that approximates the sum O(N^2) using fewer landmarks. They derived a landmark-based lower bound for the repulsion term and then tried to maximize that to approximate the objective. They showed that their optimization requires much fewer landmarks than taking randomly designated points as landmarks.",
                "Strengths And Weaknesses": "Weakness:\n\nThe authors have some strong assumptions for their derivations, whereas they did not explicitly mention when would their method fail.\nThere was no analysis of time complexity for their algorithm.\nTheir empirical evaluation, in many cases suggests that sampled edges are better. More empirical evaluation is required.",
                "Questions": "Could you explicitly elaborate in your paper on why the landmark-based approach should be taken?\nHave done any exploration on improving the min-max optimization technique for this setup?\nThere is no mention of sample complexity. Do you have any suggestions on what size of L to use based on other factors like, the number of data points, initial dimension size, etc? If yes, please mention them in the paper.",
                "Limitations": "Same as the weakness points.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "2 fair",
                "Contribution": "2 fair",
                "Rating": "2: Strong Reject: For instance, a paper with major technical flaws, and/or poor evaluation, limited impact, poor reproducibility and mostly unaddressed ethical considerations.",
                "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                "Code Of Conduct": "Yes"
            },
            {
                "Summary": "This paper presents a new approximation approach for dimensionality reduction formulation.\nTraditional dimensionality reduction is formulated as minimization of sum of attractive interaction and sum of repulsive interaction between embedding vectors. The proposed approach approximates the repulsive sum with maximizing the landmark-based lower bound w.r.t. landmarks to make it a minimax problem\nThe proposed approach is optimized by a gradient descent ascent approach. And the selection of the hyperparameters are discussed. Experimental results showed the proposed approximation gives high quality clustering.",
                "Strengths And Weaknesses": "Strengths\n\nClever formulation of the approximation in section 2\nClear interpretation of the math formulation, i.e. the embedding vectors run towards their neighbors and away from the landmarks....\nClear visualization to show the clustering quality\n\nWeakness\n\nQuantitative results are not impressive, proposed method performs worse than sampled-edge algorithms when sampling size is the same. the proposed approach needs more computation to achieve comparable results.\nThe discussion of the learning rate selection is not sufficient, neither with a mathematical analysis nor a more comprehensive combination (current work fix \\eta_y, any other options?)",
                "Questions": "Do you have any mathematical analysis of the learning rate selection besides the experiments?\nBesides fixed iteration, maybe use energy difference as the termination condition of the loop?\nFor Figure 6, energy of sampled edges are almost identical for e_optimized and e_allpairs which indicates sampled_edges has a better approximation than embedding_game. Why do you need RMS(gradients) other than RMS(energy) to tell the approximation quality?",
                "Limitations": "Authors did mentioned the limitations and looking forward to seeing the approach to be applied to dimensionality increase problem.",
                "Ethics Flag": "No",
                "Soundness": "3 good",
                "Presentation": "3 good",
                "Contribution": "2 fair",
                "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.",
                "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                "Code Of Conduct": "Yes"
            }
        ],
        "rating_avg": 3.0,
        "confidence_avg": 3.667,
        "soundness_avg": 2.333,
        "presentation_avg": 2.667,
        "contribution_avg": 2.0,
        "ai_sum_meta": "Recommendation: Reject\nConfidence: Certain\nMeta Review: Based on the reviews from other reviewers, it is clear that there are several weaknesses and limitations in the paper. The proposed formulation of the problem and objective raise questions about their validity. The lack of details in the proposed method and algorithm also raises concerns about its suitability and efficiency. The empirical evaluation shows that the proposed method performs worse than sampled-edge algorithms in terms of quantitative results. The discussion on learning rate selection is insufficient and lacks mathematical analysis. Overall, the paper has major technical flaws, weak evaluation, and limited impact. Therefore, I recommend rejecting the paper."
    }
}